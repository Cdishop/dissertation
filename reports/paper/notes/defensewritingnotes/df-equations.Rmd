---
title: "math"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The logic underlying the Dickey-Fuller test is as follows. Consider a simple stochastic trajectory: $y_{t} = \rho y_{t-1} + e_{t}$, where $y_t$ is the value of series at the current time, $y_{t-1}$ is the value of the series one step prior, and $e_{t}$ is an error term with mean zero and constant variance $\sigma^2_e$. The goal is to assess whether this trajectory contains a unit root, which would occur if $\rho = 1$. The insight discovered by Dickey and Fuller was that such a series could be rearranged and then subjected to familiar hypothesis-testing frameworks more readily understood by statisticians and other scientists. Various statistics within the null hypothesis framework were well-developed by the 1970s. The trick was to find a way to make time-series unit-root testing amenable to those procedures. Here is how. After subtracting $y_{t-1}$ from both sides, the trajectory above can be written as $y_{t} - y_{t - 1} = \rho y_{t-1} - y_{t-1} + e_{t}$. I now have an equation that is commonly known as a first differenced series, referring to the fact that I subtracted a lag-one term from the left and right-hand sides of the equation. The first differenced series can be reduced by recognizing that $\rho y_{t-1} - y_{t-1}$ contains two $y_{t-1}$ terms, which means that it can be written more succintly as $(\rho - 1) y_{t-1}$. The full equation then becomes $\Delta y_{t} = (\rho - 1) y_{t-1} + e_{t}$. Now, a test of $\rho = 1$ is a simple $t$-test of whether the parameter on the “lagged level” of $y$ is equal to zero. Moreover, the term $(\rho - 1)$ can be treated as an estimated coefficient of $y_{t-1}$ and so the equation becomes $\Delta y_{t} = \delta y_{t-1} + e_{t}$. If $\delta$ is equal to 0, then $\rho$ must equal 1 since $\delta = (\rho - 1)$.

Dickey and Fuller (1979) used Monte Carlo techniques to compute critical values for the lag-one process above. They later developed an augmented test to accommodate unknown orders and lags in the data-generating process. Although the DF procedure can conceptually be thought of as a $t$-test, the estimated values assessing $\delta = 0$ (i.e., testing for a random walk with the null hypothesis of a unit root) do not have an asymptotic normal distribution. For this reason, Dickey and Fuller computed a unique sampling distribution for the test statistics underlying the unit root assessment. MacKinnon (1991, 2010) showed how to calculate its $p$-values for arbitrary sample sizes. Critical values are now automatically implemented in statistical software and programs, and they are also listed in many introductory econometric textbooks.

With a process equation ($\Delta y_{t} = \delta y_{t-1} + e_{t}$) and null hypothesis in mind ($\delta = 0$), the last step is to evaluate the hypothesis. Ordinary-least-squares regression is used to estimate delta, and the coefficient is divided by its standard error to find what is known as the tau statistic ($\tau$). Tau is then compared to the critical values under the unique sampling distribution computed by Dickey and Fuller (and developed further by MacKinnon). If $\tau$ in absolute value exceeds the MacKinnon critical values, then the hypothesis that $\delta = 0$ is rejected. If tau is smaller in absolute value than the MacKinnon critical values, conversely, then the null hypothesis (unit root) is retained. 
